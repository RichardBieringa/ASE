{"acm":[{"url":"https://dl.acm.org/doi/10.5555/3370272.3370337","title":"research-article ","type":"Kubernetes security and access management: a workshop exploring security & access features in Kubernetes","venue":"CASCON '19: Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering","authors":["Chris Felix","Hitesh Garg","Serjik Dikaleh"],"abstract":"In this workshop, attendees were introduced to various Kubernetes (k8s) cluster security considerations. During the workshop, cluster administrator as well as development team personas were presented in a progressive fashion by using a sample application scenario. Instructors used a free IBM Cloud Kubernetes Service (IKS) (https://www.ibm.com/cloud/container-service/pricing) cluster for demos, but students could follow along on their own laptops with any Kubernetes environment. After the workshop, students should have a good understanding of how Role Based Access Control (RBAC), resource quotas, pod security policies, namespaces, network policies and image creation and scanning policies work together to achieve a safer environment for running shared services.","publicationDate":"2019-11-03T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3299869.3320229","title":"research-article ","type":"Pivotal Greenplum© for Kubernetes: Demonstration of Managing Greenplum Database on Kubernetes","venue":"SIGMOD '19: Proceedings of the 2019 International Conference on Management of Data","authors":["Jemish Patel","Goutam Tadi","Oz Basarir","Lawrence Hamel","David Sharp","Fei Yang","Xin Zhang"],"abstract":"Greenplum Database (GPDB) has many features designed to enable data scientists. Before a data scientist can use GPDB, a database administrator (DBA) must provision a cluster and install any required data science packages. Provisioning a GPDB cluster on bare metal requires a lengthy setup process. Scaling, recovering, and securing the cluster post-deployment are also complex. Greenplum for Kubernetes (GP4K) abstracts away these complexities, simplifying and automating the process for users. In this demonstration, we introduce GP4K with an opinionated deployment and a declarative manifest. We provide a brief overview of GP4K's architecture and discuss its implementation. We also demonstrate a full life cycle of managing a cluster from birth to retirement, including scale-up and self-healing all with minimal DBA inputs.","publicationDate":"2019-06-24T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3434770.3459730","title":"research-article ","type":"Rearchitecting Kubernetes for the Edge","venue":"EdgeSys '21: Proceedings of the 4th International Workshop on Edge Systems, Analytics and Networking","authors":["Andrew Jeffery","Heidi Howard","Richard Mortier"],"abstract":"Recent years have seen Kubernetes emerge as a primary choice for container orchestration. Kubernetes largely targets the cloud environment but new use cases require performant, available and scalable orchestration at the edge. Kubernetes stores all cluster state in etcd, a strongly consistent key-value store. We find that at larger etcd cluster sizes, offering higher availability, write request latency significantly increases and throughput decreases similarly. Coupled with approximately 30% of Kubernetes requests being writes, this directly impacts the request latency and availability of Kubernetes, reducing its suitability for the edge. We revisit the requirement of strong consistency and propose an eventually consistent approach instead. This enables higher performance, availability and scalability whilst still supporting the broad needs of Kubernetes. This aims to make Kubernetes much more suitable for performance-critical, dynamically-scaled edge solutions.","publicationDate":"2021-04-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3341325.3341995","title":"research-article ","type":"Cloud Computing With Kubernetes Cluster Elastic Scaling","venue":"ICFNDS '19: Proceedings of the 3rd International Conference on Future Networks and Distributed Systems","authors":["Brandon Thurgood","Ruth G. Lennon"],"abstract":"Cloud computing and artificial intelligence (AI) technologies are becoming increasingly prevalent in the industry, necessitating the requirement for advanced platforms to support their workloads through parallel and distributed architectures. Kubernetes provides an ideal platform for hosting various workloads, including dynamic workloads based on AI applications that support ubiquitous computing devices leveraging parallel and distributed architectures. The rationale is that Kubernetes can be used to support backend services running on parallel and distributed architectures, hosting ubiquitous cloud computing workloads. These applications support smart homes and concerts, providing an environment that automatically scales based on demand. While Kubernetes does offer support for auto scaling of Pods to support these workloads, automated scaling of the cluster itself is not currently offered. In this paper we introduce a Free and Open Source Software (FOSS) solution for autoscaling Kubernetes (K8s) worker nodes within a cluster to support dynamic workloads. We go on to discuss scalability issues and security concerns both on the platform and within the hosted AI applications.","publicationDate":"2019-06-30T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3409501.3409503","title":"research-article ","type":"A Scheduler for Serverless Framework base on Kubernetes","venue":"HPCCT & BDAI 2020: Proceedings of the 2020 4th High Performance Computing and Cluster Technologies Conference & 2020 3rd International Conference on Big Data and Artificial Intelligence","authors":["Dayong Fan","Dongzhi He"],"abstract":"This paper mainly studies the optimization of pod scheduling in the large-scale concurrent scenario of Serverless framework base on Kubernetes platform. In Serverless cloud computing paradigm, rapid deployment and running of pods is the most critical step to improve resource efficiency. However, the deployment and operation of pods depend on images, and Kubernetes default scheduler currently base on pod-by-pod mode for scheduling, it cannot fully meet the needs of Serverless in resource scheduling. In view of this problem, we propose an algorithm using the same pod simultaneous scheduling to further optimize the efficiency of pod scheduling in Serverless cloud paradigm. Through preliminary verification, we can greatly reduce the delay of pod start-up while ensuring the balance of node resources.","publicationDate":"2020-07-02T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3404555.3404565","title":"research-article ","type":"Multi-Tenant Machine Learning Platform Based on Kubernetes","venue":"ICCAI '20: Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence","authors":["Chun-Hsiang Lee","Zhaofeng Li","Xu Lu","Tiyun Chen","Saisai Yang","Chao Wu"],"abstract":"In this paper, we propose a flexible and scalable machine learning architecture based on Kubernetes that can support simultaneous use by huge numbers of users. Its utilization of computing resources is superior to virtual-machine-based architectures because of its container-level resource isolation and highperformance orchestration mechanism. We also describe the implementation of several important features that are designed to simplify the entire modeling lifecycle for machine learning developers. Real case studies for machine learning model development are presented that demonstrates the effectiveness of the platform in reducing the barriers to machine learning.","publicationDate":"2020-04-22T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3149457.3149473","title":"research-article ","type":"A Portable Load Balancer for Kubernetes Cluster","venue":"HPC Asia 2018: Proceedings of the International Conference on High Performance Computing in Asia-Pacific Region","authors":["Kimitoshi Takahashi","Kento Aida","Tomoya Tanjo","Jingtao Sun"],"abstract":"Linux containers have become very popular these days due to their lightweight nature and portability. Numerous web services are now deployed as clusters of containers. Kubernetes is a popular container management system that enables users to deploy such web services easily, and hence, it facilitates web service migration to the other side of the world. However, since Kubernetes relies on external load balancers provided by cloud providers, it is difficult to use in environments where there are no supported load balancers. This is particularly true for on-premise data centers, or for all but the largest cloud providers. In this paper, we proposed a portable load balancer that was usable in any environment, and hence facilitated web services migration. We implemented a containerized software load balancer that is run by Kubernetes as a part of container cluster, using Linux kernel's Internet Protocol Virtual Server(IPVS). Then we compared the performance of our proposed load balancer with existing iptables Destination Network Address Translation (DNAT) and the Nginx load balancers. During our experiments, we also clarified the importance of two network conditions to derive the best performance: the first was the choice of the overlay network operation mode, and the second was distributing packet processing to multiple cores. The results indicated that our proposed IPVS load balancer improved portability of web services without sacrificing the performance.","publicationDate":"2018-01-27T23:00:00.000Z","citationCount":8},{"url":"https://dl.acm.org/doi/10.1145/3437359.3465603","title":"research-article ","type":"Real-World, Self-Hosted Kubernetes Experience","venue":"PEARC '21: Practice and Experience in Advanced Research Computing","authors":["Michael Packard","Joe Stubbs","Justin Drake","Christian Garcia"],"abstract":" Containerized applications have exploded in popularity in recent years, due to their ease of deployment, reproducible nature, and speed of startup. Accordingly, container orchestration tools such as Kubernetes have emerged as resource providers and users alike try to organize and scale their work across clusters of systems. This paper documents some real-world experiences of building, operating, and using self-hosted Kubernetes Linux clusters. It aims at comparisons between Kubernetes and single-node container solutions and traditional multi-user, batch queue Linux clusters. The authors of this paper have background experience first running traditional HPC Linux clusters and queuing systems like Slurm, and later virtual machines using technologies such as Openstack. Much of the experience and perspective below is informed by this perspective. We will also provide a use-case from a researcher who deployed on Kubernetes without being as opinionated about other potential choices. ","publicationDate":"2021-07-16T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3290480.3290507","title":"research-article ","type":"Research on Kubernetes' Resource Scheduling Scheme","venue":"ICCNS 2018: Proceedings of the 8th International Conference on Communication and Network Security","authors":["Zhang Wei-guo","Ma Xi-lin","Zhang Jin-zhong"],"abstract":"Currently, Google's open source container orchestration tool Kubernetes (K8s for short) has become the standard of fact for deploying containerized applications on a large scale in private, public, and hybrid cloud environments. By studying the scheduling-module of K8s source code, this paper finds that when selecting node for Pod, the module only considers the current optimal node, regardless of the use of resource costs. In order to solve this problem, this paper firstly realizes the model extraction of its scheduling module, and designs and implements the simulation experiment for the model for the first time. Secondly, a large number of papers on cloud computing resource scheduling are read. In this paper, the K8s scheduling model is improved by combining ant colony algorithm and particle swarm optimization algorithm. Finally, it is scored, and the node with the smallest objective function is selected to deploy the Pod. This paper draws on the resource scheduling model of CloudSim tool and implements resource scheduling of K8s using Java language. The experimental results show that the proposed algorithm is better than the original scheduling algorithm, which reduces the total resource cost and the maximum load of the node, and makes the task assignment more balanced.","publicationDate":"2018-11-01T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.5555/3370272.3370326","title":"research-article ","type":"How can OpenShift accelerate your Kubernetes adoption: a workshop exploring OpenShift features","venue":"CASCON '19: Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering","authors":["Ben Linzel","Erica Zhu","Geofrey Flores","John Liu","Serjik Dikaleh"],"abstract":"OpenShift is a Kubernetes distribution which comes with additional capabilities for developers and operators to make building and running cloud-native applications easier.This hands-on workshop walked the participants through the deployment of an application in an OpenShift cluster. Origin Community Distribution of OpenShift (referred to as OKD) is the Kubernetes distribution that powers OpenShift. With Minishift version 3.x, participants can use OKD to get some hands-on experience of OpenShift locally.In addition to managed Kubernetes clusters, IBM Cloud also offers managed OpenShift clusters which leverages a lot of the same infrastructure as the Kubernetes clusters. We also demonstrated how to deploy the application into a paid IBM Cloud OpenShift cluster. We highlighted the similarities and differences between tasks performed in Kubernetes and OpenShift to illustrate the value of using OpenShift. We compared Kubernetes and OpenShift through real example configuration, setup and deployment.","publicationDate":"2019-11-03T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3328905.3332505","title":"demonstration ","type":"Service Function Chaining Across OpenStack and Kubernetes Domains","venue":"DEBS '19: Proceedings of the 13th ACM International Conference on Distributed and Event-based Systems","authors":["Hadi Razzaghi Kouchaksaraei","Holger Karl"],"abstract":"Remarkable advantages of Containers (CNs) over Virtual Machines (VMs) such as lower overhead and faster startup has gained the attention of Communication Service Providers (CSPs) as using CNs for providing Virtual Network Functions (VNFs) can save costs while increasing the service agility. However, as it is not feasible to realise all types of VNFs in CNs, the coexistence of VMs and CNs is proposed. To put VMs and CNs together, an orchestration framework that can chain services across distributed and heterogeneous domains is required. To this end, we implemented a framework by extending and consolidating state-of-the-art tools and technologies originated from Network Function Virtualization (NFV), Software-defined Networking (SDN) and cloud computing environments. This framework chains services provisioned across Kubernetes and OpenStack domains. During the demo, we deploy a service consist of CN- and VM-based VNFs to demonstrate different features provided by our framework.","publicationDate":"2019-06-23T22:00:00.000Z","citationCount":8},{"url":"https://dl.acm.org/doi/10.1145/3407947.3407950","title":"research-article ","type":"A Dynamic I/O Sensing Scheduling Scheme in Kubernetes","venue":"HP3C 2020: Proceedings of the 2020 4th International Conference on High Performance Compilation, Computing and Communications","authors":["Dong Li","Yi Wei","Bing Zeng"],"abstract":"With the rapid development of the Container-as-a-Service (CaaS), Kubernetes has become the de facto standard for deploying containerized applications on cloud environments. However, the Kubernetes scheduler does not take the disk I/O load of nodes into account, which leads two problems: (1) Multiple I/O-intensive applications may be dispatched to the same node, which cause I/O bottlenecks. (2) Pods are less likely to be scheduled on node with idle I/O and insufficient CPU, resulting in the waste of the node's I/O resource. To address these problems, we first propose a dynamic scheduling algorithm named by Balanced-Disk-IO-Priority (BDI) to improve the disk I/O balance between the nodes. Moreover, we also propose a dynamic scheduling algorithm called Balanced-CPU-Disk-IO-Priority (BCDI) to solve the issue of load imbalance of CPU and disk I/O on single node. The experimental results show that the BDI algorithm and BCDI algorithm are more effective than the Kubernetes default scheduling algorithms.","publicationDate":"2020-06-26T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3375555.3383585","title":"abstract ","type":"Kubernetes: Towards Deployment of Distributed IoT Applications in Fog Computing","venue":"ICPE '20: Companion of the ACM/SPEC International Conference on Performance Engineering","authors":["Paridhika Kayal"],"abstract":"Fog computing has been regarded as an ideal platform for distributed and diverse IoT applications. Fog environment consists of a network of fog nodes and IoT applications are composed of containerized microservices communicating with each other. Distribution and optimization of containerized IoT applications in the fog environment is a recent line of research. Our work took Kubernetes as an orchestrator that instantiates, manages, and terminates containers in multiple-host environments for IoT applications, where each host acts as a fog node. This paper demonstrates the industrial feasibility and practicality of deploying and managing containerized IoT applications on real devices (raspberry pis and PCs) by utilizing commercial software tools (Docker, WeaveNet). The demonstration will show that the application's functionality is not affected by the distribution of communicating microservices on different nodes.","publicationDate":"2020-04-19T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3219104.3229249","title":"extended-abstract ","type":"Scaling JupyterHub Using Kubernetes on Jetstream Cloud: Platform as a Service for Research and Educational Initiatives in the Atmospheric Sciences","venue":"PEARC '18: Proceedings of the Practice and Experience on Advanced Research Computing","authors":["Semir Sarajlic","Julien Chastang","Suresh Marru","Jeremy Fischer","Mike Lowe"],"abstract":"Unidata, an NSF funded project that started in 1983, is a diverse community of education and research institutions with the common goal of sharing geoscience data and the tools to access and visualize that data. Unidata provides weather observations and other data, software tools, and support to enhance Earth-system education and research, and continuously examines ways of adapting their workflows for new technologies to maximize the reach of their education and research efforts.In support of Unidata objectives to host workshops for atmospheric data analysis using JupyterHub, we explore a cloud computing approach leveraging Kubernetes coupled with JupyterHub that when combined will provide a solution for researchers and students to pull data from Unidata and burst onto Jetstream cloud by requesting resources dynamically via easy to use JupyterHub. More specifically, on Jetstream, Kubernetes is used for automating deployment and scaling of domain specific containerized applications, and JupyterHub is used for spawning multiple hubs within the same Kubernetes cluster instance that will be used for supporting classroom settings. JupyterHub's modular kernel feature will support dynamic needs of classroom application requirements. The proposed approach will serve as an end-to-end solution for researchers to execute their workflows, with JupyterHub serving as a powerful tool for user training and next-generation workforce development in atmospheric sciences.","publicationDate":"2018-07-21T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3439839.3458735","title":"research-article ","type":"A unified storage layer for supporting distributed workflows in kubernetes","venue":"CHEOPS '21: Proceedings of the Workshop on Challenges and Opportunities of Efficient and Performant Storage Systems","authors":["Antony Chazapis","Christian Pinto","Yiannis Gkoufas","Christos Kozanitis","Angelos Bilas"],"abstract":"The distributed computing landscape has been undergoing radical changes: High-Performance Computing (HPC) applications are moving to the Cloud, as a way of simplifying development, deployment, and migration across computing systems. Meanwhile, cloud applications are becoming increasingly complex and computationally intensive, with the advent of High-Performance Data Analytics (HPDA) pipelines --- highly distributed workflows dealing with enormous and diverse datasets, heavily relying on virtualization and containers, that would benefit from technologies used in \"traditional\" HPC. The foreseeable convergence, demands new abstractions to cope with the increased heterogeneity, so that differing workload classes can coexist seamlessly on the same infrastructure. In this paper, we propose a Unified Storage Layer (USL), to enable cloud-native applications to transparently access a wide spectrum of storage solutions, ranging from high-performance filesystems to cloud-based object stores and key-value databases. Allowing software to exploit the best out of the storage services available with no need for manual intervention from users or programmers, simplifies development and execution of workflows, and boosts overall productivity. This work has been motivated by the requirements of real-world, industry-driven applications running on Kubernetes, the industry standard for cloud infrastructure orchestration.","publicationDate":"2021-04-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3468264.3473495","title":"short-paper ","type":"Mitigating security attacks in kubernetes manifests for security best practices violation","venue":"ESEC/FSE 2021: Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","authors":["Shazibul Islam Shamim"],"abstract":"Kubernetes is an open-source software system that helps practitioners in automatically deploying, scaling, and managing containerized applications. Information technology (IT) organizations, such as IBM, Spotify, and Capital One, use Kubernetes to manage their containers and reported benefits in the deployment process. However, recent security breaches and survey results among practitioners suggest that Kubernetes deployment can be vulnerable to attacks due to misconfiguration and not following security best practices. This research explores how malicious users can perform potential security exploits from the violations of Kubernetes security best practices. We explore how attacks can be conducted such as denial of service attacks against one of the security best practices violations in Kubernetes manifests. In addition, we are exploring potential exploits in the Kubernetes cluster to propose mitigation strategies to secure the Kubernetes cluster.","publicationDate":"2021-08-19T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3217880.3217883","title":"research-article ","type":"Batch and online anomaly detection for scientific applications in a Kubernetes environment","venue":"ScienceCloud'18: Proceedings of the 9th Workshop on Scientific Cloud Computing","authors":["Sahand Hariri","Matias Carrasco Kind"],"abstract":"We present a cloud based anomaly detection service framework that uses a containerized Spark cluster and ancillary user interfaces all managed by Kubernetes. The stack of technology put together allows for fast, reliable, resilient and easily scalable service for either batch or streaming data. At the heart of the service, we utilize an improved version of the algorithm Isolation Forest called Extended Isolation Forest for robust and efficient anomaly detection. We showcase the design and a normal workflow of our infrastructure which is ready to deploy on any Kubernetes cluster without extra technical knowledge. With exposed APIs and simple graphical interfaces, users can load any data and detect anomalies on the loaded set or on newly presented data points using a batch or a streaming mode. With the latter, users can subscribe and get notifications on the desired output. Our aim is to develop and apply these techniques to use with scientific data. In particular we are interested in finding anomalous objects within the overwhelming set of images and catalogs produced by current and future astronomical surveys, but that can be easily adopted to other fields.","publicationDate":"2018-06-10T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3318265.3318288","title":"research-article ","type":"Design and implementation of an edge computing platform architecture using Docker and Kubernetes for machine learning","venue":"HP3C '19: Proceedings of the 3rd International Conference on High Performance Compilation, Computing and Communications","authors":["Yuzhou Huang","Kaiyu cai","Ran Zong","Yugang Mao"],"abstract":"Huge data sets and high resources consumption are the prominent features of machine learning services. At present, machine learning services are often deployed on large-scaled cloud servers. The cloud utilizes its rich resources to perform the model training and prediction tasks, but the performance of this method is often limited by the unstable network conditions. To combine the rich-resources advantage of the cloud server with the stable-network performance of the edge computing technology, this paper proposes a Cloud-training and Edge-predicting framework. By integrating the Docker container technology and Kubernetes container choreography technology, we build an edge computing platform, and deploy a machine learning model (Inception V3) on the platform. With this method, we implemented machine learning services on the edge side. In this paper, we have described the designing and building process of the edge computing platform and the deployment procedure of the machine learning model in detail, and we have taken an experiment to implement the service to prove the feasibility of our ideas.","publicationDate":"2019-03-07T23:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3378904.3378921","title":"research-article ","type":"An Automatic Artificial Intelligence Training Platform Based on Kubernetes","venue":"BDET 2020: Proceedings of the 2020 2nd International Conference on Big Data Engineering and Technology","authors":["Chaoyu Wu","E. Haihong","Meina Song"],"abstract":"For large-scale AI training, the manual allocation of GPU resources is too inefficient, and it faces the problems of task allocation and fault restart. In this paper, a fully automatic machine learning platform is designed, which manages server resources uniformly, and users describe the required resources through configuration files. The platform automatically performs AI task allocation and scheduling based on the cluster load, which solves the problems of low cluster resource utilization and uneven machine load distribution. The platform also provides an automatic release and continuous integration of the model, which greatly simplifies the configuration of the model's operating environment and external release process, enabling researchers to focus more on model adjustments. Finally, it is verified by experiments that the extra time spent on AI task training through this platform is negligible, which confirms the feasibility of the platform.","publicationDate":"2020-01-02T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3437359.3465598","title":"short-paper ","type":"Experiences Migrating the Agave Platform to A Kubernetes Native System on the Jetstream Cloud","venue":"PEARC '21: Practice and Experience in Advanced Research Computing","authors":["Rion Dooley","Steven Brandt","Karen Liang","Eric Tanner"],"abstract":" The Agave Platform is a Science-as-a-Service (ScaaS) platform for reproducible science. The current production deployments of the platform are deployed and managed using Ansible and Docker Compose. While capable, this has historically led to operational complexity for those adopting the platform. Over the last year, we have worked to migrate the platform to a Kubernetes native deployment. In this paper we discuss our experiences evolving the platform, its architecture, and getting the most out of the Jetstream cloud.","publicationDate":"2021-07-16T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3341325.3341992","title":"research-article ","type":"Kubernetes cluster optimization using hybrid shared-state scheduling framework","venue":"ICFNDS '19: Proceedings of the 3rd International Conference on Future Networks and Distributed Systems","authors":["Oana-Mihaela Ungureanu","Călin Vlădeanu","Robert Kooij"],"abstract":"This paper presents a novel approach for scheduling the workloads in a Kubernetes cluster, which are sometimes unequally distributed across the environment or deal with fluctuations in terms of resources utilization. Our proposal looks at a hybrid shared-state scheduling framework model that delegates most of the tasks to the distributed scheduling agents and has a scheduling correction function that mainly processes the unscheduled and unprioritized tasks. The scheduling decisions are made based on the entire cluster state which is synchronized and periodically updated by a master-state agent. By preserving the Kubernetes objects and concepts, we analyzed the proposed scheduler behavior under different scenarios, for instance we tested the failover/recovery behavior in a deployed Kubernetes cluster. Moreover, our findings show that in situations like collocation interference or priority preemption, other centralized scheduling frameworks integrated with the Kubernetes system might not perform accordingly due to high latency derived from the calculation of load spreading. In a wider context of the existing scheduling frameworks for container clusters, the distributed models lack of visibility at an upper-level scheduler might generate conflicting job placements. Therefore, our proposed scheduler encompasses the functionality of both centralized and distributed frameworks. By employing a synchronized cluster state, we ensure an optimal scheduling mechanism for the resources utilization.","publicationDate":"2019-06-30T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3342280.3342335","title":"short-paper ","type":"Sharpening Kubernetes for the Edge","venue":"SIGCOMM Posters and Demos '19: Proceedings of the ACM SIGCOMM 2019 Conference Posters and Demos","authors":["David Haja","Mark Szalay","Balazs Sonkoly","Gergely Pongracz","Laszlo Toka"],"abstract":"Kubernetes has become the most popular cluster manager during the past 5 years. It is used primarily for orchestrating data center deployments running web applications. Its powerful features, e.g., self-healing and scaling, have attracted a huge community, which in turn, is inducing a meteoric rise of this open source project. We venture to shape Kubernetes to be suited for edge infrastructure. As mostly delay-sensitive applications are to be deployed in the edge, a topology-aware Kubernetes is needed, extending its widely-used feature set with regard to network latency. Moreover, as the edge infrastructure is highly prone to failures and is considered to be expensive to build and maintain, self-healing features must receive more emphasis than in the baseline Kubernetes. We therefore designed a custom Kubernetes scheduler that makes its decisions with applications' delay constraints and edge reliability in mind. In this demonstration we show the novel features of our Kubernetes extension, and describe the solution that we release as open source.","publicationDate":"2019-08-18T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3311790.3401777","title":"research-article ","type":"SLATE: Monitoring Distributed Kubernetes Clusters","venue":"PEARC '20: Practice and Experience in Advanced Research Computing","authors":["Gabriele Carcassi","Joe Breen","Lincoln Bryant","Robert W. Gardner","Shawn Mckee","Christopher Weaver"],"abstract":"The SLATE (Services Layer at the Edge) accelerates collaborative scientific computing through a secure container orchestration framework focused on the Science DMZ, enabling creation of advanced multi-institution platforms and novel science gateways. The goal of the SLATE project is to provide a secure federation platform to simplify deployment and operation of complex and often specialized services required by multi-institution scientific collaborations, utilizing where applicable open source, cloud native tooling such as Kubernetes. This paper outlines the design and operation of a monitoring infrastructure suitable for application developers and resource providers which gives visibility to resource utilization and service deployments across a network of independently managed Kubernetes clusters.","publicationDate":"2020-07-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/2996890.3007869","title":"short-paper ","type":"Modelling performance & resource management in kubernetes","venue":"UCC '16: Proceedings of the 9th International Conference on Utility and Cloud Computing","authors":["Víctor Medel","Omer Rana","José ángel Bañares","Unai Arronategui"],"abstract":"Containers are rapidly replacing Virtual Machines (VMs) as the compute instance of choice in cloud-based deployments. The significantly lower overhead of deploying containers (compared to VMs) has often been cited as one reason for this. We analyse performance of the Kubernetes system and develop a Reference net-based model of resource management within this system. Our model is characterised using real data from a Kubernetes deployment, and can be used as a basis to design scalable applications that make use of Kubernetes.","publicationDate":"2016-12-05T23:00:00.000Z","citationCount":36},{"url":"https://dl.acm.org/doi/10.1145/3366615.3368357","title":"research-article ","type":"Leveraging Kubernetes for adaptive and cost-efficient resource management","venue":"WOC '19: Proceedings of the 5th International Workshop on Container Technologies and Container Clouds","authors":["Stef Verreydt","Emad Heydari Beni","Eddy Truyen","Bert Lagaisse","Wouter Joosen"],"abstract":"Software providers face the challenge of minimizing the amount of resources used while still meeting their customer's requirements. Several frameworks to manage resources and applications in a distributed environment are available, but their development is still ongoing and the state of the art is rapidly evolving, making it a challenge to use such frameworks and their features effectively in practice. The goal of this paper is to research how applications can be enhanced with adaptive performance management by relying on the capabilities of Kubernetes, a popular framework for container orchestration. In particular, horizontal as well as vertical scaling concepts of Kubernetes may prove useful to support adaptive resource allocation. Moreover, concepts for oversubscription as a way to simulate vertical scaling without having to reschedule applications, are evaluated. Through a series of experiments involving multiple applications and workloads, the effects of different configurations and combinations of horizontal and vertical scaling in Kubernetes are explored. Both the resource utilization of the nodes and the applications' performance are taken into account. In brief, the resource management concepts of Kubernetes allow to simulate vertical scaling without a negative effect on performance. The effectiveness of the default horizontal autoscaler, however, depends on the type of application and the user workload at hand.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/2996890.3007889","title":"short-paper ","type":"Adaptive application scheduling under interference in Kubernetes","venue":"UCC '16: Proceedings of the 9th International Conference on Utility and Cloud Computing","authors":["Víctor Medel","Omer Rana","José Ángel Bañares","Unai Arronategui"],"abstract":"Containers are rapidly replacing Virtual Machines (VMs) as the compute instance in cloud-based deployments. The significantly lower overhead of deploying containers (compared to VMs) has often been cited as one reason for this. However, interference caused by the limited isolation in shared resources can impact into the performance of hosted applications. We develop a Reference Net-based model of resource management within Kubernetes, primarily to better characterise such performance issues. Our model makes use of data obtained from a Kubernetes deployment, and can be used as a basis to design scalable (and potentially interference-tolerant) applications that make use of Kubernetes.","publicationDate":"2016-12-05T23:00:00.000Z","citationCount":7},{"url":"https://dl.acm.org/doi/10.1145/3412841.3441887","title":"research-article ","type":"Reducing cold starts during elastic scaling of containers in kubernetes","venue":"SAC '21: Proceedings of the 36th Annual ACM Symposium on Applied Computing","authors":["Emad Heydari Beni","Eddy Truyen","Bert Lagaisse","Wouter Joosen","Jordy Dieltjens"],"abstract":"Automatic scaling of containers is an important feature to handle fluctuating workloads. However, the delay caused by the time to bootstrap a container has an impact on applications with deadline-based Service-Level Objectives (SLOs). This delay is called the cold start problem. Many techniques have already been proposed to tackle this problem but not all techniques have been integrated and evaluated in Kubernetes, the de-facto standard in container orchestration. This paper combines and evaluates three techniques in the context of Kubernetes: (i) pre-creation of network containers, (ii) using container images that enable sharing of linked libraries in memory and (iii) extending the declarative configuration management approach of Kubernetes with imperative configuration for creating multiple application containers in parallel. A prototype of the approach is implemented and tested on a Java-based Spring Boot application where the cold start problem occurs due to various library dependencies. Our findings illustrate that the use of containers that allow for library sharing already has a large, positive impact when starting up a single container. The pre-creation of network containers in combination with imperative configuration enables the application to meet deadline-driven SLOs without a non-deterministic delay that appears in Kubernetes when multiple containers are created in parallel. We conclude that the use of container images that allow for library sharing is a must for all applications that require fast container start-ups in Kubernetes. Pre-creation of network containers when combined with imperative configuration also has a positive impact on SLO compliance during elastic scaling of containers.","publicationDate":"2021-03-21T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3172795.3172840","title":"research-article ","type":"Introduction to kubernetes","venue":"CASCON '17: Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering","authors":["Serjik Dikaleh","Ozair Sheikh","Chris Felix"],"abstract":"Industry disruption and market innovation have forced companies to increase the frequency of introducing new capabilities in their applications. Additionally, with the explosion of devices connected to the Internet and the availability of cloud based environments, scaling applications and providing continuous availability of the applications have also become an expected feature of applications and services. This requires that a robust, flexible and reliable mechanism is available for application deployment and management.","publicationDate":"2017-11-05T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/2890784","title":"research-article ","type":"Borg, Omega, and Kubernetes","venue":"Communications of the ACM","authors":["Brendan Burns","Brian Grant","David Oppenheimer","Eric Brewer","John Wilkes"],"abstract":"Lessons learned from three container-management systems over a decade.","publicationDate":"2016-04-25T22:00:00.000Z","citationCount":103},{"url":"https://dl.acm.org/doi/10.1145/3404709.3409389","title":"research-article ","type":"Service-Based Container Deployment on Kubernetes Using Stable Marriage Problem","venue":"ICFET 2020: Proceedings of the 2020 The 6th International Conference on Frontiers of Educational Technologies","authors":["Akhmad Alimudin","Yoshiteru Ishida"],"abstract":"Container technology is currently the most widely used technology because of its ease of use and the efficiency of resource usage compared to the use of virtual machines. Moreover, the use of container technology is now made easier by the existence of orchestration tools such as Kubernetes, Docker Swarm, and Mesos. Orchestration tools make it easier for container users to deploy services and control resource. One of the main components of orchestration tools is a scheduler whose job is to manage container placement into a host. In this research, we tried to make a custom scheduler on Kubernetes using Stable Marriage Problem to get the best deployment between containers and hosts. Our trial scenario is to match three web services with three different hosts/servers. From the results of the experiment, containers that are deployed by using the SMP-scheduler have advantages in containers that prioritize CPU usage.","publicationDate":"2020-06-04T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3144687.3144697","title":"research-article ","type":"Private cloud deployment with docker and kubernetes","venue":"Journal of Computing Sciences in Colleges","authors":["Sean Sanders","Charles Border"],"abstract":"Automated software development has been a goal of applications developers. Several new technologies are now available to realize that goal. As revealed in a recent study by LinkedIn, Site reliability engineers (SRE) are among the highest paid occupations at $140,000 [11]. They are experts at maintaining infrastructure and web development, as well as pivotal individuals who manage DevOps Engineers.","publicationDate":"2017-12-31T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/2806777.2809955","title":"abstract ","type":"Kubernetes and the path to cloud native","venue":"SoCC '15: Proceedings of the Sixth ACM Symposium on Cloud Computing","authors":["Eric A. Brewer"],"abstract":"We are in the midst of an important shift to higher levels of abstraction than virtual machines. Kubernetes aims to simplify the deployment and management of services, including the construction of applications as sets of interacting but independent services. We explain some of the key concepts in Kubernetes and show how they work together to simplify evolution and scaling.","publicationDate":"2015-08-26T22:00:00.000Z","citationCount":51},{"url":"https://dl.acm.org/doi/10.1145/3378447","title":"research-article ","type":"A Cost-Efficient Container Orchestration Strategy in Kubernetes-Based Cloud Computing Infrastructures with Heterogeneous Resources","venue":"ACM Transactions on Internet Technology","authors":["Zhiheng Zhong","Rajkumar Buyya"],"abstract":"Containers, as a lightweight application virtualization technology, have recently gained immense popularity in mainstream cluster management systems like Google Borg and Kubernetes. Prevalently adopted by these systems for task deployments of diverse workloads such as big data, web services, and IoT, they support agile application deployment, environmental consistency, OS distribution portability, application-centric management, and resource isolation. Although most of these systems are mature with advanced features, their optimization strategies are still tailored to the assumption of a static cluster. Elastic compute resources would enable heterogeneous resource management strategies in response to the dynamic business volume for various types of workloads. Hence, we propose a heterogeneous task allocation strategy for cost-efficient container orchestration through resource utilization optimization and elastic instance pricing with three main features. The first one is to support heterogeneous job configurations to optimize the initial placement of containers into existing resources by task packing. The second one is cluster size adjustment to meet the changing workload through autoscaling algorithms. The third one is a rescheduling mechanism to shut down underutilized VM instances for cost saving and reallocate the relevant jobs without losing task progress. We evaluate our approach in terms of cost and performance on the Australian National Cloud Infrastructure (Nectar). Our experiments demonstrate that the proposed strategy could reduce the overall cost by 23% to 32% for different types of cloud workload patterns when compared to the default Kubernetes framework.","publicationDate":"2020-04-12T22:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3183713.3183725","title":"keynote ","type":"Kubernetes and the New Cloud","venue":"SIGMOD '18: Proceedings of the 2018 International Conference on Management of Data","authors":["Eric Brewer"],"abstract":"No abstract available.","publicationDate":"2018-05-26T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3366615.3368352","title":"research-article ","type":"A framework for black-box SLO tuning of multi-tenant applications in Kubernetes","venue":"WOC '19: Proceedings of the 5th International Workshop on Container Technologies and Container Clouds","authors":["Matthijs Kaminski","Eddy Truyen","Emad Heydari Beni","Bert Lagaisse","Wouter Joosen"],"abstract":"Resource management concepts of container orchestration platforms such as Kubernetes can be used to achieve multi-tenancy with quality of service differentiation between tenants. However, to support cost-effective enforcement of Service Level Objectives (SLOs) about response time or throughput, an automated resource optimization approach is needed for mapping custom SLOs of different tenants to cost-efficient resource allocation policies. We propose a versatile tool for cost-effective SLO tuning, named k8-resource-optimizer, that relies on black-box performance tuning algorithms. We illustrate and validate the tool for optimizing different resource configuration properties of a simple job processing application. Our experiments showed that k8-resource-optimizer can find near-optimal configurations for different multi-tenant deployment settings and different types of resource parameters. However an open research challenge is that, when the number of parameters increases, the total tuning cost may also increase beyond what is acceptable for contemporary cloud-native applications. We shortly discuss three possible complementary solutions to tackle this challenge.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3284028.3284033","title":"research-article ","type":"NBWGuard: Realizing Network QoS for Kubernetes","venue":"Middleware '18: Proceedings of the 19th International Middleware Conference Industry","authors":["Cong Xu","Karthick Rajamani","Wesley Felter"],"abstract":"Kubernetes is a very popular and fast-growing container orchestration platform that automates the process of deploying and managing multi-container applications at scale. Users can specify required and maximum values of resources they need for their containers and Kubernetes realizes them by interfacing with lower levels (container runtime which in turn can use OS capabilities) of the stack for enforcing them. Kubernetes supports differentiated QoS classes - Guaranteed, Burstable, and Best-effort - in order of decreasing priority based on the resource size specifications for CPU and memory capacity. This allows many applications to obtain a desired level of QoS (performance isolation and throughput) when CPU or memory capacity management can provide them. However, when workloads may be critically dependent for their performance on another resource, namely network bandwidth, Kubernetes has no means to meet their QoS needs. Networking between pods in Kubernetes is supported with plug-ins and the network resource is not managed directly.In this work, we propose NBWGuard, a design for network bandwidth management and evaluate its implementation. NBWGuard lets Kubernetes manage network bandwidth as a resource (like CPU or memory capacity) while still using plug-ins for realizing the network specification desired by users. Consistent with Kubernetes approach to application QoS based on resource allocation NBWGuard also supports the 3 QoS classes: Guaranteed, Burstable, and Best-effort with respect to network bandwidth. NBWGuard is evaluated with iperf benchmark on real cloud environment, and the evaluation results demonstrate that it is able to provide network bandwidth isolation without impact on overall throughput.","publicationDate":"2018-12-09T23:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/2898442.2898444","title":"research-article ","type":"Borg, Omega, and Kubernetes: Lessons learned from three container-management systems over a decade","venue":"Queue","authors":["Brendan Burns","Brian Grant","David Oppenheimer","Eric Brewer","John Wilkes"],"abstract":"Though widespread interest in software containers is a relatively recent phenomenon, at Google we have been managing Linux containers at scale for more than ten years and built three different container-management systems in that time. Each system was heavily influenced by its predecessors, even though they were developed for different reasons. This article describes the lessons we’ve learned from developing and operating them.","publicationDate":"2015-12-31T23:00:00.000Z","citationCount":174},{"url":"https://dl.acm.org/doi/10.5555/3370272.3370334","title":"research-article ","type":"Build, deploy and administer microservices using Kubernetes and IBM cloud API management","venue":"CASCON '19: Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering","authors":["Eric Charpentier","Neil Delima","Jason Mah","Darren Pape","Vince Yuen"],"abstract":"In recent years companies have increased their adoption of cloud computing not just to improve IT operational efficiencies but also to drive growth through business innovation and gain a competitive advantage. Legacy applications are being modernized to run in cloud environments and new cloud native applications with enhanced artificial intelligence are being developed. Microservices, containers and DevOps are at the core of application modernization and cloud native application development.","publicationDate":"2019-11-03T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3239576.3239605","title":"research-article ","type":"Building a Cloud-Ready Program: A highly scalable Implementation based on Kubernetes","venue":"ICAIP '18: Proceedings of the 2nd International Conference on Advances in Image Processing","authors":["Qiankun Li","Gang Yin","Tao Wang","Yue Yu"],"abstract":"Build system, which can convert source codes into applications, is essential for the development of software. The general build systems that relying on single physical or cloud host to run bring problems such as system security, resource shortage, overload, and low availability in the face of massive build requests. After modularizing and streamlining the steps during a build process, this paper proposes a system that introduces container technology and then builds a large-scale, real-time, and huge-concurrency supported build system based on Kubernetes[1]. The system provides a highly scalable and feature-stable cloud architecture that supports huge concurrency with lower resource consumption. Also, the system controls programs' behaviors very well to avoid potential security and resource issues and shows excellent performance in concurrency, scalability, security, and load balance even when handling a large number of build tasks.","publicationDate":"2018-06-15T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.5555/3291291.3291337","title":"research-article ","type":"Come learn how to deploy open liberty applications using Docker, Kubernetes, Helm and MicroProfile!","venue":"CASCON '18: Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering","authors":["Arthur De Magalhaes","Leo Christy Jesuraj"],"abstract":"Application modernization is in everyone's mind - but what environment do you migrate your legacy application into? Can that environment also host your new cloud-native applications?","publicationDate":"2018-10-28T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3434770.3459737","title":"research-article ","type":"EdgeNet: A Multi-Tenant and Multi-Provider Edge Cloud","venue":"EdgeSys '21: Proceedings of the 4th International Workshop on Edge Systems, Analytics and Networking","authors":["Berat Can Şenel","Maxime Mouchet","Justin Cappos","Olivier Fourmaux","Timur Friedman","Rick McGeer"],"abstract":"EdgeNet is a public Kubernetes cluster dedicated to network and distributed systems research, supporting experiments that are deployed concurrently by independent groups. Its nodes are hosted by multiple institutions around the world. It represents a departure from the classic Kubernetes model, where the nodes that are available to a single tenant reside in a small number of well-interconnected data centers. The free open-source EdgeNet code extends Kubernetes to the edge, making three key contributions: multi-tenancy, geographical deployments, and single-command node installation. We show that establishing a public Kubernetes cluster over the internet, with multiple tenants and multiple hosting providers is viable. Preliminary results also indicate that the EdgeNet testbed that we run provides a satisfactory environment to run a variety of experiments with minimal network overhead.","publicationDate":"2021-04-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3154842.3154845","title":"short-paper ","type":"Orchestrating deep learning workloads on distributed infrastructure","venue":"DIDL '17: Proceedings of the 1st Workshop on Distributed Infrastructures for Deep Learning","authors":["Seetharami R. Seelam","Yubo Li"],"abstract":"Containers simplify the packaging, deployment and orchestration of diverse workloads on distributed infrastructure. Containers are primarily used for web applications, databases, application servers, etc. on infrastructure that consists of CPUs, Memory, Network and Storage. Accelerator hardware such GPUs are needed for emerging class of deep learning workloads with unique set of requirements that are not addressed by current container orchestration systems like Mesos, Kuberentes, and Docker swarm. In this extended abstract, we discuss the requirements to support GPUs in container management systems and describe our solutions in Kubernetes. We will conclude with a set of open issues that are yet to be addressed to fully support deep learning workloads on distributed infrastructure.Operating system (OS) allows flexible sharing and load balancing of resources like CPU, Memory and Network among multiple processes and containers. Unlike these GPU's are unique quantities (GPU 0, GPU 1, ...) and they must be allocated accordingly (e.g., allocate GPU 0 to Container 1). GPU topology, will heavily affect the bandwidth of GPU to GPU communication and must take into consideration. Moreover, GPU topology even affects GPU capabilities. In some systems, for example, GPUs on different CPU socket cannot have Peer to Peer communication capability.To address these issues, firstly, we have enabled GPU support on Kubernetes. We implemented a GPU allocator module to record GPU number-to-device mapping. Kubernetes users only request number of GPUs need for their workload; GPU allocator module maps the number to actual GPU devices according to required scheduling policy and expose the allocated GPUs to application inside the container. Secondly, we have developed two advanced GPU schedulers, a bin-packing scheduler and a topology-aware scheduler, to improve GPU utilization and GPU performance. Bin-packing scheduler tries to bundle GPU jobs to fewer servers, so that other idle servers can be reserved for potentially large jobs. Topology-aware scheduler can automatically collect GPU topology information of each worker node, and assign nodes that deliver the highest possible bandwidth to the application.Access to CPU, Memory, Network and Storage devices are abstracted by operating system (OS) application programming interface (API) calls. The OS translates the application calls into device specific calls internally. Unlike these resources, GPUs have device access calls that are not yet abstracted under OS API's so applications that require access to GPU devices need those GPU devices mounted inside the container, they need access to auxiliary device interfaces (like nvidia-uvm), and they need the GPU drivers inside that container. The device driver inside the container must exactly match the driver on the host for proper operation. To solve these issues, we enhanced Kubernetes to gather the device drivers on kubelet startup and mount these drivers into the container automatically. This ensures portability of the workloads across systems with potentially different drivers. A similar approach is taken by Mesos, Nvidia Docker and other systems.In addition, unlike CPU and memory, GPU is an external PCIe device and in our experience it experiences software and hardware failures far more frequently than the rest of the system. Failures could include bad connection to the PCIe slot, GPU kernel crash, bad power supply, and so on. To deal with such issues, we enabled GPU liveness check on Kubernetes (like the liveness check in any cloud service). The kubelet periodically checks the healthiness of GPU devices. Once the GPU failure is detected, the GPU will automatically be removed out from the resources pool.Finally to support multiple users, we added GPU quota support in Kubernetes so that GPU resources can be limited by different namespaces; We auto-labeled GPU devices model to Kubernetes worker nodes so that the job can use such information to filter GPUs. All these new features are originated from our real requirements and aim to enhance the usability of GPUs in a cloud context.We consider GPU related scheduling policy and algorithm to improve both GPU performance and utility as open issues. We plan to extend CPU topology and affinity support to Kubernetes, so that we can make CPU-GPU joint topology optimized scheduling. The exploration of CPU-GPU bandwidth will bring more possibilities for performance improvement especially for servers with NVLink technology (like IBM Minsky) between CPU-GPU.","publicationDate":"2017-12-10T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3400286.3418278","title":"poster ","type":"Design and Implementation an OpenMCP distributed collaborative container platform for flexible scaling and service delivery","venue":"RACS '20: Proceedings of the International Conference on Research in Adaptive and Convergent Systems","authors":["Chanhyup Kim","Jae-Hoon An","Younghwan Kim"],"abstract":"Recently, many companies have been introducing micro-service architecture framework technology to increase development productivity and portability. Google's Kubernetes is a representative micro-service architecture framework that introduces the concept of clusters to provide flexible expansion and services[1, 2]. Kubernetes applies technologies such as Scheduling and Load Balancing on a cluster-by-cluster basis, and has the flexibility to add nodes or move services within a single cluster. However, it does not provide multiple-cluster services scheduling, load balancing or flexible dynamic cluster add/delete technologies. Thus, OpenMCP(Open Multi-Cluster Container Platform) was designed for flexible expansion and service delivery between Kubernetes based Multi-Cluster. Key features of OpenMCP include multi-cluster resource collection, resource analysis, scheduling, load balancing, Auto Scaling, Cluster Synchronization, Dynamic Policy, Domain Name Server (DNS) management.","publicationDate":"2020-10-12T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3400286.3418279","title":"poster ","type":"Design and Implementation of Migration Manager between Cloud Edge Platforms","venue":"RACS '20: Proceedings of the International Conference on Research in Adaptive and Convergent Systems","authors":["Taehyuk Heo","Jae-Hoon An","Younghwan Kim"],"abstract":"Live migration is the process of moving an application of a running virtual machine between physical machines without disconnecting the client or application. In recent years, as cloud computing has developed at a rapid pace, numerous virtual systems have been developed, and container-type operating system level virtualization technology, which is attracting attention at a higher speed and lower resource consumption rate than a virtual machine which use Hypervisor. The tool that deploys and manages these containers is called a container orchestration tool, and the most widely used orchestration framework is Kubernetes. Currently, there is no function for live migration in Kubernetes. In this paper, we developed an environment where containers can be live migration in Kubernetes, and research was conducted to reduce downtime of live migration.","publicationDate":"2020-10-12T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3426746.3434055","title":"research-article ","type":"Suture: Stitching Safety onto Kubernetes Operators","venue":"CoNEXT'20: Proceedings of the Student Workshop","authors":["Akshat Mahajan","Theophilus A. Benson"],"abstract":"Kubernetes operators allow custom automation for applications to be packaged with the application in a cluster-agnostic manner. This unique property eliminates the need for inhouse operational expertise with the application --- such domain knowledge, encoded once, can be distributed to any environment --- but requires trusting the operator to run arbitrary actions across an entire cluster. Little is known about the security or reliability implications of this paradigm. We present results from a survey of 54 Kubernetes developers and an analysis of 215 feature requests against 19 operator repositories demonstrating the ways users have experienced nontrivial safety issues with operators. We further propose the development of Suture, an access-control mechanism that seeks to prevent the majority of these safety issues with operators.","publicationDate":"2020-11-30T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3357223.3365759","title":"abstract ","type":"Isopod: An Expressive DSL for Kubernetes Configuration","venue":"SoCC '19: Proceedings of the ACM Symposium on Cloud Computing","authors":["Charles Xu","Dmitry Ilyevskiy"],"abstract":"Kubernetes is an open-source cluster orchestration system for containerized workloads to reduce idiosyncrasy across cloud vendors [2]. Using Kubernetes, Cruise has built a multi-tenant platform with thousands of cores and tens of terabytes of memory. Such a scale is possible in part thanks to the declarative abstraction of Kubernetes, where desired states are described in YAML manifests [5].However, YAML as a data serialization format is unfit for workload specification. Structured data in YAML are untyped and prone to wrong indents and missing fields. Due to poor meta-programming support, composing YAML with control logic---loops and branches---suffers from YAML fragmentation and indentation tracking (example at bit.ly/yml-hell). Moreover, YAML manifests are often generated by filling a shared template with cluster-specific parameters---the image tag and the replica count might differ in development and production environments. Existing templating tools---Helm [11], Kustomize [9], Kapitan [7] and the likes---assume these parameters are statically known and use CLIs to query dynamic ones, such as secrets stored in HashiCorp Vault [10]. Such scheme is hard to test, since side effects escape through CLIs, and highly depends on the execution environment, since CLI versions vary across machines or might not exist. Not least, YAML manifests describe the eventual state but not how existing workloads will be affected. Blindly applying the manifest---for example, from a stale version of code---can be disastrous and cause unexpected outages.Isopod presents an alternative configuration paradigm by treating Kubernetes objects as first-class citizens. Without intermediate YAML artifacts, Isopod renders Kubernetes objects directly in Protocol Buffers [8], so they are strongly typed and consumed directly by the Kubernetes API. With Isopod, configurations are scripted in Starlark [3], a Python dialect by Google also used by Bazel [1] and Buck [4] build systems. To replace CLI dependencies, Isopod extends Starlark with runtime built-ins to access services and utilities such as Vault, Kubernetes apiserver, Base64 encoder, and UUID generator, etc. Isopod uses a separate runtime for unit tests to mock all built-ins, providing test coverage that was not possible before.Isopod is also hermetic and secure. The common reliance on the kubeconfig file for cluster authentication leaks secrets to disk, a security risk if working from a shared host, such as a cluster node or CICD worker. Instead, Isopod builds Oauth2 tokens [6] to the target cluster using the Identity & Access Management (IAM) service of the cloud vendor. Application secrets are stored in Vault and queried at runtime. Hence, no secrets escape to the disk. In fact, Isopod prohibits disk IO except for loading Starlark modules from other scripts. No external libraries can be loaded unless explicitly implemented as an Isopod built-in. Distributed as a single binary, Isopod is self-contained with all dependencies.Finally, Isopod is extensible. Protobuf packages of Kubernetes API groups added in the future can be loaded in the same way. Because built-ins are modular and pluggable, users can easily implement and register new built-ins with the Isopod runtime to support any Kubernetes vendors. Isopod offers many other features, such as object life cycle management and parallel rollout to multiple clusters, which is impossible if using kubeconfig. In dry-run mode, Isopod displays intended actions from the current code change as a YAML diff against live objects in the cluster to avoid unexpected configuration change.Since the adoption of Isopod, the PaaS team at Cruise has migrated 14 applications and added another 16 without outage or regression, totaling around 10,000 lines of Starlark. The migration results in up to 60% reduction in code size and 80% faster rollout due to code reuse, cluster parallelism, and the removal of YAML intermediaries. All unit tests take less than 10 secs to finish. Isopod is open source at github.com/cruise-automation/isopod.","publicationDate":"2019-11-19T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3286490.3286561","title":"research-article ","type":"Parallelized Training of Deep NN: Comparison of Current Concepts and Frameworks","venue":"DIDL '18: Proceedings of the Second Workshop on Distributed Infrastructures for Deep Learning","authors":["Sebastian Jäger","Hans-Peter Zorn","Stefan Igel","Christian Zirpins"],"abstract":"Horizontal scalability is a major facilitator of recent advances in deep learning. Common deep learning frameworks offer different approaches for scaling the training process. We operationalize the execution of distributed training using Kubernetes and helm templates. This way we lay ground for a systematic comparison of deep learning frameworks. For two of them, TensorFlow and MXNet we examine their properties with regard to throughput, scalability and practical ease of use.","publicationDate":"2018-12-09T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3344948.3344963","title":"demonstration ","type":"Kubow: an architecture-based self-adaptation service for cloud native applications","venue":"ECSA '19: Proceedings of the 13th European Conference on Software Architecture - Volume 2","authors":["Carlos M. Aderaldo","Nabor C. Mendonça","Bradley Schmerl","David Garlan"],"abstract":"This paper presents Kubow, an extensible architecture-based self-adaptation service for cloud native applications. Kubow itself was implemented by customizing and extending the Rainbow self-adaptation framework with support for Docker containers and Kubernetes. The paper highlights Kubow's architecture and main design decisions, and illustrates its use and configuration through a simple example. An accompanying demo video is available at the project's web site: https://ppgia-unifor.github.io/kubow/.","publicationDate":"2019-09-08T22:00:00.000Z","citationCount":11},{"url":"https://dl.acm.org/doi/10.1145/3368235.3369378","title":"keynote ","type":"The Journey of Cloud Computing with Open Source","venue":"UCC '19 Companion: Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing Companion","authors":["Feilong Wang"],"abstract":"Cloud computing is changing from a buzz word to a common technology nowadays. Though there is clarification for cloud computing for three types/layers: Infrastructure as a Service (IaaS), Platform as a Service (PaaS), Software as a Service (SaaS), generally people talk about IaaS and PaaS when they talking about cloud computing. There are already several giant players, like AWS, Azure and GoogleCloud, in the market and it's a 100+ billions USD market[1],but it's a competitive market and there are new players coming in. And on the other hand, people can see big demand for private cloud as well.In this talk, I'd like to share our journey about building a public cloud with OpenStack[2]. Our journey started since 2014 and the idea incubated even earlier. I will generally cover how we design and implement our cloud from bare metal, to VM, then container/Kubernetes, and the road map targeting to serverless, mainly focus on the current stage, about building a high quality managed Kubernetes service.Recently having gone through the experience of building, implementing and running a Kubernetes platform service in our public cloud, Catalyst Cloud has some interesting experiences and war stories to share about the journey.","publicationDate":"2019-12-01T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3366615.3368354","title":"research-article ","type":"Container Orchestration for Dispersed Computing","venue":"WOC '19: Proceedings of the 5th International Workshop on Container Technologies and Container Clouds","authors":["Pradipta Ghosh","Quynh Nguyen","Bhaskar Krishnamachari"],"abstract":"In the era of Internet of Things, there is an increasing demand for networked computing to support the requirements of time-constrained, compute-intensive distributed applications. We present a container orchestration architecture for dispersed computing, and its implementation in an open source software called Jupiter. The system automates the distribution of computational tasks for complex computational applications described as an Directed Acyclic Graph (DAG) to efficiently distribute the tasks among a set of networked compute nodes and orchestrates the execution of the DAG thereafter. This Kubernetes based container-orchestration system supports both centralized and decentralized scheduling algorithms for optimally mapping the tasks based on information from a range of profilers: network profilers, resource profilers, and execution time profilers.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3388440.3412460","title":"research-article ","type":"Collaborative Cloud Computing Framework for Health Data with Open Source Technologies","venue":"BCB '20: Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics","authors":["Fatemeh Rouzbeh","Ananth Grama","Paul Griffin","Mohammad Adibuzzaman"],"abstract":"The proliferation of sensor technologies and advancements in data collection methods have enabled the accumulation of very large amounts of data. Increasingly, these datasets are considered for scientific research. However, the design of the system architecture to achieve high performance in terms of parallelization, query processing time, aggregation of heterogeneous data types (e.g., time series, images, structured data, among others), and difficulty in reproducing scientific research remain a major challenge. This is specifically true for health sciences research, where the systems must be i) easy to use with the flexibility to manipulate data at the most granular level, ii) agnostic of programming language kernel, iii) scalable, and iv) compliant with the HIPAA privacy law. In this paper, we review the existing literature for such big data systems for scientific research in health sciences and identify the gaps of the current system landscape. We propose a novel architecture for software-hardware-data ecosystem using open source technologies such as Apache Hadoop, Kubernetes and JupyterHub in a distributed environment. We also evaluate the system using a large clinical data set of 69M patients.","publicationDate":"2020-09-20T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3472727.3472797","title":"chapter ","type":"Wide Area Network Autoscaling for Cloud Applications","venue":"NAI'21: Proceedings of the ACM SIGCOMM 2021 Workshop on Network-Application Integration","authors":["Berta Serracanta","Jordi Paillisse","Albert Cabellos","Anna Claiborne","Alberto Rodriguez-Natal","Dave Ward","Fabio Maino"],"abstract":"Modern cloud orchestrators like Kubernetes provide a versatile and robust way to host applications at scale. One of their key features is autoscaling, which automatically adjusts cloud resources (compute, memory, storage) in order to adapt to the demands of applications. However, the scope of cloud autoscaling is limited to the datacenter hosting the cloud and it doesn't apply uniformly to the allocation of network resources. In I/O-constrained or data-in-motion use cases this can lead to severe performance degradation for the application. For example, when the load on a cloud service increases and the Wide Area Network (WAN) connecting the datacenter to the Internet becomes saturated, the application flows experience an increase in delay and loss. In many cases this is dealt with overprovisioning network capacity, which introduces additional costs and inefficiencies.On the other hand, thanks to the concept of \"Network as Code\", the WAN exposes a set of APIs that can be used to dynamically allocate and de-allocate capacity on-demand. In this paper we propose extending the concept of cloud autoscaling into the network to address this limitation. This way, applications running in the cloud can communicate their networking requirements, like bandwidth or traffic profile, to a Software-Defined Networking (SDN) controller or Network as a Service (NaaS) platform. Moreover, we aim to define the concepts of vertical and horizontal autoscaling applied to networking. We present a prototype that automatically allocates bandwidth to the underlay network, according to the requirements of the applications hosted in Kubernetes. Finally, we discuss open research challenges.","publicationDate":"2021-08-22T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3284028.3284034","title":"research-article ","type":"A High Performance, Scalable DNS Service for Very Large Scale Container Cloud Platforms","venue":"Middleware '18: Proceedings of the 19th International Middleware Conference Industry","authors":["Haifeng Liu","Shugang Chen","Yongcheng Bao","Wanli Yang","Yuan Chen","Wei Ding","Huasong Shan"],"abstract":"Containers and microservices are dominating the world of data center and cloud computing. As the scale, dynamism and complexity grow, the performance of the DNS system in container clusters becomes vital. As the world's third and China's largest e-commerce site by revenue, JD.com runs one of the world's largest Kubernetes container clusters in production. It is imperative that the DNS system can handle extremely high traffic. In this paper, we present ContainerDNS, a high performance DNS system for very large scale container clusters with millions of containers. ContainerDNS maximizes DNS system performance and scalability by optimizing DNS packet processing and using efficient memory and cache management.ContainerDNS has been deployed in JD's container platform with 30,000 servers and 500,000 containers running tens of thousands of services and applications. It improves the maximum throughput from 130,000 to 9,000,000 QPS, a 67X performance boost comparing to existing DNS systems.","publicationDate":"2018-12-09T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3195870.3195873","title":"demonstration ","type":"Fair non-monetary scheduling in federated clouds","venue":"CrossCloud'18: Proceedings of the 5th Workshop on CrossCloud Infrastructures & Platforms","authors":["Miłosz Pacholczyk","Krzysztof Rzadca"],"abstract":"In a hybrid cloud, individual cloud service providers (CSPs) often have incentive to use each other's resources to offload peak loads or place load closer to the end user. However, CSPs have to keep track of contributions and gains in order to disincentivize long-term free-riding. We show CloudShare, a distributed version of a load balancing algorithm DirectCloud based on the Shapley value---a powerful fairness concept from game theory. CloudShare coordinates CSPs by a ZooKeeper-based coordination layer; each CSP runs a broker that interacts with local resources (such as Kubernetes-managed clusters). We quantitatively evaluate our implementation by simulation. The results confirm that CloudShare generates on the average more fair schedules than the popular FairShare algorithm. We believe our results show an viable alternative to monetary methods based on, e.g., spot markets.","publicationDate":"2018-04-22T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3209914.3209934","title":"research-article ","type":"An Extended Virtual Network Functions Manager Architecture to Support Container","venue":"ICISS '18: Proceedings of the 2018 International Conference on Information Science and System","authors":["Cong-Phuoc Hoang","Ngoc-Thanh Dinh","YoungHan Kim"],"abstract":"Network function virtualization (NFV) is a network architecture concept that decouples network functions from hardware. With NFV, virtual network functions (VNFs) can easily be instantiated and deployed on standard servers using virtual machines (VMs). To facilitate VNFs' deployment and management, Tacker is developed as a NFV manager (NFVM) and orchestrator (NFVO) in OpenStack environments. Recently, container is proposed as a promising virtualization technology for deploying and running distributed applications without launching an entire VM for each application, which helps increase cloud agility and accelerate the deployments of cloud technologies and VNFs. Unfortunately, the current VNF manager and orchestrator, Tacker, do not support container-based VNFs, thus introduces limitations to integrate container-based VNFs to the current NFV infrastructure (NFVI). In this paper, we design an extended Tacker architecture to support managing and orchestrating container-based VNFs. The Kubernetes cluster is integrated to support launching container-based VNFs and provide high availability for VNFs. Through test-bed results, we show the advantages of container-based VNFs using our architecture compared to VM-based VNFs in terms of instantiation time in Tacker.","publicationDate":"2018-04-26T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.5555/3433701.3433820","title":"research-article ","type":"An efficient and non-intrusive GPU scheduling framework for deep learning training systems","venue":"SC '20: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","authors":["Shaoqi Wang","Oscar J. Gonzalez","Xiaobo Zhou","Thomas Williams","Brian D. Friedman","Martin Havemann","Thomas Woo"],"abstract":"Efficient GPU scheduling is the key to minimizing the execution time of the Deep Learning (DL) training workloads. DL training system schedulers typically allocate a fixed number of GPUs to each job, which inhibits high resource utilization and often extends the overall training time. The recent introduction of schedulers that can dynamically reallocate GPUs has achieved better cluster efficiency. This dynamic nature, however, introduces additional overhead by terminating and restarting jobs or requires modification to the DL training frameworks.We propose and develop an efficient, non-intrusive GPU scheduling framework that employs a combination of an adaptive GPU scheduler and an elastic GPU allocation mechanism to reduce the completion time of DL training workloads and improve resource utilization. Specifically, the adaptive GPU scheduler includes a scheduling algorithm that uses training job progress information to determine the most efficient allocation and reallocation of GPUs for incoming and running jobs at any given time. The elastic GPU allocation mechanism works in concert with the scheduler. It offers a lightweight and non-intrusive method to reallocate GPUs based on a \"SideCar\" process that temporarily stops and restarts the job's DL training process with a different number of GPUs. We implemented the scheduling framework as plugins in Kubernetes and conducted evaluations on two 16-GPU clusters with multiple training jobs based on TensorFlow. Results show that our proposed scheduling framework reduces the overall execution time and the average job completion time by up to 45% and 63%, respectively, compared to the Kubernetes default scheduler. Compared to a termination-based scheduler, our framework reduces the overall execution time and the average job completion time by up to 20% and 37%, respectively.","publicationDate":"2020-11-08T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3311790.3396671","title":"research-article ","type":"Workflow Submit Nodes as a Service on Leadership Class Systems","venue":"PEARC '20: Practice and Experience in Advanced Research Computing","authors":["George Papadimitriou","Karan Vahi","Jason Kincl","Valentine Anantharaj","Ewa Deelman","Jack Wells"],"abstract":"DOE scientists, today, have access to high performance computing (HPC) facilities with very powerful systems that enable them to execute their computations faster, more efficiently, and at greater scales than ever before. To further their knowledge and produce new discoveries, scientists rely on workflows - sometimes very complex - that provide them with an easy way to automate, reproduce and verify their computations. However, historically, creating workflow submission environments in large HPC facilities has been cumbersome, requires expertise and many man-hours of effort due to the peculiarities, policies, and the restrictions that these systems present. In this paper we discuss the approach a large DOE facility (OLCF) is taking in order to provide containers as a service to its users. This capability is used to create Pegasus workflow management system submit nodes as a service (WSaaS) at the Oak Ridge Leadership Computing Facilities (OLCF), targeting the Summit supercomputer. This deployment builds upon the Kubernetes/Openshift cluster (Slate) that exists within OLCF’s DMZ and its automation triggers. Additionally, we evaluate our approach’s overhead and effort to deploy the solution as compared to previous solutions, such as setting up a Pegasus submission environment on OLCF’s login nodes or submitting jobs remotely via the rvGAHP.","publicationDate":"2020-07-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3378065.3378138","title":"research-article ","type":"An Improved Container Cloud Resource Scheduling Strategy","venue":"ICIIP 2019: Proceedings of the 2019 4th International Conference on Intelligent Information Processing","authors":["Cai Zhiyong","Xie Xiaolan"],"abstract":"Docker as the representative container technology promotes the rapid development of container cloud with its flexible, efficient and fast characteristics. As a better resource virtualization technology, container is widely recognized and favored by the industry. The resource scheduling strategy in the container cloud has an important impact on the cluster performance. The default priorities strategy of Kubernetes container orchestration tool only considers CPU and memory. With the complexity of the production environment, only considering the above two factors in the priorities stage can easily lead to some node load imbalance, which is difficult to guarantee the cluster service performance. In order to balance the resources of container clusters, this paper proposes a new priorities stage strategy based on Kubernetes' default scheduling strategy, which takes the storage and network bandwidth of task nodes into account, then calculates the weight of each resource, and finally puts it into the scoring formula as the basis of resource scheduling. By comparing the load balancing rate of the default priorities scheduling algorithm and the improved priorities scheduling algorithm, it is verified that the improved container cloud resource scheduling strategy can make the load of the task nodes in the cluster more balanced.","publicationDate":"2019-11-15T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3366615.3368356","title":"research-article ","type":"Can Container Fusion Be Securely Achieved?","venue":"WOC '19: Proceedings of the 5th International Workshop on Container Technologies and Container Clouds","authors":["Sahil Suneja","Ali Kanso","Canturk Isci"],"abstract":"Linux containers are key enablers for building microservices. The application's microservices fall broadly under two categories, the core-microservices implementing the business logic and the utility-microservices implementing middleware functionalities. Such functionalities include vulnerability scanning, monitoring, telemetry, etc. Segregating the utility-microservices in separate containers from the core-microservice containers may prevent them from achieving their functionality. This is due to the strong isolation between containers. By diffusing the boundaries between containers we can fuse them together and enable close collaboration. However, this raises several security concerns, especially that the utility-microservices may include vulnerabilities that threaten the entire application. In this paper, we analyze the different techniques to enhance the security of container fusion and present an automated solution based on Kubernetes to configure utility-microservices containers to fuse with core-microservices containers.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3416012.3424633","title":"short-paper ","type":"An Evolution of Mobile IPv6 to the Cloud","venue":"MobiWac '20: Proceedings of the 18th ACM Symposium on Mobility Management and Wireless Access","authors":["Ákos Leiter","László Bokor","István Kispál"],"abstract":"The disruptions caused by Network Function Virtualization (NFV) and Software Defined Networking (SDN) introduce severe impacts also on mobility management. In this work, we will show how IP-based mobility management, especially Mobile IPv6 (MIPv6), can be redesigned to fit into the new environment. We will present an evolutionary procedure on how MIPv6 can arrive in the cloud. At the end of the process, the unique architecture of MIPv6 can run on the top of Kubernetes and OpenStack while keeping compatibility with the existing standards. Orchestration is also an environmental change, comes with cloud, where MIPv6 should be aligned with closed-loop orchestration support.","publicationDate":"2020-11-15T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3357223.3365441","title":"abstract ","type":"Accordia: Adaptive Cloud Configuration Optimization for Recurring Data-Intensive Applications","venue":"SoCC '19: Proceedings of the ACM Symposium on Cloud Computing","authors":["Yang Liu","Huanle Xu","Wing Cheong Lau"],"abstract":"Recognizing the diversity of big data analytic jobs, cloud providers offer a wide range of virtual machine (VM) instances for different use cases. The choice of cloud instance configurations can have significant impact on the response time and running cost of data-intensive, recurring jobs for production. A poor choice of cloud instance-type/configuration can substantially degrade the response time by 5x, or increase the cost by 10x. Identifying the best cloud configuration under low search budget is a challenging problem due to i) the large and high-dimensional configuration-parameters space, ii) the dynamically varying price of some instance types, iii) job response time variation even given the same configuration, and iv) gradual drifts/ unexpected changes of the characteristics of the recurring jobs. To tackle this problem, we have designed and implemented Accordia, a system which enables Adaptive Cloud Configuration Optimization for Recurring Data-Intensive Applications.Accordia extends the Gaussian-Process Upper Confidence Bound (GP-UCB) approach in [3] to search for and track the potentially dynamic optimal cloud configuration within a high-dimensional para-meter-space. Unlike other state-of-the-art schemes, such as CherryPick[1] and Arrow[2], Accordia can handle time-varying instance pricing while providing a performance guarantee of sub-linear regret when comparing with the static, offline optimial solution.Figure 1 depicts the system architecture of our implementation of Accordia for Apache Spark running over Kubernetes. When a job is submitted, a Spark driver and multiple Spark executors are deployed as containers, each within its own Kubernetes pod. Accordia then dynamically adjusts the resource types/ allocation for the containers within their respective pods to minimize the job completion cost using the GP-UCB online-learning approach.To evaluate the performance of Accordia, we have run different mixes of recurring Spark jobs over the Google public cloud. In our experiments, Accordia dynamically learns the best cloud configuration from over 7000 candidate choices within a 5-dimensional parameter space, covering the number of executors, as well as the number of CPU cores and memory (RAM) allocation for the driver and the executor pods. Empirical measurements show that Accordia can find a near-cost-optimal configuration for a recurring job (i.e. within 10% of the optimal cost) with fewer than 20 runs, which translates to a 2X-speedup and a 20.9% cost-savings, when comparing to CherryPick. To highlight Accordia's capability to handle abrupt/unexpected changes of the characteristics of a recurring job, we even dynamically switch the type of a recurring job (without notifying Accordia) over exponentially-distributed time-intervals. Under such cases, Accordia can still achieve on average a cost-savings of 18.4% over CherryPick. The full technical report is available at http://mobitec.ie.cuhk.edu.hk/cloudComputing/Accordia.pdf.","publicationDate":"2019-11-19T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3416505.3423560","title":"research-article ","type":"RARE: a labeled dataset for cloud-native memory anomalies","venue":"MaLTeSQuE 2020: Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation","authors":["Francesco Lomio","Diego Martínez Baselga","Sergio Moreschini","Heikki Huttunen","Davide Taibi"],"abstract":"Anomaly detection has been attracting interest from both the industry and the research community for many years, as the number of published papers and services adopted grew exponentially over the last decade. One of the reasons behind this is the wide adoption of cloud systems from the majority of players in multiple industries, such as online shopping, advertisement or remote computing. In this work we propose a Dataset foR cloud-nAtive memoRy anomaliEs: RARE. It includes labelled anomaly time-series data, comprising of over 900 unique metrics. This dataset has been generated using a microservice for injecting artificial byte stream in order to overload the nodes, provoking memory anomalies, which in some cases resulted in a crash. The system was built using a Kafka server deployed on a Kubernetes system. Moreover, in order to get access and download the metrics related to the server, we utilised Prometheus. In this paper we present a dataset that can be used coupled with machine learning algorithms for detecting anomalies in a cloud based system. The dataset will be available in the form of CSV file through an online repository. Moreover, we also included an example of application using a Random Forest algorithm for classifying the data as anomalous or not. The goal of the RARE dataset is to help in the development of more accurate and reliable machine learning methods for anomaly detection in cloud based systems.","publicationDate":"2020-11-12T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3219104.3219122","title":"research-article ","type":"Deploying Jupyter Notebooks at scale on XSEDE resources for Science Gateways and workshops","venue":"PEARC '18: Proceedings of the Practice and Experience on Advanced Research Computing","authors":["Andrea Zonca","Robert S. Sinkovits"],"abstract":"Jupyter Notebooks have become a mainstream tool for interactive computing in every field of science. Jupyter Notebooks are suitable as companion applications for Science Gateways, providing more flexibility and post-processing capability to the users. Moreover they are often used in training events and workshops to provide immediate access to a pre-configured interactive computing environment. The Jupyter team released the JupyterHub web application to provide a platform where multiple users can login and access a Jupyter Notebook environment. When the number of users and memory requirements are low, it is easy to setup JupyterHub on a single server. However, setup becomes more complicated when we need to serve Jupyter Notebooks at scale to tens or hundreds of users. In this paper we will present three strategies for deploying JupyterHub at scale on XSEDE resources. All options share the deployment of JupyterHub on a Virtual Machine on XSEDE Jetstream. In the first scenario, JupyterHub connects to a supercomputer and launches a single node job on behalf of each user and proxies back the Notebook from the computing node back to the user's browser. In the second scenario, implemented in the context of a XSEDE consultation for the IRIS consortium for Seismology, we deploy Docker in Swarm mode to coordinate many XSEDE Jetstream virtual machines to provide Notebooks with persistent storage and quota. In the last scenario we install the Kubernetes containers orchestration framework on Jetstream to provide a fault-tolerant JupyterHub deployment with a distributed filesystem and capability to scale to thousands of users. In the conclusion section we provide a link to step-by-step tutorials complete with all the necessary commands and configuration files to replicate these deployments.","publicationDate":"2018-07-21T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3306307.3328194","title":"invited-talk ","type":"Building modern VFX infrastructure","venue":"SIGGRAPH '19: ACM SIGGRAPH 2019 Talks","authors":["Natasha Kelkar"],"abstract":"In order to meet the rapidly evolving needs of the VFX industry, studios need to be able to adapt and upgrade quickly. However, the infrastructure stack at most companies is complex, usually set up over a number of years with significant customizations and proprietary software. Maintaining this stack requires dedicated teams. Upgrades can take months and are usually fraught with risk.The engineering team at MPC drastically reduced this time to deployment from months to a few days by using cloud native solutions. Built on a foundation of microservices, the infrastructure stack provides an asset management system, storage, sync and compute capabilities. Within the first year it was deployed across two sites in different timezones, supporting up to 200 artists. Thus proving the ability for VFX studios to scale rapidly.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3319647.3325852","title":"poster ","type":"Runbox: serverless interactive computing platform","venue":"SYSTOR '19: Proceedings of the 12th ACM International Conference on Systems and Storage","authors":["Alex Glikson","Shichao Nie","David Breitgand"],"abstract":"Serverless computing revolutionizes cloud software by eliminating the need to manage the underlying infrastructure, while providing efficient scaling, performance and security isolation as well as usage metering.The goal of Runboxes is to bring the benefits of serverless computing to Interactive Computing, involving ad-hoc, stateful, resource-intensive tasks, whose resource demand is directly affected by the observed user behavior. We evaluate Runboxes in the context of cost-efficient hosting of sandbox programming environments for Computer Science students.","publicationDate":"2019-05-21T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3332186.3332192","title":"research-article ","type":"Singularity: Simple, secure containers for compute-driven workloads","venue":"PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning)","authors":["David Godlove"],"abstract":"Container technology makes it easy to create highly portable and reproducible research environments. The Singularity container platform has a unique security model allowing untrusted users to run untrusted containers safely on multi-tenant systems. Singularity has a special file format (called the Singularity Image Format or SIF) for packaging and distributing containers. This format allows for novel features like cryptographic signing and verification of containers, extreme portability, and guaranteed reproducibility. The Singularity runtime supports both integration as well as isolation, making it easy to read and write data to the host system, leverage hardware like GPUs and high-speed interconnects, and integrate with batch schedulers like Slurm, PBS, LSF, UGE, etc. This emphasis on integration is part of the overall development philosophy: Singularity is intended to be a simple, secure, feature-rich container solution. Sylabs Inc. has developed SingularityPRO, a professionally curated and supported version of the open source offering as well as the Singularity Container Services, an end-to-end cloud hosted solution for creating and distributing trusted containers. Most top HPC centers use Singularity in production, and enterprise users are rapidly adopting this solution as well.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3437359.3465591","title":"short-paper ","type":"A Scalable Cloud-based Architecture to Deploy JupyterHub for Computational Social Science Research","venue":"PEARC '21: Practice and Experience in Advanced Research Computing","authors":["Da Li","Robert Pyke","Runchao Jiang"],"abstract":" With the increasing popularity of computational approaches to conduct social science research, building a scalable and efficient computing platform has become a topic of interest for academia to empower research labs and institutes to analyze large-scale data. While social science researchers have been very excited about the advancement of emerging technologies in big data, deep learning, computer vision, network analysis, etc., they are also constrained by the available computing resources to analyze data. This paper describes a scalable solution to deploy JupyterHub for computational social science research on the cloud. We use a reference architecture on AWS to walk through the design principles and details. Our architecture has helped facilitate several collaborations between Facebook and academia. The case study (Facebook Open Research and Transparency platform) shows that our architecture, using technologies like containerization and serverless computing, can support thousands of users to analyze web-scale datasets. ","publicationDate":"2021-07-16T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3378891.3378899","title":"research-article ","type":"On-Premise AI Platform: From DC to Edge","venue":"ICRSA 2019: Proceedings of the 2019 2nd International Conference on Robot Systems and Applications","authors":["Bukhary Ikhwan Ismail","Mohammad Fairus Khalid","Rajendar Kandan","Ong Hong Hoe"],"abstract":"Artificial Intelligence (AI) is powering everything from devices, applications and services. Machine learning a branch of AI requires powerful infrastructure platform to do training and to serve the AI model. In this paper, we share our blueprint to build and host internal on-premise AI platform. We make use of our existing services such as private cloud, distributed storage, unified authentication platform, and build the AI platform on top of it. We discuss the requirements gathered from user, the technologies to make it possible, implementation and lesson learned from hosting it internally. Based on our evaluation, based on specific need, it is economical and viable option to host on-premise AI Platform.","publicationDate":"2019-08-03T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3388440.3414911","title":"abstract ","type":"A Unified Cloud-Native Architecture For Heterogeneous Data Aggregation And Computation","venue":"BCB '20: Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics","authors":["Fatemeh Rouzbeh","Ananth Grama","Paul Griffin","Mohammad Adibuzzaman"],"abstract":"Improving healthcare depends on collecting and analyzing different types of health related data such as Electronic Health Records (EHR), Patient Generated Health Data (PGHD), prescription and medication data and medical image data. Even though different solutions in terms of storage and processing have been designed and developed but each solution is usually designed for a specific type of data. Storing, processing, and analyzing all types of data using a single solution necessarily doesn't result in best performance and quality of analysis. To acquire the better quality, each types of data requires its own type of storage, data processing and machine learning solutions which cannot be integrated as a unified system in some cases. In order to have a unified system that serves all types of data we propose a modular cloud native architecture with autonomous modules in terms of control, deployment and management for each types of data.","publicationDate":"2020-09-20T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3034950.3034965","title":"research-article ","type":"FAS: A Flow Aware Scaling Mechanism for Stream Processing Platform Service based on LMS","venue":"ICMSS '17: Proceedings of the 2017 International Conference on Management Engineering, Software Engineering and Service Sciences","authors":["Yongfeng Wu","Ruonan Rao","Pei Hong","Jin Ma"],"abstract":"Stream Processing Platform Service (SPPS is a service built on container cloud and implemented for purpose to develop a stream processing application with simple configuration. The service needs to provide scaling ability in order to adjust system capacity for dynamic incoming data volume. Data flow is a significant indicator for system load thus it becomes a fundamental factor for analyzing. Data flow prediction thus becomes important in order to improve Quality of Service (QoS) as well as optimize resource usage. In this paper, an approach applying Least Mean Squares (LMS) on data flow prediction with a scaling mechanism for system scaling is proposed. The algorithm takes period time and data flow into consideration to predicate the required resource for processing. After the data flow prediction is calculated, decision for new coming data is made, the service scales the processing cluster in advance for predicted volume. The experiment shows the method is effective for periodically changed data flow.","publicationDate":"2017-01-13T23:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3297663.3310309","title":"short-paper ","type":"Performance Modeling for Cloud Microservice Applications","venue":"ICPE '19: Proceedings of the 2019 ACM/SPEC International Conference on Performance Engineering","authors":["Anshul Jindal","Vladimir Podolskiy","Michael Gerndt"],"abstract":"Microservices enable a fine-grained control over the cloud applications that they constitute and thus became widely-used in the industry. Each microservice implements its own functionality and communicates with other microservices through language- and platform-agnostic API. The resources usage of microservices varies depending on the implemented functionality and the workload. Continuously increasing load or a sudden load spike may yield a violation of a service level objective (SLO). To characterize the behavior of a microservice application which is appropriate for the user, we define a MicroService Capacity (MSC) as a maximal rate of requests that can be served without violating SLO.The paper addresses the challenge of identifying MSC individually for each microservice. Finding individual capacities of microservices ensures the flexibility of the capacity planning for an application. This challenge is addressed by sandboxing a microservice and building its performance model. This approach was implemented in a tool Terminus. The tool estimates the capacity of a microservice on different deployment configurations by conducting a limited set of load tests followed by fitting an appropriate regression model to the acquired performance data. The evaluation of the microservice performance models on microservices of four different applications shown relatively accurate predictions with mean absolute percentage error (MAPE) less than 10%.The results of the proposed performance modeling for individual microservices are deemed as a major input for the microservice application performance modeling.","publicationDate":"2019-04-03T22:00:00.000Z","citationCount":21},{"url":"https://dl.acm.org/doi/10.1145/3241403.3241418","title":"extended-abstract ","type":"A microservices experience in the banking industry","venue":"ECSA '18: Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings","authors":["David García Gil","Rubén Aguilera Díaz-Heredero"],"abstract":"The traditional banking industry is not traditional anymore. Society, economics, regulations and last but not least technology have changed, fostering what could be called a \"second baking revolution\" (the first one being the introduction of computer-based information systems).","publicationDate":"2018-09-23T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3147234.3148100","title":"research-article ","type":"Cloud Robotics: SLAM and Autonomous Exploration on PaaS","venue":"UCC '17 Companion: Companion Proceedings of the10th International Conference on Utility and Cloud Computing","authors":["Giovanni Toffetti","Tobias Lötscher","Saken Kenzhegulov","Josef Spillner","Thomas Michael Bohnert"],"abstract":"Robots are moving out of factories, service robotics is bringing them to our homes, work environments, cities, and outdoors. While the Robot Operating System (ROS) is promising to open the world of robotics to developers, a proper platform and ecosystem supporting robotic applications development is still missing. This work presents an example of cloud robotics application in which cloud computing is not just complementing limited robot capabilities, but is leveraged to provide a development and operations environment supporting the complete life-cycle of a robotics-enabled application. We relate on our experience building cloud robotics applications spanning heterogeneous hardware (i.e., robots and cloud servers) through a use case scenario.","publicationDate":"2017-12-04T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3307334.3328640","title":"poster ","type":"Multi-Access Edge Computing based Simulation Offloading for 5G Mobile Application (poster)","venue":"MobiSys '19: Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services","authors":["Sungjoo Kang","Junhee Lee","Jaeho Jeon","Ingeol Chun"],"abstract":"Simulation is a method of predicting future events and system states through analysis of the state model of the system over time. It can support to make decisions of mobile terminals (ex. threat assessment in an autonomous vehicle) operating in various situations under uncertain reality. Unlike a single simulation, which is executed in one mobile terminal using data collected from the same terminal, a multiple simulation, which supports to make sophisticated decisions through data collected from multiple terminals, is not only complicated to implement but also requires a large number of computations and has network delay problem in collecting data from plenty of data sources [1]. Consequently, it is impossible to implement in a single mobile terminal.","publicationDate":"2019-06-11T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3368308.3415380","title":"research-article ","type":"A Case Study in Comparative Speech-to-Text Libraries for Use in Transcript Generation for Online Education Recordings","venue":"SIGITE '20: Proceedings of the 21st Annual Conference on Information Technology Education","authors":["Pablo Ángel Álvarez Fernández","Jeremy R. Hajek"],"abstract":"With a proliferation of Cloud based Speech-to-Text services it can be difficult to decide where to start and how to make use of these technologies. These include the major Cloud providers as well as several Open Source Speech-to-Text projects available. We desired to investigate a sample of the available libraries and their attributes relating to the recording artifacts that are the by-product of Online Education.The fact that so many resources are available means that the computing and technical barriers for applying speech recognition algorithms have decreased to the point of being a non-factor in the decision to use Speech-to-Text services. New barriers such as price, compute time, and access to the services? source code (software freedom) can be factored into the decision of which platform to use.This case study provides a beginning to developing a test-suite and guide to compare Speech-to-Text libraries and their out-of-the-box accuracy. Our initial test suite employed two models: 1) a Cloud model employing AWS S3 using AWS Transcribe, 2) an on-premises Open Source model that relies on Mozilla's DeepSpeech[1]. We present our findings and recommendations based on the criteria discovered.In order to deliver this test-suite, we also conducted research into the latest web development technologies with emphasis on security. This was done to produce a reliable and secure development process and to provide open access to this proof of concept for further testing and development.","publicationDate":"2020-10-06T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3400286.3418277","title":"poster ","type":"Design and Implementation of Analytical Load Balancing between Distributed Collaborative Container Platforms","venue":"RACS '20: Proceedings of the International Conference on Research in Adaptive and Convergent Systems","authors":["Jae-Seung Han","Jae-Hoon An","Younghwan Kim"],"abstract":"Container-based Micro Service technology has problems with the limitations of resource expansion and the inability to move services between container platforms to respond to growing user traffic. For this reason, distributed collaborative container plat-form(DCCP) technology has emerged that provides the expansion and availability of services and enables collaboration among locally distributed container platforms. DCCP is an essential technology to overcome the limitations of existing stand-alone container platforms by maximizing flexible expansion of resources and service mobility through collaboration between distributed platforms. In this paper, the inter-platform traffic load balancing technology is proposed to construct DDCP. The proposed technology analyzes the user's traffic, identifies the user's geographic location information, and calculates scores for each distributed platform. The scoring method calculates the geographical score based on the platform's geographical location information and the user's geographical location, and calculates the resource score by analyzing the platform's resource status. Transport traffic through the calculated geographical scores and resource scores to the platform that holds the highest scores. The proposed technology provides analytical load balancing technology that addresses the non-efficient problem of randomly dispersing loads on existing independent platforms by load balancing according to the location and resource status of the platform.","publicationDate":"2020-10-12T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3418899","title":"research-article ","type":"A Black-box Monitoring Approach to Measure Microservices Runtime Performance","venue":"ACM Transactions on Architecture and Code Optimization","authors":["Rolando Brondolin","Marco D. Santambrogio"],"abstract":"Microservices changed cloud computing by moving the applications’ complexity from one monolithic executable to thousands of network interactions between small components. Given the increasing deployment sizes, the architectural exploitation challenges, and the impact on data-centers’ power consumption, we need to efficiently track this complexity. Within this article, we propose a black-box monitoring approach to track microservices at scale, focusing on architectural metrics, power consumption, application performance, and network performance. The proposed approach is transparent w.r.t. the monitored applications, generates less overhead w.r.t. black-box approaches available in the state-of-the-art, and provides fine-grain accurate metrics.","publicationDate":"2020-11-09T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3341617.3326143","title":"research-article ","type":"Optimizing the Cost of Executing Mixed Interactive and Batch Workloads on Transient VMs","venue":"Proceedings of the ACM on Measurement and Analysis of Computing Systems","authors":["Pradeep Ambati","David Irwin"],"abstract":"Container Orchestration Platforms (COPs), such as Kubernetes, are increasingly used to manage large-scale clusters by automating resource allocation between applications encapsulated in containers. Increasingly, the resources underlying COPs are virtual machines (VMs) dynamically acquired from cloud platforms. COPs may choose from many different types of VMs offered by cloud platforms, which differ in their cost, performance, and availability. In particular, while transient VMs cost significantly less than on-demand VMs, platforms may revoke them at any time, causing them to become unavailable. While transient VMs' price is attractive, their unreliability is a problem for COPs designed to support mixed workloads composed of, not only delay-tolerant batch jobs, but also long-lived interactive services with high availability requirements. To address the problem, we design TR-Kubernetes, a COP that optimizes the cost of executing mixed interactive and batch workloads on cloud platforms using transient VMs. To do so, TR-Kubernetes enforces arbitrary availability requirements specified by interactive services despite transient VM unavailability by acquiring many more transient VMs than necessary most of the time, which it then leverages to opportunistically execute batch jobs when excess resources are available. When cloud platforms revoke transient VMs, TR-Kubernetes relies on existing Kubernetes functions to internally revoke resources from batch jobs to maintain interactive services' availability requirements. We show that TR-Kubernetes requires minimal extensions to Kubernetes, and is capable of lowering the cost (by 53%) and improving the availability (99.999%) of a representative interactive/batch workload on Amazon EC2 when using transient compared to on-demand VMs.","publicationDate":"2019-06-18T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3309697.3331489","title":"extended-abstract ","type":"Optimizing the Cost of Executing Mixed Interactive and Batch Workloads on Transient VMs","venue":"SIGMETRICS '19: Abstracts of the 2019 SIGMETRICS/Performance Joint International Conference on Measurement and Modeling of Computer Systems","authors":["Pradeep Ambati","David Irwin"],"abstract":"Container Orchestration Platforms (COPs), such as Kubernetes, are increasingly used to manage large-scale clusters by automating resource allocation between applications encapsulated in containers. Increasingly, the resources underlying COPs are virtual machines (VMs) dynamically acquired from cloud platforms. COPs may choose from many different types of VMs offered by cloud platforms, which differ in their cost, performance, and availability. While transient VMs cost significantly less than on-demand VMs, platforms may revoke them at any time, causing them to become unavailable. While transient VMs' price is attractive, their unreliability is a problem for COPs designed to support mixed workloads composed of, not only delay-tolerant batch jobs, but also long-lived interactive services with high availability requirements.To address the problem, we design TR-Kubernetes, a COP that optimizes the cost of executing mixed interactive and batch workloads on cloud platforms using transient VMs. To do so, TR-Kubernetes enforces arbitrary availability requirements specified by interactive services despite transient VM unavailability by acquiring many more transient VMs than necessary most of the time, which it then leverages to opportunistically execute batch jobs when excess resources are available. When cloud platforms revoke transient VMs, TR-Kubernetes relies on existing Kubernetes functions to internally revoke resources from batch jobs to maintain interactive services' availability requirements. We show that TR-Kubernetes requires minimal extensions to Kubernetes, and is capable of lowering the cost (by 53%) and improving the availability (99.999%) of a representative interactive/batch workload on Amazon EC2 when using transient compared to on-demand VMs.","publicationDate":"2019-06-19T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3376930.3376960","title":"research-article ","type":"Optimizing the Cost of Executing Mixed Interactive and Batch Workloads on Transient VMs","venue":"ACM SIGMETRICS Performance Evaluation Review","authors":["Pradeep Ambati","David Irwin"],"abstract":"Container Orchestration Platforms (COPs), such as Kubernetes, are increasingly used to manage large-scale clusters by automating resource allocation between applications encapsulated in containers. Increasingly, the resources underlying COPs are virtual machines (VMs) dynamically acquired from cloud platforms. COPs may choose from many different types of VMs offered by cloud platforms, which differ in their cost, performance, and availability. While transient VMs cost significantly less than on-demand VMs, platforms may revoke them at any time, causing them to become unavailable. While transient VMs' price is attractive, their unreliability is a problem for COPs designed to support mixed workloads composed of, not only delay-tolerant batch jobs, but also long-lived interactive services with high availability requirements.To address the problem,we design TR-Kubernetes, a COP that optimizes the cost of executing mixed interactive and batch workloads on cloud platforms using transient VMs. To do so, TR-Kubernetes enforces arbitrary availability requirements specified by interactive services despite transient VM unavailability by acquiring many more transient VMs than necessary most of the time, which it then leverages to opportunistically execute batch jobs when excess resources are available. When cloud platforms revoke transient VMs, TR-Kubernetes relies on existing Kubernetes functions to internally revoke resources from batch jobs to maintain interactive services' availability requirements. We show that TR-Kubernetes requires minimal extensions to Kubernetes, and is capable of lowering the cost (by 53%) and improving the availability (99.999%) of a representative interactive/batch workload on Amazon EC2 when using transient compared to on-demand VMs.","publicationDate":"2019-12-16T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3297280.3297536","title":"poster ","type":"Performance overhead of container orchestration frameworks for management of multi-tenant database deployments","venue":"SAC '19: Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing","authors":["Eddy Truyen","Dimitri Van Landuyt","Bert Lagaisse","Wouter Joosen"],"abstract":"The most preferred approach in the literature on service-level objectives for multi-tenant databases is to group tenants according to their SLA class in separate database processes and find optimal co-placement of tenants across a cluster of nodes. To implement performance isolation between co-located database processes, request scheduling is preferred over hypervisor-based virtualization that introduces a significant performance overhead. A relevant question is whether the more light-weight container technology such as Docker is a viable alternative for running high-end performance database workloads. Moreover, the recent uprise and industry adoption of container orchestration (CO) frameworks for the purpose of automated placement of cloud-based applications raises the question what is the additional performance overhead of CO frameworks in this context. In this paper, we evaluate the performance overhead introduced by Docker engine and two representative CO frameworks, Docker Swarm and Kubernetes, when running and managing a CPU-bound Cassandra workload in OpenStack. Firstly, we have found that Docker engine deployments that run in host mode exhibit negligible performance overhead in comparison to native OpenStack deployments. Secondly, we have found that virtual IP networking introduces a substantial overhead in Docker Swarm and Kubernetes due to virtual network bridges when compared to Docker engine deployments. This demands for service networking approaches that run in true host mode but offer support for network isolation between containers. Thirdly, volume plugins for persistent storage have a large impact on the overall resource model of a database workload; more specifically, we show that a CPU-bound Cassandra workload changes into an I/O-bound workload in both Docker Swarm and Kubernetes because their local volume plugins introduce a disk I/O performance bottleneck that does not appear in Docker engine deployments. These findings imply that solved placement decisions for native or Docker engine deployments cannot be reused for Docker Swarm and Kubernetes.","publicationDate":"2019-04-07T22:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3341105.3374034","title":"research-article ","type":"Feasibility of container orchestration for adaptive performance isolation in multi-tenant SaaS applications","venue":"SAC '20: Proceedings of the 35th Annual ACM Symposium on Applied Computing","authors":["Eddy Truyen","André Jacobs","Stef Verreydt","Emad Heydari Beni","Bert Lagaisse","Wouter Joosen"],"abstract":"SaaS application instances typically serve multiple tenants to improve cost-efficiency. This results in the need for adaptive performance isolation between tenants in order to guarantee custom service level objectives (SLOs) about request latency or throughput. Current solutions, which are based on request scheduling algorithms, suffer from SLO instability under globally varying workloads. This means that the configuration for an SLO has to be recalibrated when total workload patterns change such as an increase or decrease in the number of subscribed tenants, or the application becomes co-located with other types of resource-intensive applications. Lately container technology such as Docker and container orchestration frameworks like Kubernetes have been used to increase cost-efficiency, multi-tenancy and elasticity. This paper investigates if the problem of adaptive performance isolation can be mapped to resource management concepts of Kubernetes through a series of experiments. These experiments show that Kubernetes provides good support for QoS differentiation and adaptive resource allocation by grouping tenants according to their SLO class (e.g gold vs bronze) in different containers. Moreover, SLO instability does not occur when co-locating these containers with other container-based applications provided that a few interferences between CPU-, memory- and disk-io intensive applications are taken into account. However SLO instability does occur when the number of subscribed tenants changes. This latter problem is not caused by the replication and auto-scaling concepts of Kubernetes, but by a non-linear resource scaling phenomenon that is inherent when the goal is to meet multiple custom SLOs in a cost-optimal way.","publicationDate":"2020-03-29T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3267809.3275466","title":"poster ","type":"The Curious Case of Container Orchestration and Scheduling in GPU-based Datacenters","venue":"SoCC '18: Proceedings of the ACM Symposium on Cloud Computing","authors":["Prashanth Thinakaran","Jashwant Raj","Bikash Sharma","Mahmut T. Kandemir","Chita R. Das"],"abstract":"Modern data centers are increasingly being provisioned with compute accelerators such as GPUs, FPGAs and ASIC's to catch up with the workload performance demands and reduce the total cost of ownership (TCO). By 2021, traffic within hyperscale datacenters is expected to quadruple with 94% of workloads moving to cloud-based datacenters according to Cisco's global cloud index. A majority of these workloads include data mining, image processing, speech recognition and gaming which uses GPUs for high throughput computing. This trend is evident as public cloud operators like Amazon and Microsoft have started to offer GPU-based infrastructure services in the recent times.The GPU-bound applications in general, can either be batch or latency-sensitive. Typically the latency-critical applications subscribe to datacenter resources in the form of queries (e.g. inference requests from a DNN model). For example, a wearable health monitoring device aggregates several sensor data through a mobile application. In case of a data anomaly, inference services can be triggered from the mobile device to the cloud, requesting for a deep neural network (DNN) model that fits the symptom. Such inference requests which are GPU bound impose strict Service Level Agreements (SLAs) that is typically set around 150 to 500ms. In contrast to the regular datacenter batch workloads, these user-facing applications are typically hosted as services that occur and scale in short bursts. On the other hand, batch applications are HPC based compute-bound workloads which are throughput oriented. In a typical datacenter, these both applications might co-exist on the same device depends on the orchestration and scheduling policy. With the expected increase in such workloads, this GPU resource management problem is expected to exacerbate. Hence, GPUs/accelerators are on the critical path to ensure the performance and meet the end-to-end latency demands of such queries.State-of-the-art resource orchestrators are agnostic of GPUs and their resource utilization footprints, and thus not equipped to dynamically orchestrate these accelerator-bound containers. On the other hand, job schedulers at the datacenter are heavily optimized and tuned for CPU-based systems. Kubernetes and Mesos by default does uniform task scheduling which statically assigns the GPU resources to the applications. The scheduled tasks access the GPUs via PCIe pass-through which gives the application complete access to the GPU as seen in Figure 1. Hence the resource utilization of the GPU is based on the parallelism of the application which is scheduled to run on it. In case of CPUs, Kubernetes has support for dynamic orchestration with the features such as node affinity, pod affinity, and pod preemption. However, these features cannot be extended for GPUs. This is because, it neither has the support for pod preemption nor the ability to query the real-time GPU metrics such as memory, symmetric multiprocessor (SM) utilization, PCIe bandwidth, etc. Moreover, the containers often overstate their GPU resource requirements such as memory, and this leads to severe resource underutilization which leads to multiple QoS violations because of queuing delays. We identify that by employing CPU-based scheduling policies for GPU-bound workloads would fail to yield high accelerator utilization and lead to poor performance per watt per query. Motivated by this, we propose a GPU-aware resource orchestration layer which enables the resource scheduler to take advantage of the GPUs by knowing their real-time utilization.We further discuss the ideal scheduler properties for a GPU rich datacenter and list the challenges in developing such a production-grade GPU-based datacenter scheduler. Therefore we modify the well-known Google's Kubernetes datacenter-level resource orchestrator by making it GPU-aware by exposing GPU driver APIs. Based on our observations from Alibaba's cluster traces and real hardware GPU cluster experiments, we build Knots, a GPU-aware resource orchestration layer and integrate it with Kubernetes container orchestrator. In addition, we also evaluate three GPU-based scheduling schemes to schedule datacenter representative GPU workload mixes through Kube-Knots. Evaluations on a ten node GPU cluster demonstrate that Knots together with our proposed GPU-aware scheduling scheme improves the cluster-wide GPU utilization while significantly reducing the cluster-wide power consumption across three different workload mixes when compared against Kubernetes's default uniform scheduler.","publicationDate":"2018-10-10T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3369583.3392679","title":"research-article ","type":"KubeShare: A Framework to Manage GPUs as First-Class and Shared Resources in Container Cloud","venue":"HPDC '20: Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing","authors":["Ting-An Yeh","Hung-Hsin Chen","Jerry Chou"],"abstract":"Container has emerged as a new technology in clouds to replace virtual machines~(VM) for distributed applications deployment and operation. With the increasing number of new cloud-focused applications, such as deep learning and high performance applications, started to reply on the high computing throughput of GPUs, efficiently supporting GPU in container cloud becomes essential. While GPU virtualization has been extensively studied for VM, limited work has been done for containers. One of the key challenges is the lack of support for GPU sharing between multiple concurrent containers. This limitation leads to low resource utilization when a GPU device cannot be fully utilized by a single application due to the burstiness of GPU workload and the limited memory bandwidth. To overcome this issue, we designed and implemented KubeShare, which extends Kubernetes to enable GPU sharing with fine-grained allocation. KubeShare is the first solution for Kubernetes to make GPU device as a first class resources for scheduling and allocations. Using real deep learning workloads, we demonstrated KubeShare can significantly increase GPU utilization and overall system throughput around 2x with less than 10% performance overhead during container initialization and execution.","publicationDate":"2020-06-22T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3397271.3401397","title":"short-paper ","type":"Agent Dialogue: A Platform for Conversational Information Seeking Experimentation","venue":"SIGIR '20: Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval","authors":["Adam Czyzewski","Jeffrey Dalton","Anton Leuski"],"abstract":"Conversational Information Seeking (CIS) is an emerging area of Information Retrieval focused on interactive search systems. As a result there is a need for new benchmark datasets and tools to enable their creation. In this demo we present the Agent Dialogue (AD) platform, an open-source system developed for researchers to perform Wizard-of-Oz CIS experiments. AD is a scalable cloud-native platform developed with Docker and Kubernetes with a flexible and modular micro-service architecture built on production-grade state-of-the-art open-source tools (Kubernetes, gRPC streaming, React, and Firebase). It supports varied front-ends and has the ability to interface with multiple existing agent systems, including Google Assistant and open-source search libraries. It includes support for centralized structure logging as well as offline relevance annotation.","publicationDate":"2020-07-24T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3366623.3368135","title":"research-article ","type":"Towards Serverless as Commodity: a case of Knative","venue":"WOSC '19: Proceedings of the 5th International Workshop on Serverless Computing","authors":["Nima Kaviani","Dmitriy Kalinin","Michael Maximilien"],"abstract":"Serverless computing promises to evolve cloud computing architecture from VMs and containers-as-a-service (CaaS) to function-as-a-service (FaaS). This takes away complexities of managing and scaling underlying infrastructure and can result in simpler code, cheaper realization of services, and higher availability. Nonetheless, one of the primary drawbacks customers face when making decision to move their software to a serverless platform is the potential for getting locked-in with a particular provider. This used to be a concern with Platform-as-a-Service (PaaS) offerings too. However with Kubernetes emerging as the industry standard PaaS layer, PaaS is closer to becoming commodity with the Kubernetes API as its common interface. The question is if a similar unification for the API interface layer and runtime contracts can be achieved for serverless. If achieved, this would free up serverless users from their fears of platform lock-in. Our goal in this paper is to extract a minimal common denominator model of execution that can move us closer to a unified serverless platform. As contributors to Knative [13] with in-depth understanding of its internal design, we use Knative as the baseline for this comparison and contrast its API interface and runtime contracts against other prominent serverless platforms to identify commonalities and differences. Influenced by the work in Knative, we also discuss challenges as well as the necessary evolution we expect to see as serverless platforms themselves reach commodity status.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3152881.3152887","title":"research-article ","type":"Adaptive sensing using internet-of-things with constrained communications","venue":"ARM '17: Proceedings of the 16th Workshop on Adaptive and Reflective Middleware","authors":["Mahmudur Rahman","Hua-Jun Hong","Amatur Rahman","Pei-Hsuan Tsai","Afia Afrin","Md Yusuf Sarwar Uddin","Nalini Venkatasubramanian","Cheng-Hsin Hsu"],"abstract":"In this paper, we design and implement an Internet-of-Things (IoT) based platform for developing cities using environmental sensing as driving application with a set of air quality sensors that periodically upload sensor data to the cloud. Ubiquitous and free WiFi access is unavailable in most developing cities; IoT deployments must leverage 3G cellular connections that are expensive and metered. In order to best utilize the limited 3G data plan, we envision two adaptation strategies to drive sensing and sensemaking. The first technique is an infrastructure-level adaptation approach where we adjust sensing intervals of periodic sensors so that the data volume remains bounded within the plan. The second approach is at the information-level where application-specific analytics are deployed on board devices (or the edge) through container technologies (Docker and Kubernetes); the use case focuses on multimedia sensors that process captured raw information to lower volume semantic data that is communicated. This approach is implemented through the EnviroSCALE (Environmental Sensing and Community Alert Network) platform, an inexpensive Raspberry Pi based environmental sensing system that periodically publishes sensor data over a 3G connection with a limited data plan. We outline our deployment experience of EnviroSCALE in Dhaka city, the capital of Bangladesh. For information-level adaptation, we enhanced EnviroSCALE with Docker containers with rich media analytics, along Kubernetes for provisioning IoT devices and deploying the Docker images. To limit data communication overhead, the Docker images are preloaded in the board but a small footprint of analytic code is transferred whenever required. Our experiment results demonstrate the practicality of adaptive sensing and triggering rich sensing analytics via user-specified criteria, even over constrained data connections.","publicationDate":"2017-12-10T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3456727.3463833","title":"research-article ","type":"Self managed data protection for containers","venue":"SYSTOR '21: Proceedings of the 14th ACM International Conference on Systems and Storage","authors":["Umesh Deshpande","Nick Linck","Sangeetha Seshadri"],"abstract":"Container frameworks have been gaining popularity in recent years, with container native storage being one of the fastest growing segment. According to IDC report [1], 90% of applications on cloud platforms and over 95% of new microservices are being deployed in containers. The growth of container native storage is largely driven by stateful applications [2, 3], the mainstay of enterprise IT environments. As organizations are increasingly adopting containerized deployments, they must also deal with data protection to maintain business continuity.The users or application developers in containerized environment focus on designing and configuring the application, whereas various management aspects are handled by the orchestration system. For instance, the Kubernetes framework deals with load balancing and failover of application components without active user involvement. In the same mold, we present a self-service backup system for containerized stateful applications. Here, backups refer to physically distinct copies of point-in-time logical copies of data that are used to protect data from logical corruption, human error and cyber attacks such as ransomware attacks. Our goal is to allow users to convey their data protection requirements, such as Recovery Point Objective (RPO) or retention period, in a similar manner as application configuration. The RPO expresses the data loss tolerance for the backup. The RPO is said to be T hours if the application can lose no more data than the changes made in the last T hours. Given the user requirements, the backup system snapshots the application data volumes and copies out the snapshots to an external repository. In case of a failure of the primary volume, the volume can be restored from the repository.In traditionally managed data centers, administrators are responsible for assessing the load on the storage system and accordingly configuring backup objectives for all users. However, self-service containerized environment present the following challenges. First, in such environments each application instance, i.e. a stateful container, is provisioned with a separate volume. Therefore a cluster may consist of thousands of small volumes with varying RPOs. Moreover, the end users may not be aware of failures or resource fluctuations, e.g., load on the storage system, to know if the specified data protection guarantee can be fulfilled. Second, when the storage system is being used by IO intensive applications, the application traffic competes with the backup traffic and maintaining the RPO of backups becomes challenging. When the rate of data copying for backups is increased to meet the RPO, the applications may suffer from the adverse impact. In contrast, when the rate of data copying is decreased to reduce its interference with the application traffic, the backup may violate the provided RPO guarantee.We address the above problems in the proposed self-service backup system. To protect data of their stateful applications, users can simply specify the desired protection policies, namely RPO and retention period, and need not dictate when or how frequently the volumes are backed up. The users can request and monitor backups through a familiar Kubernetes interface, i.e, kubectl. Additionally, we propose adaptive scheduling to minimize the snapshots required to provide the necessary RPO guarantee. The scheduler varies the interval between the snapshots based on system load. When storage system, network is under heavy load, or experiencing any failures or outages, the snapshot frequency is increased, thus affording more time for offloading the data. At other times, the scheduler reduces the snapshot frequency thereby reducing system processing and network overhead. The system is also resilient to resource, component and backup job failures. It treats each operation (request creation, snapshot, data copy) as a transaction and leverage Kubernetes to restart the erroneous or failed component on same or different nodes. The transactional semantic ensures continuity through such restarts.Our evaluation with thousands volumes with varying RPOs shows that our system can quickly react to resource fluctuations and minimize RPO violations as compared to the fixed schedulers.","publicationDate":"2021-06-13T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3155112.3173558","title":"department ","type":"Cluster Scheduling for Data Centers: Expert-curated Guides to the Best of CS Research: Distributed Cluster Scheduling","venue":"Queue","authors":["Malte Schwarzkopf"],"abstract":"This installment of Research for Practice features a curated selection from Malte Schwarzkopf, who takes us on a tour of distributed cluster scheduling, from research to practice, and back again. With the rise of elastic compute resources, cluster management has become an increasingly hot topic in systems R&D, and a number of competing cluster managers including Kubernetes, Mesos, and Docker are currently jockeying for the crown in this space.","publicationDate":"2017-09-30T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3465222.3465233","title":"research-article ","type":"LambdaKube - A Functional Programming Approach in a Distributed Realm","venue":"ICGDA 2021: 2021 4th International Conference on Geoinformatics and Data Analysis","authors":["Ádám Révész","Norbert Pataki"],"abstract":"Containerization has become an essential approach in modern software engineering. Docker is a widely-used solutio for separate services (like database, backend, etc.) and start the as a standalone, isolated process instance on the same host kernel. Kubernetes is distributed approach over Docker, it supports multiple hosts for the deployment. Kubeless in new approach that aims at the functionwise deployment, so every subprogram can be deployed, scaled, operated separately, thererfore a functional programming approach can be realized in a modern, highly distributed realm. In this paper, we propose our solution that is based on the constructs of functional programming (e.g. map-reduce transformations). We take advantage of the Kubeless system and provide a functional programming framework called LambdaKube.","publicationDate":"2021-04-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3317550.3321444","title":"research-article ","type":"Synthesizing Cluster Management Code for Distributed Systems","venue":"HotOS '19: Proceedings of the Workshop on Hot Topics in Operating Systems","authors":["Lalith Suresh","João Loff","Nina Narodytska","Leonid Ryzhyk","Mooly Sagiv","Brian Oki"],"abstract":"Management planes for data-center systems are complicated to develop, test, maintain, and evolve. They routinely grapple with hard combinatorial optimization problems like load balancing, placement, scheduling, rolling upgrades and configuration management. To tackle these problems, developers are left with two bad choices: (i) develop ad-hoc mechanisms for systems to solve these optimization problems, or (ii) use specialized solvers that require steep engineering effort.We propose Weave, a tool that enables programmers to specify cluster management policies in a high-level declarative language, and compute policy-compliant configurations automatically and efficiently. Weave allows constraints and policies, the essence of a management plane, to be easily added, removed and modified over time, using a language familiar to developers (SQL). In this paper, we discuss our approach of management plane synthesis, its benefits, and present preliminary results from implementing a Kubernetes scheduler and a CorfuDB management plane using Weave.","publicationDate":"2019-05-12T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.5555/3291291.3291339","title":"research-article ","type":"Modernize digital applications with microservices management using the istio service mesh","venue":"CASCON '18: Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering","authors":["Ozair Sheikh","Serjik Dikaleh","Dharmesh Mistry","Darren Pape","Chris Felix"],"abstract":"Digital solutions are being built on modernized enterprise platforms deployed on cloud infrastructure and managed using container platforms. Foundational infrastructure capabilities such as load balancing and routing, previously available as software are now being provided as part of the underlying cloud platform. When designing your next generation architecture, its integral to understand the capabilities available from the cloud platform versus acquiring / developing it with software. For example, load balancing and automatic scaling are features that are built-into container orchestration platforms such as Kubernetes; therefore, you should not expect your applications to develop these capabilities, rather write your applications in a manner that allows you to embrace the container platform.","publicationDate":"2018-10-28T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3437984.3458831","title":"research-article ","type":"Predicting CPU usage for proactive autoscaling","venue":"EuroMLSys '21: Proceedings of the 1st Workshop on Machine Learning and Systems","authors":["Thomas Wang","Simone Ferlin","Marco Chiesa"],"abstract":"Private and public clouds require users to specify requests for resources such as CPU and memory (RAM) to be provisioned for their applications. The values of these requests do not necessarily relate to the application's run-time requirements, but only help the cloud infrastructure resource manager to map requested resources to physical resources. If an application exceeds these values, it might be throttled or even terminated. As a consequence, requested values are often overestimated, resulting in poor resource utilization in the cloud infrastructure. Autoscaling is a technique used to overcome these problems.We observed that Kubernetes Vertical Pod Autoscaler (VPA) might be using an autoscaling strategy that performs poorly on workloads that periodically change. Our experimental results show that compared to VPA, predictive methods based on Holt-Winters exponential smoothing (HW) and Long Short-Term Memory (LSTM) can decrease CPU slack by over 40% while avoiding CPU insufficiency for various CPU workloads. Furthermore, LSTM has been shown to generate stabler predictions compared to that of HW, which allowed for more robust scaling decisions.","publicationDate":"2021-04-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3185768.3186293","title":"short-paper ","type":"Autoscaling Performance Measurement Tool","venue":"ICPE '18: Companion of the 2018 ACM/SPEC International Conference on Performance Engineering","authors":["Anshul Jindal","Vladimir Podolskiy","Michael Gerndt"],"abstract":"More companies are shifting focus to adding more layers of virtualization for their cloud applications thus increasing the flexibility in development, deployment and management of applications. Increase in the number of layers can result in additional overhead during autoscaling and also in coordination issues while layers may use the same resources while managed by different software. In order to capture these multilayered autoscaling performance issues, an Autoscaling Performance Measurement Tool (APMT) was developed. This tool evaluates the performance of cloud autoscaling solutions and combinations thereof for varying types of load patterns. In the paper, we highlight the architecture of the tool and its configuration. An autoscaling behavior for major IaaS providers with Kubernetes pods as the second layer of virtualization is illustrated using the data collected by APMT.","publicationDate":"2018-04-01T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3008167.3008173","title":"research-article ","type":"Towards a container-based architecture for multi-tenant SaaS applications","venue":"ARM 2016: Proceedings of the 15th International Workshop on Adaptive and Reflective Middleware","authors":["Eddy Truyen","Dimitri Van Landuyt","Vincent Reniers","Ansar Rafique","Bert Lagaisse","Wouter Joosen"],"abstract":"SaaS providers continuously aim to optimize the cost-efficiency, scalability and trustworthiness of their offerings. Traditionally, these concerns have been addressed by application-level middleware platforms that implement a multi-tenant architecture.However, the recent uprise and industry adoption of container technology such as Docker and Kubernetes, exactly for the purpose of improving the cost-efficiency, elasticity and resilience of cloud native services, triggers the unanswered question whether and how container technology may affect such multi-tenant architectures.To answer this question, we outline our ideas on a container-based multi-tenant architecture for SaaS applications. Subsequently, we make an assessment of the technical Strengths, Weaknesses, Opportunities, and Threats (SWOT) which should be taken into account by a SaaS provider when considering the adoption of such container-based architecture.","publicationDate":"2016-12-11T23:00:00.000Z","citationCount":20},{"url":"https://dl.acm.org/doi/10.1145/3011141.3011202","title":"short-paper ","type":"Implementing time-critical functionalities with a distributed adaptive container architecture","venue":"iiWAS '16: Proceedings of the 18th International Conference on Information Integration and Web-based Applications and Services","authors":["Vlado Stankovski","Jernej Trnkoczy","Salman Taherizadeh","Matej Cigale"],"abstract":"Software developers increasingly need to include time-critical functionalities in their Web applications. Examples of these can be Internet-of-Things (IoT), gaming systems, instant messaging, video conferencing, and similar. Ensuring the Quality of Service (QoS) for such applications has been a challenging issue mostly due to runtime variations in the network quality between the clients and the service running in the Cloud. In this paper, we propose an adaptive multi-instance container-based architecture called Autonomous Self-Adaptation Platform (ASAP) that applies an edge computing concept with technologies, such as Docker and Kubernetes to facilitate the desired QoS for every single usage event of the time-critical functionality. We use a \"File Upload\" use case as an example to explore time-critical functionality. Each time a client needs to use the File Upload functionality, a specific setup, physical host selection and resources allocation is made in order to provide the desired QoS to that functionality.","publicationDate":"2016-11-27T23:00:00.000Z","citationCount":8},{"url":"https://dl.acm.org/doi/10.1145/3418094.3418102","title":"research-article ","type":"On Architecture of BodyInNumbers Exercise and Wellness Health Strategy Framework","venue":"ICMHI 2020: Proceedings of the 4th International Conference on Medical and Health Informatics","authors":["Petr Brůha","Roman Mouček","P. Volf","L. Šimečková","O. Šťáva"],"abstract":"They are many risk factors decreasing overall human physical and cognitive performance and increasing incidence of chronic diseases. It is very beneficial for any society to map, discuss and cope with these factors. This can be supported and evaluated by designing, developing, testing and using suitable self-management health systems. One of these systems is the BodyInNumbers exercise and wellness health strategy framework that allows experimenters to collect various heterogeneous health related data in a highly organized and efficient way. Thanks to its success and daily use, new requirements related to better security, scalability and maintainability of its architecture have emerged. The aim of this work is to present advances and changes in the architecture of the BodyInNumbers health strategy framework mainly focusing on new definition of user roles, optimization of the system deployment, and orchestration of the system components. As a proof of concept, a Kubernetes cluster prototype has been used to demonstrate the improved architectural solution.","publicationDate":"2020-08-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3429885.3429963","title":"short-paper ","type":"Flexible Migration in Blue-Green Deployments within a Fixed Cost","venue":"WOC'20: Proceedings of the 2020 6th International Workshop on Container Technologies and Container Clouds","authors":["Eddy Truyen","Bert Lagaisse","Wouter Joosen","Arnout Hoebreckx","Cédric De Dycker"],"abstract":"This paper presents the concept of PolyPod that consists of multiple Pods that run different versions of the same container image on the same node in order to share common libraries in memory. Its novelty is that it proposes a blueprint for blue-green deployments in order to balance maximum flexibility in the number of migration steps with maximum workload consolidation within a fixed total resource cost. This balance between flexibility and improved resource utilization is important for various application areas where users are served by the same application instance and have different time preferences for being upgraded to a new application version. The PolyPod concept is also relevant for a planned feature of Kubernetes so that Pods can be vertically scaled without re-starting them, but where scaling actions are aborted if the capacity of the node is to be exceeded. We explain how the PolyPod concept supports balancing flexible migration and resource utilization, with and without Pod restarts, by simulating various migration scenarios based on a quantitative cost model.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3380786.3391395","title":"research-article ","type":"Microservices made attack-resilient using unsupervised service fissioning","venue":"EuroSec '20: Proceedings of the 13th European workshop on Systems Security","authors":["Ataollah Fatahi Baarzi","George Kesidis","Dan Fleck","Angelos Stavrou"],"abstract":"Application-layer DoS attacks are increasing as the number of cloud-deployed microservice applications is increasing. The attacker tries to exhaust computing resources and brings the nominal applications down by exploiting application-layer vulnerabilities. As traditional solutions for volumetric DoS attacks will not be able to handle these attacks, new approaches are required to detect and respond to application-layer attacks. In this work, we propose an unsupervised, non-intrusive and application-agnostic detection approach and fissioning based response mechanism. We built our prototype on Kubernetes, the state of the art container orchestrator for microservices, and show its effectiveness through experimental evaluation. Our preliminary results show that using our detection and defense mechanism, we are able to a) efficiently identify the attacks and b) reduce the effect of the attack on legitimate users by 3× compared to a case where there is no detection/defense in place.","publicationDate":"2020-04-26T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3332186.3332246","title":"research-article ","type":"Publishing and Serving Machine Learning Models with DLHub","venue":"PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning)","authors":["Ryan Chard","Logan Ward","Zhuozhao Li","Yadu Babuji","Anna Woodard","Steven Tuecke","Kyle Chard","Ben Blaiszik","Ian Foster"],"abstract":"In this paper we introduce the Data and Learning Hub for Science (DLHub). DLHub serves as a nexus for publishing, sharing, discovering, and reusing machine learning models. It provides a flexible publication platform that enables researchers to describe and deposit models by associating publication and model-specific metadata and assigning a persistent identifier for subsequent citation. DLHub also supports scalable model inference, allowing researchers to execute inference tasks using a distributed execution engine, containerized models, and Kubernetes. Here we describe DLHub and present four scientific use cases that illustrate how DLHub can be used to reliably, efficiently, and scalably integrate ML into scientific processes.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3469259.3470486","title":"research-article ","type":"A Comparative Study of Virtual Infrastructure Management Solutions for UAV Networks","venue":"Dronet'21: Proceedings of the 7th Workshop on Micro Aerial Vehicle Networks, Systems, and Applications","authors":["Luis F. Gonzalez","Ivan Vidal","Francisco Valera","Victor Sanchez-Aguero"],"abstract":"The promising combination of Unmanned Aerial Vehicles (UAVs) with network virtualisation technologies has positively shown many advantages enabling the deployment of communication services over aerial networks, that is, networks conformed by a set of interconnected UAVs. However, this synergy may certainly involve diverse challenges that must be carefully considered. In this respect, this paper compares some of the most common virtual infrastructure management solutions that could potentially be used to deal with virtualised payloads over aerial networks, identifying their main strength and limitations. The paper also presents a preliminary exploration on the utilisation of the Kubernetes virtual infrastructure management platform to support value-added services over UAV networks, showing off its potential as a suitable platform to this purpose.","publicationDate":"2021-06-23T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3447851.3458738","title":"research-article ","type":"Frisbee: A Suite for Benchmarking Systems Recovery","venue":"HAOC '21: Proceedings of the 1st Workshop on High Availability and Observability of Cloud Systems","authors":["Fotis Nikolaidis","Antony Chazapis","Manolis Marazakis","Angelos Bilas"],"abstract":"With failures being unavoidable, a system's ability to recover from failures quickly is a critical factor in the overall availability of the system. Although many systems exhibit self-healing properties, their behavior in the presence of failures is poorly understood. This is primarily due to the shortcomings of existing benchmarks, which cannot generate failures. For a more accurate systems evaluation, we argue that it is essential to create new suites that treat failures as first-class citizens. We present Frisbee, a benchmark suite and evaluation methodology for comparing the recovery behavior of highly available systems. Frisbee is built for the Kubernetes environment, leveraging several valuable tools in its stack, including Chaos tools for fault injection, Prometheus for distributed monitoring, and Grafana for visualization. We discuss a set of design requirements and present an initial prototype that makes faultloads as easy to run and characterize as traditional performance workloads. Furthermore, we define a core set of failure patterns against which systems can be compared.","publicationDate":"2021-04-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3448016.3457555","title":"research-article ","type":"Toto – Benchmarking the Efficiency of a Cloud Service","venue":"SIGMOD/PODS '21: Proceedings of the 2021 International Conference on Management of Data","authors":["Justin Moeller","Zi Ye","Katherine Lin","Willis Lang"],"abstract":"Microsoft aims to increase the efficiency of Azure SQL DB by maximizing the number of databases that can be hosted in a cluster. However, resource contention among customers increases when changing the configurations, policies, and features that control database co-location on cluster nodes. Tuning and evaluating the efficiency and customer impact of these variables in a scientific manner in production, with a dynamic system and customer workloads, is difficult or infeasible. Here, we present Toto, a benchmark framework for evaluating the efficiency of any cloud service that leverages orchestrators like Service Fabric or Kubernetes. Toto allows for reliable and repeatable specification of a benchmarking scenario of arbitrary scale, complexity, and time-length. An implementation of Toto is deployed in all SQL DB staging clusters and is used to evaluate system efficiency and behaviors. As an example of Toto's capabilities, we present a study to explore the balance between cluster database density and quality of service.","publicationDate":"2021-06-08T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3342195.3387547","title":"research-article ","type":"AlloX: compute allocation in hybrid clusters","venue":"EuroSys '20: Proceedings of the Fifteenth European Conference on Computer Systems","authors":["Tan N. Le","Xiao Sun","Mosharaf Chowdhury","Zhenhua Liu"],"abstract":"Modern deep learning frameworks support a variety of hardware, including CPU, GPU, and other accelerators, to perform computation. In this paper, we study how to schedule jobs over such interchangeable resources - each with a different rate of computation - to optimize performance while providing fairness among users in a shared cluster. We demonstrate theoretically and empirically that existing solutions and their straightforward modifications perform poorly in the presence of interchangeable resources, which motivates the design and implementation of AlloX. At its core, AlloX transforms the scheduling problem into a min-cost bipartite matching problem and provides dynamic fair allocation over time. We theoretically prove its optimality in an ideal, offline setting and show empirically that it works well in the online scenario by incorporating with Kubernetes. Evaluations on a small-scale CPU-GPU hybrid cluster and large-scale simulations highlight that AlloX can reduce the average job completion time significantly (by up to 95% when the system load is high) while providing fairness and preventing starvation.","publicationDate":"2020-04-14T22:00:00.000Z","citationCount":10},{"url":"https://dl.acm.org/doi/10.1145/3267809.3275448","title":"poster ","type":"Resource Profile Advisor for Containers in Cognitive Platform","venue":"SoCC '18: Proceedings of the ACM Symposium on Cloud Computing","authors":["Mehmet F. Aktaş","Chen Wang","Alaa Youssef","Malgorzata Gosia Steinder"],"abstract":"Containers have transformed the cluster management into an application oriented endeavor, thus being widely used as the deployment units (i.e., micro-services) of large scale cloud services. As opposed to VMs, containers allow for resource provisioning with fine granularity and their resource usage directly reflects the micro-service behaviors. Container management systems like Kubernetes and Mesos provision resources to containers according to the capacity requested by the developers. Resource usages estimated by the developers are grossly inaccurate. They tend to be risk-averse and over provision resources, as under-provisioning would cause poor runtime performance or failures.Without actually running the workloads, resource provisioning is challenging. However, benchmarking production workloads at scale requires huge manual efforts. In this work, we leverage IBM Monitoring service to profile the resource usage of production IBM Watson services in rolling windows by focusing on both evaluating how developers request resources and characterizing the actual resource usage.Our resource profiling study reveals two important characteristics of the cognitive workloads. 1. Stationarity. According to Augmented Dickey-Fuller test with 95% confidence, more than 95% of the container instances have stationary CPU usage while more than 85% have stationary memory usage, indicating that resource usage statistics do not change over time. We find for the majority of containers that the stationarity can be detected at the early stage of container execution and can hold throughout their lifespans. In addition, containers with non-stationary CPU or memory usage are also observed to implement predictable usage trends and patterns (e.g., trend stationarity or seasonality). 2. Predictability by container image. By clustering the containers based on their images, container resource usages within the same cluster are observed to exhibit strong statistical similarity. This suggests that the history of resource usage for one instance can be used to predict usage for future instances that run the same container image.Based on profiling results of running containers in rolling windows, we propose a resource usage advisory system to refine the requested resource values of the running and arriving containers as illustrated in Fig. 1. Our system continuously retrieves the resource usage metrics of running containers from IBM monitoring service and predicts the resource usage profiles in a container resource usage prediction agent. Upon the arrival of a new pod1, the resource profile advisor, proposed as a module in the web-hooked admission controller in Kubernetes, checks whether the resource profile of each container in the pod has been predicted with confidence. If a container's profile has been predicted and cached in the container resource profile database, the default requested values of containers are refined by the predicted ones; otherwise, containers are forwarded to the scheduler without any change. Similarly, a resource profile auto-scaler is proposed to update the requested resource values of containers for running pods2 as soon as the database is updated.Our study shows that developers request at least 1 core-per-second (cps) CPU and 1 GB memory for ≥ 70% of the containers, while ≥ 80% of the containers actually use less than 1 cps and 1GB. Additionally, ~ 20% of the containers are significantly under provisioned. We use resource usage data in one day to generate container resource profiles and evaluate our approach based on the actual usage on the following day. Without our system, average CPU (memory) usage for >90% of containers lies outside of 50% - 100% (70% - 100%) of the requested values. Our evaluation shows that our system can advise request values appropriately so that average and 95th percentile CPU (memory) usage for >90% of the containers are within 50% - 100% (70% - 100%) of the requested values. Furthermore, average CPU (memory) utilization across all pods is raised from 10% (26%) to 54% (88%).","publicationDate":"2018-10-10T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3411495.3421357","title":"research-article ","type":"Co-residency Attacks on Containers are Real","venue":"CCSW'20: Proceedings of the 2020 ACM SIGSAC Conference on Cloud Computing Security Workshop","authors":["Sushrut Shringarputale","Patrick McDaniel","Kevin Butler","Thomas La Porta"],"abstract":"Public clouds are inherently multi-tenant: applications deployed by different parties (including malicious ones) may reside on the same physical machines and share various hardware resources. With the introduction of newer hypervisors, containerization frameworks like Docker, and managed/orchestrated clusters using systems like Kubernetes, cloud providers downplay the feasibility of co-tenant attacks by marketing a belief that applications do not operate on shared hardware. In this paper, we challenge the conventional wisdom that attackers cannot confirm co-residency with a victim application from inside state-of-the-art containers running on virtual machines. We analyze the degree of vulnerability present in containers running on various systems including within a broad range of commercially utilized orchestrators. Our results show that on commercial cloud environments including AWS and Azure, we can obtain over 90% success rates for co-residency detection using real-life workloads. Our investigation confirms that co-residency attacks are a significant concern on containers running on modern orchestration systems.","publicationDate":"2020-11-08T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3311790.3396647","title":"research-article ","type":"Tapis API Development with Python: Best Practices In Scientific REST API Implementation: Experience implementing a distributed Stream API","venue":"PEARC '20: Practice and Experience in Advanced Research Computing","authors":["Sean B. Cleveland","Anagha Jamthe","Smruti Padhy","Joe Stubbs","Michale Packard","Julia Looney","Steve Terry","Richard Cardone","Maytal Dahan","Gwen A. Jacobs"],"abstract":"In the last decade, the rise of hosted Software-as-a-Service (SaaS) application programming interfaces (APIs) across both academia and industry has exploded, and simultaneously, microservice architectures have replaced monolithic application platforms for the flexibility and maintainability they offer. These SaaS APIs rely on small, independent and reusable microservices that can be assembled relatively easily into more complex applications. As a result, developers can focus on their own unique functionality and surround it with fully functional, distributed processes developed by other specialists, which they access through APIs. The Tapis framework, a NSF funded project, provides SaaS APIs to allow researchers to achieve faster scientific results, by eliminating the need to set up a complex infrastructure stack. In this paper, we describe the best practices followed to create Tapis APIs using Python and the Stream API as an example implementation illustrating authorization and authentication with the Tapis Security Kernel, Tenants and Tokens APIs, leveraging OpenAPI v3 specification for the API definitions and docker containerization. Finally, we discuss our deployment strategy with Kubernetes, which is an emerging orchestration technology and the early adopter use cases of the Streams API service.","publicationDate":"2020-07-25T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3474624.3474631","title":"short-paper ","type":"Identifying Logging Practices in Open Source Python Containerized Application Projects","venue":"SBES '21: Brazilian Symposium on Software Engineering","authors":["Marco Alves","Hugo Paula"],"abstract":" Despite the popularity of microservice architectures using container based virtualization, there are not many studies that describe how logging practices are being employed in this scenario. In this empirical study, we cloned 10,918 of the most stargazed GitHub Python repositories with a Docker/Kubernetes associated file. We were able to find 1,166 Python projects that used containers. A custom parser identified and saved log statements from Python source code. We discovered that certain licenses tend to have a higher log density; over 99% of projects use the built-in Python logging library; the repository age does not affect its log statements/LLOC ratio; logging verbosity levels debug and info are used almost twice as much as warning and error. We hope our study provides the community with useful data about this topic, possibly contributing to the improvement of techniques that stimulate its applications.","publicationDate":"2021-09-26T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3401025.3401731","title":"research-article ","type":"Triggerflow: trigger-based orchestration of serverless workflows","venue":"DEBS '20: Proceedings of the 14th ACM International Conference on Distributed and Event-based Systems","authors":["Pedro García López","Aitor Arjona","Josep Sampé","Aleksander Slominski","Lionel Villard"],"abstract":"As more applications are being moved to the Cloud thanks to serverless computing, it is increasingly necessary to support native life cycle execution of those applications in the data center.But existing systems either focus on short-running workflows (like IBM Composer or Amazon Express Workflows) or impose considerable overheads for synchronizing massively parallel jobs (Azure Durable Functions, Amazon Step Functions, Google Cloud Composer). None of them are open systems enabling extensible interception and optimization of custom workflows.We present Triggerflow: an extensible Trigger-based Orchestration architecture for serverless workflows built on top of Knative Eventing and Kubernetes technologies. We demonstrate that Triggerflow is a novel serverless building block capable of constructing different reactive schedulers (State Machines, Directed Acyclic Graphs, Workflow as code). We also validate that it can support high-volume event processing workloads, auto-scale on demand and transparently optimize scientific workflows.","publicationDate":"2020-07-12T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3337821.3337840","title":"research-article ","type":"Nested Virtualization Without the Nest","venue":"ICPP 2019: Proceedings of the 48th International Conference on Parallel Processing","authors":["Mathieu Bacou","Grégoire Todeschi","Daniel Hagimont","Alain Tchana"],"abstract":"With the increasing popularity of containers, managing them on top of virtual machines becomes a common practice, called nested virtualization. This paper presents BrFusion and Hostlo, two solutions that address each of two networking issues of nested virtualization: network virtualization duplication and virtual machine-bounded pod deployments. The first issue lengthens network packet paths while the second issue leads to resource fragmentation. For instance, in respect with the first issue, we measured a throughput degradation of about 68% and a latency increase of about 31% in comparison with a single networking layer. We prototype BrFusion and Hostlo in Linux KVM/QEMU, Docker and Kubernetes systems. The evaluation results show that BrFusion leads to the same performance as a single-layer virtualization deployment. Concerning Hostlo, the results show that more than 11% of cloud clients see their cloud utilization cost reduced by down to 40%.","publicationDate":"2019-08-04T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3366614.3368101","title":"research-article ","type":"Container deployment strategy for edge networking","venue":"MECC '19: Proceedings of the 4th Workshop on Middleware for Edge Clouds & Cloudlets","authors":["Walter Wong","Aleksandr Zavodovski","Pengyuan Zhou","Jussi Kangasharju"],"abstract":"Edge computing paradigm has been proposed to support latency-sensitive applications such as Augmented Reality (AR)/ Virtual Reality(VR) and online gaming, by placing computing resources close to where they are most demanded, at the edge of the network. Many solutions have proposed to deploy virtual resources as close as possible to the consumers using virtual machines and containers. However, the most popular container orchestration tools, e.g., Docker Swarm and Kubernetes, do not take into account the locality aspect during deployment, resulting in poor location choices at the edge of the network. In this paper, we propose an edge deployment strategy to tackle the lack of locality awareness of the container orchestrator. In this strategy, the orchestrator collects information about latency and the real-time resource consumption from the current container deployments, providing a bird's-eye view of the most demanded locations and the best places for deployment to cover the largest number of clients. We evaluated the proposed model using 16 AWS regions across the globe and compared to the standard deployment strategies. The experimental results show our edge strategy reduces the average latency between serving container to the clients by up to 4 times compared to the standard deployment algorithms.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3194133.3194162","title":"short-paper ","type":"K8-scalar: a workbench to compare autoscalers for container-orchestrated database clusters","venue":"SEAMS '18: Proceedings of the 13th International Conference on Software Engineering for Adaptive and Self-Managing Systems","authors":["Wito Delnat","Eddy Truyen","Ansar Rafique","Dimitri Van Landuyt","Wouter Joosen"],"abstract":"Although a considerable amount of research exists on auto-scaling of database clusters, the design of an effective auto-scaling strategy requires fine-grained tailoring towards the specific application scenario.This paper presents an easy-to-use and extensible workbench exemplar, named K8-Scalar (Kube-Scalar), which allows researchers to implement and evaluate different self-adaptive approaches to auto-scaling container-orchestrated services. The workbench is based on Docker, a popular technology for easing the deployment of containerized software that also has been positioned as an enabler for reproducible research. The workbench also relies on a container orchestration framework: Kubernetes (K8s), the de-facto industry standard for orchestration and monitoring of elastically scalable container-based services. Finally, it integrates and extends Scalar, a generic testbed for evaluating the scalability of large-scale systems with support for evaluating the performance of autoscalers for database clusters.The paper discusses (i) the architecture and implementation of K8-Scalar and how a particular autoscaler can be plugged in, (ii) sketches the design of a Riemann-based autoscaler for database clusters, (iii) illustrates how to design, setup and analyze a series of experiments to configure and evaluate the performance of this autoscaler for a particular database (i.e., Cassandra) and a particular workload type, and (iv) validates the effectiveness of K8-Scalar as a workbench for accurately comparing the performance of different auto-scaling strategies.","publicationDate":"2018-05-27T22:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3297280.3297296","title":"research-article ","type":"Secure container orchestration in the cloud: policies and implementation","venue":"SAC '19: Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing","authors":["Gabriel P. Fernandez","Andrey Brito"],"abstract":"In the late few years, cloud computing has been moving towards becoming the predominant infrastructure paradigm because of its scale economy advantages. Consequently, a great deal of sensitive and valuable information has begun to inhabit the cloud environment. At the current stage, a large amount of organizations is yet to step to the public cloud world because, primarily, the loss of infrastructure ownership gives away control of such information, and that is generally perceived as a severe security risk.Currently available cloud security platforms fail to present a process to accomplish a secure and cloud compatible operation flow. In this work we propose a policy that enforces data security in the cloud. To implement the cloud based components of that policy we created SCO (Secure Container Orchestrator) a container orchestration engine that makes use of the most recent hardware-based trusted execution environment technologies for data protection, in our case, Intel SGX. SCO implements SGX friendly container auto-scaling schemes, load balancing routing and packs SGX compatibility features. These characteristics enable the deployment of trusted applications in alignment with standard cloud practices.We also compare SCO to the state-of-the-practice in container orchestration (Kubernetes), demonstrate the inherent costs of employing this security enhanced solution, and present a methodology to support business decisions regarding its utilization.","publicationDate":"2019-04-07T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3297858.3304069","title":"research-article ","type":"Understanding Real-World Concurrency Bugs in Go","venue":"ASPLOS '19: Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems","authors":["Tengfei Tu","Xiaoyu Liu","Linhai Song","Yiying Zhang"],"abstract":"Go is a statically-typed programming language that aims to provide a simple, efficient, and safe way to build multi-threaded software. Since its creation in 2009, Go has matured and gained significant adoption in production and open-source software. Go advocates for the usage of message passing as the means of inter-thread communication and provides several new concurrency mechanisms and libraries to ease multi-threading programming. It is important to understand the implication of these new proposals and the comparison of message passing and shared memory synchronization in terms of program errors, or bugs. Unfortunately, as far as we know, there has been no study on Go's concurrency bugs. In this paper, we perform the first systematic study on concurrency bugs in real Go programs. We studied six popular Go software including Docker, Kubernetes, and gRPC. We analyzed 171 concurrency bugs in total, with more than half of them caused by non-traditional, Go-specific problems. Apart from root causes of these bugs, we also studied their fixes, performed experiments to reproduce them, and evaluated them with two publicly-available Go bug detectors. Overall, our study provides a better understanding on Go's concurrency models and can guide future researchers and practitioners in writing better, more reliable Go software and in developing debugging and diagnosis tools for Go.","publicationDate":"2019-04-03T22:00:00.000Z","citationCount":16},{"url":"https://dl.acm.org/doi/10.1145/3423211.3425677","title":"research-article ","type":"TEEMon: A continuous performance monitoring framework for TEEs","venue":"Middleware '20: Proceedings of the 21st International Middleware Conference","authors":["Robert Krahn","Donald Dragoti","Franz Gregor","Do Le Quoc","Valerio Schiavoni","Pascal Felber","Clenimar Souza","Andrey Brito","Christof Fetzer"],"abstract":"Trusted Execution Environments (TEEs), such as Intel Software Guard eXtensions (SGX), are considered as a promising approach to resolve security challenges in clouds. TEEs protect the confidentiality and integrity of application code and data even against privileged attackers with root and physical access by providing an isolated secure memory area, i.e., enclaves. The security guarantees are provided by the CPU, thus even if system software is compromised, the attacker can never access the enclave's content. While this approach ensures strong security guarantees for applications, it also introduces a considerable runtime overhead in part by the limited availability of protected memory (enclave page cache). Currently, only a limited number of performance measurement tools for TEE-based applications exist and none offer performance monitoring and analysis during runtime.This paper presents TEEMon, the first continuous performance monitoring and analysis tool for TEE-based applications. TEEMon provides not only fine-grained performance metrics during runtime, but also assists the analysis of identifying causes of performance bottlenecks, e.g., excessive system calls. Our approach smoothly integrates with existing open-source tools (e.g., Prometheus or Grafana) towards a holistic monitoring solution, particularly optimized for systems deployed through Docker containers or Kubernetes and offers several dedicated metrics and visualizations. Our evaluation shows that TEEMon's overhead ranges from 5% to 17%.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3332186.3332236","title":"research-article ","type":"Developing Edge Services for Federated Infrastructure Using MiniSLATE","venue":"PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning)","authors":["Joe Breen","Lincoln Bryant","Jiahui Chen","Emerson Ford","Robert W. Gardner","Gage Glupker","Skyler Griffith","Ben Kulbertis","Shawn McKee","Rose Pierce","Benedikt Riedel","Mitchell Steinman","Jason Stidd","Luan Truong","Jeremy Van","Ilija Vukotic","Christopher Weaver"],"abstract":"Modern software development workflow patterns often involve the use of a developer's local machine as the first platform for testing code. SLATE mimics this paradigm with an implementation of a light-weight version, called MiniSLATE[? ], that runs completely contained on the developer's local machine or scales to larger machines (laptop, virtual machine, or another physical server). MiniSLATE resolves many development environment issues by providing an isolated and local configuration for the developer. Application developers are able to download MiniSLATE which provides a fully orchestrated set of containers on top of a production SLATE platform, complete with central information service, API server, and a local Kubernetes cluster. This approach mitigates the overhead of a hypervisor but still provides the requisite isolated environment. They are able to create the environment, iterate, destroy it, and repeat at will. A local MiniSLATE environment also allows the developer to explore the packaging of the edge service within a constrained security context in order to validate its full functionality within limited permissions. As a result, developers are able to test the functionality of their application with the complete complement of SLATE components local to their development environment without the overhead of building a cluster or virtual machine, registering a cluster, interacting with the production SLATE platform, etc.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3417310.3431399","title":"research-article ","type":"ThingVisor factory: thing virtualization platform for things as a service","venue":"CCIoT '20: Proceedings of the Workshop on Cloud Continuum Services for Smart IoT Systems","authors":["Kenji Kanai","Hidenori Nakazato","Hidehiro Kanemitsu","Andrea Detti"],"abstract":"In order to provide interoperability of cross-domain IoT applications involving different IoT platforms, the authors previously proposed a virtual IoT system called VirIoT. The proposed system is composed of two functionalities: ThingVisor and vSilo, and it aims at decoupling IoT device providers and IoT application developers. ThingVisor enables to produce virtual IoT devices, or Virtual Things, from physical IoT devices for sharing the physical devices among cross-domain IoT applications. In addition, vSilo enables to bridge between such Virtual Things and IoT applications for the interoperability of cross-domain IoT devices. In this paper, in order to enhance the VirIoT system, we propose ThingVisor Factory that helps to design ThingVisors in a user-friendly way and deploy them on demand autonomously by following container orchestration methodologies, such as Kubernetes. ThingVisor Factory is based on two concepts: dataflow programming-based Graphical User Interface (GUI) and service function chaining-based ThingVisor development.","publicationDate":"2020-11-15T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3423211.3425683","title":"research-article ","type":"Fifer: Tackling Resource Underutilization in the Serverless Era","venue":"Middleware '20: Proceedings of the 21st International Middleware Conference","authors":["Jashwant Raj Gunasekaran","Prashanth Thinakaran","Nachiappan C. Nachiappan","Mahmut Taylan Kandemir","Chita R. Das"],"abstract":"Datacenters are witnessing a rapid surge in the adoption of serverless functions for microservices-based applications. A vast majority of these microservices typically span less than a second, have strict SLO requirements, and are chained together as per the requirements of an application. The aforementioned characteristics introduce a new set of challenges, especially in terms of container provisioning and management, as the state-of-the-art resource management frameworks, employed in serverless platforms, tend to look at microservice-based applications similar to conventional monolithic applications. Hence, these frameworks suffer from microservice agnostic scheduling and colossal container over-provisioning, especially during workload fluctuations, thereby resulting in poor resource utilization.In this work, we quantify the above shortcomings using a variety of workloads on a multi-node cluster managed by the Kubernetes and Brigade serverless framework. To address them, we propose Fifer --- an adaptive resource management framework to efficiently manage function-chains on serverless platforms. The key idea is to make Fifer (i) utilization conscious by efficiently bin packing jobs to fewer containers using function-aware container scaling and intelligent request batching, and (ii) at the same time, SLO-compliant by proactively spawning containers to avoid cold-starts, thus minimizing the overall response latency. Combining these benefits, Fifer improves container utilization and cluster-wide energy consumption by 4× and 31%, respectively, without compromising on SLO's, when compared to the state-of-the-art schedulers employed by serverless platforms.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3010079.3012014","title":"research-article ","type":"Securebox: Toward Safer and Smarter IoT Networks","venue":"CAN '16: Proceedings of the 2016 ACM Workshop on Cloud-Assisted Networking","authors":["Ibbad Hafeez","Aaron Yi Ding","Lauri Suomalainen","Alexey Kirichenko","Sasu Tarkoma"],"abstract":"In this paper we present Securebox, an affordable and deployable platform for securing and managing IoT networks. Our proposal targets an alarming spot in the fast growing IoT industry where security is often overlooked due to device limitation, budget constraint, and development deadline. In contrast to existing host-centric and hardware-coupled solutions, Securebox empowers a cloud-assisted \"charge for network service\" model that is dedicated to budget and resource constrained IoT environments. Owing to its cloud-driven and modular design, Securebox allows us to 1) flexibly offload and onload security and management functions to the cloud and network edge components; 2) offer advanced security and management services to end users in an affordable and on-demand manner; 3) ease the upgrade and deployment of new services to guard against abrupt security breakouts. To demonstrate Securebox, we have implemented the platform consisting of a plug-n-play frontend, a Kubernetes-powered backend cluster, and a smartphone mobile application. Based on the testbed evaluation, we show that Securebox is robust and responsive. Its collaborative and extensible architecture enforces rapid update cycles and can scale with the growing diversity of IoT devices.","publicationDate":"2016-12-11T23:00:00.000Z","citationCount":10},{"url":"https://dl.acm.org/doi/10.1145/3447851.3458740","title":"research-article ","type":"Service mesh circuit breaker: From panic button to performance management tool","venue":"HAOC '21: Proceedings of the 1st Workshop on High Availability and Observability of Cloud Systems","authors":["Mohammad Reza Saleh Sedghpour","Cristian Klein","Johan Tordsson"],"abstract":"Site Reliability Engineers are at the center of two tensions: On one hand, they need to respond to alerts within a short time, to restore a non-functional system. On the other hand, short response times is disruptive to everyday life and lead to alert fatigue. To alleviate this tension, many resource management mechanisms are proposed handle overload and mitigate the faults. One recent such mechanism is circuit breaking in service meshes. Circuit breaking rejects incoming requests to protect latency at the expense of availability (successfully answered requests), but in many scenarios achieve neither due to the difficulty of knowing when to trigger circuit breaking in highly dynamic microservice environments.We propose an adaptive circuit breaking mechanism, implemented through an adaptive controller, that not only avoids overload and mitigate failure, but keeps the tail response time below a given threshold while maximizing service throughput. Our proposed controller is experimentally compared with a static circuit breaker across a wide set of overload scenarios in a testbed based on Istio and Kubernetes. The results show that our controller maintains tail response time below the given threshold 98% of the time (including cold starts) on average with an availability of 70% with 29% of requests circuit broken. This compares favorably to a static circuit breaker configuration, which features a 63% availability, 30% circuit broken requests, and more than 5% of requests timing out.","publicationDate":"2021-04-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3190508.3190517","title":"research-article ","type":"Optimus: an efficient dynamic resource scheduler for deep learning clusters","venue":"EuroSys '18: Proceedings of the Thirteenth EuroSys Conference","authors":["Yanghua Peng","Yixin Bao","Yangrui Chen","Chuan Wu","Chuanxiong Guo"],"abstract":"Deep learning workloads are common in today's production clusters due to the proliferation of deep learning driven AI services (e.g., speech recognition, machine translation). A deep learning training job is resource-intensive and time-consuming. Efficient resource scheduling is the key to the maximal performance of a deep learning cluster. Existing cluster schedulers are largely not tailored to deep learning jobs, and typically specifying a fixed amount of resources for each job, prohibiting high resource efficiency and job performance. This paper proposes Optimus, a customized job scheduler for deep learning clusters, which minimizes job training time based on online resource-performance models. Optimus uses online fitting to predict model convergence during training, and sets up performance models to accurately estimate training speed as a function of allocated resources in each job. Based on the models, a simple yet effective method is designed and used for dynamically allocating resources and placing deep learning tasks to minimize job completion time. We implement Optimus on top of Kubernetes, a cluster manager for container orchestration, and experiment on a deep learning cluster with 7 CPU servers and 6 GPU servers, running 9 training jobs using the MXNet framework. Results show that Optimus outperforms representative cluster schedulers by about 139% and 63% in terms of job completion time and makespan, respectively.","publicationDate":"2018-04-22T22:00:00.000Z","citationCount":97},{"url":"https://dl.acm.org/doi/10.1145/3292500.3330671","title":"research-article ","type":"PinText: A Multitask Text Embedding System in Pinterest","venue":"KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","authors":["Jinfeng Zhuang","Yu Liu"],"abstract":"Text embedding is a fundamental component for extracting text features in production-level data mining and machine learning systems given textual information is the most ubiqutious signals. However, practitioners often face the tradeoff between effectiveness of underlying embedding algorithms and cost of training and maintaining various embedding results in large-scale applications. In this paper, we propose a multitask text embedding solution called PinText for three major vertical surfaces including homefeed, related pins, and search in Pinterest, which consolidates existing text embedding algorithms into a single solution and produces state-of-the-art performance. Specifically, we learn word level semantic vectors by enforcing that the similarity between positive engagement pairs is larger than the similarity between a randomly sampled background pairs. Based on the learned semantic vectors, we derive embedding vector of a user, a pin, or a search query by simply averaging its word level vectors. In this common compact vector space, we are able to do unified nearest neighbor search with hashing by Hadoop jobs or dockerized images on Kubernetes cluster. Both offline evaluation and online experiments show effectiveness of this PinText system and save storage cost of multiple open-sourced embeddings significantly.","publicationDate":"2019-07-24T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1109/AST.2019.000-2","title":"research-article ","type":"Software metrics artifacts making web quality measurable: AST 2019 invited paper","venue":"AST '19: Proceedings of the 14th International Workshop on Automation of Software Test","authors":["Andres-Leonardo Martinez-Ortiz","David Lizcano","Miguel Ortega"],"abstract":"Mining open source repositories introduces an effective approach to put in practice empirical software engineering in a variety of technologies. Kernel development (Linux) first and then Internet (Chromium) and more recently cloud orchestration (Kubernetes) and machine learning (TensorFlow) are fundamental pieces not just for open source ecosystem but also for the industry leading software innovation. Empirical software engineering sustains a better understanding of these projects, reducing even more the barriers for adoption. In this work we focus on empirical quality assessment developing software metrics artifacts to make web components quality measurable. After reviewing the state of the art and main frameworks for software measurement, we will present our proposal for the empirical evaluation of quality metrics for web components, data collection, measurement and prediction, discussing main benefits and some drawback of the selected approach, which will be aimed at future works.","publicationDate":"2019-05-26T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3445814.3446756","title":"research-article ","type":"Automatically detecting and fixing concurrency bugs in go software systems","venue":"ASPLOS 2021: Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems","authors":["Ziheng Liu","Shuofei Zhu","Boqin Qin","Hao Chen","Linhai Song"],"abstract":"Go is a statically typed programming language designed for efficient and reliable concurrent programming. For this purpose, Go provides lightweight goroutines and recommends passing messages using channels as a less error-prone means of thread communication. Go has become increasingly popular in recent years and has been adopted to build many important infrastructure software systems. However, a recent empirical study shows that concurrency bugs, especially those due to misuse of channels, exist widely in Go. These bugs severely hurt the reliability of Go concurrent systems. To fight Go concurrency bugs caused by misuse of channels, this paper proposes a static concurrency bug detection system, GCatch, and an automated concurrency bug fixing system, GFix. After disentangling an input Go program, GCatch models the complex channel operations in Go using a novel constraint system and applies a constraint solver to identify blocking bugs. GFix automatically patches blocking bugs detected by GCatch using Go’s channel-related language features. We apply GCatch and GFix to 21 popular Go applications, including Docker, Kubernetes, and gRPC. In total, GCatch finds 149 previously unknown blocking bugs due to misuse of channels and GFix successfully fixes 124 of them. We have reported all detected bugs and generated patches to developers. So far, developers have fixed 125 blocking misuse-of-channel bugs based on our reporting. Among them, 87 bugs are fixed by applying GFix’s patches directly.","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3337821.3337873","title":"research-article ","type":"Cynthia: Cost-Efficient Cloud Resource Provisioning for Predictable Distributed Deep Neural Network Training","venue":"ICPP 2019: Proceedings of the 48th International Conference on Parallel Processing","authors":["Haoyue Zheng","Fei Xu","Li Chen","Zhi Zhou","Fangming Liu"],"abstract":"It becomes an increasingly popular trend for deep neural networks with large-scale datasets to be trained in a distributed manner in the cloud. However, widely known as resource-intensive and time-consuming, distributed deep neural network (DDNN) training suffers from unpredictable performance in the cloud, due to the intricate factors of resource bottleneck, heterogeneity and the imbalance of computation and communication which eventually cause severe resource under-utilization. In this paper, we propose Cynthia, a cost-efficient cloud resource provisioning framework to provide predictable DDNN training performance and reduce the training budget. To explicitly explore the resource bottleneck and heterogeneity, Cynthia predicts the DDNN training time by leveraging a lightweight analytical performance model based on the resource consumption of workers and parameter servers. With an accurate performance prediction, Cynthia is able to optimally provision the cost-efficient cloud instances to jointly guarantee the training performance and minimize the training budget. We implement Cynthia on top of Kubernetes by launching a 56-docker cluster to train four representative DNN models. Extensive prototype experiments on Amazon EC2 demonstrate that Cynthia can provide predictable training performance while reducing the monetary cost for DDNN workloads by up to 50.6%, in comparison to state-of-the-art resource provisioning strategies, yet with acceptable runtime overhead.","publicationDate":"2019-08-04T22:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3332186.3332233","title":"research-article ","type":"Implementing a Flexible, Fault Tolerant Job Management System for Science Gateways","venue":"PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning)","authors":["Dimuthu Wannipurage","Suresh Marru","Marlon Piece","Eroma Abeysinghe","Sudhakar Pamidighantam","Marcus Christie","Gourav Shenoy","Ajinkya Dhamnaskar","Lahiru Jayathilaka"],"abstract":"This paper summarizes our experiences evaluating and deploying a new task execution management system within the open source Apache Airavata framework for science gateways. We base our choices on our operational requirements and experiences running Airavata software as a multi-tenanted production service for multiple gateway clients. Our considerations include integrating semi-independent components, making major upgrades to those components while retaining the system's overall functionality, and choosing between integrating third party and in-house developed components. While we focus on Apache Airavata as the platform for evaluation, our results should be of general interest. After considering the options of extensions to our previous, in-house job management system using Apache Kafka or replacing it with Kubernetes, we ultimately chose Apache Helix, primarily for its ability to execute multiple tasks coupled into directed acyclic graphs. We have integrated this approach into Apache Airavata and have tested extensively over several months with many thousands of jobs, both from our internal throughput testing and operational tests with early adopter science gateway clients. The new system has proven to be at least as reliable as the previous system with the advantages that we now have simplified maintenance, do not need to support an in-house system that required extensive developer training to modify, and can support more sophisticated job execution scenarios.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3361525.3361534","title":"research-article ","type":"OS-Augmented Oversubscription of Opportunistic Memory with a User-Assisted OOM Killer","venue":"Middleware '19: Proceedings of the 20th International Middleware Conference","authors":["Wei Chen","Aidi Pi","Shaoqi Wang","Xiaobo Zhou"],"abstract":"Exploiting opportunistic memory by oversubscription is an appealing approach to improving cluster utilization and throughput. In this paper, we find the efficacy of memory oversubscription depends on whether or not the oversubscribed tasks can be killed by an OutOf Memory (OOM) killer in a timely manner to avoid significant memory thrashing upon memory pressure. However, current approaches in modern cluster schedulers are actually unable to unleash the power of opportunistic memory because their user space OOM killers are unable to timely deliver a task killing signal to terminate the oversubscribed tasks. Our experiments observe that a user space OOM killer fails to do that because of lacking the memory pressure knowledge from OS while the kernel space Linux OOM killer is too conservative to relieve memory pressure.In this paper, we design a user-assisted OOM killer (namely UA killer) in kernel space, an OS augmentation for accurate thrashing detection and agile task killing. To identify a thrashing task, UA killer features a novel mechanism, constraint thrashing. Upon UA killer, we develop Charon, a cluster scheduler for oversubscription of opportunistic memory in an on-demand manner. We implement Charon upon Mercury, a state-of-the-art opportunistic cluster scheduler. Extensive experiments with a Google trace in a 26-node cluster show that Charon can: (1) achieve agile task killing, (2) improve the best-effort job throughput by 3.5X over Mercury while prioritizing the production jobs, and (3) improve the 90th job completion time of production jobs over Kubernetes opportunistic scheduler by 62%.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3318216.3363375","title":"research-article ","type":"Informer: irregular traffic detection for containerized microservices RPC in the real world","venue":"SEC '19: Proceedings of the 4th ACM/IEEE Symposium on Edge Computing","authors":["Jiyu Chen","Heqing Huang","Hao Chen"],"abstract":"Containerized microservices have been widely deployed in industry. Meanwhile, security issues also arise. Many security enhancement mechanisms for containerized microservices require predefined rules and policies. However, it is challenging when it comes to thousands of microservices and a massive amount of real-time unstructured data. Hence, automatic policy generation becomes indispensable. In this paper, we focus on the automatic solution for the security problem: irregular traffic detection for RPCs.We propose Informer, which is a two-phase machine learning framework to track the traffic of each RPC and report anomalous points automatically. Firstly, we identify RPC chain patterns by density-based clustering techniques and build a graph for each critical pattern. Next, we solve the irregular RPC traffic detection problem as a prediction problem for time-series of attributed graphs by leveraging spatial-temporal graph convolution networks. Since the framework builds multiple models and makes individual predictions for each RPC chain pattern, it can be efficiently updated upon legitimate changes in any of the graphs.In evaluations, we applied Informer to a dataset containing more than 7 billion lines of raw RPC logs sampled from an large Kubernetes system for two weeks. We provide two case studies of detected real-world threats. As a result, our framework found fine-grained RPC chain patterns and accurately captured the anomalies in a dynamic and complicated microservice production scenario, which demonstrates the effectiveness of Informer.","publicationDate":"2019-11-06T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3026877.3026930","title":"Article ","type":"SCONE: secure Linux containers with Intel SGX","venue":"OSDI'16: Proceedings of the 12th USENIX conference on Operating Systems Design and Implementation","authors":["Sergei Arnautov","Bohdan Trach","Franz Gregor","Thomas Knauth","Andre Martin","Christian Priebe","Joshua Lind","Divya Muthukumaran","Dan O'Keeffe","Mark L. Stillwell","David Goltzsche","David Eyers","Rüdiger Kapitza","Peter Pietzuch","Christof Fetzer"],"abstract":"In multi-tenant environments, Linux containers managed by Docker or Kubernetes have a lower resource footprint, faster startup times, and higher I/O performance compared to virtual machines (VMs) on hypervisors. Yet their weaker isolation guarantees, enforced through software kernel mechanisms, make it easier for attackers to compromise the confidentiality and integrity of application data within containers.We describe SCONE, a secure container mechanism for Docker that uses the SGX trusted execution support of Intel CPUs to protect container processes from outside attacks. The design of SCONE leads to (i) a small trusted computing base (TCB) and (ii) a low performance overhead: SCONE offers a secure C standard library interface that transparently encrypts/decrypts I/O data; to reduce the performance impact of thread synchronization and system calls within SGX enclaves, SCONE supports user-level threading and asynchronous system calls. Our evaluation shows that it protects unmodified applications with SGX, achieving 0.6×-1.2× of native throughput.","publicationDate":"2016-11-01T23:00:00.000Z","citationCount":118},{"url":"https://dl.acm.org/doi/10.1145/3337821.3337868","title":"research-article ","type":"FlowCon: Elastic Flow Configuration for Containerized Deep Learning Applications","venue":"ICPP 2019: Proceedings of the 48th International Conference on Parallel Processing","authors":["Wenjia Zheng","Michael Tynes","Henry Gorelick","Ying Mao","Long Cheng","Yantian Hou"],"abstract":"An increasing number of companies are using data analytics to improve their products, services, and business processes. However, learning knowledge effectively from massive data sets always involves nontrivial computational resources. Most businesses thus choose to migrate their hardware needs to a remote cluster computing service (e.g., AWS) or to an in-house cluster facility which is often run at its resource capacity. In such scenarios, where jobs compete for available resources utilizing resources effectively to achieve high-performance data analytics becomes desirable. Although cluster resource management is a fruitful research area having made many advances (e.g., YARN, Kubernetes), few projects have investigated how further optimizations can be made specifically for training multiple machine learning (ML) / deep learning (DL) models. In this work, we introduce FlowCon, a system which is able to monitor loss functions of ML/DL jobs at runtime, and thus to make decisions on resource configuration elastically. We present a detailed design and implementation of FlowCon, and conduct intensive experiments over various DL models. Our experimental results show that FlowCon can strongly improve DL job completion time and resource utilization efficiency, compared to existing approaches. Specifically, FlowCon can reduce the completion time by up to 42.06% for a specific job without sacrificing the overall makespan, in the presence of various DL job workloads.","publicationDate":"2019-08-04T22:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3167132.3167248","title":"research-article ","type":"Monitoring-based auto-scalability across hybrid clouds","venue":"SAC '18: Proceedings of the 33rd Annual ACM Symposium on Applied Computing","authors":["Constantin-Cosmin Crecana","Florin Pop"],"abstract":"Cloud computing is a relatively new type of Internet-based computing that becomes more and more popular. Using methods like virtualization, adopting architectures based on microservices, automation of building and deployment processes, Cloud could provide on-demand resources and scale them accordingly to a Service Level Agreement (SLA). Even if there are a lot of Cloud computing providers (like Amazon AWS, Microsoft Azure, IBM, Google etc.), many of them providing advanced services, already deployed technologies, auto-scaling and monitoring tools, on the long run a private Cloud could cost less than a public Cloud. On the other hand, a private Cloud has the disadvantage of lacking hardware resources for scaling an unexpected spike of usage or periodical growths in the number of requests. This problem could be solved using a public Cloud provider API for extending the hardware by buying and selling resources, using a pay-per-use or a pay-as-you-go model. This paper describes and evaluates a private Cloud architecture capable of on demand deployment of microservices based applications, monitoring every instance using CPU, memory, networking and disk data collectors' software, monitoring every task queue and horizontally auto-scaling the number of instances per service. Using Cloud monitoring data, SLA and budget constraints we decide if a new instance should be spawned or terminated in the private Cloud or in a public Cloud. From the customer point of view the process of auto-scaling across the hybrid Cloud is transparent, but requires a horizontally scalable service. We will illustrate our work running an application packaged as microservices in containers in a Kubernetes private Cloud that will be extended using public resources from AWS. The results of the paper offers an architectural model that can be used to build an in-house, scalable Cloud.","publicationDate":"2018-04-08T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3297858.3304016","title":"research-article ","type":"X-Containers: Breaking Down Barriers to Improve Performance and Isolation of Cloud-Native Containers","venue":"ASPLOS '19: Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems","authors":["Zhiming Shen","Zhen Sun","Gur-Eyal Sela","Eugene Bagdasaryan","Christina Delimitrou","Robbert Van Renesse","Hakim Weatherspoon"],"abstract":"\"Cloud-native\" container platforms, such as Kubernetes, have become an integral part of production cloud environments. One of the principles in designing cloud-native applications is called Single Concern Principle, which suggests that each container should handle a single responsibility well. In this paper, we propose X-Containers as a new security paradigm for isolating single-concerned cloud-native containers. Each container is run with a Library OS (LibOS) that supports multi-processing for concurrency and compatibility. A minimal exokernel ensures strong isolation with small kernel attack surface. We show an implementation of the X-Containers architecture that leverages Xen paravirtualization (PV) to turn Linux kernel into a LibOS. Doing so results in a highly efficient LibOS platform that does not require hardware-assisted virtualization, improves inter-container isolation, and supports binary compatibility and multi-processing. By eliminating some security barriers such as seccomp and Meltdown patch, X-Containers have up to 27X higher raw system call throughput compared to Docker containers, while also achieving competitive or superior performance on various benchmarks compared to recent container platforms such as Google's gVisor and Intel's Clear Containers.","publicationDate":"2019-04-03T22:00:00.000Z","citationCount":20},{"url":"https://dl.acm.org/doi/10.1145/3299869.3314042","title":"research-article ","type":"Entity Matching Meets Data Science: A Progress Report from the Magellan Project","venue":"SIGMOD '19: Proceedings of the 2019 International Conference on Management of Data","authors":["Yash Govind","Pradap Konda","Paul Suganthan G.C.","Philip Martinkus","Palaniappan Nagarajan","Han Li","Aravind Soundararajan","Sidharth Mudgal","Jeff R. Ballard","Haojun Zhang","Adel Ardalan","Sanjib Das","Derek Paulsen","Amanpreet Singh Saini","Erik Paulson","Youngchoon Park","Marshall Carter","Mingju Sun","Glenn M. Fung","AnHai Doan"],"abstract":"Entity matching (EM) finds data instances that refer to the same real-world entity. In 2015, we started the Magellan project at UW-Madison, joint with industrial partners, to build EM systems. Most current EM systems are stand-alone monoliths. In contrast, Magellan borrows ideas from the field of data science (DS), to build a new kind of EM systems, which is an ecosystem of interoperable tools. \\em This paper provides a progress report on the past 3.5 years of Magellan, focusing on the system aspects and on how ideas from the field of data science have been adapted to the EM context. We argue why EM can be viewed as a special class of DS problems, and thus can benefit from system building ideas in DS. We discuss how these ideas have been adapted to build \\pymatcher\\ and \\cloudmatcher, EM tools for power users and lay users. These tools have been successfully used in 21 EM tasks at 12 companies and domain science groups, and have been pushed into production for many customers. We report on the lessons learned, and outline a new envisioned Magellan ecosystem, which consists of not just on-premise Python tools, but also interoperable microservices deployed, executed, and scaled out on the cloud, using tools such as Dockers and Kubernetes.","publicationDate":"2019-06-24T22:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3211890.3211916","title":"short-paper ","type":"Towards Serverless NFV for 5G Media Applications","venue":"SYSTOR '18: Proceedings of the 11th ACM International Systems and Storage Conference","authors":["David Breitgand","Avi Weit","Stamatia Rizou","David Griffin","Ugur Acar","Gino Carrozzo","Nikolaos Zioulis","Pasquale Andriani","Francesco Iadanza"],"abstract":"The advent of virtualization and IaaS have revolutionized the telecom industry via SDN/NFV. A new wave of cloud-native PaaS promises to further improve SDN/NFV performance, portability, and cost-efficiency. In this poster, we highlight a work in progress being done in the 5G-MEDIA project [2], which pioneers the application of the serverless paradigm to NFV in the context of media intensive applications in 5G networks. Motivational use cases include tele-immersive gaming, mobile journalism and UHD content distribution. For example, consider a next-gen e-sport, in which bouts between gamers last only a few minutes. FaaS offers a clear cost-efficiency benefit for hosting such applications. An architecture is shown in Fig. 1. It includes i) an Application/Service Development Kit (SDK) to enable access to media applications development tools; ii) a Service Virtualization Platform (SVP) to run the ETSI MANO framework, the Media Service MAPE optimization component and the VIM and WIM plugins to enable NFVIs integration; iii) different NFVIs to execute media-specific VNFs. FaaS VIM is implemented for integration of FaaS with the rest of the MANO stack. It allows mixing FaaS and \"regular\" VNFs within the same media forwarding graph. For reference implementation, Apache OpenWhisk [1] and Kubernetes are used. The main challenge is extending the programming model to support groups of actions communicating over a network, while retaining the simplicity of FaaS. The project is supported by EU H2020 R&I program (Grant Agreement No 761699).","publicationDate":"2018-06-03T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3263046","title":"section ","type":"Session details: The 3rd Annual Workshop on Distributed Cloud Computing (DCC 2015)","venue":"ACM SIGMETRICS Performance Evaluation Review","authors":["Marco Canini","James Kempf","Stefan Schmid"],"abstract":"The Third Annual Workshop on Distributed Cloud Computing (DCC) was held on June 15, 2015 in conjunction with the ACM SIGMETRICS conference in Portland, OR, and was chaired by Marco Canini, Université catholique de Louvain, Belgium, James Kempf, TU Berlin, Germany and Ericsson Research Silicon Valley, USA, and Stefan Schmid, TU Berlin and Telkom Innovation Labs, Germany.The DCC workshop is intended to provide a forum for academic and industrial researchers working in the different fields of networking, cloud computing, and distributed systems, to meet and exchange their vision and expertise on how to plan and manage future research on distributed cloud. After the first edition of DCC, which was collocated with a cloud computing conference (namely IEEE/ACM Utility and Cloud Computing 2013), and the second edition, which was collocated with a networking conference (namely ACM SIGCOMM 2014), we broadened the scope further with this year's third edition, which was collocated with the premier conference on performance evaluation.The great interest in distributed cloud computing is reflected in the number of submissions received. The CFP received 31 submissions of which 9 were selected by the Technical Program Committee as full papers and 4 as posters. Topics ranged from a new mechanism for auctioning off cloud resources to a Markov decision process model for deciding how to handle server failures in the cloud. In addition, the US Ignite project presented a demo of their distributed collaborative scientific visualization system, which allows visualization of large, complex scientific data sets on handheld devices.A highlight of this year's DCC workshop was the keynote given by John Wilkes, Principle Software Engineer at Google, on Google's Borg cluster management system. John noted that many of the key pieces of Borg have been open sourced in the Kubernetes container management software.","publicationDate":"2015-11-18T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3243734.3243823","title":"research-article ","type":"Mystique: Uncovering Information Leakage from Browser Extensions","venue":"CCS '18: Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security","authors":["Quan Chen","Alexandros Kapravelos"],"abstract":"Browser extensions are small JavaScript, CSS and HTML programs that run inside the browser with special privileges. These programs, often written by third parties, operate on the pages that the browser is visiting, giving the user a programmatic way to configure the browser. The privacy implications that arise by allowing privileged third-party code to execute inside the users' browser are not well understood. In this paper, we develop a taint analysis framework for browser extensions and use it to perform a large scale study of extensions in regard to their privacy practices. We first present a hybrid approach to traditional taint analysis: by leveraging the fact that extension source code is available to the runtime JavaScript engine, we implement as well as enhance traditional taint analysis using information gathered from static data flow and control-flow analysis of the JavaScript source code. Based on this, we further modify the Chromium browser to support taint tracking for extensions. We analyzed 178,893 extensions crawled from the Chrome Web Store between September 2016 and March 2018, as well as a separate set of all available extensions (2,790 in total) for the Opera browser at the time of analysis. From these, our analysis flagged 3,868 (2.13%) extensions as potentially leaking privacy-sensitive information. The top 10 most popular Chrome extensions that we confirmed to be leaking privacy-sensitive information have more than 60 million users combined. We ran the analysis on a local Kubernetes cluster and were able to finish within a month, demonstrating the feasibility of our approach for large-scale analysis of browser extensions. At the same time, our results emphasize the threat browser extensions pose to user privacy, and the need for countermeasures to safeguard against misbehaving extensions that abuse their privileges.","publicationDate":"2018-10-14T22:00:00.000Z","citationCount":11},{"url":"https://dl.acm.org/doi/10.1145/3465481.3470066","title":"research-article ","type":"Performance Evaluation of Container-Level Anomaly-Based Intrusion Detection Systems for Multi-Tenant Applications Using Machine Learning Algorithms","venue":"ARES 2021: The 16th International Conference on Availability, Reliability and Security","authors":["Marcos Cavalcanti","Pedro Inacio","Mario Freire"],"abstract":"The virtualization of computing resources provided by containers has gained increasing attention and has been widely used in cloud computing. This new demand for container technology has been growing and the use of Docker and Kubernetes is considerable. According to recent technology surveys, containers are now mainstream. However, currently, one of the major challenges rises from the fact that multiple containers, with different owners, may cohabit on the same host. In container-based multi-tenant environments, security issues are of major concern. In this paper we investigate the performance of container-level anomaly-based intrusion detection systems for multi-tenant applications. We investigate the use of Bag of System Calls (BoSC) technique and the sliding window with the classifier and we consider eight machine learning algorithms for classification purposes. We show that among the eight machine learning algorithms, the best classification results are obtained with Decision Tree and Random Forest which lead to an F-Measure of 99.8%, using a sliding window with a size of 30 and the BoSC algorithm in both cases. We also show that, although both Decision Tree and Random Forest algorithms leads to the best classification results, the Decision Tree algorithm has a shorter execution time and consumes less CPU and memory than the Random Forest. ","publicationDate":"2021-08-16T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3425269.3425270","title":"research-article ","type":"Applying a Multi-platform Architectural Conformance Solution in a Real-world Microservice-based System","venue":"SBCARS '20: Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse","authors":["Elena A. Araujo","Álvaro M. Espíndola","Vinicius Cardoso Garcia","Ricardo Terra"],"abstract":"Microservice architectures are composed of a set of independent microservices that execute well-defined functionalities, allowing each one to be developed in different programming languages and data management technologies. The problem, however, is that such heterogeneity implies in a harder verification process of communication among microservices and the architectural designs of each microservice. Although the state-of-the-art provides several architectural conformance solutions, none formally restricts communications (e.g., over HTTP) between different systems. Even stable and industrial solutions---such as Kubernetes, Terraform, and Docker Compose---provide basic mechanisms to restrict communications between microservices. Thereupon, this paper proposes and evaluates a multi-platform architectural conformance solution for the microservice architecture. For this purpose, (i) we specify an architectural constraint language, called DCL+---adapted from the DCL (Dependency Constraint Language) language; (ii) we propose a multi-platform process that restricts the communication between the microservices and also verifies the architectural projects of each one of them; (iii) we develop DCL+check, a tool that implements the proposed solution; (iv) we apply our process in a medium-size real-world application composed of eleven microservices, developed in two different languages (JavaScript and Java). As result, we found 16 communication and 171 structural design violations. The communication violations occurred in general due to the lack of knowledge of the developers about the restrictions of communication among the modules of the orchestrator system and other microservices, as well as the evolution of two microservices.","publicationDate":"2020-10-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3319647.3325850","title":"poster ","type":"Noisy neighbor detection using skydive","venue":"SYSTOR '19: Proceedings of the 12th ACM International Conference on Systems and Storage","authors":["Ofir Zeilig","Noa Bratman","Itzik Ashkenazi","Eran Raichstein","Anna Levin","Katherine Barabash"],"abstract":"Cloud computing technology enables uniform access to shared pools of configurable system resources and higher-level services, rapidly provisioned with minimal management effort. Cloud computing relies on sharing the resources to achieve coherence and economies of scale, through virtualizion. Cloud network, in particular, is virtualized through multiple logical constructs and SW layers, making cloud connectivity complex to configure, debug, and visualize. In this work, we show how to detect cloud network operational issues through monitoring and analytics, using and enhancing open source network analyzer, Skydive [2]. In particular, we focus on Noisy Neighbor Effect, a situation in which a common resource is monopolized by a noisy tenant, resulting in performance degradation experienced by other tenants.Skydive is an open-source network topology and protocol analyzer, capable of discovering and visualizing cloud network topology across its multiple layers, as well as capturing network traffic at programmable granularity, injecting network traffic, and more. Typical Skydive setup consists of multiple Skydive agents installed on various network components and one or more Skydive analyzers deployed on any compute resource in the cloud. Skydive agents discover and report the information to a Skydive analyzer, that stores it over time so it can be consumed via Web UI, command line tools, and REST API, for visualization, exploration, and analytics.In our work we used Skydive to investigate and detect the Noisy Neighbor Effect in Kubernetes (k8s) network. Our setup consisted of a commercial cloud platform, IBM Cloud Private (ICP) [1], running an HTTP server and two HTTP clients constantly sending requests to the server, all 3 are containerized Python applications as shown in Figure 1. We have installed Skydive agents on all the k8s worker nodes.To achieve our goal of detecting anomalous client behavior and creating a visual indication of such anomaly in Skydive UI, we have enhanced Skydive capabilities and contributed our enhancements back to the project by extending the Python REST client library to support traffic injections, and fixing existing bugs in the Skydive system.We used those enhancements to measure Round Trip Time (RTT) between nodes in the cloud network, detect anomalies in RTT measurements and indicate them in Skydive UI, such as the green indication in Figure 1.In this work, we have made the first step towards automatic detection of Noisy Neighbor with Skydive, using simple threshold based approach, in an experimental setup. This work can be extended in a multiple ways - support more generic and realistic multi-tenant setup; employ deeper analyses, e.g. ML and DL, also on historical data; explore additional anomalous cases, beyond the Noisy Neighbor Effect.","publicationDate":"2019-05-21T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3432601.3432641","title":"research-article ","type":"4th workshop on advances in open runtimes and cloud performance technologies","venue":"CASCON '20: Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering","authors":["Daryl Maier","Vijay Sundaresan","David Bremner"],"abstract":"Cloud services such as IBM Cloud or Amazon Web Services are increasingly becoming the environments where applications are developed, tested, and deployed, data gets stored, and businesses are run. Many of the features that define a cloud (e.g., resiliency, elasticity, consistency, security) are realized through runtime technologies. Clouds are polyglot environments, and therefore advances in cloud development are directly driven by innovation in runtime technologies. However, cloud environments pose unique and often conflicting demands on runtime systems that are generally less of a concern in isolated systems. Throughput performance (how many results can my application produce?), density (how many instances of my application can I create and run simultaneously in my provisioned environment?), startup performance (how quickly can I start a new instance of my application?), and language interoperability are all examples of important considerations that require innovative solutions.Modern language runtimes are complex, dynamic systems that involve a myriad of components that must work cooperatively to achieve the functional and performance requirements of a given language. Typical core runtime technologies include dynamic just-in-time compilers for performance, garbage collection for heap management, platform abstraction for ease of portability to different hardware and operating system environments, test infrastructure for quality control, developer tooling for diagnosis and tuning of the various components, and interoperability between different language environments.Cloud workloads are typically containerized and employ microservice and serverless architectures. Achieving peak performance in such environments requires careful tuning of the cloud services and applications in concert with the runtime system.The goal of this workshop was to bring together research, industry, and developers from runtimes and cloud communities to share and discuss innovations, challenges, and research across a broad set of open source technologies (such as Eclipse OMR, Eclipse OpenJ9, Node.js, Open Liberty, Kubernetes) to improve performance in cloud environments. The focus on open solutions rather than proprietary was key as it allowed for greater collaboration amongst individuals, communities, researchers, and industry through shared learning on common technology.This was a full-day virtual speaker session workshop where researchers, students, and practitioners presented their recent innovative work and findings. Topics discussed in the workshop included, but were not limited to:• Open runtime technology frameworks;• Compiler technology and innovative optimizations for dynamic cloud environments;• Garbage collection and memory subsystem performance;• Runtimes/Cloud cooperative tuning;• Hardware techniques to assist runtime technologies;• Dynamic languages for the cloud;• Testing and correctness of runtime technology;• Throughput and startup performance, and memory footprint reduction;• Use of tools and infrastructure built on open technologies; and• Innovative ways of exploiting open runtime technologies.This workshop was successful in exploring a wide range of innovative runtime problems and solutions for the cloud environments. Many of the innovations were based on the open-source Eclipse OMR and Eclipse OpenJ9 projects. Eclipse OMR is a toolkit of language-agnostic runtime components that can be integrated in runtime environments to provide or extend the desired runtime features. The most popular components include garbage collection and compilation technologies as well as a common, portable interface for abstracting operating system functionality. Eclipse OpenJ9 is an open source, high-performance Java Virtual Machine that fully implements that Java Virtual Machine Specification and is used by several open source Java projects such as Open Liberty.","publicationDate":"2020-11-09T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3332186.3332214","title":"research-article ","type":"Slicing and Dicing OpenHPC Infrastructure: Virtual Clusters in OpenStack","venue":"PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning)","authors":["Satrio Husodo","Jacob Chappell","Vikram Gazula","Lowell Pike","James Griffioen"],"abstract":"University research computing centers are increasingly faced with the need to support applications that are better suited for cloud infrastructure than HPC infrastructure. A common approach is to shoehorn cloud-based applications onto the university's existing HPC system, which has been done with varying levels of success. Another approach as been to create stand-alone HPC systems and private cloud systems, resulting in ineffective use of resources. A more recent approach has been to use hybrid systems where the HPC system \"bursts\" excess jobs to private cloud nodes configured as bare-metal nodes built from the same (expensive) hardware as the HPC system.This paper explores another model, namely the use of private cloud infrastructure (built from inexpensive commodity networks and storage systems) to host both HPC jobs and VMs simultaneously Utilizing VMs allows these emerging applications to leverage cloud frameworks specifically designed for them (e.g., OpenStack, Kubernetes, Mesos, Hadoop, and Spark), while at the same time effectively supporting a growing percentage of the HPC jobs (e.g., single node jobs, and embarrassingly parallel jobs). Because the system can be constructed from commodity cloud networks and storage, it makes cost-effective use of the resources as opposed to HPC systems used to run jobs that do not use (waste) its expensive resources.To demonstrate the advantages of using cloud infrastructure for both cloud applications and HPC applications, we describe a system that can dynamically launch OpenHPC systems on commodity OpenStack infrastructure. Moreover, users can use the system to deploy \"personal\" OpenHPC clusters, customized to their application's needs (e.g., number of nodes, cores per node, memory per node). We have used the system to effectively run OpenHPC work-loads on a cluster of large memory OpenStack nodes, allowing users to create, for example, a large memory HPC-style cluster of 500 GB nodes running OpenHPC, and a cluster of 1TB VMs operating simultaneously. Performance degradation due to virtualization has been insignificant, particularly when compared to the advantages of being able to use optimized frameworks running on cost-effective hardware.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3318464.3380591","title":"research-article ","type":"Black or White? How to Develop an AutoTuner for Memory-based Analytics","venue":"SIGMOD '20: Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data","authors":["Mayuresh Kunjir","Shivnath Babu"],"abstract":"There is a lot of interest today in building autonomous (or, self-driving) data processing systems. An emerging school of thought is to leverage AI-driven \"black box\" algorithms for this purpose. In this paper, we present a contrarian view. We study the problem of autotuning the memory allocation for applications running on modern distributed data processing systems. We show that an empirically-driven \"white-box\" algorithm, called RelM, that we have developed provides a close-to-optimal tuning at a fraction of the overheads compared to state-of-the-art AI-driven \"black box\" algorithms, namely, Bayesian Optimization (BO) and Deep Distributed Policy Gradient (DDPG). The main reason for RelM's superior performance is that the memory management in modern memory-based data analytics systems is an interplay of algorithms at multiple levels: (i) at the resource-management level across various containers allocated by resource managers like Kubernetes and YARN, (ii) at the container level among the OS, pods, and processes such as the Java Virtual Machine (JVM), (iii) at the application level for caching, aggregation, data shuffles, and application data structures, and (iv) at the JVM level across various pools such as the Young and Old Generation. RelM understands these interactions and uses them in building an analytical solution to autotune the memory management knobs. In another contribution, called Guided-BO (GBO), we use RelM's analytical models to speed up BO. Through an evaluation based on Apache Spark, we showcase that the RelM's recommendations are significantly better than what commonly-used Spark deployments provide, and are close to the ones obtained by brute-force exploration; while GBO provides optimality guarantees for a higher, but still significantly lower cost overhead compared to the state-of-the-art AI-driven policies.","publicationDate":"2020-06-10T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3460231.3474610","title":"abstract ","type":"Personalizing Peloton: Combining Rankers and Filters To Balance Engagement and Business Goals","venue":"RecSys '21: Fifteenth ACM Conference on Recommender Systems","authors":["Shayak Banerjee","Arnab Bhadury","Nilothpal Talukder","Santosh Thammana"],"abstract":"Peloton is at the forefront of the at-home fitness market, with two business pillars: (a) a line of connected fitness equipment, and (b) a subscription-based service that offers access to a rich catalog of high quality fitness classes. As of May 2021, the total member base for Peloton stood at over 5.4 million, who took more than 170 million workouts. Peloton classes cover a diversity of instructors, languages, fitness disciplines, durations, intensity and muscle groups. On the other side, each user has their own specific fitness goals, time available to work out, fitness equipment and level of skill or strength. This diversity of content and individuality of user needs creates the need for a recommender system capable of personalizing the Peloton experience.Most recommendation engines optimize for user lifetime value or time of engagement. However, Peloton users have very different usage habits when compared to other industry recommendation problems. Users arrive on the platform with a clear intent to workout, which allows our recommendation algorithms to not just focus on the short-term classic metrics such as click-through-rates and optimizing session lengths for exploration. Instead, fitness content recommendations at Peloton also help solve longer term problems such as: It helps balance engagement and business goals. A classic example of this is the introduction of a new instructor. For existing users, who already have developed affinities to certain instructors, how can we ensure that enough of them see and try some classes from the new instructor so that they can build their own following?It helps guide users to explore the vast library of content. Peloton users quickly develop set routines with our fitness content, with high repeat plays of the same instructor/duration/class type. Recommendations serve as a mechanism to encourage them to try something outside this comfort zone, which both increases the breadth of a user's engagement with the platform and leads to a more holistic workout routine.We achieve these two goals by utilizing a combination of rankers and filters. Ranking models help order the universe of content for each user according to their preferences. Filters take a slice of this ordered content to generate a shelf of content with a reason for suggesting it. Explainability is heavily linked to business goals, while ranking is linked to engagement goals. For instance, ranking and filtering can work in tandem to populate a shelf that helps promote a new music partnership, e.g. Workouts Featuring The Beatles, where we highlight classes that contain music by The Beatles (filter), ordered by the user's class preferences (ranker). With rankers and filters, we empower other teams to curate personalized experiences. The creation process is simplified to picking a ranker and a filter to create a shelf, and then giving it a title to then have it displayed to users.Further, we have context-based models that order the shelves for each user depending on both their preferences and context, such as platform and time. For ranking our various filters, we take a multi-armed bandit approach, due to the need to handle cold starts on users and balance exploration (keep putting new shelves in front of the user) with exploitation (keep showing them shelves they already interact with). To start with, we implemented a simple Thompson Sampling based bandits algorithm, which accumulates rewards (for shelves interacted with) and penalties (for shelves ignored), which in turn constantly adapts the shelf ordering for a user, making the experience more personalized over time. We are able to perform all calculations offline in batch, using Spark, and cache the Thompson Sampling parameters in DynamoDB. When a user requests their shelves, a random sampling is performed using these parameters to serve up a contextually ordered list of shelves.A unique feature of Peloton classes is that they are usually aired “live” first, which seeds the class with a set of users. This ameliorates the cold start problem for recommending classes, opening us up to using collaborative filtering approaches. Also, users typically take one session in a given day, and most even just take one class in a given day. This means we are able to compute class recommendations for each user offline, cache it and serve it up when requested. In the offline world, we use Spark to pre-process our user-class interaction data, and then train a deep learning model using PyTorch. Our ranking model is a sequential recommender using long-short-term memory (LSTMs). From our ranked list of classes, we apply our various filters and generate the shelves of recommendations. These are cached in AWS DynamoDB, and served up via Kubernetes-driven APIs.Recommending fitness content at Peloton has the potential to go beyond simply guiding users to their next class. With a holistic overview of both what classes a user is taking and a user's feedback on their performance (explicit or implicit), there is an opportunity to tailor workout routines that optimize for long-term metrics such as health, strength or flexibility.SPEAKER BIOShayak Banerjee is currently a Staff Machine Learning Engineer on the Personalization team at Peloton, where he works on personalizing the Discovery and Browse experiences for users. His contributions relate to building out the infrastructure for running data pipelines and tools for balancing content production and consumption needs. Prior to Peloton, he worked on connecting users to communities at Meetup. Shayak graduated from The University of Texas at Austin with a PhD in Electrical & Computer Engineering.","publicationDate":"2021-09-12T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3477132.3483559","title":"research-article ","type":"dSpace: Composable Abstractions for Smart Spaces","venue":"SOSP '21: Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles CD-ROM","authors":["Silvery Fu","Sylvia Ratnasamy"],"abstract":"We present dSpace, an open and modular programming framework that aims to simplify and accelerate the development of smart space applications. To achieve this, dSpace provides two key building blocks~digivices that implement device control and actuation and digidata that process IoT data to generate events and insights. In addition, dSpace introduces novel abstractions - mount, yield, and pipe - via which digivices and digidata can be composed into higher-level abstractions. We apply dSpace to home automation systems and show how developers can easily and flexibly leverage these abstractions to support a wide range of home automation scenarios. Finally, we show how the dSpace concepts can be realized using a microservices-based architecture and implement dSpace as a Kubernetes-compatible framework.","publicationDate":"2021-10-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3474624.3477072","title":"research-article ","type":"Towards First-Class Architectural Connectors: The Case for Self-Adaptive Service Meshes","venue":"SBES '21: Brazilian Symposium on Software Engineering","authors":["Nabor Mendonca","Carlos Aderaldo"],"abstract":"The development of architectural connectors as first-class software entities is a long-standing software engineering promise that has not been fully realized thus far. This observation is especially true in self-adaptive software systems, where most advances within academia and industry have targeted software components as the primary locus for run-time adaptation. In this paper, we revisit the evolutionary history of architectural connectors and discuss the challenges of implementing architectural connectors as first-class self-adaptation entities in the domain of modern microservice applications. We then make a case for our ongoing work on a cloud-native self-adaptive service mesh framework that builds on recent container orchestration, self-adaptation, and service mesh technologies. ","publicationDate":"2021-09-26T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/2956641.2965647","title":"research-article ","type":"Cluster-level Logging of Containers with Containers: Logging Challenges of Container-Based Cloud Deployments","venue":"Queue","authors":["Satnam Singh"],"abstract":"This article shows how cluster-level logging infrastructure can be implemented using open source tools and deployed using the very same abstractions that are used to compose and manage the software systems being logged. Collecting and analyzing log information is an essential aspect of running production systems to ensure their reliability and to provide important auditing information. Many tools have been developed to help with the aggregation and collection of logs for specific software components (e.g., an Apache web server) running on specific servers (e.g., Fluentd and Logstash.) They are accompanied by tools such as Elasticsearch for ingesting log information into persistent storage and tools such as Kibana7 for querying log information.","publicationDate":"2016-05-13T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3361525.3361538","title":"research-article ","type":"FfDL: A Flexible Multi-tenant Deep Learning Platform","venue":"Middleware '19: Proceedings of the 20th International Middleware Conference","authors":["K. R. Jayaram","Vinod Muthusamy","Parijat Dube","Vatche Ishakian","Chen Wang","Benjamin Herta","Scott Boag","Diana Arroyo","Asser Tantawi","Archit Verma","Falk Pollok","Rania Khalaf"],"abstract":"Deep learning (DL) is becoming increasingly popular in several application domains and has made several new application features involving computer vision, speech recognition and synthesis, self-driving automobiles, drug design, etc. feasible and accurate. As a result, large scale \"on-premise\" and \"cloud-hosted\" deep learning platforms have become essential infrastructure in many organizations. These systems accept, schedule, manage and execute DL training jobs at scale.This paper describes the design, implementation and our experiences with FfDL, a DL platform used at IBM. We describe how our design balances dependability with scalability, elasticity, flexibility and efficiency. We examine FfDL qualitatively through a retrospective look at the lessons learned from building, operating, and supporting FfDL; and quantitatively through a detailed empirical evaluation of FfDL, including the overheads introduced by the platform for various DL models, the load and performance observed in a real case study using FfDL within our organization, the frequency of various faults observed including faults that we did not anticipate, and experiments demonstrating the benefits of various scheduling policies. FfDL has been open-sourced.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3366623.3368139","title":"research-article ","type":"Understanding Open Source Serverless Platforms: Design Considerations and Performance","venue":"WOSC '19: Proceedings of the 5th International Workshop on Serverless Computing","authors":["Junfeng Li","Sameer G. Kulkarni","K. K. Ramakrishnan","Dan Li"],"abstract":"Serverless computing is increasingly popular because of the promise of lower cost and the convenience it provides to users who do not need to focus on server management. This has resulted in the availability of a number of proprietary and open-source serverless solutions. We seek to understand how the performance of serverless computing depends on a number of design issues using several popular open-source serverless platforms. We identify the idiosyncrasies affecting performance (throughput and latency) for different open-source serverless platforms. Further, we observe that just having either resource-based (CPU and memory) or workload-based (request per second (RPS) or concurrent requests) auto-scaling is inadequate to address the needs of the serverless platforms.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":11},{"url":"https://dl.acm.org/doi/10.1145/3458336.3465276","title":"research-article ","type":"Reasoning about modern datacenter infrastructures using partial histories","venue":"HotOS '21: Proceedings of the Workshop on Hot Topics in Operating Systems","authors":["Xudong Sun","Lalith Suresh","Aishwarya Ganesan","Ramnatthan Alagappan","Michael Gasch","Lilia Tang","Tianyin Xu"],"abstract":"Modern datacenter infrastructures are increasingly architected as a cluster of loosely coupled services. The cluster states are typically maintained in a logically centralized, strongly consistent data store (e.g., ZooKeeper, Chubby and etcd), while the services learn about the evolving state by reading from the data store, or via a stream of notifications. However, it is challenging to ensure services are correct, even in the presence of failures, networking issues, and the inherent asynchrony of the distributed system. In this paper, we identify that partial histories can be used to effectively reason about correctness for individual services in such distributed infrastructure systems. That is, individual services make decisions based on observing only a subset of changes to the world around them. We show that partial histories, when applied to distributed infrastructures, have immense explanatory power and utility over the state of the art. We discuss the implications of partial histories and sketch tooling for reasoning about distributed infrastructure systems.","publicationDate":"2021-05-31T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3429357.3430523","title":"research-article ","type":"Secure Volume Hot-plugging for Containers (industry track)","venue":"Middleware '20: Proceedings of the 21st International Middleware Conference Industrial Track","authors":["Eunsoo Park","Kyungho Jeon"],"abstract":"Containers are becoming a common platform for companies to build and run their applications. We find many challenges we do not experience in VM-based virtualizations from our own experience of migrating and deploying various applications from Virtual Machines (VMs) to containers. One of the challenges arises from running stateful applications that not only read static data but also write and update data to storage. Specifically, to mount a volume (which includes NFS shares, network-attached storage, and block devices connected via networks) to a container becomes a task that requires various considerations due to security and maintenance of the host that runs containers. This paper presents a solution based on a sidecar container design pattern to the challenges of running stateful applications as containers. Our evaluation shows that the solution achieves better performance in terms of the time required to mount a new volume. Also, we share our 1-year experience of running the solution and present the lessons learned. Our solution is not only applicable to accessing storage from containers but also usable to connecting devices from IoT applications.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3332186.3332234","title":"research-article ","type":"Managing Privilege and Access on Federated Edge Platforms","venue":"PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning)","authors":["Joe Breen","Lincoln Bryant","Jiahui Chen","Emerson Ford","Robert W. Gardner","Gage Glupker","Skyler Griffith","Ben Kulbertis","Shawn McKee","Rose Pierce","Benedikt Riedel","Mitchell Steinman","Jason Stidd","Luan Truong","Jeremy Van","Ilija Vukotic","Christopher Weaver"],"abstract":"The SLATE (Services Layer at the Edge) platform supports collaborative, multi-institution scientific computing through federation of containerized edge services. This paper considers issues of trust between resource providers and developers of orchestrated services which span administrative domains. The context for discussion is the SLATE federation architecture and application deployment pattern. The major features are a custom central API server which implements the federation, partitioning of user and group applications on edge clusters, and a curated catalog of applications which can be installed within the federation.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1109/ECASE.2019.00013","title":"research-article ","type":"Architecture interoperability and repeatability with microservices: an industry perspective","venue":"ECASE '19: Proceedings of the 2nd International Workshop on Establishing a Community-Wide Infrastructure for Architecture-Based Software Engineering","authors":["Eric Yuan"],"abstract":"Microservices, along with supporting technologies such as containers, have become a prevalent architecture approach for today's software systems, especially in enterprise environments. They represent the latest evolutionary step in the decades-old journey towards service- and component-based software architectures. Along with virtualization technologies, microservices have enabled the loose-coupling of both service interfaces (message passing) and service integration (form and fit). This paper attempts to explore the impact of microservices on software architecture interoperability and repeatability, based on our experiences in developing two microservice-based systems. Our central thesis is that, if we view software architecture as a set of principal design decisions, the microservices approach enable us to more elegantly separate these decisions from non-architectural, domain-specific ones, and thus make these decisions more interoperable, reusable, and repeatable across disparate problem domains. We therefore propose that a microservices based reference architecture (RA) and reference implementation (RI) be created for the community-wide infrastructure for software engineering and software architecture research, along with a set of detailed considerations.","publicationDate":"2019-05-26T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3457388.3458621","title":"research-article ","type":"EVOLVE: HPC and cloud enhanced testbed for extracting value from large-scale diverse data","venue":"CF '21: Proceedings of the 18th ACM International Conference on Computing Frontiers","authors":["Antony Chazapis","Jean-Thomas Acquaviva","Angelos Bilas","Georgios Gardikis","Christos Kozanitis","Stelios Louloudakis","Huy-Nam Nguyen","Christian Pinto","Arno Scharl","Dimitrios Soudris"],"abstract":"EVOLVE is a pan-European Innovation Action building a converged infrastructure to bring together the HPC, Cloud, and Big Data worlds. EVOLVE's platform and software stack supports large-scale, data-intensive applications, driven primarily by industry requirements set by pilot and proof-of-concept use cases from diverse fields. Given the unprecedented data growth we are experiencing, EVOLVE's infrastructure is key in enabling the cost-effective processing of massive amounts of data and the adaptation of multiple high-end technologies, in an environment that fosters interoperability and enforces increased security.","publicationDate":"2021-05-10T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3400302.3415756","title":"invited-talk ","type":"Challenges for building a cloud native scalable and trustable multi-tenant AIoT platform","venue":"ICCAD '20: Proceedings of the 39th International Conference on Computer-Aided Design","authors":["Jinjun Xiong","Huamin Chen"],"abstract":"The arrival of 5G together with advances in artificial intelligence, machine learning, cloud computing, virtualization, and service orchestration have created a ubiquitous computing model at the network edge, enabling a host of new, AI driven edge computing applications. Although edge computing shares many characteristics of cloud computing, there are unique challenges for edge computing to meet the ever growing demands for scalability, security and multi-tenancy, especially in the upcoming 5G era. These challenges are discussed through two typical edge computing use cases: streaming video analytics and industrial IoT. A number of open research problems are discussed to call for help from the design automation community with the focus on new automation methodologies in building a cloud-native end-to-end edge computing platform.","publicationDate":"2020-11-01T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3387939.3391608","title":"demonstration ","type":"A platform to enable self-adaptive cloud applications using trustworthiness properties","venue":"SEAMS '20: Proceedings of the IEEE/ACM 15th International Symposium on Software Engineering for Adaptive and Self-Managing Systems","authors":["José D'Abruzzo Pereira","Rui Silva","Nuno Antunes","Jorge L. M. Silva","Breno de França","Regina Moraes","Marco Vieira"],"abstract":"Self-Adaptive Systems (SASs) reflect on both their state and on the environment and change their behavior to satisfy the expected objectives. Cloud systems are self-adaptive by nature, especially considering the resources used in a pay-as-you-go manner. Satisfying trustworthiness (worthiness of a service based on evidences of its trust) properties also demands self-adaptation capabilities. Unfortunately, developers lack an easy-to-use platform to support the assessment of such properties and to execute the required adaptions. This paper presents TMA, a platform that implements a MAPE-K control loop for cloud systems, supported by a distributed monitoring system based on probes. Quality Models are used to express trustworthiness properties, resulting in scores, which are used to plan adaptations through evaluation rules. These plans are executed by actuators. A demo shows the scaling up/down of the number of containers in a cloud application of a set of web services from TPC Benchmarks, as a result of changes observed in the environment.","publicationDate":"2020-06-28T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3447993.3483248","title":"research-article ","type":"Nervion: a cloud native RAN emulator for scalable and flexible mobile core evaluation","venue":"MobiCom '21: Proceedings of the 27th Annual International Conference on Mobile Computing and Networking","authors":["Jon Larrea","Mahesh K. Marina","Jacobus Van der Merwe"],"abstract":"Given the wide interest on mobile core systems and their pivotal role in the operations of current and future mobile network services, we focus on the issue of their effective evaluation, considering the radio access network (RAN) emulation methodology. While there exist a number of different RAN emulators, following different paradigms, they are limited in their scalability and flexibility, and moreover there is no one commonly accepted RAN emulator. Motivated by this, we present Nervion, a scalable and flexible RAN emulator for mobile core system evaluation that takes a novel cloud-native approach. Nervion embeds innovations to enable scalability via abstractions and RAN element containerization, and additionally supports an even more scalable control-plane only mode. It also offers ample flexibility in terms of realizing arbitrary RAN emulation scenarios, mapping them to compute clusters, and evaluating diverse core system designs. We develop a prototype implementation of Nervion that supports 4G and 5G standard compliant RAN emulation and integrate it into the Powder platform to benefit the research community. Our experimental evaluations validate its correctness and demonstrate its scalability relative to representative set of existing RAN emulators. We also present multiple case studies using Nervion that highlight its flexibility to support diverse types of mobile core evaluations.","publicationDate":"2021-10-24T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3401025.3401740","title":"research-article ","type":"The Kaiju project: enabling event-driven observability","venue":"DEBS '20: Proceedings of the 14th ACM International Conference on Distributed and Event-based Systems","authors":["Mario Scrocca","Riccardo Tommasini","Alessandro Margara","Emanuele Della Valle","Sherif Sakr"],"abstract":"Microservices architectures are getting momentum. Even small and medium-size companies are migrating towards cloud-based distributed solutions supported by lightweight virtualization techniques, containers, and orchestration systems. In this context, understanding the system behavior at runtime is critical to promptly react to errors. Unfortunately, traditional monitoring techniques are not adequate for such complex and dynamic environments. Therefore, a new challenge, namely observability, emerged from precise industrial needs: expose and make sense of the system behavior at runtime. In this paper, we investigate observability as a research problem. We discuss the benefits of events as a unified abstraction for metrics, logs, and trace data, and the advantages of employing event stream processing techniques and tools in this context. We show that an event-based approach enables understanding the system behavior in near real-time more effectively than state-of-the-art solutions in the field. We implement our model in the Kaiju system and we validate it against a realistic deployment supported by a software company.","publicationDate":"2020-07-12T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3219104.3219144","title":"research-article ","type":"Building the SLATE Platform","venue":"PEARC '18: Proceedings of the Practice and Experience on Advanced Research Computing","authors":["Joe Breen","Lincoln Bryant","Gabriele Carcassi","Jiahui Chen","Robert W. Gardner","Ryan Harden","Martin Izdimirski","Robert Killen","Ben Kulbertis","Shawn McKee","Benedikt Riedel","Jason Stidd","Luan Truong","Ilija Vukotic"],"abstract":"We describe progress on building the SLATE (Services Layer at the Edge) platform. The high level goal of SLATE is to facilitate creation of multi-institutional science computing systems by augmenting the canonical Science DMZ pattern with a generic, \"programmable\", secure and trusted underlayment platform. This platform permits hosting of advanced container-centric services needed for higher-level capabilities such as data transfer nodes, software and data caches, workflow services and science gateway components. SLATE uses best-of-breed data center virtualization and containerization components, and where available, software defined networking, to enable distributed automation of deployment and service lifecycle management tasks by domain experts. As such it will simplify creation of scalable platforms that connect research teams, institutions and resources to accelerate science while reducing operational costs and development cycle times.","publicationDate":"2018-07-21T22:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3300061.3343400","title":"poster ","type":"Poster: SeamFarm -- Distributed Data Analytic for Precision Agriculture based on Seamless Computing","venue":"MobiCom '19: The 25th Annual International Conference on Mobile Computing and Networking","authors":["Da-Hye Kim","Muhammad Rusyadi Ramli","Jae-Min Lee","Dong-Seong Kim"],"abstract":"This work proposes a framework for distributed data analytic for precision agriculture based on seamless computing paradigm named SeamFarm. Generally, heterogeneous nodes deployed for precision agriculture where these nodes generated an extensive amount of data. Then machine learning can be used to analyze this data for precision agriculture. However, most of the IoT devices are resource-constrained devices, which results in poor performance while conducting a machine learning task. Thus, in SeamFarm, we consider distributing the data as well as the task to all available nodes. The results show that SeamFarm can meet all of the functional and non-functional requirements of distributed data analytic for precision agriculture. Moreover, it can obtain faster data analytic results.","publicationDate":"2019-10-10T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3373669.3373676","title":"research-article ","type":"The secure container manager pattern","venue":"PLoP '18: Proceedings of the 25th Conference on Pattern Languages of Programs","authors":["Madiha H. Syed","Eduardo B. Fernandez"],"abstract":"Software containers have become very popular recently as flexible and portable operating-system-level virtualization solutions. They offer isolated virtual execution environments for applications while sharing host operating system, binaries and libraries with other containers. Containers are used to test and deploy applications. Large numbers of containers in a cluster can be organized, orchestrated and managed by container managers. Container managers facilitate optimal resource utilization for efficient and balanced execution of workloads. Container managers allow automation of tasks related to organization, scheduling and distribution of applications running in containers and they also improve the performance of applications running in them by supporting scalability and replication in distributed application environments. While these systems have a lot of benefits, they can only be utilized to their full potential if they are secure. Container managers incorporate various security features. We present in this paper a pattern for the security of container managers.","publicationDate":"2018-10-23T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3425269.3425274","title":"research-article ","type":"RefDiff4Go: Detecting Refactorings in Go","venue":"SBCARS '20: Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse","authors":["Rodrigo Brito","Marco Tulio Valente"],"abstract":"Refactoring is a key software development practice that seeks to improve the internal structure of the code without changing its external behavior. In this way, the identification of refactorings is a key source of information for researchers, practitioners, and tool builders. However, existing approaches and tools documented in the literature do not support emerging ecosystems, such as the one of the Go programming language, which is nowadays widely used to develop robust and popular projects. To address these challenges, we present in this paper RefDiff4Go, a Go extension for RefDiff, which is a multi-language refactoring detection tool. RefDiff4Go detects 13 refactoring types in Go projects. We also evaluated RefDiff4Go with six well-known Go open-source projects, achieving 92% of precision and 80% of recall. Finally, we show that RefDiff4Go runtime performance supports its adoption in professional software projects.","publicationDate":"2020-10-18T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3018896.3018961","title":"research-article ","type":"A framework for evaluating continuous microservice delivery strategies","venue":"ICC '17: Proceedings of the Second International Conference on Internet of things, Data and Cloud Computing","authors":["Martin Lehmann","Frode Eika Sandnes"],"abstract":"The emergence of service-oriented computing, and in particular microservice architecture, has introduced a new layer of complexity to the already challenging task of continuously delivering changes to the end users. Cloud computing has turned scalable hardware into a commodity, but also imposes some requirements on the software development process. Yet, the literature mainly focuses on quantifiable metrics such as number of manual steps and lines of code required to make a change. The industry, on the other hand, appears to focus more on qualitative metrics such as increasing the productivity of their developers. These are common goals, but must be measured using different approaches. Therefore, based on interviews of industry stakeholders a framework for evaluating and comparing approaches to continuous microservice delivery is proposed. We show that it is possible to efficiently evaluate and compare strategies for continuously delivering microservices.","publicationDate":"2017-03-21T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3344948.3344986","title":"research-article ","type":"Measuring performance quality scenarios in big data analytics applications: a DevOps and domain-specific model approach","venue":"ECSA '19: Proceedings of the 13th European Conference on Software Architecture - Volume 2","authors":["Camilo Castellanos","Carlos A. Varela","Dario Correal"],"abstract":"Big data analytics (BDA) applications use advanced analysis algorithms to extract valuable insights from large, fast, and heterogeneous data sources. These complex BDA applications require software design, development, and deployment strategies to deal with volume, velocity, and variety (3vs) while sustaining expected performance levels. BDA software complexity frequently leads to delayed deployments, longer development cycles and challenging performance monitoring. This paper proposes a DevOps and Domain Specific Model (DSM) approach to design, deploy, and monitor performance Quality Scenarios (QS) in BDA applications. This approach uses high-level abstractions to describe deployment strategies and QS enabling performance monitoring. Our experimentation compares the effort of development, deployment and QS monitoring of BDA applications with two use cases of near mid-air collisions (NMAC) detection. The use cases include different performance QS, processing models, and deployment strategies. Our results show shorter (re)deployment cycles and the fulfillment of latency and deadline QS for micro-batch and batch processing.","publicationDate":"2019-09-08T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3377811.3380335","title":"research-article ","type":"Mitigating turnover with code review recommendation: balancing expertise, workload, and knowledge distribution","venue":"ICSE '20: Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering","authors":["Ehsan Mirsaeedi","Peter C. Rigby"],"abstract":"Developer turnover is inevitable on software projects and leads to knowledge loss, a reduction in productivity, and an increase in defects. Mitigation strategies to deal with turnover tend to disrupt and increase workloads for developers. In this work, we suggest that through code review recommendation we can distribute knowledge and mitigate turnover with minimal impacton the development process. We evaluate review recommenders in the context of ensuring expertise during review, Expertise, reducing the review workload of the core team, CoreWorkload, and reducing the Files at Risk to turnover, FaR. We find that prior work that assigns reviewers based on file ownership concentrates knowledge on a small group of core developers increasing risk of knowledge loss from turnover by up to 65%. We propose learning and retention aware review recommenders that when combined are effective at reducing the risk of turnover by -29% but they unacceptably reduce the overall expertise during reviews by -26%. We develop the Sofia recommender that suggests experts when none of the files under review are hoarded by developers, but distributes knowledge when files are at risk. In this way, we are able to simultaneously increase expertise during review with a ΔExpertise of 6%, with a negligible impact on workload of ΔCoreWorkload of 0.09%, and reduce the files at risk by ΔFaR -28%. Sofia is integrated into GitHub pull requests allowing developers to select an appropriate expert or \"learner\" based on the context of the review. We release the Sofia bot as well as the code and data for replication purposes.","publicationDate":"2020-06-26T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3361242.3361254","title":"research-article ","type":"Duplicate Pull Request Detection: When Time Matters","venue":"Internetware '19: Proceedings of the 11th Asia-Pacific Symposium on Internetware","authors":["Qingye Wang","Bowen Xu","Xin Xia","Ting Wang","Shanping Li"],"abstract":"In open source communities (e.g., GitHub), developers frequently submit pull requests to fix bugs or add new features during development process. Since the process of pull request is uncoordinated and distributed, it causes massive duplication. Usually, only the first pull request qualified by reviewers can be merged to the main branch of the repository, and the others are regarded as duplication by maintainers. Since the duplication largely aggravates workloads of project reviewers and maintainers, the evolutionary process of open source repositories is delayed. To identify the duplicate pull requests automatically, Ren et al. proposed a state-of-the-art approach that models a pull request by nine features and determine whether a given request is duplicate with the other existing requests or not. Nevertheless, we notice that their approach overlooked the time factor which is a significant feature for the task. In this study, we investigate the influence of time factor and improve the pull request representation. We assume that two pull requests are more likely duplicate when their created time are close to each other. We verify the assumption based on 26 open source repositories from GitHub with over 100,000 pairs of pull requests. We integrate the time feature to the nine features proposed by Ren et al. and the experimental results show that it can substantially improve the performance of Ren et al.'s work by 14.36% and 11.93% in terms of [email protected] and [email protected], respectively.","publicationDate":"2019-10-27T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3434770.3459741","title":"research-article ","type":"eCaaS: A Management Framework of Edge Container as a Service for Business Workload","venue":"EdgeSys '21: Proceedings of the 4th International Workshop on Edge Systems, Analytics and Networking","authors":["Lianjie Cao","Anu Merican","Diman Zad Tootaghaj","Faraz Ahmed","Puneet Sharma","Vinay Saxena"],"abstract":"Enterprises are containerizing their business applications and extending those applications from cloud to edge to achieve better flexibility, agility, and performance for their business workload. Unlike data centers, edge sites including infrastructure and orchestration systems are often heterogeneous and highly customized depending on the resource availability, business requirements of the use case, and technical requirements of the application. However, in many business use cases, the lack of IT professionals with proper domain expertise makes it very challenging to create, manage, and support heterogeneous containerized edge sites at a large scale.In this work, we present the eCaaS framework that provides automated lifecycle management of containerized edge sites and applications. With eCaaS, users can create customized edge sites with only high-level business intents which are analyzed and translated to deployment templates with low-level specifications. The edge site deployment templates are then automatically executed to build, deploy, and configure the containerized edge sites and applications. To support more customization options in the future, eCaaS decouples user intents, deployment rules, and deployment specifications and formulates deployment template generation as an SMT problem to achieve better scalability and extensibility. For creating an edge site with five nodes, eCaaS takes less than one second to generate the deployment template and less than ten minutes to complete the entire deployment.","publicationDate":"2021-04-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3468791.3468813","title":"short-paper ","type":"SCHeMa: Scheduling Scientific Containers on a Cluster of Heterogeneous Machines","venue":"SSDBM 2021: 33rd International Conference on Scientific and Statistical Database Management","authors":["Thanasis Vergoulis","Konstantinos Zagganas","Loukas Kavouras","Martin Reczko","Stelios Sartzetakis","Theodore Dalamagas"],"abstract":" In the era of data-driven science, conducting computational experiments that involve analysing large datasets using heterogeneous computational clusters, is part of the everyday routine for many scientists. Moreover, to ensure the credibility of their results, it is very important for these analyses to be easily reproducible by other researchers. Although various technologies, that could facilitate the work of scientists in this direction, have been introduced in the recent years, there is still a lack of open-source platforms that combine them to this end. In this work, we describe and demonstrate SCHeMa, an open-source platform that facilitates the execution and reproducibility of computational analysis on heterogeneous clusters, leveraging containerization, experiment packaging, workflow management, and machine learning technologies.","publicationDate":"2021-07-05T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3358528.3358568","title":"research-article ","type":"A Service Performance based Dynamic Provisioning Approach in Containerized Cloud Environments","venue":"ICBDT2019: Proceedings of the 2nd International Conference on Big Data Technologies","authors":["Han Li","Limin Zhang","Wubin Li","Jing Gao"],"abstract":"Along with the evolution of cloud technology and big data technology, cloud service is becoming an emerging trend for big data processing. Cloud services are facing the challenges of dynamic provisioning and adaptation to the unpredictability of business requirements. The emergence of container technologies provides new technical opportunities for the optimization of service performance and the dynamic provisioning in cloud environments. In this paper, a service performance based dynamic provisioning approach in containerized cloud environments is proposed. The approach continuously monitors and collects the system metrics and based on the metrics customized scheduling strategies of the cloud environment are dynamically designed and adjusted. The feasibility of the approach is verified by experiments, and the experimental results show that the proposed approach can successfully completed the dynamic provisioning of the cloud environment, and it can improve the availability and reliability of cloud services. It is a new attempt of the cloud support environment to meet the business requirements.","publicationDate":"2019-08-27T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3379177.3388904","title":"research-article ","type":"Action-based Recommendation in Pull-request Development","venue":"ICSSP '20: Proceedings of the International Conference on Software and System Processes","authors":["Muhammad Ilyas Azeem","Sebastiano Panichella","Andrea Di Sorbo","Alexander Serebrenik","Qing Wang"],"abstract":"Pull requests (PRs) selection is a challenging task faced by integrators in pull-based development (PbD), with hundreds of PRs submitted on a daily basis to large open-source projects. Managing these PRs manually consumes integrators' time and resources and may lead to delays in the acceptance, response, or rejection of PRs that can propose bug fixes or feature enhancements. On the one hand, well-known platforms for performing PbD, like GitHub, do not provide built-in recommendation mechanisms for facilitating the management of PRs. On the other hand, prior research on PRs recommendation has focused on the likelihood of either a PR being accepted or receive a response by the integrator. In this paper, we consider both those likelihoods, this to help integrators in the PRs selection process by suggesting to them the appropriate actions to undertake on each specific PR. To this aim, we propose an approach, called CARTESIAN (aCceptance And Response classificaTion-based requESt IdentificAtioN) modeling the PRs recommendation according to PR actions. In particular, CARTESIAN is able to recommend three types of PR actions: accept, respond, and reject. We evaluated CARTESIAN on the PRs of 19 popular GitHub projects. The results of our study demonstrate that our approach can identify PR actions with an average precision and recall of about 86%. Moreover, our findings also highlight that CARTESIAN outperforms the results of two baseline approaches in the task of PRs selection.","publicationDate":"2020-06-25T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3429880.3430097","title":"research-article ","type":"Active-Standby for High-Availability in FaaS","venue":"WoSC'20: Proceedings of the 2020 Sixth International Workshop on Serverless Computing","authors":["Yasmina Bouizem","Nikos Parlavantzas","Djawida Dib","Christine Morin"],"abstract":"Serverless computing is becoming more and more attractive for cloud solution architects and developers. This new computing paradigm relies on Function-as-a-Service (FaaS) platforms that enable deploying functions without being concerned with the underlying infrastructure. An important challenge in designing FaaS platforms is ensuring the availability of deployed functions. Existing FaaS platforms address this challenge principally through retrying function executions. In this paper, we propose and implement an alternative fault-tolerance approach based on active-standby failover. Results from an experimental evaluation show that our approach increases availability and performance compared to the retry-based approach.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3382494.3421464","title":"research-article ","type":"Getting Started with Chaos Engineering - design of an implementation framework in practice","venue":"ESEM '20: Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)","authors":["Hugo Jernberg","Per Runeson","Emelie Engström"],"abstract":"Background. Chaos Engineering is proposed as a practice to verify a system's resilience under real, operational conditions. It employs fault injection, is originally developed at Netflix, and supported by several tools from there and other sources. Aims. We aim to introduce Chaos Engineering at ICA Gruppen AB, a group of companies whose core business is grocery retail, to improve their systems' resilience, and to capture our knowledge gained from literature and interviews in a process framework for the introduction of Chaos Engineering. Method. The research is conducted under the design science paradigm, where the problem is conceptualized through a literature study of Chaos Engineering and exploratory interviews in the company. The solution framework is designed based on the literature and a tool survey, and validated by letting software engineers at ICA apply parts of it to the software systems of ica.se website, including its e-shop. Results. The main contributions are a synthesis of Chaos Engineering literature and tools, in depth understanding of the needs of the case company, and guidelines for introducing Chaos Engineering. Conclusions. The applied parts were concluded to be feasible and they successfully discovered a set of initial improvement opportunities for the system's resilience, as well as a suitable Chaos Engineering practice for future resilience testing of the system. We recommend companies using the framework as a guide for the implementation of Chaos Engineering.","publicationDate":"2020-10-04T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3241403.3241423","title":"research-article ","type":"Generality vs. reusability in architecture-based self-adaptation: the case for self-adaptive microservices","venue":"ECSA '18: Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings","authors":["Nabor C. Mendonça","David Garlan","Bradley Schmerl","Javier Cámara"],"abstract":"Why is it so difficult to build self-adaptive systems by reusing existing self-adaptation services and frameworks? In this paper, we argue that one possible explanation is that there is a fundamental mismatch between the adaptation needs of modern software systems, and the architectural models and adaptation mechanisms supported by current self-adaptation solutions. We identify and discuss the main reasons leading to this problem by looking into a number of representative self-adaptation solutions that have been proposed in recent years, including open source frameworks and cloud-based services, from two perspectives: generality, i.e., their ability to support a variety of architectural models and adaptation mechanisms, and reusability, i.e., their ability to be reused without requiring substantial effort from software developers. We then make the case that recent industry progress toward microservices and their enabling technologies can open the way to the development of more general and reusable self-adaptation solutions.","publicationDate":"2018-09-23T22:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3437802.3437805","title":"research-article ","type":"A Cloud Robotic Application Platform Design Based on the Microservices Architecture","venue":"CCRIS 2020: 2020 International Conference on Control, Robotics and Intelligent System","authors":["Binhuai Xu","Jing Bian"],"abstract":" The paradigm of cloud robotics points out a direction for the future development of robots. By deploying robotic applications in the cloud, the workload and cost of local robots are greatly reduced. The rise of microservices and cloud-native technology provides conveniences and guarantees for the development and deployment of cloud applications. This paper proposes a cloud robotic application platform design based on microservices. With the help of Robot Operating System (ROS), we can use the existing rich and diverse robot software packages and deploy them in the cloud without extra modifications. Through the microservices architecture and container technology, robotic applications can be further decoupled in the cloud. That improves the flexibility and compatibility of the platform and embodies the core idea of microservices. In the end, we present a demonstration to cooperate with a simulated robot to complete the simultaneous localization and mapping (SLAM) task, which verifies the feasibility of our design.","publicationDate":"2020-10-26T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3317549.3323410","title":"research-article ","type":"Scaling pseudonymous authentication for large mobile systems","venue":"WiSec '19: Proceedings of the 12th Conference on Security and Privacy in Wireless and Mobile Networks","authors":["Mohammad Khodaei","Hamid Noroozi","Panos Papadimitratos"],"abstract":"The central building block of secure and privacy-preserving Vehicular Communication (VC) systems is a Vehicular Public-Key Infrastructure (VPKI), which provides vehicles with multiple anonymized credentials, termed pseudonyms. These pseudonyms are used to ensure message authenticity and integrity while preserving vehicle (thus passenger) privacy. In the light of emerging large-scale multi-domain VC environments, the efficiency of the VPKI and, more broadly, its scalability are paramount. By the same token, preventing misuse of the credentials, in particular, Sybil-based misbehavior, and managing \"honest-but-curious\" insiders are other facets of a challenging problem. In this paper, we leverage the state-of-the-art VPKI system and enhance its functionality towards a highly-available, dynamically-scalable, and resilient design; this ensures that the system remains operational in the presence of benign failures or resource depletion attacks, and that it dynamically scales out, or possibly scales in, according to request arrival rates. Our full-blown implementation on the Google Cloud Platform shows that deploying large-scale and efficient VPKI can be cost-effective.","publicationDate":"2019-05-14T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3147234.3148111","title":"research-article ","type":"Towards Quantifiable Boundaries for Elastic Horizontal Scaling of Microservices","venue":"UCC '17 Companion: Companion Proceedings of the10th International Conference on Utility and Cloud Computing","authors":["Manuel Ramírez López","Josef Spillner"],"abstract":"One of the most useful features of a microservices architecture is its versatility to scale horizontally. However, not all services scale in or out uniformly. The performance of an application composed of microservices depends largely on a suitable combination of replica count and resource capacity. In practice, this implies limitations to the efficiency of autoscalers which often overscale based on an isolated consideration of single service metrics. Consequently, application providers pay more than necessary despite zero gain in overall performance. Solving this issue requires an application-specific determination of scaling limits due to the general infeasibility of an application-agnostic solution. In this paper, we study microservices scalability, the auto-scaling of containers as microservice implementations and the relation between the number of replicas and the resulting application task performance. We contribute a replica count determination solution with a mathematical approach. Furthermore, we offer a calibration software tool which places scalability boundaries into declarative composition descriptions of applications ready to be consumed by cloud platforms.","publicationDate":"2017-12-04T23:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3147234.3148111","title":"research-article ","type":"Towards Quantifiable Boundaries for Elastic Horizontal Scaling of Microservices","venue":"UCC '17 Companion: Companion Proceedings of the10th International Conference on Utility and Cloud Computing","authors":["Manuel Ramírez López","Josef Spillner"],"abstract":"One of the most useful features of a microservices architecture is its versatility to scale horizontally. However, not all services scale in or out uniformly. The performance of an application composed of microservices depends largely on a suitable combination of replica count and resource capacity. In practice, this implies limitations to the efficiency of autoscalers which often overscale based on an isolated consideration of single service metrics. Consequently, application providers pay more than necessary despite zero gain in overall performance. Solving this issue requires an application-specific determination of scaling limits due to the general infeasibility of an application-agnostic solution. In this paper, we study microservices scalability, the auto-scaling of containers as microservice implementations and the relation between the number of replicas and the resulting application task performance. We contribute a replica count determination solution with a mathematical approach. Furthermore, we offer a calibration software tool which places scalability boundaries into declarative composition descriptions of applications ready to be consumed by cloud platforms.","publicationDate":"2017-12-04T23:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3267120","title":"research-article ","type":"Using remote cache service for bazel","venue":"Communications of the ACM","authors":["Alpha Lam"],"abstract":"Save time by sharing and reusing build and test output.","publicationDate":"2018-12-18T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3468267.3470621","title":"research-article ","type":"X-composer: enabling cross-environments in-situ workflows between HPC and cloud","venue":"PASC '21: Proceedings of the Platform for Advanced Scientific Computing Conference","authors":["Feng Li","Dali Wang","Feng Yan","Fengguang Song"],"abstract":"As large-scale scientific simulations and big data analyses become more popular, it is increasingly more expensive to store huge amounts of raw simulation results to perform post-analysis. To minimize the expensive data I/O, \"in-situ\" analysis is a promising approach, where data analysis applications analyze the simulation generated data on the fly without storing it first. However, it is challenging to organize, transform, and transport data at scales between two semantically different ecosystems due to the distinct software and hardware difference. To tackle these challenges, we design and implement the X-Composer framework. X-Composer connects cross-ecosystem applications to form an \"in-situ\" scientific workflow, and provides a unified approach and recipe for supporting such hybrid in-situ workflows on distributed heterogeneous resources. X-Composer reorganizes simulation data as continuous data streams and feeds them seamlessly into the Cloud-based stream processing services to minimize I/O overheads. For evaluation, we use X-Composer to set up and execute a cross-ecosystem workflow, which consists of a parallel Computational Fluid Dynamics simulation running on HPC, and a distributed Dynamic Mode Decomposition analysis application running on Cloud. Our experimental results show that X-Composer can seamlessly couple HPC and Big Data jobs in their own native environments, achieve good scalability, and provide high-fidelity analytics for ongoing simulations in real-time.","publicationDate":"2021-07-04T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3366615.3368355","title":"research-article ","type":"A Case for Performance-Aware Deployment of Containers","venue":"WOC '19: Proceedings of the 5th International Workshop on Container Technologies and Container Clouds","authors":["Edwin F. Boza","Cristina L. Abad","Shankaranarayanan Puzhavakath Narayanan","Bharath Balasubramanian","Minsung Jang"],"abstract":"Cloud-native applications are increasingly adopting microservices architectures that support the development agility required by modern software. These applications deploy their components in containers that enable microservices to be deployed across different platforms, supporting the independent scaling of the different components. However, the operational complexity of microservices presents significant challenges in maintaining the performance of such applications, especially in clouds with performance variability and unpredictability. While virtual machine based deployment of applications has been well studied---with sophisticated orchestrators in the literature and practice---there has been little such studies on the opportunity in improving application performance using performance-aware deployment strategies for containers. In this paper, we consider both the runtime and initialization time performance of containerized applications and show that default placement strategies provided by orchestrators are often insufficient. Our experiments on multiple services show that a performance-aware approach is able to outperform the default placement strategy by up to factor of 2x and 2.21x for the 50th and 99th percentiles.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3387902.3394031","title":"extended-abstract ","type":"Management of container-based genetic algorithm workloads over cloud infrastructure","venue":"CF '20: Proceedings of the 17th ACM International Conference on Computing Frontiers","authors":["Thamer Alrefai","Leandro Soares Indrusiak"],"abstract":"This paper proposes two approaches to managing the workload of multiple instances of genetic algorithms (GAs) running as containers over a cloud environment. The aim of both approaches is to obtain, for as many instances as possible, a GA output which achieves a user-defined fitness level by a user-defined deadline. To reach such a goal, the proposed approaches allocate the GA containers to cloud nodes and carefully control the execution of every GA instance by forcing them to run in stages. The paper proposes two approaches, fitness tracking (FT) and fitness prediction (FP), with both approaches compared against state-of-the-art container-based orchestration approaches.","publicationDate":"2020-05-10T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3422604.3425949","title":"research-article ","type":"Towards Verified Self-Driving Infrastructure","venue":"HotNets '20: Proceedings of the 19th ACM Workshop on Hot Topics in Networks","authors":["Bingzhe Liu","Ali Kheradmand","Matthew Caesar","P. Brighten Godfrey"],"abstract":"Modern \"self-driving'' service infrastructures consist of a diverse collection of distributed control components providing a broad spectrum of application- and network-centric functions. The complex and non-deterministic nature of these interactions leads to failures, ranging from subtle gray failures to catastrophic service outages, that are difficult to anticipate and repair.Our goal is to call attention to the need for formal understanding of dynamic service infrastructure control. We provide an overview of several incidents reported by large service providers as well as issues in a popular orchestration system, identifying key characteristics of the systems and their failures. We then propose a verification approach in which we treat abstract models of control components and the environment as parametric transition systems and leverage symbolic model checking to verify safety and liveness properties, or propose safe configuration parameters. Our preliminary experiments show that our approach is effective in analyzing complex failure scenarios with acceptable performance overhead.","publicationDate":"2020-11-03T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3009925.3009930","title":"short-paper ","type":"The Prospects for Multi-Cloud Deployment of SaaS Applications with Container Orchestration Platforms","venue":"Middleware Doctoral Symposium'16: Proceedings of the Doctoral Symposium of the 17th International Middleware Conference","authors":["Vincent Reniers"],"abstract":"Recent years have seen an increased adoption of container technology for software deployment and lightweight virtualization. More recently, container orchestration systems provide a platform for container deployment and management of cluster resources.Software-as-a-Service (SaaS) providers traditionally make use of middleware to facilitate multi-tenancy in a federated cloud. Container orchestration presents many opportunities in achieving scalability and providing cost-efficient multi-tenancy. In this paper, we outline opportunities and challenges for multi-cloud deployment of containerized SaaS applications.","publicationDate":"2016-12-11T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1109/CGO51591.2021.9370317","title":"research-article ","type":"GoBench: a benchmark suite of real-world go concurrency bugs","venue":"CGO '21: Proceedings of the 2021 IEEE/ACM International Symposium on Code Generation and Optimization","authors":["Ting Yuan","Guangwei Li","Jie Lu","Chen Liu","Lian Li","Jingling Xue"],"abstract":"Go, a fast growing programming language, is often considered as \"the programming language of the cloud\". The language provides a rich set of synchronization primitives, making it easy to write concurrent programs with great parallelism. However, the rich set of primitives also introduces many bugs.We build GoBench, the first benchmark suite for Go concurrency bugs. Currently, GoBench consists of 82 real bugs from 9 popular open source applications and 103 bug kernels. The bug kernels are carefully extracted and simplified from 67 out of these 82 bugs and 36 additional bugs reported in a recent study to preserve their bug-inducing complexities as much as possible. These bugs cover a variety of concurrency issues, both traditional and Go-specific. We believe GoBench will be instrumental in helping researchers understand concurrency bugs in Go and develop effective tools for their detection. We have therefore evaluated a range of representative concurrency error detection tools using GoBench. Our evaluation has revealed their limitations and provided insights for making further improvements.","publicationDate":"2021-02-26T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3355738.3355751","title":"research-article ","type":"Human in the Loop Virtual Machine Management on Comet","venue":"HARC '19: Proceedings of the Humans in the Loop: Enabling and Facilitating Research on Cloud Computing","authors":["Gregor von Laszewski","Fugang Wang","Geoffrey C. Fox","Shawn Strande","Christopher Irving","Trevor Cooper","Dmitry Mishin","Michael L. Norman"],"abstract":"The Comet petascale system is an XSEDE resource with the goal of serving a large user community. The Comet project has served a large number of users while using traditional supercomputing as well as science gateways. In addition to these offerings, Comet also includes a non traditional virtual machine framework that allows users to access entire Virtual Clusters instead of just focusing on individual virtual machines. The virtual machine framework integrates a custom administration interface, a novel virtual machine image management back-end, industry standard hardware virtualization technology and leverages the Comet resource manager and job scheduler to provide access to Comet compute nodes. However, to access and manage it user input is required. In this paper, we summarize the efforts of human in the loop-for-cloud require as part of the computing activities on comet. This includes a discussion of how to get access, how to use the system, how to obtain support and what lessons we learned form the operation of this facility for users.","publicationDate":"2019-07-28T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3382494.3410693","title":"research-article ","type":"Challenges in Docker Development: A Large-scale Study Using Stack Overflow","venue":"ESEM '20: Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)","authors":["Mubin Ul Haque","Leonardo Horn Iwaya","M. Ali Babar"],"abstract":"Background: Docker technology has been increasingly used among software developers in a multitude of projects. This growing interest is due to the fact that Docker technology supports a convenient process for creating and building containers, promoting close cooperation between developer and operations teams, and enabling continuous software delivery. As a fast-growing technology, it is important to identify the Docker-related topics that are most popular as well as existing challenges and difficulties that developers face.Aims: This paper presents a large-scale empirical study identifying practitioners' perspectives on Docker technology by mining posts from the Stack Overflow (SoF) community. Method: A dataset of 113, 922 Docker-related posts was created based on a set of relevant tags and contents. The dataset was cleaned and prepared. Topic modelling was conducted using Latent Dirichlet Allocation (LDA), allowing the identification of dominant topics in the domain. Results: Our results show that most developers use SoF to ask about a broad spectrum of Docker topics including framework development, application deployment, continuous integration, web-server configuration and many more. We determined that 30 topics that developers discuss can be grouped into 13 main categories. Most of the posts belong to categories of application development, configuration, and networking. On the other hand, we find that the posts on monitoring status, transferring data, and authenticating users are more popular among developers compared to the other topics. Specifically, developers face challenges in web browser issues, networking error and memory management. Besides, there is a lack of experts in this domain. Conclusion: Our research findings will guide future work on the development of new tools and techniques, helping the community to focus efforts and understand existing trade-offs on Docker topics.","publicationDate":"2020-10-04T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3318216.3363305","title":"research-article ","type":"Infrastructure fault detection and prediction in edge cloud environments","venue":"SEC '19: Proceedings of the 4th ACM/IEEE Symposium on Edge Computing","authors":["Mbarka Soualhia","Chunyan Fu","Foutse Khomh"],"abstract":"As an emerging 5G system component, edge cloud becomes one of the key enablers to provide services such us mission critical, IoT and content delivery applications. However, because of limited fail-over mechanisms in edge clouds, faults (e.g., CPU or HDD faults) are highly undesirable. When infrastructure faults occur in edge clouds, they can accumulate and propagate; leading to severe degradation of system and application performance. It is therefore crucial to identify these faults early on and mitigate them. In this paper, we propose a framework to detect and predict several faults at infrastructure-level of edge clouds using supervised machine learning and statistical techniques. The proposed framework is composed of three main components responsible for: (1) data pre-processing, (2) fault detection, and (3) fault prediction. The results show that the framework allows to timely detect and predict several faults online. For instance, using Support Vector Machine (SVM), Random Forest(RF) and Neural Network(NN)models, the framework is able to detect non-fatal CPU and HDD overload faults with an F1 score of more than 95%. For the prediction, the Convolutional Neural Network (CNN) and Long Short Term Memory (LSTM) have comparable accuracy at 96.47% vs. 96.88% for CPU-overload fault and 85.52% vs. 88.73% for network fault.","publicationDate":"2019-11-06T23:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3332186.3333150","title":"research-article ","type":"Interdependent Networked Community Resilience Modeling Environment (INCORE)","venue":"PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning)","authors":["Jong S. Lee","Christopher M. Navarro","Nathan Tolbert","Yong Wook Kim","Vara Veera Gowtham Naraharisetty","Chen Wang","Michal Ondrejcek","Diego Calderon","Shannon L. Bradley","Mark Fredricksen"],"abstract":"No abstract available.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3154011","title":"research-article ","type":"Research for practice: cluster scheduling for datacenters","venue":"Communications of the ACM","authors":["Malte Schwarzkopf","Peter Bailis"],"abstract":"Expert-curated guides to the best of CS research.","publicationDate":"2018-04-23T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3437359.3465588","title":"short-paper ","type":"Expanse: Computing without Boundaries: Architecture, Deployment, and Early Operations Experiences of a Supercomputer Designed for the Rapid Evolution in Science and Engineering","venue":"PEARC '21: Practice and Experience in Advanced Research Computing","authors":["Shawn Strande","Haisong Cai","Mahidhar Tatineni","Wayne Pfeiffer","Christopher Irving","Amit Majumdar","Dmitry Mishin","Robert Sinkovits","Mike Norman","Nicole Wolter","Trevor Cooper","Ilkay Altintas","Marty Kandes","Ismael Perez","Manu Shantharam","Mary Thomas","Subhashini Sivagnanam","Thomas Hutton"],"abstract":"We describe the design motivation, architecture, deployment, and early operations of Expanse, a 5 Petaflop, heterogenous HPC system that entered production as an NSF-funded resource in December 2020 and will be operated on behalf of the national community for five years. Expanse will serve a broad range of computational science and engineering through a combination of standard batch-oriented services, and by extending the system to the broader CI ecosystem through science gateways, public cloud integration, support for high throughput computing, and composable systems. Expanse was procured, deployed, and put into production entirely during the COVID-19 pandemic, adhering to stringent public health guidelines throughout. Nevertheless, the planned production date of October 1, 2020 slipped by only two months, thanks to thorough planning, a dedicated team of technical and administrative experts, collaborative vendor partnerships, and a commitment to getting an important national computing resource to the community at a time of great need.","publicationDate":"2021-07-16T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3451906.3451917","title":"research-article ","type":"Collision avoidance proposal in a MEC based VANET environment","venue":"DS-RT '20: Proceedings of the IEEE/ACM 24th International Symposium on Distributed Simulation and Real Time Applications","authors":["Nicolas Nevigato","Mauro Tropea","Floriano De Rango"],"abstract":"Mobile Edge Computing (MEC) is a new network paradigm that allows resource management and IT services at the edge of a communication network and, so, closer to the devices guaranteeing low latency and high bandwidth requirements. This characteristic makes MEC paradigm suitable for critical communication services used in collaboration with container-based virtualization and with 5G networks. In this paper, an implementation of a collision avoidance system based on MEC in a VANET environment is proposed. This system makes use of cloud and edge computing and it is able to switch communication from edge to cloud server and vice versa when possible, trying to guarantee the required constraints and balancing the communication among the servers avoiding of overloading edge layer. The simulation results have proved how, in some cases, the MEC-5G combination is the best solution for avoiding collisions in a VANET environment.","publicationDate":"2020-09-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1109/MODELS-C.2019.00011","title":"research-article ","type":"Simulation as a service for cooperative vehicles","venue":"MODELS '19: Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems","authors":["Jörg Christian Kirchhof","Evgeny Kusmenko","Bernhard Rumpe","Hengwen Zhang"],"abstract":"Simulating connected vehicles in realistic environments is a computationally expensive task, particularly when large numbers of traffic participants are involved. To cope with exploding hardware requirements it can become indispensable to tackle such simulations in a divide and conquer manner. A promising approach breaking down a simulation scenario in a set of small tasks is the spatial subdivision of the simulated area. Thereby, each spatial sector is simulated by a dedicated sub-simulator enabling efficient distribution of the overall simulation across multiple machines. However, a distributable and easy-to-use simulation solution providing automated scalability and hiding the distribution complexity from the simulation engineer requires a service-based simulator architecture equipped with interfaces for simulation control, integration, and resource management. In this work, building upon previous results we propose a cloud-ready simulation infrastructure providing automotive engineers with the ability to analyze large scale connected traffic scenarios without caring about the execution environment. As a consequence, the proposed solution can be integrated seamlessly into existing continuous integration environments supporting agile research and development processes for cooperatively interacting vehicles.","publicationDate":"2019-09-14T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3311790.3396635","title":"research-article ","type":"Custos: Security Middleware for Science Gateways","venue":"PEARC '20: Practice and Experience in Advanced Research Computing","authors":["Isuru Ranawaka","Suresh Marru","Juleen Graham","Aarushi Bisht","Jim Basney","Terry Fleury","Jeff Gaynor","Dimuthu Wannipurage","Marcus Christie","Alexandru Mahmoud","Enis Afgan","Marlon Pierce"],"abstract":"Science gateways represent potential targets for cybersecurity threats to users, scientific research, and scientific resources. In this paper, we introduce Custos, a software framework that provides common security operations for science gateways, including user identity and access management, gateway tenant profile management, resource secrets management, and groups and sharing management. The goals of the Custos project are to provide these services to a wide range of science gateway frameworks, providing the community with an open source, transparent, and reviewed code base for common security operations; and to operate trustworthy security services for the science gateway community using this software base. To accomplish these goals, we implement Custos using a scalable microservice architecture that can provide highly available, fault tolerant operations. Custos exposes these services through a language-independent Application Programming Interface that encapsulates science gateway usage scenarios. ","publicationDate":"2020-07-25T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/2741948.2741964","title":"research-article ","type":"Large-scale cluster management at Google with Borg","venue":"EuroSys '15: Proceedings of the Tenth European Conference on Computer Systems","authors":["Abhishek Verma","Luis Pedrosa","Madhukar Korupolu","David Oppenheimer","Eric Tune","John Wilkes"],"abstract":"Google's Borg system is a cluster manager that runs hundreds of thousands of jobs, from many thousands of different applications, across a number of clusters each with up to tens of thousands of machines.It achieves high utilization by combining admission control, efficient task-packing, over-commitment, and machine sharing with process-level performance isolation. It supports high-availability applications with runtime features that minimize fault-recovery time, and scheduling policies that reduce the probability of correlated failures. Borg simplifies life for its users by offering a declarative job specification language, name service integration, real-time job monitoring, and tools to analyze and simulate system behavior.We present a summary of the Borg system architecture and features, important design decisions, a quantitative analysis of some of its policy decisions, and a qualitative examination of lessons learned from a decade of operational experience with it.","publicationDate":"2015-04-16T22:00:00.000Z","citationCount":457},{"url":"https://dl.acm.org/doi/10.1145/3373360.3380834","title":"research-article ","type":"Full-stack SDN: The Next Big Challenge?","venue":"SOSR '20: Proceedings of the Symposium on SDN Research","authors":["Gianni Antichi","Gábor Rétvári"],"abstract":"This paper challenges the common assumption that SDN networks shall be run only at lowest layers of the stack, i.e., L2 and L3. Using as use case data center networks providing virtualized services, we show how state-of-the-art solutions already employ some application-level processing via a central controller. With this in mind, we question if the lessons learned from a decade of SDN networking can be also extended to the upper layers. We make the case for a full-stack SDN framework that encompasses all protocol layers in the network stack, and call for further research in the area.","publicationDate":"2020-03-02T23:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3277539.3287302","title":"research-article ","type":"Using Remote Cache Service for Bazel: Save time by sharing and reusing build and test output","venue":"Queue","authors":["Alpha Lam"],"abstract":"Remote cache service is a new development that significantly saves time in running builds and tests. It is particularly useful for a large code base and any size of development team. Bazel is an actively developed open-source build and test system that aims to increase productivity in software development. It has a growing number of optimizations to improve the performance of daily development tasks.","publicationDate":"2018-07-31T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3282308.3282315","title":"research-article ","type":"Engineering Software for the Cloud: Automated Recovery and Scheduler","venue":"EuroPLoP '18: Proceedings of the 23rd European Conference on Pattern Languages of Programs","authors":["Tiago Boldt Sousa","Hugo Sereno Ferreira","Filipe Figueiredo Correia","Ademar Aguiar"],"abstract":"Cloud software continues to expand globally, highly motivated by how widespread the Internet is and the possibilities it unlocks with cloud computing. Still, cloud development has some intrinsic properties to it, making it complex to unexperienced developers.This research is capturing those intricacies in the form of a pattern language that gathers ten patterns for engineering software for the cloud. This paper elaborates on that research by contributing with two new patterns: AUTOMATED RECOVERY, which checks if a container is working properly, automatically recovering it in case of failure and SCHEDULER, which periodically executes actions within the infrastructure.The described patterns are useful for anyone designing software for the cloud, either to bootstrap or to validate their design decisions with the end goal of enabling them to create better software for the cloud.","publicationDate":"2018-07-03T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3360468.3368180","title":"short-paper ","type":"Efficient Microservices with Elastic Containers","venue":"CoNEXT '19 Companion: Proceedings of the 15th International Conference on emerging Networking EXperiments and Technologies","authors":["Greg Cusack","Maziyar Nazari","Sepideh Goodarzy","Prerit Oberai","Eric Rozner","Eric Keller","Richard Han"],"abstract":"Containers are a popular mechanism used among application developers when deploying their systems on cloud platforms. Both developers and cloud providers are constantly looking to simplify container management, provisioning, and monitoring. In this paper, we present a container management layer that sits beside a container orchestrator that runs, what we call, Elastic Containers. Each elastic container contains multiple subcontainers that are connected to a centralized Global Cloud Manager (GCM). The GCM gathers subcontainer resource utilization information directly from inside each kernel running the subcontainers. The GCM then tries to efficiently and optimally distribute resources between the application subcontainers residing on a distributed environment.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/2747470.2747474","title":"research-article ","type":"An architecture for self-managing microservices","venue":"AIMC '15: Proceedings of the 1st International Workshop on Automated Incident Management in Cloud","authors":["Giovanni Toffetti","Sandro Brunner","Martin Blöchlinger","Florian Dudouet","Andrew Edmonds"],"abstract":"Running applications in the cloud efficiently requires much more than deploying software in virtual machines. Cloud applications have to be continuously managed: 1) to adjust their resources to the incoming load and 2) to face transient failures replicating and restarting components to provide resiliency on unreliable infrastructure. Continuous management monitors application and infrastructural metrics to provide automated and responsive reactions to failures (health management) and changing environmental conditions (auto-scaling) minimizing human intervention.In the current practice, management functionalities are provided as infrastructural or third party services. In both cases they are external to the application deployment. We claim that this approach has intrinsic limits, namely that separating management functionalities from the application prevents them from naturally scaling with the application and requires additional management code and human intervention. Moreover, using infrastructure provider services for management functionalities results in vendor lock-in effectively preventing cloud applications to adapt and run on the most effective cloud for the job.In this position paper we propose a novel architecture that enables scalable and resilient self-management of microservices applications on cloud.","publicationDate":"2015-04-20T22:00:00.000Z","citationCount":45},{"url":"https://dl.acm.org/doi/10.1145/3357141.3357148","title":"research-article ","type":"A Microservice Based Architecture to Support Offloading in Mobile Cloud Computing","venue":"SBCARS '19: Proceedings of the XIII Brazilian Symposium on Software Components, Architectures, and Reuse","authors":["Adriano L. Cândido","Fernando A. M. Trinta","Lincoln S. Rocha","Paulo A. L. Rego","Nabor C. Mendonça","Vinicius C. Garcia"],"abstract":"Mobile devices are increasingly present in people's daily lives. However, despite the substantial improvement of new generations of smartphones, the amount of information and the complexity of the procedures delegated to these devices still imposes certain restrictions on processing, especially regarding energy consumption. A promise solution to this issue is the technique known as offloading. Over the last few years, several offloading support platforms have been proposed. This work has a particular interest in one of those platforms, called CAOS. Despite its success to perform offloading tasks, CAOS still has problems such as low scalability. In this paper, we report on the refactoring of CAOS into a new microservice-based architecture. Performance and scalability evaluations were performed in both monolithic and microservices versions to show the benefits achieved with the new CAOS architecture.","publicationDate":"2019-09-22T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3477133.3477135","title":"research-article ","type":"Detailed black-box monitoring of distributed systems","venue":"ACM SIGAPP Applied Computing Review","authors":["Francisco Neves","Ricardo Vilaça","José Pereira"],"abstract":"Modern containerized distributed systems, such as big data storage and processing stacks or micro-service based applications, are inherently hard to monitor and optimize, as resource usage does not directly match hardware resources due to multiple virtualization layers. For instance, interapplication traffic is an important factor in as it directly indicates how components interact, it has not been possible to accurately monitor it in an application independent way and without severe overhead, thus putting it out of reach of cloud platforms.In this paper we present an efficient black-box monitoring approach for gathering detailed structural information of collaborating processes in a distributed system that can be queried for various purposes, as it includes both information about processes, containers, and hosts, as well as resource usage and amount of data exchanged. The key to achieving high detail and low overhead without custom application instrumentation is to use a kernel-aided event driven strategy. We validate a prototype implementation by applying it to multi-platform microservice deployments, evaluate its performance with micro-benchmarks, and demonstrate its usefulness for container placement in a distributed data storage and processing stack (i.e., Cassandra and Spark).","publicationDate":"2021-07-19T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3419111.3421304","title":"research-article ","type":"Bypassing the load balancer without regrets","venue":"SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing","authors":["Marios Kogias","Rishabh Iyer","Edouard Bugnion"],"abstract":"Load balancers are a ubiquitous component of cloud deployments and the cornerstone of workload elasticity. Load balancers can significantly affect the end-to-end application latency with their load balancing decisions, and constitute a significant portion of cloud tenant expenses.We propose CRAB, an alternative L4 load balancing scheme that eliminates latency overheads and scalability bottlenecks while simultaneously enabling the deployment of complex, stateful load balancing policies. A CRAB load balancer only participates in the TCP connection establishment phase and stays off the connection's datapath. Thus, load balancer provisioning depends on the rate of new connections rather than the actual connection bandwidth. CRAB depends on a new TCP option that enables connection redirection. We provide different implementations for a CRAB load balancer on different technologies, e.g., P4, DPDK, and eBPF, showing that a CRAB load balancer does not require many resources to perform well. We introduce the connection redirection option to the Linux kernel with minor modifications, so that it that can be shipped with the VM images offered by the cloud providers. We show how the same functionality can be achieved with a vanilla Linux kernel using a Netfilter module, while we discuss how CRAB can work while clients and servers remain completely agnostic, based on functionality added on the host.Our evaluation shows that CRAB pushes the IO bottleneck from the load balancer to the servers in cases where vanilla L4 load balancing does not scale and provides end-to-end latencies that are close to direct communication while retaining all the scheduling benefits of stateful L4 load balancing.","publicationDate":"2020-10-11T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3357141.3357148","title":"research-article ","type":"A Microservice Based Architecture to Support Offloading in Mobile Cloud Computing","venue":"SBCARS '19: Proceedings of the XIII Brazilian Symposium on Software Components, Architectures, and Reuse","authors":["Adriano L. Cândido","Fernando A. M. Trinta","Lincoln S. Rocha","Paulo A. L. Rego","Nabor C. Mendonça","Vinicius C. Garcia"],"abstract":"Mobile devices are increasingly present in people's daily lives. However, despite the substantial improvement of new generations of smartphones, the amount of information and the complexity of the procedures delegated to these devices still imposes certain restrictions on processing, especially regarding energy consumption. A promise solution to this issue is the technique known as offloading. Over the last few years, several offloading support platforms have been proposed. This work has a particular interest in one of those platforms, called CAOS. Despite its success to perform offloading tasks, CAOS still has problems such as low scalability. In this paper, we report on the refactoring of CAOS into a new microservice-based architecture. Performance and scalability evaluations were performed in both monolithic and microservices versions to show the benefits achieved with the new CAOS architecture.","publicationDate":"2019-09-22T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3445814.3446714","title":"research-article ","type":"Benchmarking, analysis, and optimization of serverless function snapshots","venue":"ASPLOS 2021: Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems\n\t\t\t\t\n                    Benchmarking, Analysis, and Optimization of Serverless Function Snapshots\n                \n            ","authors":["Dmitrii Ustiugov","Plamen Petrov","Marios Kogias","Edouard Bugnion","Boris Grot"],"abstract":"Serverless computing has seen rapid adoption due to its high scalability and flexible, pay-as-you-go billing model. In serverless, developers structure their services as a collection of functions, sporadically invoked by various events like clicks. High inter-arrival time variability of function invocations motivates the providers to start new function instances upon each invocation, leading to significant cold-start delays that degrade user experience. To reduce cold-start latency, the industry has turned to snapshotting, whereby an image of a fully-booted function is stored on disk, enabling a faster invocation compared to booting a function from scratch.  This work introduces vHive, an open-source framework for serverless experimentation with the goal of enabling researchers to study and innovate across the entire serverless stack. Using vHive, we characterize a state-of-the-art snapshot-based serverless infrastructure, based on industry-leading Containerd orchestration framework and Firecracker hypervisor technologies. We find that the execution time of a function started from a snapshot is 95% higher, on average, than when the same function is memory-resident. We show that the high latency is attributable to frequent page faults as the function's state is brought from disk into guest memory one page at a time. Our analysis further reveals that functions access the same stable working set of pages across different invocations of the same function. By leveraging this insight, we build REAP, a light-weight software mechanism for serverless hosts that records functions' stable working set of guest memory pages and proactively prefetches it from disk into memory. Compared to baseline snapshotting, REAP slashes the cold-start delays by 3.7x, on average.","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3477133.3477135","title":"research-article ","type":"Detailed black-box monitoring of distributed systems","venue":"ACM SIGAPP Applied Computing Review","authors":["Francisco Neves","Ricardo Vilaça","José Pereira"],"abstract":"Modern containerized distributed systems, such as big data storage and processing stacks or micro-service based applications, are inherently hard to monitor and optimize, as resource usage does not directly match hardware resources due to multiple virtualization layers. For instance, interapplication traffic is an important factor in as it directly indicates how components interact, it has not been possible to accurately monitor it in an application independent way and without severe overhead, thus putting it out of reach of cloud platforms.In this paper we present an efficient black-box monitoring approach for gathering detailed structural information of collaborating processes in a distributed system that can be queried for various purposes, as it includes both information about processes, containers, and hosts, as well as resource usage and amount of data exchanged. The key to achieving high detail and low overhead without custom application instrumentation is to use a kernel-aided event driven strategy. We validate a prototype implementation by applying it to multi-platform microservice deployments, evaluate its performance with micro-benchmarks, and demonstrate its usefulness for container placement in a distributed data storage and processing stack (i.e., Cassandra and Spark).","publicationDate":"2021-07-19T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3212480.3226100","title":"demonstration ","type":"VPKIaaS: A Highly-Available and Dynamically-Scalable Vehicular Public-Key Infrastructure","venue":"WiSec '18: Proceedings of the 11th ACM Conference on Security & Privacy in Wireless and Mobile Networks","authors":["Hamid Noroozi","Mohammad Khodaei","Panos Papadimitratos"],"abstract":"The central building block of secure and privacy-preserving Vehicular Communication (VC) systems is a Vehicular Public-Key Infrastructure (VPKI), which provides vehicles with multiple anonymized credentials, termed pseudonyms. These pseudonyms are used to ensure message authenticity and integrity while preserving vehicle (and thus passenger) privacy. In the light of emerging large-scale multi-domain VC environments, the efficiency of the VPKI and, more broadly, its scalability are paramount. In this extended abstract, we leverage the state-of-the-art VPKI system and enhance its functionality towards a highly-available and dynamically-scalable design; this ensures that the system remains operational in the presence of benign failures or any resource depletion attack, and that it dynamically scales out, or possibly scales in, according to the requests' arrival rate. Our full-blown implementation on the Google Cloud Platform shows that deploying a VPKI for a large-scale scenario can be cost-effective, while efficiently issuing pseudonyms for the requesters.","publicationDate":"2018-06-17T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3445968.3452090","title":"research-article ","type":"Towards a Blockchain-SDN Architecture for Secure and Trustworthy 5G Massive IoT Networks","venue":"SDN-NFV Sec'21: Proceedings of the 2021 ACM International Workshop on Software Defined Networks & Network Function Virtualization Security","authors":["Akram Hakiri","Behnam Dezfouli"],"abstract":"The emerging 5G mobile network is a prominent technology for addressing networking related challenges of Internet of Things (IoT). The forthcoming 5G is expected to allow low-power massive IoT devices to produce high volumes of data that can be transmitted over ultra-reliable, low-latency wireless communication services. However, IoT systems encounter several security and privacy issues to prevent unauthorized access to IoT nodes. To address these challenges, this paper introduces a novel blockchain-based architecture that leverages Software Defined Network (SDN) and Network Function Virtualization (NFV) for securing IoT transactions. A novel security appliance is introduced in a form of Virtualized Network Functions (VNFs) for improving the scalability and performance of IoT networks. Then, we introduce a novel consensus algorithm to detect and report suspected IoT nodes and mitigate malicious traffic. We evaluate and compare our proposed solution against three well-known consensus algorithms, i.e., Proof of Work (PoW), Proof of Elapsed Time (PoET), and Proof of Stake (PoS). We demonstrate that the proposed solution provides substantially lower latency and higher throughput as well as trustworthy IoT communication.","publicationDate":"2021-04-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3359989.3365431","title":"research-article ","type":"Tuple space explosion: a denial-of-service attack against a software packet classifier","venue":"CoNEXT '19: Proceedings of the 15th International Conference on Emerging Networking Experiments And Technologies","authors":["Levente Csikor","Dinil Mon Divakaran","Min Suk Kang","Attila Kőrösi","Balázs Sonkoly","Dávid Haja","Dimitrios P. Pezaros","Stefan Schmid","Gábor Rétvári"],"abstract":"Efficient and highly available packet classification is fundamental for various security primitives. In this paper, we evaluate whether the de facto Tuple Space Search (TSS) packet classification algorithm used in popular software networking stacks such as the Open vSwitch is robust against low-rate denial-of-service attacks. We present the Tuple Space Explosion (TSE) attack that exploits the fundamental space/time complexity of the TSS algorithm.TSE can degrade the switch performance to 12% of its full capacity with a very low packet rate (0.7 Mbps) when the target only has simple policies such as, \"allow some, but drop others\". Worse, an adversary with additional partial knowledge of these policies can virtually bring down the target with the same low attack rate. Interestingly, TSE does not generate any specific traffic patterns but only requires arbitrary headers and payloads which makes it particularly hard to detect.Due to the fundamental complexity characteristics of TSS, unfortunately, there seems to be no complete mitigation to the problem. As a long-term solution, we suggest the use of other algorithms (e.g., HaRP) that are not vulnerable to the TSE attack. As a short-term countermeasure, we propose MFCGuard that carefully manages the tuple space and keeps packet classification fast.","publicationDate":"2019-12-02T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3007748.3007777","title":"research-article ","type":"Feasibility of Fog Computing Deployment based on Docker Containerization over RaspberryPi","venue":"ICDCN '17: Proceedings of the 18th International Conference on Distributed Computing and Networking","authors":["Paolo Bellavista","Alessandro Zanni"],"abstract":"Fog computing is strongly emerging as a relevant and interest-attracting paradigm+technology for both the academic and industrial communities. However, architecture and methodological approaches are still prevalent in the literature, while few research activities have specifically targeted so far the issues of practical feasibility, cost-effectiveness, and efficiency of fog solutions over easily-deployable environments. In this perspective, this paper originally presents i) our fog-oriented framework for Internet-of-Things applications based on innovative scalability extensions of the open-source Kura gateway and ii) its Docker-based containerization over challenging and resource-limited fog nodes, i.e., RaspberryPi devices. Our practical experience and experimental work show the feasibility of using even extremely constrained nodes as fog gateways; the reported results demonstrate that good scalability and limited overhead can be coupled, via proper configuration tuning and implementation optimizations, with the significant advantages of containerization in terms of flexibility and easy deployment, also when working on top of existing, off-the-shelf, and limited-cost gateway nodes.","publicationDate":"2017-01-04T23:00:00.000Z","citationCount":76},{"url":"https://dl.acm.org/doi/10.1145/3311790.3396648","title":"research-article ","type":"Integrating Jupyter into Research Computing Ecosystems: Challenges and Successes in Architecting JupyterHub for Collaborative Research Computing Ecosystems","venue":"PEARC '20: Practice and Experience in Advanced Research Computing","authors":["Joe Stubbs","Julia Looney","Marjo Poindexter","Elias Chalhoub","Gregory J. Zynda","Erik S. Ferlanti","Matthew Vaughn","John M. Fonner","Maytal Dahan"],"abstract":"Beginning with the initial release of the DesignSafe JupyterHub in late 2015, TACC has been building and maintaining custom JupyterHub clusters for research groups across different domains of science and engineering. Today, TACC maintains five production JupyterHub systems utilizing over half a terabyte of memory and hundreds of CPU cores supporting nearly 1,600 unique users combined. In this paper, we describe our approach to utilizing JupyterHub in these cyberinfrastructure projects and our collaborative approach to integrating Jupyter into different research communities. For two such groups, we present an in-depth discussion of the science use cases and technical drivers that informed and evolved the design of our offering, and our outreach and engagement efforts to promote adoption. We discuss the implementation of custom features we have added to better integrate JupyterHub into other components of the cyberinfrastructure platforms, and we conclude with a description of our plans for future architecture and usage of JupyterHub at TACC.","publicationDate":"2020-07-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3365199","title":"survey ","type":"The Ideal Versus the Real: Revisiting the History of Virtual Machines and Containers","venue":"ACM Computing Surveys","authors":["Allison Randal"],"abstract":"The common perception in both academic literature and industry today is that virtual machines offer better security, whereas containers offer better performance. However, a detailed review of the history of these technologies and the current threats they face reveals a different story. This survey covers key developments in the evolution of virtual machines and containers from the 1950s to today, with an emphasis on countering modern misperceptions with accurate historical details and providing a solid foundation for ongoing research into the future of secure isolation for multitenant infrastructures, such as cloud and container deployments.","publicationDate":"2020-02-04T23:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3147704.3147735","title":"research-article ","type":"The Container Manager Pattern","venue":"EuroPLoP '17: Proceedings of the 22nd European Conference on Pattern Languages of Programs","authors":["Madiha H. Syed","Eduardo B. Fernandez"],"abstract":"A container manager orchestrates and manages distributed environments composed of groups or clusters of software containers. Virtual machines have long been the option when it comes to virtualization solutions in clouds but containers provide a more portable, reusable and lightweight alternative. Containers provide operating system level virtualization where applications are executed in isolated environments sharing a host operating system, binaries, and libraries with other containers. Software containers although not new, have become very important to support convenient, and low overhead applications. Containers facilitate application deployment and distribution across computing environments. Containers are not the only components in the environment but work closely with other components that manage and support them. We present a pattern for a Container Manager which describes these components along with the required functions of this manager.","publicationDate":"2017-07-11T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3404397.3404451","title":"research-article ","type":"URSA: Precise Capacity Planning and Fair Scheduling based on Low-level Statistics for Public Clouds","venue":"ICPP '20: 49th International Conference on Parallel Processing - ICPP","authors":["Wei Zhang","Ningxin Zheng","Quan Chen","Yong Yang","Zhuo Song","Tao Ma","Jingwen Leng","Minyi Guo"],"abstract":"Database platform-as-a-service (dbPaaS) is developing rapidly and a large number of databases have been migrated to run on the Clouds for the low cost and flexibility. Emerging Clouds rely on the tenants to provide the resource specification for their database workloads. However, they tend to over-estimate the resource requirement of their databases, resulting in the unnecessarily high cost and low Cloud utilization. A methodology that automatically suggests the “just-enough” resource specification that fulfills the performance requirement of every database workload is profitable. To this end, we propose URSA, a capacity planning and fair scheduling system that is comprised of an online capacity planner, a performance interference estimator, and a contention-aware scheduling engine. The capacity planner identifies the most cost-efficient resource specification for a database workload to achieve the required performance online. The interference estimator quantifies the pressure on the shared resource and the tolerance to the shared resource contention of each workload. The scheduling engine schedules the workloads across Cloud nodes carefully to eliminate unfair performance interference between the co-located workloads. Experimental results show that URSA reduces up to 25.9% of CPU usage, 53.4% of memory and reduces the performance unfairness between the co-located workloads by 47.6% usage compared to the prior works without hurting their performance. ","publicationDate":"2020-08-16T22:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3318236.3318254","title":"research-article ","type":"Continuous A/B Testing in Containers","venue":"ICGDA 2019: Proceedings of the 2019 2nd International Conference on Geoinformatics and Data Analysis","authors":["Ádám Révész","Norbert Pataki"],"abstract":"Software version ranking plays an important role in improved user experience and software quality. A/B testing is a technique to distinguish between the popularity and usability of two quite similar versions (A and B) of a product, marketing strategy, search ad, etc. It is a kind of two-sample hypothesis testing, used in the field of statistics. This controlled experiment can evaluate user engagement or satisfaction with a new service, feature, or product. A/B testing is typically used in evaluation of user-experience design in software technology. DevOps is an emerging software methodology in which the development and operations are not independent processes, they affect each other. DevOps emphasizes the usage of virtualization technologies (e.g. containers). Docker is widely-used technology for containerization. In this paper, we deal with a new approach for regular A/B testing via Docker containers. Our solution provides an API that can be available from many DevOps tools. This approach is DevOps-style A/B testing because after the evaluation the better version remains in production.","publicationDate":"2019-03-14T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3366615.3368353","title":"research-article ","type":"PRISM: An Experiment Framework for Straggler Analytics in Containerized Clusters","venue":"WOC '19: Proceedings of the 5th International Workshop on Container Technologies and Container Clouds","authors":["Dominic Lindsay","Sukhpal Singh Gill","Peter Garraghan"],"abstract":"Containerized clusters of machines at scale that provision Cloud services are encountering substantive difficulties with stragglers -- whereby a small subset of task execution negatively degrades system performance. Stragglers are an unsolved challenge due to a wide variety of root-causes and stochastic behavior. While there have been efforts to mitigate their effects, few works have attempted to empirically ascertain how system operational scenarios precisely influence straggler occurrence and severity. This challenge is further compounded with the difficulties of conducting experiments within real-world containerized clusters. System maintenance and experiment design are often error-prone and time-consuming processes, and a large portion of tools created for workload submission and straggler injection are bespoke to specific clusters, limiting experiment reproducibility. In this paper we propose PRISM, a framework that automates containerized cluster setup, experiment design, and experiment execution. Our framework is capable of deployment, configuration, execution, performance trace transformation and aggregation of containerized application frameworks, enabling scripted execution of diverse workloads and cluster configurations. The framework reduces time required for cluster setup and experiment execution from hours to minutes. We use PRISM to conduct automated experimentation of system operational conditions and identify straggler manifestation is affected by resource contention, input data size and scheduler architecture limitations.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3122865.3122876","title":"chapter ","type":"Multimedia fog computing: minions in the cloud and crowd","venue":"Frontiers of Multimedia Research","authors":["Cheng-Hsin Hsu","Hua-Jun Hong","Tarek Elgamal","Klara Nahrstedt","Nalini Venkatasubramanian"],"abstract":"In cloud computing, minions refer to virtual or physical machines that carry out the actual workload. Minions in the cloud hide in faraway data centers and thus cloud computing is less friendly to multimedia applications. The fog computing paradigm pushes minions toward edge networks. We adopt a generalized definition, where minions get into end devices owned by the crowd. The serious uncertainty, such as dynamic network conditions, limited battery levels, and unpredictable minion availability in multimedia fog platforms makes them harder to be managed than cloud platforms. In this chapter, we share our experience on utilizing resources from the crowd to optimize multimedia applications. The learned lessons shed some light on the optimal design of a unified multimedia fog platform for distributed multimedia applications.","publicationDate":"2017-12-18T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3241539.3267745","title":"poster ","type":"A SDN/NFV-Based IoT Network Slicing Creation System","venue":"MobiCom '18: Proceedings of the 24th Annual International Conference on Mobile Computing and Networking","authors":["Meng Wang","Bo Cheng","Xuan Liu","Yi Yue","Biyi Li","Junliang Chen"],"abstract":"With the emergency of IoT, there are many IoT network slices with different network requirements. Most of the current IoT system are specific and non-programmable and therefore their slices are difficult to reuse. It is difficult to meet different QoS requirements especially in IoT system because there are plenty of IoT sensors in IoT system. In this paper, we propose a novel IoT network slicing creation system which based on two emerging SDN and NFV technologies. It provides an easily-operating service creation environment and a service execution environment based on micro service architecture. We implement an IoT muti-flow transmission scenario. After adding subservices and QoS policies into a business process at the design plane, the IoT scenario can run automatically at the execution plane. Experiment results on the scenario show that the numbers of packets per second of different flows are changing gradually depend on QoS policies.","publicationDate":"2018-10-14T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3342827.3342843","title":"research-article ","type":"Big Data Framework for Scalable and Efficient Biomedical Literature Mining in the Cloud","venue":"NLPIR 2019: Proceedings of the 2019 3rd International Conference on Natural Language Processing and Information Retrieval","authors":["Zhengru Shen","Xi Wang","Marco Spruit"],"abstract":"The massive size of available biomedical literature requires researchers to utilize novel big data technologies in data storage and analysis. Among them is cloud computing which has become the most popular solution for big data applications in industry. However, many bioinformaticians still rely on expensive and inefficient in-house infrastructure to discover knowledge from biomedical literature. Although some cloud-based solutions were constructed recently, they failed to sufficiently address a few key issues including scalability, flexibility, and reusability. Moreover, no study has taken computational cost into consideration. To fill the gap, we proposed a cloud-based big data framework that enables researchers to perform reproducible and scalable large-scale biomedical literature mining in an efficient and cost-effective way. Additionally, a cloud agnostic platform was constructed and then evaluated on two open access corpora with millions of full-text biomedical articles. The results indicate that our framework supports scalable and efficient large-scale biomedical literature mining.","publicationDate":"2019-06-27T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/2988336.2988337","title":"research-article ","type":"Containers and Virtual Machines at Scale: A Comparative Study","venue":"Middleware '16: Proceedings of the 17th International Middleware Conference","authors":["Prateek Sharma","Lucas Chaufournier","Prashant Shenoy","Y. C. Tay"],"abstract":"Virtualization is used in data center and cloud environments to decouple applications from the hardware they run on. Hardware virtualization and operating system level virtualization are two prominent technologies that enable this. Containers, which use OS virtualization, have recently surged in interest and deployment. In this paper, we study the differences between the two virtualization technologies. We compare containers and virtual machines in large data center environments along the dimensions of performance, manageability and software development.We evaluate the performance differences caused by the different virtualization technologies in data center environments where multiple applications are running on the same servers (multi-tenancy). Our results show that co-located applications can cause performance interference, and the degree of interference is higher in the case of containers for certain types of workloads. We also evaluate differences in the management frameworks which control deployment and orchestration of containers and VMs. We show how the different capabilities exposed by the two virtualization technologies can affect the management and development of applications. Lastly, we evaluate novel approaches which combine hardware and OS virtualization.","publicationDate":"2016-11-27T23:00:00.000Z","citationCount":85},{"url":"https://dl.acm.org/doi/10.1145/3393822.3432339","title":"research-article ","type":"Development Frameworks for Microservice-based Applications: Evaluation and Comparison","venue":"ESSE 2020: Proceedings of the 2020 European Symposium on Software Engineering","authors":["Hai Dinh-Tuan","Maria Mora-Martinez","Felix Beierle","Sandro Rodriguez Garzon"],"abstract":"The microservice architectural style has gained much attention from both academia and industry recently as a novel way to design, develop, and deploy cloud-native applications. This concept encourages the decomposition of a monolith into multiple independently deployable units. A typical microservices-based application is formed of two service types: functional services, which provide the core business logic, and infrastructure services, which provide essential functionalities for a microservices ecosystem. To improve developers' productivity, many software frameworks have been developed to provide those reusable infrastructure services, allowing programmers to focus on implementing microservices in arbitrary ways. In this work, we made use of four open source frameworks to develop a cloud-based application in order to compare and evaluate their usability and practicability. While all selected frameworks promote asynchronous microservice design in general, there are differences in the ways each implements services. This leads to interoperability issues, such as message topic naming convention. Additionally, a key finding is the long startup times of JVM-based services that might reduce application's resiliency and portability. Some other advantages come directly from the programming language, such as the ability of Go to generate native binary executables, which results in very small and compact Docker images (up to 78% smaller compared to other languages).","publicationDate":"2020-11-05T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3219104.3219108","title":"research-article ","type":"The Pacific Research Platform: Making High-Speed Networking a Reality for the Scientist","venue":"PEARC '18: Proceedings of the Practice and Experience on Advanced Research Computing","authors":["Larry Smarr","Camille Crittenden","Thomas DeFanti","John Graham","Dmitry Mishin","Richard Moore","Philip Papadopoulos","Frank Würthwein"],"abstract":"While NSF's recent Campus Cyberinfrastructure investments have catalyzed an enormous leap in campus networking capabilities, it remains necessary to integrate these capabilities into the routine workflows of researchers transferring data among their remote collaborators, data repositories, and visualization facilities. The Pacific Research Platform (PRP) is a program to develop a science-driven, data-centric \"freeway system\" by federating campus Science DMZs into a regional Science DMZ. Research collaborations across PRP partners serve as use cases for deploying the hardware/software and addressing security/policy/social issues to achieve high-performance data transfers between researchers. The regional PRP represents a manageable scale for initial deployment efforts and capturing lessons learned, but the PRP also informs national deployments --i.e., an eventual National Research Platform (NRP). The recent First NRP Workshop included many campuses and networking organizations and addressed scientific requirements, scaling approaches, and socio-technical issues to extend the PRP to a national level; a second NRP Workshop will be held in August 2018. In this paper, we describe efforts to build the PRP, the social and technical approaches, the domain science applications of PRP's capabilities, and results of the recent NRP workshop.","publicationDate":"2018-07-21T22:00:00.000Z","citationCount":7},{"url":"https://dl.acm.org/doi/10.1145/3338906.3341185","title":"research-article ","type":"VARYS: an agnostic model-driven monitoring-as-a-service framework for the cloud","venue":"ESEC/FSE 2019: Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","authors":["Alessandro Tundo","Marco Mobilio","Matteo Orrù","Oliviero Riganelli","Michell Guzmàn","Leonardo Mariani"],"abstract":"Cloud systems are large scalable distributed systems that must be carefully monitored to timely detect problems and anomalies. While a number of cloud monitoring frameworks are available, only a few solutions address the problem of adaptively and dynamically selecting the indicators that must be collected, based on the actual needs of the operator. Unfortunately, these solutions are either limited to infrastructure-level indicators or technology-specific, for instance, they are designed to work with OpenStack but not with other cloud platforms. This paper presents the VARYS monitoring framework, a technology-agnostic Monitoring-as-a-Service solution that can address KPI monitoring at all levels of the Cloud stack, including the application-level. Operators use VARYS to indicate their monitoring goals declaratively, letting the framework to perform all the operations necessary to achieve a requested monitoring configuration automatically. Interestingly, the VARYS architecture is general and extendable, and can thus be used to support increasingly more platforms and probing technologies.","publicationDate":"2019-08-11T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3382025.3414942","title":"research-article ","type":"Variability management meets microservices: six challenges of re-engineering microservice-based webshops","venue":"SPLC '20: Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A","authors":["Wesley K. G. Assunção","Jacob Krüger","Willian D. F. Mendonça"],"abstract":"A microservice implements a small unit of functionality that it provides through a network using lightweight protocols. So, microservices can be combined to fulfill tasks and implement features of a larger software system---resembling a variability mechanism in the context of a software product line (SPL). Microservices and SPLs have similar goals, namely facilitating reuse and customizing, but they are usually employed in different contexts. Any developer who has access to the network can provide a microservice for any task, while SPLs are usually intended to implement features of a specific domain. Due to their different concepts, using microservices to implement an SPL or adopting SPL practices (e.g., variability management) for microservices is a challenging cross-area research problem. However, both techniques can complement each other, and thus tackling this problem promises benefits for organizations that employ either technique. In this paper, we reason on the importance of advancing in this direction, and sketch six concrete challenges to initiate research, namely (1) feature identification, (2) variability modeling, (3) variable microservice architectures, (4) interchangeability, (5) deep customization, and (6) re-engineering an SPL. We intend these challenges to serve as a starting point for future research in this cross-area research direction---avoiding that the concepts of one area are reinvented in the other.","publicationDate":"2020-10-18T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3400286.3418281","title":"poster ","type":"Scheduler for Distributed and Collaborative Container Clusters based on Multi-Resource Metric","venue":"RACS '20: Proceedings of the International Conference on Research in Adaptive and Convergent Systems","authors":["Yena Lee","Jae-Hoon An","Younghwan Kim"],"abstract":"With the development of cloud technology, distributed and collaborative container platform technology has emerged to overcome the limitations of the existing stand-alone container platform, which has limitations in the mobility and resource scalability of cloud services. Distributed and collaborative container platform technology enables flexible expansion of resources and maximization of service mobility between container platforms distributed locally.In this paper, we propose a two-stage scheduler based on multi-resource metrics. The proposed scheduler determines the proper federated cluster where the request deployment can be deployed in a distributed and collaborative cluster environment. In order to select an proper federated cluster, filtering to select candidate clusters to which the scheduling request deployment can be deployed and scoring to evaluate the preference of each filtered cluster are performed.","publicationDate":"2020-10-12T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3484272.3484962","title":"research-article ","type":"Teaching DevOps: a tale of two universities","venue":"SPLASH-E 2021: Proceedings of the 2021 ACM SIGPLAN International Symposium on SPLASH-E","authors":["Richard Hobeck","Ingo Weber","Len Bass","Hasan Yasar"],"abstract":"DevOps is a set of practices in software engineering that is in high demand by industry. It is a dynamic field which constantly adds new methods and tools. Teaching DevOps prepares today’s computer science students for best-practices in a working environment but challenges university lecturers to provide central concepts while staying up-to-date with current trends. In this paper we report and reflect on our experiences teaching DevOps at two universities (in the USA and Germany) in an inverted classroom format. We describe how we set-up the courses, provide a brief analysis of data we collected, and share our lessons learned.","publicationDate":"2021-10-19T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3093338.3093370","title":"research-article ","type":"Portable Learning Environments for Hands-On Computational Instruction: Using Container- and Cloud-Based Technology to Teach Data Science","venue":"PEARC17: Proceedings of the Practice and Experience in Advanced Research Computing 2017 on Sustainability, Success and Impact","authors":["Chris Holdgraf","Aaron Culich","Ariel Rokem","Fatma Deniz","Maryana Alegro","Dani Ushizima"],"abstract":"There is an increasing interest in learning outside of the traditional classroom setting. This is especially true for topics covering computational tools and data science, as both are challenging to incorporate in the standard curriculum. These atypical learning environments offer new opportunities for teaching, particularly when it comes to combining conceptual knowledge with hands-on experience/expertise with methods and skills. Advances in cloud computing and containerized environments provide an attractive opportunity to improve the efficiency and ease with which students can learn. This manuscript details recent advances towards using commonly-available cloud computing services and advanced cyberinfrastructure support for improving the learning experience in bootcamp-style events. We cover the benefits (and challenges) of using a server hosted remotely instead of relying on student laptops, discuss the technology that was used in order to make this possible, and give suggestions for how others could implement and improve upon this model for pedagogy and reproducibility.","publicationDate":"2017-07-08T22:00:00.000Z","citationCount":12},{"url":"https://dl.acm.org/doi/10.1145/3093338.3093370","title":"research-article ","type":"Portable Learning Environments for Hands-On Computational Instruction: Using Container- and Cloud-Based Technology to Teach Data Science","venue":"PEARC17: Proceedings of the Practice and Experience in Advanced Research Computing 2017 on Sustainability, Success and Impact","authors":["Chris Holdgraf","Aaron Culich","Ariel Rokem","Fatma Deniz","Maryana Alegro","Dani Ushizima"],"abstract":"There is an increasing interest in learning outside of the traditional classroom setting. This is especially true for topics covering computational tools and data science, as both are challenging to incorporate in the standard curriculum. These atypical learning environments offer new opportunities for teaching, particularly when it comes to combining conceptual knowledge with hands-on experience/expertise with methods and skills. Advances in cloud computing and containerized environments provide an attractive opportunity to improve the efficiency and ease with which students can learn. This manuscript details recent advances towards using commonly-available cloud computing services and advanced cyberinfrastructure support for improving the learning experience in bootcamp-style events. We cover the benefits (and challenges) of using a server hosted remotely instead of relying on student laptops, discuss the technology that was used in order to make this possible, and give suggestions for how others could implement and improve upon this model for pedagogy and reproducibility.","publicationDate":"2017-07-08T22:00:00.000Z","citationCount":12},{"url":"https://dl.acm.org/doi/10.1145/3368235.3368838","title":"research-article ","type":"Cloud Enablers For Testing Large-Scale Distributed Applications","venue":"UCC '19 Companion: Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing Companion","authors":["Piyush Harsh","Juan Francisco Ribera Laszkowski","Andy Edmonds","Tran Quang Thanh","Michael Pauls","Radoslav Vlaskovski","Orlando Avila-García","Enric Pages","Francisco Gortázar Bellas","Micael Gallego Carrillo"],"abstract":"Testing large-scale distributed systems (also known as testing in the large) is a challenge that spreads across different technical domains and areas of expertise. Current methods and tools provide some minimal guarantees in relation to the correctness of their functional properties and have serious limitations when evaluating their extra-functional properties in realistic conditions, such as scalability, availability and performance efficiency. Cloud Testing and more specifically \"testing in the cloud'' has arisen to tackle those challenges. In this new paradigm, cloud-based environment and infrastructure are used to run realistic end-to-end and/or system-level tests, collect test data and analyse them. In this paper we present a set of cloud-native services to take from the tester the responsibility of managing the resources and complementary services required to simulate realistic operational conditions and production environments. Specifically, they provide cloud testing capabilities such as logs and measurements collection from both testing jobs and system under test; test data analytics and visualization; provisioning and operation of additional services and processes to replicate realistic production ecosystems; support to scalability and diversity of underlying testing infrastructure; and replication of the operational conditions of the software under test through its instrumentation. We present the architecture of the cloud testing solution and the detailed design of each of the services; we also evaluate their relative contribution to satisfy different needs in the context of test execution.","publicationDate":"2019-12-01T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3400286.3418281","title":"poster ","type":"Scheduler for Distributed and Collaborative Container Clusters based on Multi-Resource Metric","venue":"RACS '20: Proceedings of the International Conference on Research in Adaptive and Convergent Systems","authors":["Yena Lee","Jae-Hoon An","Younghwan Kim"],"abstract":"With the development of cloud technology, distributed and collaborative container platform technology has emerged to overcome the limitations of the existing stand-alone container platform, which has limitations in the mobility and resource scalability of cloud services. Distributed and collaborative container platform technology enables flexible expansion of resources and maximization of service mobility between container platforms distributed locally.In this paper, we propose a two-stage scheduler based on multi-resource metrics. The proposed scheduler determines the proper federated cluster where the request deployment can be deployed in a distributed and collaborative cluster environment. In order to select an proper federated cluster, filtering to select candidate clusters to which the scheduling request deployment can be deployed and scoring to evaluate the preference of each filtered cluster are performed.","publicationDate":"2020-10-12T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3425269.3425273","title":"research-article ","type":"Towards a method for monitoring the coupling evolution of microservice-based architectures","venue":"SBCARS '20: Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse","authors":["Daniel Rodrigo de Freitas Apolinário","Breno Bernard Nicolau de França"],"abstract":"The microservice architecture is claimed to satisfy ongoing software development demands, such as resilience, flexibility, and velocity. However, developing applications based on microservices also brings some drawbacks, such as the increased software operational complexity. Recent studies have also pointed out the lack of methods to prevent problems related to the maintainability of these solutions. Disregarding established design principles during the software evolution may lead to the so-called architectural erosion, which can end up in a condition of unfeasible maintenance. As microservices can be considered a new architecture style, there are few initiatives to monitoring the evolution of software microservice-based architectures. In this paper, we introduce the SYMBIOTE method for monitoring the coupling evolution of microservice-based systems. More specifically, this method collects coupling metrics during runtime (staging or production environments) and monitors them throughout software evolution. The longitudinal analysis of the collected measures allows detecting an upward trend in coupling metrics that could be signs of architectural erosion. To develop the proposed method, we performed an experimental analysis of the coupling metrics behavior using artificially-generated data.","publicationDate":"2020-10-18T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3196398.3196444","title":"short-paper ","type":"Natural language or not (NLON): a package for software engineering text analysis pipeline","venue":"MSR '18: Proceedings of the 15th International Conference on Mining Software Repositories","authors":["Mika V. Mäntylä","Fabio Calefato","Maelick Claes"],"abstract":"The use of natural language processing (NLP) is gaining popularity in software engineering. In order to correctly perform NLP, we must pre-process the textual information to separate natural language from other information, such as log messages, that are often part of the communication in software engineering. We present a simple approach for classifying whether some textual input is natural language or not. Although our NLoN package relies on only 11 language features and character tri-grams, we are able to achieve an area under the ROC curve performances between 0.976-0.987 on three different data sources, with Lasso regression from Glmnet as our learner and two human raters for providing ground truth. Cross-source prediction performance is lower and has more fluctuation with top ROC performances from 0.913 to 0.980. Compared with prior work, our approach offers similar performance but is considerably more lightweight, making it easier to apply in software engineering text mining pipelines. Our source code and data are provided as an R-package for further improvements.","publicationDate":"2018-05-27T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3321707.3321826","title":"research-article ","type":"Cloud-based dynamic distributed optimisation of integrated process planning and scheduling in smart factories","venue":"GECCO '19: Proceedings of the Genetic and Evolutionary Computation Conference","authors":["Shuai Zhao","Piotr Dziurzanski","Michal Przewozniczek","Marcin Komarnicki","Leandro Soares Indrusiak"],"abstract":"In smart factories, process planning and scheduling need to be performed every time a new manufacturing order is received or a factory state change has been detected. A new plan and schedule need to be determined quickly to increase the responsiveness of the factory and enlarge its profit. Simultaneous optimisation of manufacturing process planning and scheduling leads to better results than a traditional sequential approach but is computationally more expensive and thus difficult to be applied to real-world manufacturing scenarios. In this paper, a working approach for cloud-based distributed optimisation of process planning and scheduling is presented. It executes a multi-objective genetic algorithm on multiple subpopulations (islands). The number of islands is automatically decided based on the current optimisation state. A number of test cases based on two real-world manufacturing scenarios are used to show the applicability of the proposed solution.","publicationDate":"2019-07-12T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3452369.3463816","title":"research-article ","type":"Inter-operability and Orchestration in Heterogeneous Cloud/Edge Resources: The ACCORDION Vision","venue":"FRAME '21: Proceedings of the 1st Workshop on Flexible Resource and Application Management on the Edge","authors":["Ioannis Korontanis","Konstantinos Tserpes","Maria Pateraki","Lorenzo Blasi","John Violos","Ferran Diego","Eduard Marin","Nicolas Kourtellis","Massimo Coppola","Emanuele Carlini","Zbyszek Ledwoń","Przemysław Tarkowski","Thomas Loven","Yago González Rozas","Mike Kentros","Michael Dodis","Patrizio Dazzi"],"abstract":"This paper introduces the ACCORDION framework, a novel framework for the management of the cloud-edge continuum, targeting the support of NextGen applications with strong QoE requirements. The framework addresses the need for an ever expanding and heterogeneous pool of edge resources in order to deliver the promise of ubiquitous computing to the NextGen application clients. This endeavor entails two main technical challenges. First, to assure interoperability when incorporating heterogeneous infrastructures in the pool. Second, the management of the largely dynamic pool of edge nodes. The optimization of the delivered QoE stands as the core driver to this work, therefore its monitoring and modelling comprises a core part of the conducted work. The paper discusses the main pillars that support the ACCORDION vision, and provide a description of the three planned use case that are planned to demonstrate ACCORDION capabilities.","publicationDate":"2020-06-24T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3417699.3417701","title":"research-article ","type":"Simplifying teaching continuous integration and continuous deployment with hands-on application in a web development course","venue":"Journal of Computing Sciences in Colleges","authors":["Bryan Dixon"],"abstract":"Teaching web programming can lend itself as a course where students can learn to develop with version control, containers, continuous integration (CI), and continuous deployment or delivery (CD). In my web programming course, I built a starter repo that simplifies the initial setup and helps students become familiar with CI/CD and containers. Using the GitLab/GitHub APIs allows me to automate the creation of private mirrored repos across these sites for each student, with each private repo including the starter repo I developed. Students gain access to their repo by submitting a form through my website. This paper will discuss the motivation and benefit of this approach, as well as describe how I have been able to successfully implement it. The conclusions of the impact of this approach in part come from student feedback since I started doing this approach over the past 3 semesters.","publicationDate":"2020-03-31T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3241403.3241442","title":"short-paper ","type":"Large scale anomaly detection in data center logs and metrics","venue":"ECSA '18: Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings","authors":["Rafael P. Martínez-Álvarez","Carlos Giraldo-Rodríguez","David Chaves-Diéguez"],"abstract":"Data centers continuously produce large amounts of data related to their internal operation. This kind of machine-generated data is flowing 24x7x365; however, it is seldom exploited to benefit the health of the processes and the business itself. The information usually comes in two flavors: application events or system logs, and periodic measurements of some changing magnitude (processor load, used memory, etc.). We have, therefore, a mix of structured and unstructured data with a high intrinsic variety, yet containing a high strategic value for those able to extract it. In this work, we propose a data processing engine for anomaly detection based on a real setup made for an IT services company who wanted to enhance its portfolio of technological solutions. Two were the main challenges we faced as fundamental requirements: making the system work in tough big data environments, and being able to yield accurate real-time responses.","publicationDate":"2018-09-23T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3234200.3234250","title":"short-paper ","type":"Policy Injection: A Cloud Dataplane DoS Attack","venue":"SIGCOMM '18: Proceedings of the ACM SIGCOMM 2018 Conference on Posters and Demos","authors":["Levente Csikor","Christian Rothenberg","Dimitrios P. Pezaros","Stefan Schmid","László Toka","Gábor Rétvári"],"abstract":"Enterprises continue to migrate their services to the cloud on a massive scale, but the increasing attack surface has become a natural target for malevolent actors. We show policy injection, a novel algorithmic complexity attack that enables a tenant to add specially tailored ACLs into the data center fabric to mount a denial-of-service attack through exploiting the built-in security mechanisms of the cloud management systems (CMS). Our insight is that certain ACLs, when fed with special covert packets by an attacker, may be very difficult to evaluate, leading to an exhaustion of cloud resources. We show how a tenant can inject seemingly harmless ACLs into the cloud data plane to abuse an algorithmic deficiency in the most popular cloud hypervisor switch, Open vSwitch, and reduce its effective peak performance by 80--90%, and, in certain cases, denying network access altogether.","publicationDate":"2018-08-06T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3341105.3374007","title":"research-article ","type":"Black-box inter-application traffic monitoring for adaptive container placement","venue":"SAC '20: Proceedings of the 35th Annual ACM Symposium on Applied Computing","authors":["Francisco Neves","Ricardo Vilaça","José Pereira"],"abstract":"A key issue in the performance of modern containerized distributed systems, such as big data storage and processing stacks or micro-service based applications, is the placement of each container, or container pod, in virtual and physical servers. Although it has been shown that inter-application traffic is an important factor in placement decisions, as it directly indicates how components interact, it has not been possible to accurately monitor it in an application independent way, thus putting it out of reach of cloud platforms.In this paper we present an efficient black-box monitoring approach for detecting and building a weighted communication graph of collaborating processes in a distributed system that can be queried for various purposes, including adaptive placement. The key to achieving high detail and low overhead without custom application instrumentation is to use a kernel-aided event driven strategy. We evaluate a prototype implementation with micro-benchmarks and demonstrate its usefulness for container placement in a distributed data storage and processing stack (i.e., Cassandra and Spark).","publicationDate":"2020-03-29T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3236024.3275528","title":"research-article ","type":"Building lean continuous integration and delivery pipelines by applying DevOps principles: a case study at Varidesk","venue":"ESEC/FSE 2018: Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","authors":["Vidroha Debroy","Senecca Miller","Lance Brimble"],"abstract":"Continuous Integration (CI) and Continuous Delivery (CD) are widely considered to be best practices in software development. Studies have shown however, that adopting these practices can be challenging and there are many barriers that engineers may face, such as – overly long build times, lack of support for desired workflows, issues with configuration, etc. At Varidesk, we recently began shifting our primary web application (from a monolithic) to a micro-services-based architecture and also adapted our software development practices to aim for more effective CI/CD. In doing so, we also ran into some of the same afore-mentioned barriers. In this paper we focus on two specific challenges that we faced – long wait times for builds/releases to be queued and completed, and the lack of support for tooling, especially from a cross-cloud perspective. We then present the solutions that we came up with, which involved re-thinking DevOps as it applied to us, and re-building our own CI/CD pipelines based on DevOps-supporting approaches such as containerization, infrastructure-as-code, and orchestration. Our re-designed pipelines have led us to see speed increases, in terms of total build/release time, in the range of 330x-1110x and have enabled us to seamlessly move from a single-cloud to a multi- cloud environment, with no architectural changes to any apps.","publicationDate":"2018-10-25T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3318216.3363309","title":"research-article ","type":"Couper: DNN model slicing for visual analytics containers at the edge","venue":"SEC '19: Proceedings of the 4th ACM/IEEE Symposium on Edge Computing","authors":["Ke-Jou Hsu","Ketan Bhardwaj","Ada Gavrilovska"],"abstract":"Applications incorporating DNN-based visual analytics are growing in demand. This class of data-intensive and latency-sensitive workloads has an opportunity to benefit from the emerging edge computing tier. However, to decouple the growing resource demand of DNN models, from the characteristics and resource limitations of the infrastructure elements available at the edge, new methods are needed to quickly slice the DNNs into appropriately-sized components, and to deploy those DNN slices to be executed on the edge infrastructure stacks. This paper presents Couper, a practical solution that provides for quick creation of slices of production DNNs for visual analytics, and enables their deployment in contemporary container-based edge software stacks. Couper is evaluated with 7 production DNNs, under varying edge configurations.","publicationDate":"2019-11-06T23:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.5555/3233397.3233457","title":"research-article ","type":"Docker containers across multiple clouds and data centers","venue":"UCC '15: Proceedings of the 8th International Conference on Utility and Cloud Computing","authors":["Moustafa AbdelBaky","Javier Diaz-Montes","Manish Parashar","Merve Unuvar","Malgorzata Steinder"],"abstract":"Emerging lightweight cloud technologies, such as Docker containers, are gaining wide traction in IT due to the fact that they allow users to deploy applications in any environment faster and more efficiently than using virtual machines. However, current Docker-based container deployment solutions are aimed at managing containers in a single-site, which limits their capabilities. As more users look to adopt Docker containers in dynamic, heterogenous environments, the ability to deploy and effectively manage containers across multiple clouds and data centers becomes of utmost importance. In this paper, we propose a prototype framework, called C-Ports, that enables the deployment and management of Docker containers across multiple hybrid clouds and traditional clusters while taking into consideration user and resource provider objectives and constraints. The framework leverages a constraint-programming model for resource selection and uses CometCloud to allocate/deallocate resources as well as to deploy containers on top of these resources. Our prototype has been effectively used to deploy and manage containers in a dynamic federation composed of five clouds and two clusters.","publicationDate":"2015-12-06T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3465332.3470876","title":"research-article ","type":"Self-service data protection for stateful containers","venue":"HotStorage '21: Proceedings of the 13th ACM Workshop on Hot Topics in Storage and File Systems","authors":["Umesh Deshpande","Nick Linck","Sangeetha Seshadri"],"abstract":"Data protection in containerized environments poses several challenges arising from the need for self-service and the resulting churn in the environment. We present a self-managing backup system for containerized frameworks designed to work for users with little knowledge of the underlying infrastructure. Our system presents users with an interface which allows them to interact with data protection service in the same way used for managing their applications. Additionally, we present a backup scheduler to honor user expressed data protection guarantees while reacting to resource fluctuations on the underlying shared infrastructure. We demonstrate the effectiveness of our system with thousands of request having different data protection guarantees in an environment with various bandwidth and IO patterns.","publicationDate":"2021-07-26T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3366613.3368121","title":"research-article ","type":"ProgCEP: A Programming Model for Complex Event Processing over Fog Infrastructure","venue":"DFSD '19: Proceedings of the 2nd International Workshop on Distributed Fog Services Design","authors":["Manisha Luthra","Boris Koldehofe"],"abstract":"Complex Event Processing (CEP) is a powerful paradigm that can derive meaningful insights by correlating multiple data sources, e.g., in the Internet-of-Things applications. However, these applications often require deployment across a wide variety of devices ranging from mobile devices to edge and cloud or simply put: fog infrastructure. This is not easily possible using existing programming models because of missing (i) support for deployment on heterogeneous devices and (ii) important interfaces for the deployment of CEP, e.g., for developing operator placement [email protected] this paper, we present ProgCEP: a programming model that facilitates the development of the operator placement algorithm and its deployment in a fog computing setting. In addition, it is portable and deployable on any kind of fog infrastructure and provides dynamic scaling of resources and deployment using the operator placement algorithm. We evaluate ProgCEP on its applicability and realizability on a publicly available fog testbed involving on-site, GENI and CloudLab resources using Docker tools. To this end, we enable (i) deployment of CEP using our dockerized implementation on the aforementioned fog infrastructure in less than 50 secs (on 25 distributed resources) and (ii) easy development of operator placement algorithms in terms of minimum lines of code.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3465630","title":"research-article ","type":"Optimizing the Performance of Containerized Cloud Software Systems Using Adaptive PID Controllers","venue":"ACM Transactions on Autonomous and Adaptive Systems","authors":["Mikael Sabuhi","Nima Mahmoudi","Hamzeh Khazaei"],"abstract":"Control theory has proven to be a practical approach for the design and implementation of controllers, which does not inherit the problems of non-control theoretic controllers due to its strong mathematical background. State-of-the-art auto-scaling controllers suffer from one or more of the following limitations: (1) lack of a reliable performance model, (2) using a performance model with low scalability, tractability, or fidelity, (3) being application- or architecture-specific leading to low extendability, and (4) no guarantee on their efficiency. Consequently, in this article, we strive to mitigate these problems by leveraging an adaptive controller, which is composed of a neural network as the performance model and a Proportional-Integral-Derivative (PID) controller as the scaling engine. More specifically, we design, implement, and analyze different flavours of these adaptive and non-adaptive controllers, and we compare and contrast them against each other to find the most suitable one for managing containerized cloud software systems at runtime. The controller’s objective is to maintain the response time of the controlled software system in a pre-defined range, and meeting the Service-level Agreements, while leading to efficient resource provisioning.","publicationDate":"2021-08-17T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3369583.3392683","title":"research-article ","type":"funcX: A Federated Function Serving Fabric for Science","venue":"HPDC '20: Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing","authors":["Ryan Chard","Yadu Babuji","Zhuozhao Li","Tyler Skluzacek","Anna Woodard","Ben Blaiszik","Ian Foster","Kyle Chard"],"abstract":"Exploding data volumes and velocities, new computational methods and platforms, and ubiquitous connectivity demand new approaches to computation in the sciences. These new approaches must enable computation to be mobile, so that, for example, it can occur near data, be triggered by events (e.g., arrival of new data), be offloaded to specialized accelerators, or run remotely where resources are available. They also require new design approaches in which monolithic applications can be decomposed into smaller components, that may in turn be executed separately and on the most suitable resources. To address these needs we present funcX---a distributed function as a service (FaaS) platform that enables flexible, scalable, and high performance remote function execution. funcX's endpoint software can transform existing clouds, clusters, and supercomputers into function serving systems, while funcX's cloud-hosted service provides transparent, secure, and reliable function execution across a federated ecosystem of endpoints. We motivate the need for funcX with several scientific case studies, present our prototype design and implementation, show optimizations that deliver throughput in excess of 1 million functions per second, and demonstrate, via experiments on two supercomputers, that funcX can scale to more than more than 130 000 concurrent workers.","publicationDate":"2020-06-22T22:00:00.000Z","citationCount":19},{"url":"https://dl.acm.org/doi/10.1145/3274326","title":"research-article ","type":"Eight Observations and 24 Research Questions About Open Source Projects: Illuminating New Realities","venue":"Proceedings of the ACM on Human-Computer Interaction","authors":["Matt Germonprez","Georg J.P. Link","Kevin Lumbard","Sean Goggins"],"abstract":"The rapid acceleration of corporate engagement with open source projects is drawing out new ways for CSCW researchers to consider the dynamics of these projects. Research must now consider the complex ecosystems within which open source projects are situated, including issues of for-profit motivations, brokering foundations, and corporate collaboration. Localized project considerations cannot reveal broader workings of an open source ecosystem, yet much empirical work is constrained to a local context. In response, we present eight observations from our eight-year engaged field study about the changing nature of open source projects. We ground these observations through 24 research questions that serve as primers to spark research ideas in this new reality of open source projects. This paper contributes to CSCW in social and crowd computing by delivering a rich and fresh look at corporately-engaged open source projects with a call for renewed focus and research into newly emergent areas of interest.","publicationDate":"2018-10-31T23:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3325097","title":"survey ","type":"A Survey on Scheduling Strategies for Workflows in Cloud Environment and Emerging Trends","venue":"ACM Computing Surveys","authors":["Mainak Adhikari","Tarachand Amgoth","Satish Narayana Srirama"],"abstract":"Workflow scheduling is one of the challenging issues in emerging trends of the distributed environment that focuses on satisfying various quality of service (QoS) constraints. The cloud receives the applications as a form of a workflow, consisting of a set of interdependent tasks, to solve the large-scale scientific or enterprise problems. Workflow scheduling in the cloud environment has been studied extensively over the years, and this article provides a comprehensive review of the approaches. This article analyses the characteristics of various workflow scheduling techniques and classifies them based on their objectives and execution model. In addition, the recent technological developments and paradigms such as serverless computing and Fog computing are creating new requirements/opportunities for workflow scheduling in a distributed environment. The serverless infrastructures are mainly designed for processing background tasks such as Internet-of-Things (IoT), web applications, or event-driven applications. To address the ever-increasing demands of resources and to overcome the drawbacks of the cloud-centric IoT, the Fog computing paradigm has been developed. This article also discusses workflow scheduling in the context of these emerging trends of cloud computing.","publicationDate":"2019-08-29T22:00:00.000Z","citationCount":18},{"url":"https://dl.acm.org/doi/10.1145/3386164.3390516","title":"research-article ","type":"Performance Measurements of Function as a Service Platforms","venue":"ISCSIC 2019: Proceedings of the 2019 3rd International Symposium on Computer Science and Intelligent Control","authors":["Gellért István Hegyi","Markosz Maliosz","Csaba Simon"],"abstract":"This paper evaluates the current state of the Function as a Service (FaaS) landscape and investigates the extent of the applicability of this new technology for the use-cases of today. We have selected the most popular Function as a Service platforms and have measured the relevant application performance parameters (latency and database access rate) under different types of load. Our source code used by our experiments is available from our public repository. Our measurements confirm that the investigated FaaS technologies have stable performance characteristics under various load conditions. They can be safely applied to a large number of use-cases, and their performance will hold up to the traditional solutions with also added benefits as well, such as less operational costs and better scalability.","publicationDate":"2019-09-24T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3366424.3382692","title":"research-article ","type":"Microsoft Recommenders: Best Practices for Production-Ready Recommendation Systems","venue":"WWW '20: Companion Proceedings of the Web Conference 2020","authors":["Andreas Argyriou","Miguel González-Fierro","Le Zhang"],"abstract":"Recommendation algorithms have been widely applied in various contemporary business areas, however the process of implementing them in production systems is complex and has to address significant challenges. We present Microsoft Recommenders, an open-source Github repository for helping researchers, developers and non-experts in general to prototype, experiment with and bring to production both classic and state-of-the-art recommendation algorithms. A focus of this repository is on best practices in development of recommendation systems. We have also incorporated learnings from our experience with recommendation systems in production, in order to enhance ease of use; speed of implementation and deployment; scalability and performance.","publicationDate":"2020-04-19T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3425329.3425333","title":"research-article ","type":"The Application of Edge Computing in High-Definition Maps Distribution","venue":"WSSE 2020: Proceedings of the 2020 The 2nd World Symposium on Software Engineering","authors":["Rongbo Zhang","Kaiyu Cai"],"abstract":"The High-Definition map (HD map) is a key technology to achieve automatic driving above the grade of L3, with the amount of data comes to more than 105 times that of traditional navigation map. With the arrival of 5G communication and the rapid development of Internet of Things, each autonomous vehicle will request HD map service by accessing the Internet. The service of traditional navigation map under \"cloud-end\" mode may not be well adapted to future HD map application, so the paper proposes a MEC proposal for HD map application, deploying HD map server under \"cloud-edge-end\" mode to mitigate the high latency and improve low reliability caused by the faraway physical distance rather than \"cloud-end\" mode. The HD map is divided according to the latitude and longitude regions, being pushed to local edge computing node servers respectively to realize the interaction between autonomous vehicles and edge servers, which makes more convenient and reliable HD map services available. The experimental results show that the proposed proposal can cut off the communication delay effectively, ensuring the reliability of the HD map service, and providing high-quality HD map service for autonomous vehicles.","publicationDate":"2020-09-24T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3342195.3387540","title":"research-article ","type":"Kollaps: decentralized and dynamic topology emulation","venue":"EuroSys '20: Proceedings of the Fifteenth European Conference on Computer Systems","authors":["Paulo Gouveia","João Neves","Carlos Segarra","Luca Liechti","Shady Issa","Valerio Schiavoni","Miguel Matos"],"abstract":"The performance and behavior of large-scale distributed applications is highly influenced by network properties such as latency, bandwidth, packet loss, and jitter. For instance, an engineer might need to answer questions such as: What is the impact of an increase in network latency in application response time? How does moving a cluster between geographical regions affect application throughput? What is the impact of network dynamics on application stability? Currently, answering these questions in a systematic and reproducible way is very hard due to the variability and lack of control over the underlying network. Unfortunately, state-of-the-art network emulation or testbed environments do not scale beyond a single machine or small cluster (i.e., MiniNet), are focused exclusively on the control-plane (i.e., CrystalNet) or lack support for network dynamics (i.e., EmuLab).In this paper, we address these limitations with Kollaps, a fully distributed network emulator. Kollaps hinges on two key observations. First, from an application's perspective, what matters are the emergent end-to-end properties (e.g., latency, bandwidth, packet loss, and jitter) rather than the internal state of the routers and switches leading to those properties. This premise allows us to build a simpler, dynamically adaptable, emulation model that does not require maintaining the full network state. Second, this simplified model is amenable to be maintained in a fully decentralized way, allowing the emulation to scale with the number of machines required by the application.Kollaps is fully decentralized, agnostic of the application language and transport protocol, scales to thousands of processes and is accurate when compared against a bare-metal deployment or state-of-the-art approaches that emulate the full state of the network. We showcase how Kollaps can accurately reproduce results from the literature and predict the behaviour of a complex unmodified distributed key-value store (i.e., Cassandra) under different deployments.","publicationDate":"2020-04-14T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3429880.3430094","title":"research-article ","type":"Resource Management for Cloud Functions with Memory Tracing, Profiling and Autotuning","venue":"WoSC'20: Proceedings of the 2020 Sixth International Workshop on Serverless Computing","authors":["Josef Spillner"],"abstract":"Application software provisioning evolved from monolithic designs towards differently designed abstractions including serverless applications. The promise of that abstraction is that developers are free from infrastructural concerns such as instance activation and autoscaling. Today's serverless architectures based on FaaS are however still exposing developers to explicit low-level decisions about the amount of memory to allocate for the respective cloud functions. In many cases, guesswork and ad-hoc decisions determine the values a developer will put into the configuration. We contribute tools to measure the memory consumption of a function in various Docker, OpenFaaS and GCF/GCR configurations over time and to create trace profiles that advanced FaaS engines can use to autotune memory dynamically. Moreover, we explain how pricing forecasts can be performed by connecting these traces with a FaaS characteristics knowledge base.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3379310.3379323","title":"research-article ","type":"A Survey of Attack Instances of Cryptojacking Targeting Cloud Infrastructure","venue":"APIT 2020: Proceedings of the 2020 2nd Asia Pacific Information Technology Conference","authors":["Keshani Jayasinghe","Guhanathan Poravi"],"abstract":"Cryptojacking is the act of using an individual's or an organization's computational power in order to mine cryptocurrency. In some scenarios, this can be considered as a monetization strategy, very much similar to advertisements. But to do so without the explicit consent of the computer owners is considered illegitimate. During previous years, attackers' focus was heavily laid on browser-based cryptojacking. However, it was noted that the attackers are now shifting their attention to more robust, more superior targets, such as cloud servers and cloud infrastructure. This paper analyses 11 forms of practical scenarios of cryptojacking attacks that are targeted towards cloud infrastructure. We carefully look at their similarities and properties, comparing those features with the limitations of existing literature regarding the detection systems. In this paper, we survey the attack forms, and we also survey the limitations of existing literature as an attempt to outline the research gap between the practical scenarios and existing work.","publicationDate":"2020-01-16T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3127479.3134348","title":"abstract ","type":"Batch spot market for data analytics cloud providers","venue":"SoCC '17: Proceedings of the 2017 Symposium on Cloud Computing","authors":["Stefania Costache","Tommaso Madonia","Asser Tantawi","Malgorzata Steinder"],"abstract":"Hosting data analytics services is challenging as their workload is often composed of on-line (e.g., interactive or streaming), requiring fast on-demand provisioning, and batch jobs. As workload demand fluctuations lead to varying idle capacity, efficient resource management is difficult, in particular given different provider objectives, e.g., utilization, revenue.","publicationDate":"2017-09-23T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.14778/3311880.3311881","title":"research-article ","type":"Autoscaling tiered cloud storage in Anna","venue":"Proceedings of the VLDB Endowment","authors":["Chenggang Wu","Vikram Sreekanti","Joseph M. Hellerstein"],"abstract":"In this paper, we describe how we extended a distributed key-value store called Anna into an autoscaling, multi-tier service for the cloud. In its extended form, Anna is designed to overcome the narrow cost-performance limitations typical of current cloud storage systems. We describe three key aspects of Anna's new design: multi-master selective replication of hot keys, a vertical tiering of storage layers with different cost-performance tradeoffs, and horizontal elasticity of each tier to add and remove nodes in response to load dynamics. Anna's policy engine uses these mechanisms to balance service-level objectives around cost, latency and fault tolerance. Experimental results explore the behavior of Anna's mechanisms and policy, exhibiting orders of magnitude efficiency improvements over both commodity cloud KVS services and research systems.","publicationDate":"2019-01-31T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3452370.3466001","title":"research-article ","type":"A Layered Approach for Modular Container Construction and Orchestration in HPC Environments","venue":"ScienceCloud '21: Proceedings of the 11th Workshop on Scientific Cloud Computing","authors":["Quincy Wofford","Patrick G. Bridges","Patrick Widener"],"abstract":"Large-scale, high-throughput computational science faces an accelerating convergence of software and hardware. Software container-based solutions have become common in cloud-based datacenter environments, and are considered promising tools for addressing heterogeneity and portability concerns. However, container solutions reflect a set of assumptions which complicate their adoption by developers and users of scientific workflow applications. Nor are containers a universal solution for deployment in high-performance computing (HPC) environments which have specialized and vertically integrated scheduling and runtime software stacks. In this paper, we present a container design and deployment approach which uses modular layering to ease the deployment of containers into existing HPC environments. This layered approach allows operating system integrations, support for different communication and performance monitoring libraries, and application code to be defined and interchanged in isolation. We describe in this paper the details of our approach, including specifics about container deployment and orchestration for different HPC scheduling systems. We also describe how this layering method can be used to build containers for two separate applications, each deployed on clusters with different batch schedulers, MPI networking support, and performance monitoring requirements. Our experience indicates that the layered approach is a viable strategy for building applications intended to provide similar behavior across widely varying deployment targets.","publicationDate":"2020-06-20T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3387940.3391455","title":"research-article ","type":"Platform Teams: An Organizational Structure for Continuous Delivery","venue":"ICSEW'20: Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops","authors":["Leonardo Leite","Fabio Kon","Gustavo Pinto","Paulo Meirelles"],"abstract":"Software-producing organizations are seeking to release faster and more efficiently new versions of their products to their customers to remain competitive in the fierce software market. Continuous delivery practices arise as a potential solution since every commit to the repository could result in a production-candidate version of a product, accelerating time to market, and improving customer satisfaction. In this work, we employed Grounded Theory to investigate how organizations pursuing continuous delivery should organize their development and operations teams. We collected data from 27 IT professionals. After a careful analysis, we started the elaboration of a taxonomy with four patterns of organizational structures: (1) siloed departments, (2) classical DevOps, (3) cross-functional teams, and (4) platform teams. We observed that the platform team structure is the most distinctive classification of our taxonomy, and it has promising results regarding delivery performance. Some relevant aspects we found out about platform teams include: infrastructure specialists need coding skills; product teams have to operate their business services; and much of the non-functional concerns are handled by the platform, alleviating product teams.","publicationDate":"2020-06-26T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3358960.3379124","title":"research-article ","type":"Microservices: A Performance Tester's Dream or Nightmare?","venue":"ICPE '20: Proceedings of the ACM/SPEC International Conference on Performance Engineering","authors":["Simon Eismann","Cor-Paul Bezemer","Weiyi Shang","Dušan Okanović","André van Hoorn"],"abstract":"In recent years, there has been a shift in software development towards microservice-based architectures, which consist of small services that focus on one particular functionality. Many companies are migrating their applications to such architectures to reap the benefits of microservices, such as increased flexibility, scalability and a smaller granularity of the offered functionality by a service. On the one hand, the benefits of microservices for functional testing are often praised, as the focus on one functionality and their smaller granularity allow for more targeted and more convenient testing. On the other hand, using microservices has their consequences (both positive and negative) on other types of testing, such as performance testing. Performance testing is traditionally done by establishing the baseline performance of a software version, which is then used to compare the performance testing results of later software versions. However, as we show in this paper, establishing such a baseline performance is challenging in microservice applications. In this paper, we discuss the benefits and challenges of microservices from a performance tester's point of view. Through a series of experiments on the TeaStore application, we demonstrate how microservices affect the performance testing process, and we demonstrate that it is not straightforward to achieve reliable performance testing results for a microservice application.","publicationDate":"2020-04-19T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3411016.3411019","title":"research-article ","type":"A Performance Analysis of Container Cluster Networking Alternatives","venue":"ICNSER2020: Proceedings of the 2nd International Conference on Industrial Control Network And System Engineering Research","authors":["Gulsum Atici","Pinar Sarisaray Boluk"],"abstract":"The use of containers in the informatics industry is increasing rapidly day by day. Although containers have many advantages, such as flexibility, readiness, easy configurability, scalability and low resource consumption, previous researches showed that there are momentous decrements in network performance in containerized cluster environments. Yielded packet sizes and data transfer methods play important roles in the network performance for the networking solutions used in container clusters. As different applications apply different packet sizes and transfer methods, it is of the essence to find and use the best performing networking solution according to application needs. Hence, it is quite important to identify the most convenient container networking solution, especially in production environments. This research analyzed the throughput and latency at varying message sizes on bulk and HTTP-like data transfer methods for container cluster networking solutions, which are Libnetwork, Flannel, Calico, Weave and Open Virtual Networking for Open vSwitch. Furthermore, it compared the performance of cluster networking solutions with a native host. As a result of the experiments, Open Virtual Networking for Open vSwitch and Calico were found to be the most adequate solutions for production environments with the highest throughput and minimum latency values depending on selected message sizes and transfer methods. In addition, a bare-metal host generally outperforms all the container networking solutions except HTTP-like transfer throughput results at a large message size. Hence, this study also demonstrates the offloading impact in container networking solutions.","publicationDate":"2020-06-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3371049.3371056","title":"research-article ","type":"An IoT and Analytics Platform for Characterizing Adolescent Dogs' Suitability for Guide Work","venue":"ACI'19: Proceedings of the Sixth International Conference on Animal-Computer Interaction","authors":["Zach Cleghern","Evan Williams","Sean Mealin","Marc Foster","Timothy Holder","Alper Bozkurt","David L. Roberts"],"abstract":"Evaluating potential guide dogs is crucial for guide dog schools as raising and training is an expensive process. During adolescence, volunteers raise dogs in training away from guide dog schools and expose them to a variety of stimuli and teach them obedience skills. However, no objective data exists about the dog's behavior and environment during this period, usually lasting several months to a year. We developed an Internet of Things sensor-equipped collar to quantify dogs' behaviors and environments during this stage. Raisers collect data from the collar using a smartphone app which in turn uploads data to a central processing pipeline. We present an overview of the system and an evaluation showing how we can learn meaningful information about a dog's environment and physical activities while away from the school for months on end, ideally to help predict which dogs will be successful in training.","publicationDate":"2019-11-11T23:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3219104.3219162","title":"research-article ","type":"Jupyter as Common Technology Platform for Interactive HPC Services","venue":"PEARC '18: Proceedings of the Practice and Experience on Advanced Research Computing","authors":["Michael B. Milligan"],"abstract":"The Minnesota Supercomputing Institute has implemented Jupyterhub and the Jupyter notebook server as a general-purpose point-of-entry to interactive high performance computing services. This mode of operation runs counter to traditional job-oriented HPC operations, but offers significant advantages for ease-of-use, data exploration, prototyping, and workflow development. From the user perspective, these features bring the computing cluster nearer to parity with emerging cloud computing options. On the other hand, retreating from fully-scheduled, job-based resource allocation poses challenges for resource availability and utilization efficiency, and can involve tools and technologies outside the typical core competencies of a supercomputing center's operations staff. MSI has attempted to mitigate these challenges by adopting Jupyter as a common technology platform for interactive services, capable of providing command-line, graphical, and workflow-oriented access to HPC resources while still integrating with job scheduling systems and using existing compute resources. This paper will describe the mechanisms that MSI has put in place, advantages for research and instructional uses, and lessons learned.","publicationDate":"2018-07-21T22:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3341069.3342985","title":"research-article ","type":"Database Docker persistence Framework based on Swarm and Ceph","venue":"HPCCT 2019: Proceedings of the 2019 3rd High Performance Computing and Cluster Technologies Conference","authors":["Shaojia Hong","Dong Li","Xiaobing Huang"],"abstract":"The swarm cluster has two main limitations: 1) the data of database container will lost after the container goes down; 2) the lack of migration ability of database container across the hosts. To tackle these issues, we propose a novel persistence framework in both single database and database cluster. To be specific, we use ceph to provide migrable data volumes, and use two frameworks to migrate container from the perspective of container downtime recovery. By comparing the processing time of downtime database container, the experimental results demonstrate that our proposed method is able to shorten the recovery time of database container and improve the availability of database services.","publicationDate":"2019-06-21T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3427228.3427665","title":"research-article ","type":"Workflow Integration Alleviates Identity and Access Management in Serverless Computing","venue":"ACSAC '20: Annual Computer Security Applications Conference","authors":["Arnav Sankaran","Pubali Datta","Adam Bates"],"abstract":"As serverless computing continues to revolutionize the design and deployment of web services, it has become an increasingly attractive target to attackers. These adversaries are developing novel tactics for circumventing the ephemeral nature of serverless functions, exploiting container reuse optimizations and achieving lateral movement by “living off the land” provided by legitimate serverless workflows. Unfortunately, the traditional security controls currently offered by cloud providers are inadequate to counter these new threats. In this work, we propose will.iam,1 a workflow-aware access control model and reference monitor that satisfies the functional requirements of the serverless computing paradigm. will.iam encodes the protection state of a serverless application as a permissions graph that describes the permissible transitions of its workflows, associating web requests with a permissions set at the point of ingress according to a graph-based labeling state. By proactively enforcing the permissions requirements of downstream workflow components, will.iam is able to avoid the costs of partially processing unauthorized requests and reduce the attack surface of the application. We implement the will.iam framework in Go and evaluate its performance as compared to recent related work against the well-established Nordstrom “Hello, Retail!” application. We demonstrate that will.iam imposes minimal burden to requests, averaging 0.51% overhead across representative workflows, but dramatically improves performance when handling unauthorized requests (e.g., DDoS attacks) as compared to past solutions. will.iam thus demonstrates an effective and practical alternative for authorization in the serverless paradigm. ","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.5555/3291168.3291212","title":"Article ","type":"Gandiva: introspective cluster scheduling for deep learning","venue":"OSDI'18: Proceedings of the 13th USENIX conference on Operating Systems Design and Implementation","authors":["Wencong Xiao","Romil Bhardwaj","Ramachandran Ramjee","Muthian Sivathanu","Nipun Kwatra","Zhenhua Han","Pratyush Patel","Xuan Peng","Hanyu Zhao","Quanlu Zhang","Fan Yang","Lidong Zhou"],"abstract":"We introduce Gandiva, a new cluster scheduling framework that utilizes domain-specific knowledge to improve latency and efficiency of training deep learning models in a GPU cluster.One key characteristic of deep learning is feedback-driven exploration, where a user often runs a set of jobs (or a multi-job) to achieve the best result for a specific mission and uses early feedback on accuracy to dynamically prioritize or kill a subset of jobs; simultaneous early feedback on the entire multi-job is critical. A second characteristic is the heterogeneity of deep learning jobs in terms of resource usage, making it hard to achieve best-fit a priori. Gandiva addresses these two challenges by exploiting a third key characteristic of deep learning: intra-job predictability, as they perform numerous repetitive iterations called mini-batch iterations. Gandiva exploits intra-job predictability to time-slice GPUs efficiently across multiple jobs, thereby delivering low-latency. This predictability is also used for introspecting job performance and dynamically migrating jobs to better-fit GPUs, thereby improving cluster efficiency.We show via a prototype implementation and micro-benchmarks that Gandiva can speed up hyper-parameter searches during deep learning by up to an order of magnitude, and achieves better utilization by transparently migrating and time-slicing jobs to achieve better job-to-resource fit. We also show that, in a real workload of jobs running in a 180-GPU cluster, Gandiva improves aggregate cluster utilization by 26%, pointing to a new way of managing large GPU clusters for deep learning.","publicationDate":"2018-10-07T22:00:00.000Z","citationCount":22},{"url":"https://dl.acm.org/doi/10.1145/3190508.3190549","title":"research-article ","type":"Medea: scheduling of long running applications in shared production clusters","venue":"EuroSys '18: Proceedings of the Thirteenth EuroSys Conference","authors":["Panagiotis Garefalakis","Konstantinos Karanasos","Peter Pietzuch","Arun Suresh","Sriram Rao"],"abstract":"The rise in popularity of machine learning, streaming, and latency-sensitive online applications in shared production clusters has raised new challenges for cluster schedulers. To optimize their performance and resilience, these applications require precise control of their placements, by means of complex constraints, e.g., to collocate or separate their long-running containers across groups of nodes. In the presence of these applications, the cluster scheduler must attain global optimization objectives, such as maximizing the number of deployed applications or minimizing the violated constraints and the resource fragmentation, but without affecting the scheduling latency of short-running containers.We present Medea, a new cluster scheduler designed for the placement of long- and short-running containers. Medea introduces powerful placement constraints with formal semantics to capture interactions among containers within and across applications. It follows a novel two-scheduler design: (i) for long-running containers, it applies an optimization-based approach that accounts for constraints and global objectives; (ii) for short-running containers, it uses a traditional task-based scheduler for low placement latency. Evaluated on a 400-node cluster, our implementation of Medea on Apache Hadoop YARN achieves placement of long-running applications with significant performance and resilience benefits compared to state-of-the-art schedulers.","publicationDate":"2018-04-22T22:00:00.000Z","citationCount":25},{"url":"https://dl.acm.org/doi/10.1145/3180155.3180208","title":"research-article ","type":"Almost there: a study on quasi-contributors in open source software projects","venue":"ICSE '18: Proceedings of the 40th International Conference on Software Engineering","authors":["Igor Steinmacher","Gustavo Pinto","Igor Scaliante Wiese","Marco A. Gerosa"],"abstract":"Recent studies suggest that well-known OSS projects struggle to find the needed workforce to continue evolving---in part because external developers fail to overcome their first contribution barriers. In this paper, we investigate how and why quasi-contributors (external developers who did not succeed in getting their contributions accepted to an OSS project) fail. To achieve our goal, we collected data from 21 popular, non-trivial GitHub projects, identified quasi-contributors, and analyzed their pull-requests. In addition, we conducted surveys with quasi-contributors, and projects' integrators, to understand their perceptions about nonacceptance. We found 10,099 quasi-contributors --- about 70% of the total actual contributors --- that submitted 12,367 nonaccepted pull-requests. In five projects, we found more quasi-contributors than actual contributors. About one-third of the developers who took our survey disagreed with the nonacceptance, and around 30% declared the nonacceptance demotivated or prevented them from placing another pull-request. The main reasons for pull-request nonacceptance from the quasi-contributors' perspective were \"superseded/duplicated pull-request\" and \"mismatch between developer's and team's vision/opinion.\" A manual analysis of a representative sample of 263 pull-requests corroborated with this finding. We also found reasons related to the relationship with the community and lack of experience or commitment from the quasi-contributors. This empirical study is particularly relevant to those interested in fostering developers' participation and retention in OSS communities.","publicationDate":"2018-05-26T22:00:00.000Z","citationCount":34},{"url":"https://dl.acm.org/doi/10.5555/3408352.3408546","title":"research-article ","type":"BlastFunction: an FPGA-as-a-service system for accelerated serverless computing","venue":"DATE '20: Proceedings of the 23rd Conference on Design, Automation and Test in Europe","authors":["Marco Bacis","Rolando Brondolin","Marco D. Santambrogio"],"abstract":"Heterogeneous computing platforms are now a valuable solution to continue to meet Service Level Agreements (SLAs) for compute intensive cloud workloads. Field Programmable Gate Arrays (FPGAs) effectively accelerate cloud workloads, however, these workloads have a spiky behavior as well as long periods of underutilization. Sharing the FPGA with multiple tenants then helps to increase the board's time utilization. In this paper we present BlastFunction, a distributed FPGA sharing system for the acceleration of microservices and serverless applications in cloud environments. BlastFunction includes a Remote OpenCL Library to access the shared devices transparently; multiple Device Managers to time-share and monitor the FPGAs and a central Accelerators Registry to allocate the available devices. BlastFunction reaches higher utilization and throughput w.r.t. a native execution thanks to device sharing, with minimal differences in latency given by the concurrent accesses.","publicationDate":"2020-03-08T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3093338.3104164","title":"poster ","type":"Container-based Analysis Environments for Low-Barrier Access to Research Data","venue":"PEARC17: Proceedings of the Practice and Experience in Advanced Research Computing 2017 on Sustainability, Success and Impact","authors":["Craig Willis","Mike Lambert","Kenton McHenry","Christine Kirkpatrick"],"abstract":"The growing size of high-value sensor-born or computationally derived scientific datasets are pushing the boundaries of traditional models of data access and discovery. Due to their size, these datasets are often accessible only through the systems on which they were created. Access for scientific exploration and reproducibility is limited to file transfer or by applying for access to the systems used to store or generate the original data, which is often infeasible. There is a growing trend toward providing access to large-scale research datasets in-place via container-based analysis environments. This paper describes the National Data Service (NDS) Labs Workbench platform and DataDNS initiative. The Labs Workbench platform is designed to provide scalable and low-barrier access to research data via container-based services. The DataDNS effort is a new initiative designed to enable discovery, access, and in-place analysis for large-scale data, providing a suite of interoperable services to enable researchers, as well as the tools they are most familiar with, to access and analyze these datasets where they reside.","publicationDate":"2017-07-08T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3332186.3332241","title":"research-article ","type":"Petrel: A Programmatically Accessible Research Data Service","venue":"PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning)","authors":["William E. Allcock","Benjamin S. Allen","Rachana Ananthakrishnan","Ben Blaiszik","Kyle Chard","Ryan Chard","Ian Foster","Lukasz Lacinski","Michael E. Papka","Rick Wagner"],"abstract":"We report on our experiences deploying and operating Petrel, a data service designed to support science projects that must organize and distribute large quantities of data. Building on a high-performance 3.2 PB parallel file system and embedded in Argonne National Laboratory's 100+ Gbps network fabric, Petrel leverages Science DMZ concepts and Globus APIs to provide application scientists with a high-speed, highly connected, and programmatically controllable data store. We describe Petrel's design, implementation, and usage and give representative examples to illustrate the many different ways in which scientists have employed the system.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3302541.3311966","title":"demonstration ","type":"TeaStore - A Micro-Service Reference Application for Performance Engineers","venue":"ICPE '19: Companion of the 2019 ACM/SPEC International Conference on Performance Engineering","authors":["Jóakim v. Kistowski","Simon Eismann","Johannes Grohmann","Norbert Schmitt","André Bauer","Samuel Kounev"],"abstract":"Performance engineering researchers propose and employ various methods to analyze, model, optimize and manage the performance of modern distributed applications. In order to evaluate these methods in realistic scenarios, researchers rely on reference applications. Existing testing and benchmarking applications are usually difficult to set up and either outdated, designed for specific testing scenarios, or do not offer the necessary degrees of freedom.In this paper, we present the TeaStore, a micro-service-based reference application. The TeaStore offers multiple services with various performance characteristics and a high degree of freedom regarding its deployment and configuration to be used as a cloud reference application for researchers. The TeaStore is designed for the evaluation of performance modeling and resource management techniques. We invite researchers to use the TeaStore and provide it open-source, extendable, easily deployable and monitorable.","publicationDate":"2019-03-26T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3390566.3391689","title":"research-article ","type":"Blockchain Enabled IoT Edge Computing: Addressing Privacy, Security and other Challenges","venue":"ICBCT'20: Proceedings of the 2020 The 2nd International Conference on Blockchain Technology","authors":["Pankaj Mendki"],"abstract":"The earlier work related to this paper described blockchain enabled IoT edge computing architecture, where any compute resource owner can join the ecosystem and lend out the compute resources required for edge computing/analytics. This paper lists possible set of challenges implementing the above solution. The primary challenges are ensuring data privacy for the input data files and ensuring computation integrity when executing the computation remotely. The paper talks about current state research and possible practical implementation to address the privacy and integrity challenges using hardware assisted trusted executing environment primarily Intel SGX. The paper proposes using unidirectional payment channels to address payment related challenges.","publicationDate":"2020-03-11T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3286062.3286065","title":"research-article ","type":"ICON: Intelligent Container Overlays","venue":"HotNets '18: Proceedings of the 17th ACM Workshop on Hot Topics in Networks","authors":["Aleksandr Zavodovski","Nitinder Mohan","Suzan Bayhan","Walter Wong","Jussi Kangasharju"],"abstract":"The Internet is largely a self-organizing system that adapts to changes in its operating environment. In this work, we extend these principles to service infrastructure and introduce ICON, standing for intelligent container. Technically, ICON is a container encapsulating a service that is consumed either directly by end-clients or other services. The novelty of ICON is in the ability of containers to adapt to their environment, targeting near-optimal service delivery and requiring only high-level guidance from the application management. Once deployed, containers form an overlay, observe their setting, and migrate or replicate themselves as needed, to the locations e.g., closest to service consumers. ICON captures our long-term vision for self-organizing service overlays that have the potential for global outreach. Bringing intelligence and adaptation to the level of individual containers renders a decentralized solution that has desirable properties, such as scalability, resilience, reliability, and adaptability to volatile environments. We hope that technology like ICON can open the way for more democratized service provisioning, disintermediating service providers from centralized brokers and optimizing orchestrators.","publicationDate":"2018-11-14T23:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3377813.3381368","title":"research-article ","type":"Escape from escape analysis of Golang","venue":"ICSE-SEIP '20: Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice","authors":["Cong Wang","Mingrui Zhang","Yu Jiang","Huafeng Zhang","Zhenchang Xing","Ming Gu"],"abstract":"Escape analysis is widely used to determine the scope of variables, and is an effective way to optimize memory usage. However, the escape analysis algorithm can hardly reach 100% accurate, mistakes of which can lead to a waste of heap memory. It is challenging to ensure the correctness of programs for memory optimization.In this paper, we propose an escape analysis optimization approach for Go programming language (Golang), aiming to save heap memory usage of programs. First, we compile the source code to capture information of escaped variables. Then, we change the code so that some of these variables can bypass Golang's escape analysis mechanism, thereby saving heap memory usage and reducing the pressure of memory garbage collection. Next, we present a verification method to validate the correctness of programs, and evaluate the effect of memory optimization. We implement the approach to an automatic tool and make it open-source1. For evaluation, we apply our approach to 10 open-source projects. For the optimized Golang code, the heap allocation is reduced by 8.88% in average, and the heap usage is reduced by 8.78% in average. Time consumption is reduced by 9.48% in average, while the cumulative time of GC pause is reduced by 5.64% in average. We also apply our approach to 16 industrial projects in Bytedance Technology. Our approach successfully finds 452 optimized cases which are confirmed by developers.","publicationDate":"2020-06-26T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3231848.3231875","title":"research-article ","type":"A New Model of Docker-based E-learning in Hadoop","venue":"ICDEL '18: Proceedings of the 2018 International Conference on Distance Education and Learning","authors":["Feng Tuo","Yu Bai","Saiqin Long","Yu Luo","Tao Wang","Renmin Wang","Gang Yin"],"abstract":"Online programming education is a new trend of E-learning, and there are already some platforms that support online programming tutoring with common programming languages and several software development techniques. However, cloud computing is a practical technology (e.g., Hadoop) with limited platforms support since it takes up a lot of computer resources. In this paper, we construct Hadoop on Educoder with virtualization technologies (such as Docker), it makes online programing with the data processing possible, which makes up for the weaknesses of building environment in local machine or paying for online resources a lot. Furthermore, we design and implement some online programming challenges of cloud computing in Hadoop, including knowledge guidance and evaluation. Educoder records students' programming information during the programming processes, together with the feedback of questionnaires, which can be used to evaluate students' performance in cloud computing programming. The analysis results reveal some interesting observations over the online programming in Hadoop. For example, results show that even they get the same scores, the students with fewer code modifications have better performance. Yet the challenge is more difficult than before, the more they practice, the fewer mistakes of programming details they will make and the more efficient they will be. Therefore, it is necessary to design step by step practice and to emphasize the program details which influence efficiency at the beginning.","publicationDate":"2018-05-25T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3338906.3338961","title":"research-article ","type":"Latent error prediction and fault localization for microservice applications by learning from system trace logs","venue":"ESEC/FSE 2019: Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","authors":["Xiang Zhou","Xin Peng","Tao Xie","Jun Sun","Chao Ji","Dewei Liu","Qilin Xiang","Chuan He"],"abstract":"In the production environment, a large part of microservice failures are related to the complex and dynamic interactions and runtime environments, such as those related to multiple instances, environmental configurations, and asynchronous interactions of microservices. Due to the complexity and dynamism of these failures, it is often hard to reproduce and diagnose them in testing environments. It is desirable yet still challenging that these failures can be detected and the faults can be located at runtime of the production environment to allow developers to resolve them efficiently. To address this challenge, in this paper, we propose MEPFL, an approach of latent error prediction and fault localization for microservice applications by learning from system trace logs. Based on a set of features defined on the system trace logs, MEPFL trains prediction models at both the trace level and the microservice level using the system trace logs collected from automatic executions of the target application and its faulty versions produced by fault injection. The prediction models thus can be used in the production environment to predict latent errors, faulty microservices, and fault types for trace instances captured at runtime. We implement MEPFL based on the infrastructure systems of container orchestrator and service mesh, and conduct a series of experimental studies with two opensource microservice applications (one of them being the largest open-source microservice application to our best knowledge). The results indicate that MEPFL can achieve high accuracy in intraapplication prediction of latent errors, faulty microservices, and fault types, and outperforms a state-of-the-art approach of failure diagnosis for distributed systems. The results also show that MEPFL can effectively predict latent errors caused by real-world fault cases.","publicationDate":"2019-08-11T22:00:00.000Z","citationCount":24},{"url":"https://dl.acm.org/doi/10.5555/3026877.3026886","title":"Article ","type":"Firmament: fast, centralized cluster scheduling at scale","venue":"OSDI'16: Proceedings of the 12th USENIX conference on Operating Systems Design and Implementation","authors":["Ionel Gog","Malte Schwarzkopf","Adam Gleave","Robert N. M. Watson","Steven Hand"],"abstract":"Centralized datacenter schedulers can make high-quality placement decisions when scheduling tasks in a cluster. Today, however, high-quality placements come at the cost of high latency at scale, which degrades response time for interactive tasks and reduces cluster utilization.This paper describes Firmament, a centralized scheduler that scales to over ten thousand machines at sub-second placement latency even though it continuously reschedules all tasks via a min-cost max-flow (MCMF) optimization. Firmament achieves low latency by using multiple MCMF algorithms, by solving the problem incrementally, and via problem-specific optimizations.Experiments with a Google workload trace from a 12,500-machine cluster show that Firmament improves placement latency by 20× over Quincy [22], a prior centralized scheduler using the same MCMF optimization. Moreover, even though Firmament is centralized, it matches the placement latency of distributed schedulers for workloads of short tasks. Finally, Firmament exceeds the placement quality of four widely-used centralized and distributed schedulers on a real-world cluster, and hence improves batch task response time by 6×.","publicationDate":"2016-11-01T23:00:00.000Z","citationCount":35},{"url":"https://dl.acm.org/doi/10.1145/3342195.3387524","title":"research-article ","type":"Autopilot: workload autoscaling at Google","venue":"EuroSys '20: Proceedings of the Fifteenth European Conference on Computer Systems","authors":["Krzysztof Rzadca","Pawel Findeisen","Jacek Swiderski","Przemyslaw Zych","Przemyslaw Broniek","Jarek Kusmierek","Pawel Nowak","Beata Strack","Piotr Witusowski","Steven Hand","John Wilkes"],"abstract":"In many public and private Cloud systems, users need to specify a limit for the amount of resources (CPU cores and RAM) to provision for their workloads. A job that exceeds its limits might be throttled or killed, resulting in delaying or dropping end-user requests, so human operators naturally err on the side of caution and request a larger limit than the job needs. At scale, this results in massive aggregate resource wastage.To address this, Google uses Autopilot to configure resources automatically, adjusting both the number of concurrent tasks in a job (horizontal scaling) and the CPU/memory limits for individual tasks (vertical scaling). Autopilot walks the same fine line as human operators: its primary goal is to reduce slack - the difference between the limit and the actual resource usage - while minimizing the risk that a task is killed with an out-of-memory (OOM) error or its performance degraded because of CPU throttling. Autopilot uses machine learning algorithms applied to historical data about prior executions of a job, plus a set of finely-tuned heuristics, to walk this line. In practice, Autopiloted jobs have a slack of just 23%, compared with 46% for manually-managed jobs. Additionally, Autopilot reduces the number of jobs severely impacted by OOMs by a factor of 10.Despite its advantages, ensuring that Autopilot was widely adopted took significant effort, including making potential recommendations easily visible to customers who had yet to opt in, automatically migrating certain categories of jobs, and adding support for custom recommenders. At the time of writing, Autopiloted jobs account for over 48% of Google's fleet-wide resource usage.","publicationDate":"2020-04-14T22:00:00.000Z","citationCount":23},{"url":"https://dl.acm.org/doi/10.1145/3319647.3325849","title":"poster ","type":"Estimating client QoE from measured network QoS","venue":"SYSTOR '19: Proceedings of the 12th ACM International Conference on Systems and Storage","authors":["Kenneth Nagin","Andre Kassis","Dean Lorenz","Katherine Barabash","Eran Raichstein"],"abstract":"This research is done in the context of the SliceNet project [4] that aims to extend 5G infrastructure with cognitive management of cross-domain, cross-layer network slices [1], with emphasis on Quality of Experience (QoE) for vertical industries. The provisioning of network slices with proper QoE guarantees is seen as one of the key enablers of future 5G-enabled networks. The challenge is to assess the QoE experienced by the vertical application and its users without requiring the applications or the users to measure and report QoE related metrics back to the provider. To address this challenge, we propose a method for deriving application-level QoE from network-level Quality of Service (QoS) measurements, easily accessible by the provider. In particular, we describe a PoC where QoE, perceived by application users, is estimated from low level network monitoring data, by applying cognitive methods. Our main goal is enabling the cloud provider to support the desired E2E QoE-based Service Level Agreements (SLAs), e.g. by monitoring QoS metrics within the provider's domain to optimize resource allocation through provider's actuators. Additional benefit can be achieved by applying the same technique to troubleshoot issues in the provider's infrastructure. In this work, we employed classical statistical methods to assess the relationship between the application-level QoE and the network-level QoS.","publicationDate":"2019-05-21T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3390566.3391689","title":"research-article ","type":"Blockchain Enabled IoT Edge Computing: Addressing Privacy, Security and other Challenges","venue":"ICBCT'20: Proceedings of the 2020 The 2nd International Conference on Blockchain Technology","authors":["Pankaj Mendki"],"abstract":"The earlier work related to this paper described blockchain enabled IoT edge computing architecture, where any compute resource owner can join the ecosystem and lend out the compute resources required for edge computing/analytics. This paper lists possible set of challenges implementing the above solution. The primary challenges are ensuring data privacy for the input data files and ensuring computation integrity when executing the computation remotely. The paper talks about current state research and possible practical implementation to address the privacy and integrity challenges using hardware assisted trusted executing environment primarily Intel SGX. The paper proposes using unidirectional payment channels to address payment related challenges.","publicationDate":"2020-03-11T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3155921.3157052","title":"research-article ","type":"Semantic virtualization for Edge-IoT cloud: issues and challenges","venue":"CAN '17: Proceedings of the 2nd Workshop on Cloud-Assisted Networking","authors":["Si Young Jang","Hayoung Choi","Yoonhyung Lee","Byoungheon Shin","Dongman Lee"],"abstract":"It is well expected that a collection of smart objects such as IoT devices dynamically form an edge cloud allowing acquiring, storing, communicating, and processing of information done at the edge of the network. Edge cloud workers (i.e. IoT devices) usually have service specific characteristics while legacy cloud workers are more computing oriented. However, existing cloudlet architectures continue to take their allocation policy centered around computation resource virtualization without considering such characteristics of edge IoT clouds. In order to provide service specific QoS driven virtualization of an edge IoT cloud, which we call semantic virtualization, a new approach is required. In this paper, we investigate research issues and directions for realizing semantic virtualization for an edge IoT cloud.","publicationDate":"2017-12-10T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3366623.3368136","title":"research-article ","type":"FnSched: An Efficient Scheduler for Serverless Functions","venue":"WOSC '19: Proceedings of the 5th International Workshop on Serverless Computing","authors":["Amoghvarsha Suresh","Anshul Gandhi"],"abstract":"An imminent challenge in the serverless computing landscape is the escalating cost of infrastructure needed to handle the growing traffic at scale. This work presents FnSched, a function-level scheduler designed to minimize provider resource costs while meeting customer performance requirements. FnSched works by carefully regulating the resource usage of colocated functions on each invoker, and autoscaling capacity by concentrating load on few invokers in response to varying traffic. We implement a prototype of FnSched and show that, compared to existing baselines, FnSched significantly improves resource efficiency, by as much as 36%-55%, while providing acceptable application latency.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":13},{"url":"https://dl.acm.org/doi/10.1145/3344341.3368817","title":"research-article ","type":"Aperture: Fast Visualizations Over Spatiotemporal Datasets","venue":"UCC'19: Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing","authors":["Kevin Bruhwiler","Shrideep Pallickara"],"abstract":"One of the most powerful ways to explore data is to visualize it. Visualizations underpin data wrangling, feature space explorations, and understanding the dynamics of phenomena. Here, we explore interactive visualizations of voluminous, spatiotemporal datasets. Our system, Aperture, makes novel use of data sketches to reconcile I/O overheads, in particular the speed differential across the memory hierarchy, and data volumes. Queries underpin several aspects of our methodology. This includes support for a diversity of queries that are aligned with the construction of visual artifacts, facilitating their effective evaluation over the server (distributed) backend, and generating speculative queries based on a user's exploration trajectory. Aperture includes support for different visual artifacts, animations, and multilinked views via scalable brushing-and-linking. Finally, we also explore issues in effective containerization to support visualization workloads. Our empirical benchmarks profile several aspects of visualization performance and demonstrate the suitability of our methodology.","publicationDate":"2019-12-01T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3347318.3355520","title":"research-article ","type":"Detection of Tennis Events from Acoustic Data","venue":"MMSports '19: Proceedings Proceedings of the 2nd International Workshop on Multimedia Content Analysis in Sports","authors":["Aaron Baughman","Eduardo Morales","Gary Reiss","Nancy Greco","Stephen Hammer","Shiqiang Wang"],"abstract":"Professional tennis is a fast-paced sport with serves and hits that can reach speeds of over 100 mph and matches lasting long in duration. For example, in 13 years of Grand Slam data, there were 454 matches with an average of 3 sets that lasted 40 minutes. The fast pace and long duration of tennis matches make tracking the time boundaries of each tennis point in a match challenging. The visual aspect of a tennis match is highly diverse because of its variety in angles, occlusions, resolutions, contrast and colors, but the sound component is relatively stable and consistent. In this paper, we present a system that detects events such as ball hits and point boundaries in a tennis match from sound data recorded in the match. We first describe the sound processing pipeline that includes preprocessing, feature extraction, basic (atomic) event detection, and point boundary detection. Then, we describe the overall cloud-based system architecture. Afterwards, we describe the user interface that includes a tool for data labeling to efficiently generate the training dataset, and a workbench for sound and model management. The performance of our system is evaluated in experiments with real-world tennis sound data. Our proposed pipeline can detect atomic tennis events with an F1-score of 92.39% and point boundaries with average precision and recall values of around 80%. This system can be very useful for tennis coaches and players to find and extract game highlights with specific characteristics, so that they can analyze these highlights and establish their play strategy.","publicationDate":"2019-10-14T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3281375.3281409","title":"research-article ","type":"Efficient scheduling in a smart building","venue":"MEDES '18: Proceedings of the 10th International Conference on Management of Digital EcoSystems","authors":["Tarek Menouer","Christophe Cérin","Yanik Ngoko"],"abstract":"Smart buildings present challenging opportunities and issues regarding the intelligence we push in the framework that manage the building. Among them the scheduling and allocation of tasks/jobs. Based on the expertises of Qarnot Computing and LIPN Laboratory, we address three relevant matters of concern for smart buildings. First of all, we explain the economic model that the Qarnot middleware implements for managing, in a distributed way, smart buildings. The key idea is to consider the building as a data-center, managed by a cloud middleware. Then we introduce the key properties we consider as important in the context of the construction of a middleware for buildings. At last, this paper presents an efficient scheduling and allocation system according to an innovative economic model. The idea is to presents a new container scheduling system based on SLA (Service Level Agreements) classes and which is used in smart building with cloud computing environment. The novelty of our system is based on the possibility to adapt, dynamically, the scheduling and the resources allocation of containers according to the different SLA classes and the activities peaks of the nodes in the cloud i.e. the building. Experimental results show that our system gives expected results for our scenario and provides with good performance regarding the balance between objectives.","publicationDate":"2018-09-24T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3167132.3167383","title":"poster ","type":"Trigger correlation for dynamic system reconfiguration","venue":"SAC '18: Proceedings of the 33rd Annual ACM Symposium on Applied Computing","authors":["Mahin Abbasipour","Ferhat Khendek","Maria Toeroe"],"abstract":"Service Providers1 aim at optimizing resource utilisation while respecting the Service Level Agreements (SLAs) entered with customers. Dynamic reconfiguration is a mechanism for rearranging, allocating and deallocating resources as workload varies. Rearranging, adding or deallocating resources are performed by actions according to elasticity rules triggered by certain conditional events, like threshold violations, called triggers. At runtime, more than one trigger may be generated at a time. Handling them independently may jeopardize certain properties such as availability; moreover, it may harm the stability of the system. In this paper we propose a model based approach for runtime correlation of triggers and the execution of their related elasticity rule actions. This approach is part of an overall framework for SLA compliance management and dynamic reconfiguration.","publicationDate":"2018-04-08T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3487019.3487022","title":"research-article ","type":"Static Analysis at GitHub: An experience report","venue":"Queue","authors":["Timothy Clem","Patrick Thomson"],"abstract":"The Semantic Code team at GitHub builds and operates a suite of technologies that power symbolic code navigation on github.com. We learned that scale is about adoption, user behavior, incremental improvement, and utility. Static analysis in particular is difficult to scale with respect to human behavior; we often think of complex analysis tools working to find potentially problematic patterns in code and then trying to convince the humans to fix them. Our approach took a different tack: use basic analysis techniques to quickly put information that augments our ability to understand programs in front of everyone reading code on GitHub with zero configuration required and almost immediate availability after code changes.","publicationDate":"2021-08-30T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3447545.3451901","title":"research-article ","type":"Elastic Pulsar Functions for Distributed Stream Processing","venue":"ICPE '21: Companion of the ACM/SPEC International Conference on Performance Engineering","authors":["Gabriele Russo Russo","Antonio Schiazza","Valeria Cardellini"],"abstract":"An increasing number of data-driven applications rely on the ability of processing data flows in a timely manner, exploiting for this purpose Data Stream Processing~(DSP) systems. Elasticity is an essential feature for DSP systems, as workload variability calls for automatic scaling of the application processing capacity, to avoid both overload and resource wastage. In this work, we implement auto-scaling in Pulsar Functions, a function-based streaming framework built on top of Apache Pulsar. The latter is is a distributed publish-subscribe messaging platform that natively supports serverless functions. Considering various state-of-the-art policies, we show that the proposed solution is able to scale application parallelism with minimal overhead.","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3141128.3141146","title":"research-article ","type":"Team Placement in Crowd-Resourcing Virtual Laboratory for IT Security e-Learning","venue":"ICCBDC 2017: Proceedings of the 2017 International Conference on Cloud and Big Data Computing","authors":["Johannes Sianipar","Christian Willems","Christoph Meinel"],"abstract":"A crowd-resourcing virtual laboratory is a virtual laboratory in which some of the resources are obtained from the crowd. The virtual laboratory is for IT Security e-Learning, where a trainee needs an isolated laboratory environment to do the practical exercises. The isolated laboratory environment, which is called as a Team, consists of virtual machines (VMs) or containers and virtual network devices. The crowd contributes their resources such as virtual machines or physical machines, to the virtual laboratory. The virtual laboratory automatically occupies the contributed resources and uses them to create a Team. The team that consists of containers, will be run in a VM. Since there could be a lot of VMs available, the system needs to select the best VM to run a Team. We present CTPlace, an approach for Team Placement in crowd-resourcing virtual laboratory.CTPlace groups the VMs into tree hierarchical clusters based on the Geo-location of the VMs. CTPlace has two steps in the Team placement. First, it selects a nearest cluster to the trainee location to get the highest throughput. Second, it selects a VM inside the selected cluster. To select a VM inside a public cloud cluster, it uses Most-Full-First algorithm to reduce service cost by reducing the number of running VMs. To select a VM inside a private cloud or within contributed resources, it uses Least-Full-First and Tag-Pack to balance the load and try to place the same type of Teams on the same VM. We compare the CTPlace with three other placement algorithms in a simulated environment, to evaluate the performance of the CTPlace.","publicationDate":"2017-09-16T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.5555/3373669.3373678","title":"research-article ","type":"Patterns of software development with containers","venue":"PLoP '18: Proceedings of the 25th Conference on Pattern Languages of Programs","authors":["Kyle Brown","Christopher Hay"],"abstract":"This pattern language is concerned with the problems inherent in building and delivering software using containers, particularly those issues that arise during the process of mapping Docker images and containers into the stages of a software development lifecycle. We discuss practical solutions to problems of security and scaling brought on by adoption of container platforms. The language assumes that the reader will be building applications following an agile approach that is characterized by Continuous Integration/Continuous Delivery. This paper is part of a larger set of patterns of cloud adoption; for information on patterns of microservices adoption that may precede these patterns see [Brown 2016].","publicationDate":"2018-10-23T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3437359.3465565","title":"research-article ","type":"Jetstream2: Accelerating cloud computing via Jetstream","venue":"PEARC '21: Practice and Experience in Advanced Research Computing","authors":["David Y. Hancock","Jeremy Fischer","John Michael Lowe","Winona Snapp-Childs","Marlon Pierce","Suresh Marru","J. Eric Coulter","Matthew Vaughn","Brian Beck","Nirav Merchant","Edwin Skidmore","Gwen Jacobs"],"abstract":" Jetstream2 will be a category I production cloud resource that is part of the National Science Foundation’s Innovative HPC Program. The project’s aim is to accelerate science and engineering by providing “on-demand” programmable infrastructure built around a core system at Indiana University and four regional sites. Jetstream2 is an evolution of the Jetstream platform, which functions primarily as an Infrastructure-as-a-Service cloud. The lessons learned in cloud architecture, distributed storage, and container orchestration have inspired changes in both hardware and software for Jetstream2. These lessons have wide implications as institutions converge HPC and cloud technology while building on prior work when deploying their own cloud environments. Jetstream2’s next-generation hardware, robust open-source software, and enhanced virtualization will provide a significant platform to further cloud adoption within the US research and education communities.","publicationDate":"2021-07-16T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3101282.3101285","title":"research-article ","type":"Benchmark requirements for microservices architecture research","venue":"ECASE '17: Proceedings of the 1st International Workshop on Establishing the Community-Wide Infrastructure for Architecture-Based Software Engineering","authors":["Carlos M. Aderaldo","Nabor C. Mendonça","Claus Pahl","Pooyan Jamshidi"],"abstract":"Microservices have recently emerged as a new architectural style in which distributed applications are broken up into small independently deployable services, each running in its own process and communicating via lightweight mechanisms. However, there is still a lack of repeatable empirical research on the design, development and evaluation of microservices applications. As a first step towards filling this gap, this paper proposes, discusses and illustrates the use of an initial set of requirements that may be useful in selecting a community-owned architecture benchmark to support repeatable microservices research.","publicationDate":"2017-05-19T22:00:00.000Z","citationCount":11},{"url":"https://dl.acm.org/doi/10.5555/3370272.3370322","title":"research-article ","type":"Hands-on workshop on fast, efficient & seriously open cloud-native Java","venue":"CASCON '19: Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering","authors":["Yee-Kang Chang","Patrick Tiu","Eric Lau","Leo Christy Jesuraj","Alvin So","Gilbert Kwan"],"abstract":"Do speed, efficiency, open, cloud-native and Java go together? Yes, they do! Come and experience for yourself firsthand how you can build cloud-native solutions fast and efficiently with open, enterprise-grade Java programming model and runtime optimized for microservices and cloud. We will cover a range of topics in a hands-on manner from fast iterative development, automated testing to considerations for cloud deployments with containers. Join us and let's go cloud-native in warp speed with Java together!","publicationDate":"2019-11-03T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3341105.3374026","title":"research-article ","type":"Resource allocation for edge computing with multiple tenant configurations","venue":"SAC '20: Proceedings of the 35th Annual ACM Symposium on Applied Computing","authors":["Andrea Araldo","Alessandro Di Stefano","Antonella Di Stefano"],"abstract":"Edge Computing (EC) consists in deploying computational resources, e.g., memory, CPUs, at the Edge of the network, e.g., base stations, access points, and run there a part of the computation currently running on the Cloud. This approach promises to reduce latency, inter-domain traffic and enhance user experience. Since resources at the Edge are scarce, resource allocation is crucial for EC. While most of the studies assume users interact directly with the Edge submitting a sequence of tasks, we instead consider that users will interact with different Service Providers (SPs), as they currently do in the Web. We therefore consider the case of a Network Operator (NO) that owns the resources at the Edge and must decide how much resource to allocate to the different tenants (SPs).We propose MORA, a polynomial time strategy which allows the NO to maximize its utility, which can be inter-domain traffic savings, improved users' QoE or other metrics of interest. The core of MORA is that (i) it exploits service elasticity, i.e., the fact that services can adapt to the resources allocated by the NO and rely on a remote Cloud for the excess of computation, (ii) it is suitable for micro-services architecture, which decomposes a single service in a set of components, which MORA places in the different computational nodes of the Edge and (iii) it copes with multi-dimensional resources, e.g., memory and CPUs. After analyzing the properties of the algorithm, we show numerically that it performs close to the optimum. To guarantee reproducibility, the numerical evaluation is performed on publicly available traces from Google and Alibaba clusters and in synthetic scenarios and our code is open source.","publicationDate":"2020-03-29T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.5555/3432601.3432646","title":"research-article ","type":"Z modernization open tools showcase","venue":"CASCON '20: Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering","authors":["Steve Shao","Nitika Sharma","Stephanie Kuan"],"abstract":"Z Modernization Open Tools Showcase is a collection of multiple demos and use-cases built into a single environment, illustrating how to configure and debug transactions in seconds. What's more exciting, it brings support to developers first choice IDEs including VS Code. With modern tools to existing z/OS workloads, developers can start interacting with z/OS like we would any other cloud environment.","publicationDate":"2020-11-09T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3474085.3475617","title":"research-article ","type":"CARE: Cloudified Android OSes on the Cloud Rendering","venue":"MM '21: Proceedings of the 29th ACM International Conference on Multimedia","authors":["Dongjie Tang","Cathy Bao","Yong Yao","Chao Xie","Qiming Shi","Marc Mao","Randy Xu","Linsheng Li","Mohammad R. Haghighat","Zhengwei Qi","Haibing Guan"],"abstract":"GPUs have become ubiquitous in the Cloud-rendering areas due to the outstanding rendering performance. However, many existing Cloud-rendering systems suffer from low GPU utilization caused by the CPU bottleneck. Recent proposals (e.g., API-forwarding and c-GPU) for GPU-usage optimization are promising but fail to address the system-resource redundancy issues (i.e., each instance tends to occupy all the system resources exceeding their requirements), leading to unnecessary CPU consumption and lowering GPU utilization. We conducted an experiment by testing real-world applications on the percentage of unused resources to demonstrate the severity of this issue. Nearly 50% of resources are unused.To solve this problem, we present CARE, the first framework intended to reduce the system-level redundancy by cloudifying the system from monolithic to Cloud-native. To allow users to configure their own required services, CARE puts forward a functional unit called Configurable Android (CA). To allow multiple instances to share certain types of resources, CARE innovates Sharing Resource (SR). To reduce the unused services, CARE introduces Pruning Resources (PR). Last but not least, to further reduce CPU consumption, CARE proposes a new isolation unit called CiC. So far, CARE primarily focuses on Android systems due to the great popularity of Android Cloud-gaming frameworks. Furthermore, CARE can handle 60 heavyweight instances (e.g., KOG (King of Glory)) on Intel® SG1.","publicationDate":"2021-10-16T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3068126.3068129","title":"research-article ","type":"Self-Healing in a Decentralised Cloud Management System","venue":"CloudNG:17: Proceedings of the 1st International Workshop on Next generation of Cloud Architectures","authors":["Paul Stack","Huanhuan Xiong","Dali Mersel","Maxime Makhloufi","Guillaume Terpend","Dapeng Dong"],"abstract":"With the advent of heterogeneous resources and increasing scale, present cloud environments are becoming more and more complex. In order to manage heterogeneous cloud infrastructures at scale, in a reliable and robust manner, systems and services with autonomic behaviours are advantaging. In this paper, self-healing concepts are introduced for autonomic cloud management. A layered master-slave structure is proposed, providing the reliability and high availability for a decentralised, hierarchical cloud architecture.","publicationDate":"2017-04-22T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3297280.3297295","title":"research-article ","type":"Oversubscribing micro-clouds with energy-aware containers scheduling","venue":"SAC '19: Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing","authors":["Seŕgio Mendes","José Simão","Luís Veiga"],"abstract":"Cloud computation is being pushed to the edge of the network, towards Micro-clouds, to promote more energy efficiency and less latency when compared to heavy resourced centralized datacenters. This trend will enable new markets and providers to fill the current gap. There are however challenges in this design: (i) devices have less resources, leading to a frequent use of oversubscription (ii) lack of economic incentives to both provider and application owner to cope with less than full requests fulfilled. To support this trend, the virtualization layer of Micro-clouds is currently dominated by containers, which have a small memory footprint and strong isolation properties. We propose an extension to Docker Swarm, a widely used containers orchestrator, with an oversubscribing scheduling algorithm, based on improving resources utilization to levels where the energy efficiency is maximized. This solution improves CPU and memory utilization over Spread and Binpack (Docker Swarm strategies). Although we introduce a small overhead in scheduling times, our solution manages to allocate more requests, with a successful allocation rate of 83% against 57% of current solutions, measured on the scheduling of real CPU- and memory-intensive workloads (e.g. Video encoding, Key-value storages and a Deep-learning algorithm).","publicationDate":"2019-04-07T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3447545.3451180","title":"research-article ","type":"Towards Independent Run-Time Cloud Monitoring","venue":"ICPE '21: Companion of the ACM/SPEC International Conference on Performance Engineering","authors":["Luuk Klaver","Thijs van der Knaap","Johan van der Geest","Edwin Harmsma","Bram van der Waaij","Paolo Pileggi"],"abstract":"Cloud computing services are integral to the digital transformation. They deliver greater connectivity, tremendous savings, and lower total cost of ownership. Despite such benefits and benchmarking advances, costs are still quite unpredictable, performance is unclear, security is inconsistent, and there is minimal control over aspects like data and service locality. Estimating performance of cloud environments is very hard for cloud consumers. They would like to make informed decisions about which provider better suits their needs using specialized evaluation mechanisms. Providers have their own tools reporting specific metrics, but they are potentially biased and often incomparable across providers. Current benchmarking tools allow comparison but consumers need more flexibility to evaluate environments under actual operating conditions for specialized applications. Ours is early stage work and a step towards a monitoring solution that enables independent evaluation of clouds for very specific application needs. In this paper, we present our initial architecture of the Cloud Monitor that aims to integrate existing and new benchmarks in a flexible and extensible way. By way of a simplistic demonstrator, we illustrate the concept. We report some preliminary monitoring results after a brief time of monitoring and are able to observe unexpected anomalies. The results suggest an independent monitoring solution is a powerful enabler of next generation cloud computing, not only for the consumer but potentially the whole ecosystem.","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3331453.3361637","title":"research-article ","type":"Space Cloud-Fog Computing: Architecture, Application and Challenge","venue":"CSAE 2019: Proceedings of the 3rd International Conference on Computer Science and Application Engineering","authors":["Suzhi Cao","Hao Han","Junyong Wei","Yi Zhao","Shuling Yang","Lei Yan"],"abstract":"With the development of space technology, it is an inevitable trend to build a flexible and efficient computing system for space-based information network. Traditional limited computing in single satellite cannot meet the increasing needs and cannot make effective use of the resources. This paper proposes a space-based cloud-fog computing architecture, which applies cloud-fog computing system to the space-based information network, and then we introduce the deployment of the architecture, and describe its typical application. At last, we analyze the challenges and future development of space cloud-fog computing.","publicationDate":"2019-10-21T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3305275.3305280","title":"short-paper ","type":"Machine Learning Hyperparameter Fine Tuning Service on Dynamic Cloud Resource Allocation System - taking Heart Sounds as an Example","venue":"ISBDAI '18: Proceedings of the International Symposium on Big Data and Artificial Intelligence","authors":["Yu-Hsiang Peng","Chia-Chuan Chuang","Zhou-Jin Wu","Chia-Wei Chou","Hui-Shan Chen","Ting-Chia Chang","Yi-Lun Pan","Hsin-Tien Cheng","Chih-Chi Chung","Ken-Yu Lin"],"abstract":"The hyperparameters tuning of machine learning has always been a difficult and time-consuming task in deep learning area. In many practical applications, the hyperparameter tuning directly affects the accuracy. Therefore, the tuning optimization of hyperparameters is an important topic. At present, hyperparameters can only be set manually based on experience, and use Violent Enumeration, Random Search or through Grid Search to try and error, lack of effective automatic search parameters. In this study, we proposed a machine learning hyperparameter fine tuning service on dynamic cloud resource allocation system, which leverages several mainstream hyperparameter tuning methods such as Hyperopt and Optunity. In the meanwhile, various tuning methods are measured and compared by example application in this work. Finally, we dedicated actual case - Heart Sounds, and then tested it. In order to verify that the system service can not only automate the task of tuning, but also break through the limitation of the number of adjustable parameters. Furthermore the proposed hyperparameter fine tune system makes optimization process more efficient.","publicationDate":"2018-12-28T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3350768.3350788","title":"research-article ","type":"Beyond Textual Issues: Understanding the Usage and Impact of GitHub Reactions","venue":"SBES 2019: Proceedings of the XXXIII Brazilian Symposium on Software Engineering","authors":["Hudson Borges","Rodrigo Brito","Marco Tulio Valente"],"abstract":"Recently, GitHub introduced a new social feature, named reactions, which are \"pictorial characters\" similar to emoji symbols widely used nowadays in text-based communications. Particularly, GitHub users can use a pre-defined set of such symbols to react to issues and pull requests. However, little is known about the real usage and impact of GitHub reactions. In this paper, we analyze the reactions provided by developers to more than 2.5 million issues and 9.7 million issue comments, in order to answer an extensive list of nine research questions about the usage and adoption of reactions. We show that reactions are being increasingly used by open source developers. Moreover, we also found that issues with reactions usually take more time to be handled and have longer discussions.","publicationDate":"2019-09-22T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3219104.3219152","title":"research-article ","type":"TERRA-REF Data Processing Infrastructure","venue":"PEARC '18: Proceedings of the Practice and Experience on Advanced Research Computing","authors":["Maxwell Burnette","Rob Kooper","J. D. Maloney","Gareth S. Rohde","Jeffrey A. Terstriep","Craig Willis","Noah Fahlgren","Todd Mockler","Maria Newcomb","Vasit Sagan","Pedro Andrade-Sanchez","Nadia Shakoor","Paheding Sidike","Rick Ward","David LeBauer"],"abstract":"The Transportation Energy Resources from Renewable Agriculture Phenotyping Reference Platform (TERRA-REF) provides a data and computation pipeline responsible for collecting, transferring, processing and distributing large volumes of crop sensing and genomic data from genetically informative germplasm sets. The primary source of these data is a field scanner system built over an experimental field at the University of Arizona Maricopa Agricultural Center. The scanner uses several different sensors to observe the field at a dense collection frequency with high resolution. These sensors include RGB stereo, thermal, pulse-amplitude modulated chlorophyll fluorescence, imaging spectrometer cameras, a 3D laser scanner, and environmental monitors. In addition, data from sensors mounted on tractors, UAVs, an indoor controlled-environment facility, and manually collected measurements are integrated into the pipeline. Up to two TB of data per day are collected and transferred to the National Center for Supercomputing Applications at the University of Illinois (NCSA) where they are processed.In this paper we describe the technical architecture for the TERRA-REF data and computing pipeline. This modular and scalable pipeline provides a suite of components to convert raw imagery to standard formats, geospatially subset data, and identify biophysical and physiological plant features related to crop productivity, resource use, and stress tolerance. Derived data products are uploaded to the Clowder content management system and the BETYdb traits and yields database for querying, supporting research at an experimental plot level. All software is open source2 under a BSD 3-clause or similar license and the data products are open access (currently for evaluation with a full release in fall 2019). In addition, we provide computing environments in which users can explore data and develop new tools. The goal of this system is to enable scientists to evaluate and use data, create new algorithms, and advance the science of digital agriculture and crop improvement.","publicationDate":"2018-07-21T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3483899.3483904","title":"research-article ","type":"Are we speaking the industry language? The practice and literature of modernizing legacy systems with microservices","venue":"SBCARS '21: 15th Brazilian Symposium on Software Components, Architectures, and Reuse","authors":["Thelma Colanzi","Aline Amaral","Wesley Assunção","Arthur Zavadski","Douglas Tanno","Alessandro Garcia","Carlos Lucena"],"abstract":" Microservice architecture has gained much attention in the last few years in both industry and academia. Microservice is an architectural style that enables developing systems as a suite of small loosely coupled, and autonomous (micro)services that encapsulate business capabilities and communicate with each other using language-agnostic APIs. Despite the microservice adoption for modernizing legacy systems, few studies investigate how microservices are used in practice. Furthermore, the literature still scarce on presenting studies on why and how the modernization is conducted in practice in comparison to existing literature on the subject. Thus, our goal is to investigate if industry and academy are speaking the same language concerning the modernization of legacy systems with microservices, by means of a rigorous study on the use of microservices in the industry. For doing so, we design a survey to understand the state of practice from the perspective of a modernization process roadmap derived from the literature. In this paper, we report the results of a survey with 56 software companies, from which 35 (63.6%) adopt the microservice architecture in their legacy systems. Results pointed out the most expected benefits that drive the migration to microservices are easier software maintenance, better scalability, ease of deployment, and technology flexibility. Besides, we verified, based on a set of activities defined in the modernization process, that the practitioners are performing their migration process according to the best literature practices.","publicationDate":"2021-09-26T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3172795.3172823","title":"research-article ","type":"Elascale: autoscaling and monitoring as a service","venue":"CASCON '17: Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering","authors":["Hamzeh Khazaei","Rajsimman Ravichandiran","Byungchul Park","Hadi Bannazadeh","Ali Tizghadam","Alberto Leon-Garcia"],"abstract":"Auto-scalability has become an evident feature for cloud software systems including but not limited to big data and IoT applications. Cloud application providers now are in full control over their applications' microservices and macroservices; virtual machines and containers can be provisioned or deprovisioned on demand at run-time. Elascale strives to adjust both micro/macro resources with respect to workload and changes in the internal state of the whole application stack. Elascale leverages Elasticsearch stack for collection, analysis and storage of performance metrics. Elascale then uses its default scaling engine to elastically adapt the managed application. Extendibility is guaranteed through provider, schema, plug-in and policy elements in the Elascale by which flexible scalability algorithms, including both reactive and proactive techniques, can be designed and implemented for various technologies, infrastructures and software stacks. In this paper, we present the architecture and initial implementation of Elascale; an instance will be leveraged to add auto-scalability to a generic IoT application. Due to zero dependency to the target software system, Elascale can be leveraged to provide auto-scalability and monitoring as-a-service for any type of cloud software system.","publicationDate":"2017-11-05T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3341301.3359645","title":"research-article ","type":"CrashTuner: detecting crash-recovery bugs in cloud systems via meta-info analysis","venue":"SOSP '19: Proceedings of the 27th ACM Symposium on Operating Systems Principles","authors":["Jie Lu","Chen Liu","Lian Li","Xiaobing Feng","Feng Tan","Jun Yang","Liang You"],"abstract":"Crash-recovery bugs (bugs in crash-recovery-related mechanisms) are among the most severe bugs in cloud systems and can easily cause system failures. It is notoriously difficult to detect crash-recovery bugs since these bugs can only be exposed when nodes crash under special timing conditions. This paper presents CrashTuner, a novel fault-injection testing approach to combat crash-recovery bugs. The novelty of CrashTuner lies in how we identify fault-injection points (crash points) that are likely to expose errors. We observe that if a node crashes while accessing meta-info variables, i.e., variables referencing high-level system state information (e.g., an instance of node or task), it often triggers crash-recovery bugs. Hence, we identify crash points by automatically inferring meta-info variables via a log-based static program analysis. Our approach is automatic and no manual specification is required.We have applied CrashTuner to five representative distributed systems: Hadoop2/Yarn, HBase, HDFS, ZooKeeper, and Cassandra. CrashTuner can finish testing each system in 17.39 hours, and reports 21 new bugs that have never been found before. All new bugs are confirmed by the original developers and 16 of them have already been fixed (14 with our patches). These new bugs can cause severe damages such as cluster down or start-up failures.","publicationDate":"2019-10-26T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.5555/3291291.3291335","title":"research-article ","type":"Building microservices in a cloud-native world using eclipse microprofile and open liberty","venue":"CASCON '18: Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering","authors":["Eveline Cai","Gilbert Kwan","Panagiotis Roubatsis","Yee-Kang Chang"],"abstract":"Eclipse MicroProfile is a modular set of technologies designed so that you can write cloud-native Java™ microservices. Student will learn how MicroProfile helps you develop and manage cloud-native microservices. Then, follow the Open Liberty MicroProfile guides to gain hands-on experience with MicroProfile so that you can build microservices with Open Liberty.","publicationDate":"2018-10-28T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3370272.3370313","title":"research-article ","type":"Dogfooding: using IBM cloud services to monitor IBM cloud infrastructure","venue":"CASCON '19: Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering","authors":["William Pourmajidi","Andriy Miranskyy","John Steinbacher","Tony Erwin","David Godwin"],"abstract":"The stability and performance of Cloud platforms are essential as they directly impact customers' satisfaction. Cloud service providers use Cloud monitoring tools to ensure that rendered services match the quality of service requirements indicated in established contracts such as service-level agreements.Given the enormous number of resources that need to be monitored, highly scalable and capable monitoring tools are designed and implemented by Cloud service providers such as Amazon, Google, IBM, and Microsoft. Cloud monitoring tools monitor millions of virtual and physical resources and continuously generate logs for each one of them. Considering that logs magnify any technical issue, they can be used for disaster detection, prevention, and recovery. However, logs are useless if they are not assessed and analyzed promptly. Thus, we argue that the scale of Cloud-generated logs makes it impossible for DevOps teams to analyze them effectively. This implies that one needs to automate the process of monitoring and analysis (e.g., using machine learning and artificial intelligence). If the automation will witness an anomaly in the logs --- it will alert DevOps staff.The automatic anomaly detectors require a reliable and scalable platform for gathering, filtering, and transforming the logs, executing the detector models, and sending out the alerts to the DevOps staff. In this work, we report on implementing a prototype of such a platform based on the 7-layered architecture pattern, which leverages micro-service principles to distribute tasks among highly scalable, resources-efficient modules. The modules interact with each other via an instance of the Publish-Subscribe architectural pattern. The platform is deployed on the IBM Cloud service infrastructure and is used to detect anomalies in logs emitted by the IBM Cloud services, hence the dogfooding. In particular, we leverage IBM Cloud Functions to deploy the computing modules, IBM Event Streams to establish communication among the modules, and IBM Cloud Object Storage and IBM Cloudant for persistent storage.The prototype efficiency is promising: it takes the platform 17 seconds or less from the point of receiving a new log record to emitting an alert to the IBM Cloud DevOps team.","publicationDate":"2019-11-03T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3458336.3465303","title":"research-article ","type":"Rethinking networking abstractions for cloud tenants","venue":"HotOS '21: Proceedings of the Workshop on Hot Topics in Operating Systems","authors":["Sarah McClure","Sylvia Ratnasamy","Deepak Bansal","Jitendra Padhye"],"abstract":"We argue that network virtualization as experienced by many cloud tenants is overly complex and needs to be rethought. We propose that the goal for a new design should be to free cloud tenants entirely from having to build and operate virtual networks. Building on this philosophy, we propose that instead of low-level building blocks (virtual links, routers, firewalls), cloud networking should be exposed to tenants in a declarative and endpoint-centric manner.","publicationDate":"2021-05-31T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3005745.3005756","title":"research-article ","type":"FreeFlow: High Performance Container Networking","venue":"HotNets '16: Proceedings of the 15th ACM Workshop on Hot Topics in Networks","authors":["Tianlong Yu","Shadi Abdollahian Noghabi","Shachar Raindel","Hongqiang Liu","Jitu Padhye","Vyas Sekar"],"abstract":"With the tremendous popularity gained by container technology, many applications are being containerized: splitting into numerous containers connected by networks. However, current container networking solutions have either bad performance or poor portability, which undermines the advantages of containerization. In this paper, we propose FreeFlow, a container networking solution which achieves both high performance and good portability. FreeFlow is designed according to the observation that strict isolations are unnecessary among containers trusting each other, and it can significantly boost the communication quality of containers by compromising isolation a little bit. Specifically, we enable containers on the same physical machine to communicate via shared-memory and the ones on different physical machines communicate via high performance networking options, e.g. RDMA and DPDK. Naively wrapping up all the solutions together will result in poor potability of containers and huge complexity in application development. Instead, FreeFlow leverages a network abstraction which supports all common network APIs and a centralized network orchestrator which decides how to deliver data transparently to applications in the containers.","publicationDate":"2016-11-08T23:00:00.000Z","citationCount":15},{"url":"https://dl.acm.org/doi/10.1109/CCGRID.2017.52","title":"tutorial ","type":"Flexible Scheduling of Distributed Analytic Applications","venue":"CCGrid '17: Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","authors":["Francesco Pace","Daniele Venzano","Damiano Carra","Pietro Michiardi"],"abstract":"This work addresses the problem of scheduling user-defined analytic applications, which we define as high-level compositions of frameworks, their components, and the logic necessary to carry out work. The key idea in our application definition, is to distinguish classes of components, including rigid and elastic types: the first being required for an application to make progress, the latter contributing to reduced execution times. We show that the problem of scheduling such applications poses new challenges, which existing approaches address inefficiently.Thus, we present the design and evaluation of a novel, flexible heuristic to schedule analytic applications, that aims at high system responsiveness, by allocating resources efficiently. Our algorithm is evaluated using trace-driven simulations, with large-scale real system traces: our flexible scheduler outperforms a baseline approach across a variety of metrics, including application turnaround times, and resource allocation efficiency.We also present the design and evaluation of a full-fledged system, which we have called Zoe, that incorporates the ideas presented in this paper, and report concrete improvements in terms of efficiency and performance, with respect to prior generations of our system.","publicationDate":"2017-05-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3342195.3387534","title":"research-article ","type":"Rhythm: component-distinguishable workload deployment in datacenters","venue":"EuroSys '20: Proceedings of the Fifteenth European Conference on Computer Systems","authors":["Laiping Zhao","Yanan Yang","Kaixuan Zhang","Xiaobo Zhou","Tie Qiu","Keqiu Li","Yungang Bao"],"abstract":"Cloud service providers improve resource utilization by co-locating latency-critical (LC) workloads with best-effort batch (BE) jobs in datacenters. However, they usually treat an LC workload as a whole when allocating resources to BE jobs and neglect the different features of components of an LC workload. This kind of coarse-grained co-location method leaves a significant room for improvement in resource utilization.Based on the observation of the inconsistent interference tolerance abilities of different LC components, we propose a new abstraction called Servpod, which is a collection of a LC parts that are deployed on the same physical machine together, and show its merits on building a fine-grained co-location framework. The key idea is to differentiate the BE throughput launched with each LC Servpod, i.e., Servpod with high interference tolerance ability can be deployed along with more BE jobs. Based on Servpods, we present Rhythm, a co-location controller that maximizes the resource utilization while guaranteeing LC service's tail latency requirement. It quantifies the interference tolerance ability of each servpod through the analysis of tail-latency contribution. We evaluate Rhythm using LC services in forms of containerized processes and microservices, and find that it can improve the system throughput by 31.7%, CPU utilization by 26.2%, and memory bandwidth utilization by 34% while guaranteeing the SLA (service level agreement).","publicationDate":"2020-04-14T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3190564","title":"research-article ","type":"Designing cluster schedulers for internet-scale services","venue":"Communications of the ACM","authors":["Diptanu Gon Choudhury","Timothy Perrett"],"abstract":"Embracing failures for improving availability.","publicationDate":"2018-05-22T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1109/CCGRID.2017.62","title":"tutorial ","type":"SynAPTIC: Secure And Persistent connecTIvity for Containers","venue":"CCGrid '17: Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","authors":["Alireza Ranjbar","Miika Komu","Patrik Salmela","Tuomas Aura"],"abstract":"Cloud virtualization technology is shifting towards light-weight containers, which provide isolated environments for running cloud-based services. The emerging trends such as container-based micro-service architectures and hybrid cloud deployments result in increased traffic volumes between the micro-services, mobility of the communication endpoints, and some of the communication taking place over untrusted networks. Yet, the services are typically designed with the assumption of scalable, persistent and secure connectivity. In this paper, we present the SynAPTIC architecture, which enables secure and persistent connectivity between mobile containers, especially in the hybrid cloud and in multi-tenant cloud networks. The solution is based on the standardized Host Identity Protocol (HIP) that tenants can deploy on top of existing cloud infrastructure independently of their cloud provider. Optional cloud-provider extensions based on Software-Defined Networking (SDN) further optimize the networking architecture. Our qualitative and quantitative evaluation shows that SynAPTIC performs better than some of the existing solutions.","publicationDate":"2017-05-13T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.5555/3437539.3437794","title":"research-article ","type":"Enabling containerized computing and orchestration of ROS-based robotic SW applications on cloud-server-edge architectures: late breaking results","venue":"DAC '20: Proceedings of the 57th ACM/EDAC/IEEE Design Automation Conference","authors":["Stefano Aldegheri","Nicola Bombieri","Franco Fummi","Simone Girardi","Riccardo Muradore","Nicola Piccinelli"],"abstract":"We present a toolchain based on Docker and KubeEdge that enables containerization and orchestration of ROS-based robotic SW applications on heterogeneous and hierarchical HW architectures. The toolchain allows for verification of functional and real-time constraints through HW-in-the-loop simulation, and for automatic mapping exploration of the SW across Cloud-Server-Edge architectures. We present the results obtained for the deployment of a real case of study composed by an ORB-SLAM application combined to local/global planners with obstacle avoidance for a mobile robot navigation.","publicationDate":"2020-07-19T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3297280.3297427","title":"research-article ","type":"My cloudy time machine: a scalable microservice-based platform for data processing in cloud-edge systems: a proof of concept for the ROBIN-cloud project","venue":"SAC '19: Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing","authors":["Darius-Florentin Neatu","Radu-Dumitru Stochitoiu","Andrei-Vlad Postoaca","Ion-Dorinel Filip","Florin Pop"],"abstract":"As Cloud computing is a very well developed domain, many companies tend to move their entire activity in Cloud. At the same time, there is a tendency to move some of the data processing from Cloud to Edge as close as possible to the end devices. One main advantage of this approach is minimizing the latency in communication between the end devices and Cloud. Better usage of on premise devices is also a good achievement of the Edge offload. In this paper, we propose an architecture for applications that are connected to ROBIN-Cloud or to a general Cloud. We present how we have encapsulated Python-based microservices in Docker containers. We provide an implementation for the My Cloudy Time Machine application - GIGEL (Guided Intelligent GEared Legend), a nearby autonomous assistive robot. We use this prototype to evaluate the scalability of the proposed architecture. We also present results that show how to gain high performance by tuning a container-based embedded system.","publicationDate":"2019-04-07T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3368089.3409675","title":"research-article ","type":"Dimensions of software configuration: on the configuration context in modern software development","venue":"ESEC/FSE 2020: Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","authors":["Norbert Siegmund","Nicolai Ruckel","Janet Siegmund"],"abstract":"With the rise of containerization, cloud development, and continuous integration and delivery, configuration has become an essential aspect not only to tailor software to user requirements, but also to configure a software system’s environment and infrastructure. This heterogeneity of activities, domains, and processes blurs the term configuration, as it is not clear anymore what tasks, artifacts, or stakeholders are involved and intertwined. However, each re- search study and each paper involving configuration places their contributions and findings in a certain context without making the context explicit. This makes it difficult to compare findings, translate them to practice, and to generalize the results. Thus, we set out to evaluate whether these different views on configuration are really distinct or can be summarized under a common umbrella. By interviewing practitioners from different domains and in different roles about the aspects of configuration and by analyzing two qualitative studies in similar areas, we derive a model of configuration that provides terminology and context for research studies, identifies new research opportunities, and allows practitioners to spot possible challenges in their current tasks. Although our interviewees have a clear view about configuration, it substantially differs due to their personal experience and role. This indicates that the term configuration might be overloaded. However, when taking a closer look, we see the interconnections and dependencies among all views, arriving at the conclusion that we need to start considering the entire spectrum of dimensions of configuration.","publicationDate":"2020-11-07T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3190615","title":"opinion ","type":"Predicting failure of the university","venue":"Communications of the ACM","authors":["CACM Staff"],"abstract":"No abstract available.","publicationDate":"2018-03-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3381540.3381543","title":"research-article ","type":"LIBRE-ary, an open-source, distributed digital archiving system","venue":"Journal of Computing Sciences in Colleges","authors":["Ben Glick","Jens Mache"],"abstract":"As the amount of data we rely on every day has increased exponentially, the problem of digital archiving is becoming more and more important. People increasingly depend on having ready and easy access to the data they need to carry out their everyday lives. With this increased focus on data in everyday life comes a drastic increase in the amount of data people are responsible for. A corollary to this increasing dependence and scale is a problem we would define as digital clutter. Much like physical clutter, digital clutter can lead to confusion, complex data-management strategies, and often, unfortunate loss of important data and documents. In this paper, we present LIBRE-ary, our solution to the digital clutter and archiving problem.","publicationDate":"2019-09-30T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3463274.3463337","title":"research-article ","type":"On the Nature of Issues in Five Open Source Microservices Systems: An Empirical Study","venue":"EASE 2021: Evaluation and Assessment in Software Engineering","authors":["Muhammad Waseem","Peng Liang","Mojtaba Shahin","Aakash Ahmad","Ali Rezaei Nassab"],"abstract":" Due to its enormous benefits, the research and industry communities have shown an increasing interest in the Microservices Architecture (MSA) style over the last few years. Despite this, there is a limited evidence-based and thorough understanding of the types of issues (e.g., faults, errors, failures, mistakes) faced by microservices system developers and causes that trigger the issues. Such evidence-based understanding of issues and causes is vital for long-term, impactful, and quality research and practice in the MSA style. To that end, we conducted an empirical study on 1,345 issue discussions extracted from five open source microservices systems hosted on GitHub. Our analysis led to the first of its kind taxonomy of the types of issues in open source microservices systems, informing that the problems originating from Technical debt (321, 23.86%), Build (145, 10.78%), Security (137, 10.18%), and Service execution and communication (119, 8.84%) are prominent. We identified that “General programming errors”, “Poor security management”, “Invalid configuration and communication”, and “Legacy versions, compatibility and dependency” are the predominant causes for the leading four issue categories. Study results streamline a taxonomy of issues, their mapping with underlying causes, and present empirical findings that could facilitate research and development on emerging and next-generation microservices systems. ","publicationDate":"2021-06-20T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3238147.3240730","title":"research-article ","type":"Delta debugging microservice systems","venue":"ASE 2018: Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering","authors":["Xiang Zhou","Xin Peng","Tao Xie","Jun Sun","Wenhai Li","Chao Ji","Dan Ding"],"abstract":"Debugging microservice systems involves the deployment and manipulation of microservice systems on a containerized environment and faces unique challenges due to the high complexity and dynamism of microservices. To address these challenges, in this paper, we propose a debugging approach for microservice systems based on the delta debugging algorithm, which is to minimize failureinducing deltas of circumstances (e.g., deployment, environmental configurations) for effective debugging. Our approach includes novel techniques for defining, deploying/manipulating, and executing deltas following the idea of delta debugging. In particular, to construct a (failing) circumstance space for delta debugging to minimize, our approach defines a set of dimensions that can affect the execution of microservice systems. Our experimental study on a medium-size microservice benchmark system shows that our approach can effectively identify failure-inducing deltas that help diagnose the root causes.","publicationDate":"2018-09-02T22:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3464298.3476130","title":"research-article ","type":"PProx: efficient privacy for recommendation-as-a-service","venue":"Middleware '21: Proceedings of the 22nd International Middleware Conference","authors":["Guillaume Rosinosky","Simon Da Silva","Sonia Ben Mokhtar","Daniel Négru","Laurent Réveillère","Etienne Rivière"],"abstract":"We present PProx, a system preventing recommendation-as-a-service (RaaS) providers from accessing sensitive data about the users of applications leveraging their services. PProx does not impact recommendations accuracy, is compatible with arbitrary recommendation algorithms, and has minimal deployment requirements. Its design combines two proxying layers directly running inside SGX enclaves at the RaaS provider side. These layers transparently pseudonymize users and items and hide links between the two, and PProx privacy guarantees are robust even to the corruption of one of these enclaves. We integrated PProx with Harness's Universal Recommender and evaluated it on a 27-node cluster. Our results indicate its ability to withstand a high number of requests with low end-to-end latency, horizontally scaling up to match increasing workloads of recommendations.","publicationDate":"2021-11-21T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3342195.3387535","title":"research-article ","type":"A fault-tolerance shim for serverless computing","venue":"EuroSys '20: Proceedings of the Fifteenth European Conference on Computer Systems","authors":["Vikram Sreekanti","Chenggang Wu","Saurav Chhatrapati","Joseph E. Gonzalez","Joseph M. Hellerstein","Jose M. Faleiro"],"abstract":"Serverless computing has grown in popularity in recent years, with an increasing number of applications being built on Functions-as-a-Service (FaaS) platforms. By default, FaaS platforms support retry-based fault tolerance, but this is insufficient for programs that modify shared state, as they can unwittingly persist partial sets of updates in case of failures. To address this challenge, we would like atomic visibility of the updates made by a FaaS application.In this paper, we present aft, an atomic fault tolerance shim for serverless applications. aft interposes between a commodity FaaS platform and storage engine and ensures atomic visibility of updates by enforcing the read atomic isolation guarantee. aft supports new protocols to guarantee read atomic isolation in the serverless setting. We demonstrate that aft introduces minimal overhead relative to existing storage engines and scales smoothly to thousands of requests per second, while preventing a significant number of consistency anomalies.","publicationDate":"2020-04-14T22:00:00.000Z","citationCount":8},{"url":"https://dl.acm.org/doi/10.1145/3425269.3425272","title":"research-article ","type":"Generating Trustworthiness Adaptation Plans Based on Quality Models for Cloud Platforms","venue":"SBCARS '20: Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse","authors":["Jorge Luiz Machado da Silva","Breno B. Nicolau de França","Cecília Mary Fischer Rubira"],"abstract":"Cloud computing platforms can offer many benefits related to the provision of service processing and storage for hosting client applications. Trustworthiness can be defined as the trust of a customer in a cloud service and its provider; however, the assurance of this property is not trivial. First, trustworthiness in general is not composed by a single quality attribute, but by the combination of multiple attributes, such as data privacy, performance, reliability, etc. Second, during runtime clients can experience a change of the trustworthiness level required by their application due to the degradation of the cloud service. This article presents a solution that monitors during runtime the set of quality attributes of a specific application and generates adaptation plans in order to certify that an adequate resource amount be provided by the cloud in order to keep its trustworthiness level. Our solution is based on quality models to compute the metric associated to each non-functional requirement and their combination them into different types of trustworthiness levels. The main contribution of the solution is to provide an approach which deals with multiple requirements at the same time (or simultaneously) during runtime in order to adapt the cloud resources to keep the trustworthiness level required by the application. The solution was evaluated by an experiment considering a scenario where the application trustworthiness level was composed by three quality attributes: data privacy, performance and reliability. Initial results have shown that the approach is feasible in terms of the execution of the adaptation plans during runtime to certify the trustworthiness level required by the application.","publicationDate":"2020-10-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3432601.3432642","title":"research-article ","type":"Jumpstart your application into a reactive event-centric world: hands-on workshop","venue":"CASCON '20: Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering","authors":["Yee-Kang Chang","Meswan Bhaugeerutty","Gilbert Kwan","Grace Jansen"],"abstract":"We now live in a world with data at its heart. The amount of data being produced every day is growing exponentially and a large amount of this data is in the form of events. Whether it be updates from sensors, clicks on a website or even tweets, applications are bombarded with a never-ending stream of new events. So, how can we architect our applications to be more reactive and resilient to these fluctuating loads and better manage our thirst for data? In these quicklabs you'll learn what it means to easily build a cloud-native reactive application through the Eclipse MicroProfile reactive messaging framework and Apache Kafka.","publicationDate":"2020-11-09T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3230718.3230723","title":"research-article ","type":"Grafting sockets for fast container networking","venue":"ANCS '18: Proceedings of the 2018 Symposium on Architectures for Networking and Communications Systems","authors":["Ryo Nakamura","Yuji Sekiya","Hajime Tazaki"],"abstract":"This paper proposes a novel approach for fast container networking that enables applications in containers to utilize host network stacks directly with proper access control. Our approach, called socket-grafting, offers a new socket-layer communication channel by grafting sockets in containers onto sockets in host network stacks. In contrast to recent approaches that make network stacks faster by using high-speed packet I/O techniques, socket-grafting makes container networking faster by bypassing a container's network stack and virtual interfaces. As a concrete implementation of socket-grafting, we designed AF_GRAFT, which is a new address family for the socket layer. AF_GRAFT performs interconnection between the two socket layers in the container and host network stacks. In this paper, we describe socket-grafting, AF_GRAFT design, and its implementation on Linux. Our evaluation results demonstrate that the proposed method doubled throughput and reduced latency by 23% compared with traditional NAT-based container networking, and improved the network performance of containerized HTTP servers and message queues.","publicationDate":"2018-07-22T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3284028.3284031","title":"research-article ","type":"DéjàVu: Bringing Black-box Security Analytics to Cloud","venue":"Middleware '18: Proceedings of the 19th International Middleware Conference Industry","authors":["Shripad Nadgowda","Canturk Isci","Mustafa Bal"],"abstract":"Emerging security solutions for cloud commonly operate in two phases, data collection and analytics. Data collection phase provides visibility into cloud resources (images, containers, VMs, etc.) and analytics derives insights built on data. Analytics phase is commonly decoupled from data collection and cloud resources as a separate, scalable pipeline. This enables cloud-scale operation via separation of concerns and overheads. Analytics focus on deriving high-value insights from data, and data collection focuses on efficient and minimally-intrusive inspection and introspection techniques. However, this model breaks traditional security solutions, such as endpoint managers, malware and compliance checkers, that are designed to run locally inside the systems they are securing. The common cloud strategy to address this problem has been to rewrite existing solutions to \"work from data\" instead of \"working inside the system\". This requires huge amount of resources and effort, and has fueled a slew of new \"cloud-native security\" solutions in the field.In this paper we approach this problem from a different angle. Instead of rewriting security solutions to work from data, we explore how to reuse existing security solutions as black-box analytics in the cloud. We present DéjàVu, a framework that makes data accessible to traditional software by mimicking a system veneer over the data. We achieve this by re-building a standard native POSIX system interface over the data. We enable traditional security applications to run unmodified in a black-box fashion. We validate our framework with state of the art third party security solutions and demonstrate that they can be operated with modest overhead.","publicationDate":"2018-12-09T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/2983323.2983331","title":"demonstration ","type":"ConHub: A Metadata Management System for Docker Containers","venue":"CIKM '16: Proceedings of the 25th ACM International on Conference on Information and Knowledge Management","authors":["Chris Xing Tian","Aditya Pan","Yong Chiang Tay"],"abstract":"For many years now, enterprises and cloud providers have been using virtualization to run their workloads. Until recently, this means running an application in a virtual machine (hardware virtualization). However, virtual machines are increasingly replaced by containers (operating system virtualization), as evidenced by the rapid rise of Docker. A containerized software environment can generate a large amount of metadata. If properly managed, these metadata can greatly facilitate the management of containers themselves. This demonstration introduces ConHub, a PostgreSQL-based container metadata management system. Visitors will see that (1) ConHub has a language CQL that supports Docker commands; (2) it has a user-friendly interface for querying and visualizing container relationships; and (3) they can use CQL to formulate sophisticated queries to facilitate container management.","publicationDate":"2016-10-23T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3316615.3316671","title":"research-article ","type":"Survey of Hyperledger Blockchain Frameworks: Case Study in FPT University's Cryptocurrency Wallets","venue":"ICSCA '19: Proceedings of the 2019 8th International Conference on Software and Computer Applications","authors":["Tran Quy Ban","Bui Ngoc Anh","Ngo Tung Son","Tran Van Dinh"],"abstract":"There are many blockchain frameworks have been introduced to user, developer, and customer and they have to make a decision which one is most suitable for them in order for developing their applications. This paper describes an empirical research to benchmark the properties of frameworks in Hyperledger family. The purpose is to show the advantage & disadvantage of each framework. We apply the deeply study inside the framework and do the experiment to measure the properties as well as give literature and numerical review of each framework. Our results show the status of tested frameworks and do not demonstrate how to employ the framework as well as apply to the detail application. The main contribution of this paper is a statistical analysis of the effectiveness of Hyperledger frameworks as a tool for developer to develop their applications.","publicationDate":"2019-02-18T23:00:00.000Z","citationCount":7},{"url":"https://dl.acm.org/doi/10.1145/3194653.3199609","title":"research-article ","type":"Designing Cluster Schedulers for Internet-Scale Services: Embracing failures for improving availability","venue":"Queue","authors":["Diptanu Gon Choudhury","Timothy Perrett"],"abstract":"Engineers looking to build scheduling systems should consider all failure modes of the underlying infrastructure they use and consider how operators of scheduling systems can configure remediation strategies, while aiding in keeping tenant systems as stable as possible during periods of troubleshooting by the owners of the tenant systems.","publicationDate":"2018-01-31T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3154847.3154852","title":"research-article ","type":"Using a serverless framework for implementing a cognitive tutor: experiences and issues","venue":"WoSC '17: Proceedings of the 2nd International Workshop on Serverless Computing","authors":["Nirmal K Mukhi","Srijith Prabhu","Bruce Slawson"],"abstract":"We present a practical application of serverless technology to implement a key component of a personalized tutoring system. We employ OpenWhisk[2] to orchestrate a set of microservices tasked with different responsibilities in the larger system. The tutor, which is trained on a specific set of content, is embodied as a multimodal, stateful dialog system. This desired experience brings with it unique challenges, prime among them being real-time interaction and the inherently stateful nature. We discuss the drivers for selecting serverless technology, the specific design choices we made and the issues we have faced. This work is in progress, and we conclude with some notes on paths we plan to explore as we continue to evolve the system and exploit this exciting new computing paradigm to help us achieve our goals.","publicationDate":"2017-12-10T23:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3470658","title":"research-article ","type":"Adaptive Management of Volatile Edge Systems at Runtime With Satisfiability","venue":"ACM Transactions on Internet Technology","authors":["Cosmin Avasalcai","Christos Tsigkanos","Schahram Dustdar"],"abstract":"Edge computing offers the possibility of deploying applications at the edge of the network. To take advantage of available devices’ distributed resources, applications often are structured as microservices, often having stringent requirements of low latency and high availability. However, a decentralized edge system that the application may be intended for is characterized by high volatility, due to devices making up the system being unreliable or leaving the network unexpectedly. This makes application deployment and assurance that it will continue to operate under volatility challenging. We propose an adaptive framework capable of deploying and efficiently maintaining a microservice-based application at runtime, by tackling two intertwined problems: (i) finding a microservice placement across device hosts and (ii) deriving invocation paths that serve it. Our objective is to maintain correct functionality by satisfying given requirements in terms of end-to-end latency and availability, in a volatile edge environment. We evaluate our solution quantitatively by considering performance and failure recovery.","publicationDate":"2021-09-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3097983.3098162","title":"research-article ","type":"Visual Search at eBay","venue":"KDD '17: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","authors":["Fan Yang","Ajinkya Kale","Yury Bubnov","Leon Stein","Qiaosong Wang","Hadi Kiapour","Robinson Piramuthu"],"abstract":"In this paper, we propose a novel end-to-end approach for scalable visual search infrastructure. We discuss the challenges we faced for a massive volatile inventory like at eBay and present our solution to overcome those. We harness the availability of large image collection of eBay listings and state-of-the-art deep learning techniques to perform visual search at scale. Supervised approach for optimized search limited to top predicted categories and also for compact binary signature are key to scale up without compromising accuracy and precision. Both use a common deep neural network requiring only a single forward inference. The system architecture is presented with in-depth discussions of its basic components and optimizations for a trade-off between search relevance and latency. This solution is currently deployed in a distributed cloud infrastructure and fuels visual search in eBay ShopBot and Close5. We show benchmark on ImageNet dataset on which our approach is faster and more accurate than several unsupervised baselines. We share our learnings with the hope that visual search becomes a first class citizen for all large scale search engines rather than an afterthought.","publicationDate":"2017-08-12T22:00:00.000Z","citationCount":30},{"url":"https://dl.acm.org/doi/10.1145/3419111.3421275","title":"research-article ","type":"Particle: ephemeral endpoints for serverless networking","venue":"SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing","authors":["Shelby Thomas","Lixiang Ao","Geoffrey M. Voelker","George Porter"],"abstract":"Burst-parallel serverless applications invoke thousands of short-lived distributed functions to complete complex jobs such as data analytics, video encoding, or compilation. While these tasks execute in seconds, starting and configuring the virtual network they rely on is a major bottleneck that can consume up to 84% of total startup time. In this paper we characterize the magnitude of this network cold start problem in three popular overlay networks, Docker Swarm, Weave, and Linux Overlay. We focus on end-to-end startup time that encompasses both the time to boot a group of containers as well as interconnecting them. Our primary observation is that existing overlay approaches for serverless networking scale poorly in short-lived serverless environments. Based on our findings we develop Particle, a network stack tailored for multi-node serverless overlay networks that optimizes network creation without sacrificing multi-tenancy, generality, or throughput. When integrated into a serverless burst-parallel video processing pipeline, Particle improves application runtime by 2.4--3X over existing overlays.","publicationDate":"2020-10-11T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3311790.3396659","title":"research-article ","type":"Reproducible and Portable Workflows for Scientific Computing and HPC in the Cloud","venue":"PEARC '20: Practice and Experience in Advanced Research Computing","authors":["Peter Vaillancourt","Bennett Wineholt","Brandon Barker","Plato Deliyannis","Jackie Zheng","Akshay Suresh","Adam Brazier","Rich Knepper","Rich Wolski"],"abstract":"The increasing availability of cloud computing services for science has changed the way scientific code can be developed, deployed, and run. Many modern scientific workflows are capable of running on cloud computing resources. Consequently, there is an increasing interest in the scientific computing community in methods, tools, and implementations that enable moving an application to the cloud and simplifying the process, and decreasing the time to meaningful scientific results. In this paper, we have applied the concepts of containerization for portability and multi-cloud automated deployment with industry-standard tools to three scientific workflows. We show how our implementations provide reduced complexity to portability of both the applications themselves, and their deployment across private and public clouds. Each application has been packaged in a Docker container with its dependencies and necessary environment setup for production runs. Terraform and Ansible have been used to automate the provisioning of compute resources and the deployment of each scientific application in a Multi-VM cluster. Each application has been deployed on the AWS and Aristotle Cloud Federation platforms. Variation in data management constraints, Multi-VM MPI communication, and embarrassingly parallel instance deployments were all explored and reported on. We thus present a sample of scientific workflows that can be simplified using the tools and our proposed implementation to deploy and run in a variety of cloud environments. ","publicationDate":"2020-07-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3472735.3473391","title":"research-article ","type":"Practical Automation for Management Planes of Service Provider Infrastructure","venue":"FlexNets '21: Proceedings of the 4th FlexNets Workshop on Flexible Networks Artificial Intelligence Supported Network Flexibility and Agility","authors":["Bingzhe Liu","Kuan-Yen Chou","Pramod Jamkhedkar","Bilal Anwer","Rakesh K. Sinha","Kostas Oikonomou","Matthew Caesar","P. Brighten Godfrey"],"abstract":"Managing service provider infrastructures (SPI) is ever more challenging with increasing scale and complexity. Network and container orchestration systems alleviate some manual tasks, but they are generally narrow solutions, with controllers for specific subsystems that do not coordinate on high-level goals, and fall far short of automating the full range of tasks that engineers face day to day.We seek to highlight the need for \"practical automation\" to manage SPIs. Via realistic examples, we argue that practical automation should provide cross-controller coordination, and should work within the reality that many tasks will involve humans. We describe a proof-of-concept system that leverages AI planning to synthesize management steps to move the system towards a goal state. A preliminary implementation shows that our approach can accurately generate plans for complex management tasks, while scalability and modeling diverse controllers remain as future challenges.","publicationDate":"2021-08-22T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3342280.3342287","title":"short-paper ","type":"AOMO: An AI-aided Optimizer for Microservices Orchestration","venue":"SIGCOMM Posters and Demos '19: Proceedings of the ACM SIGCOMM 2019 Conference Posters and Demos","authors":["Xue Leng","Tzung-Han Juang","Yan Chen","Han Liu"],"abstract":"No abstract available.","publicationDate":"2019-08-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3203217.3205340","title":"research-article ","type":"HPC4AI: an AI-on-demand federated platform endeavour","venue":"CF '18: Proceedings of the 15th ACM International Conference on Computing Frontiers","authors":["Marco Aldinucci","Sergio Rabellino","Marco Pironti","Filippo Spiga","Paolo Viviani","Maurizio Drocco","Marco Guerzoni","Guido Boella","Marco Mellia","Paolo Margara","Idilio Drago","Roberto Marturano","Guido Marchetto","Elio Piccolo","Stefano Bagnasco","Stefano Lusso","Sara Vallero","Giuseppe Attardi","Alex Barchiesi","Alberto Colla","Fulvio Galeazzi"],"abstract":"In April 2018, under the auspices of the POR-FESR 2014-2020 program of Italian Piedmont Region, the Turin's Centre on High-Performance Computing for Artificial Intelligence (HPC4AI) was funded with a capital investment of 4.5M€ and it began its deployment. HPC4AI aims to facilitate scientific research and engineering in the areas of Artificial Intelligence and Big Data Analytics. HPC4AI will specifically focus on methods for the on-demand provisioning of AI and BDA Cloud services to the regional and national industrial community, which includes the large regional ecosystem of Small-Medium Enterprises (SMEs) active in many different sectors such as automotive, aerospace, mechatronics, manufacturing, health and agrifood.","publicationDate":"2018-05-07T22:00:00.000Z","citationCount":10},{"url":"https://dl.acm.org/doi/10.1145/3446983.3446990","title":"research-article ","type":"Research on Technical Architecture and Overall Scheme of Railway Block Chain Service Platform","venue":"ICBTA 2020: 2020 the 3rd International Conference on Blockchain Technology and Applications","authors":["Zhang Xiaodong","Li Ping","Ma Xiaoning"],"abstract":"The block chain has many unique characteristics, like decentralization, stability, openness and transparency. We can apply block chain in many fields of railway to improve the comprehensive efficiency and benefit, such as railway passenger and freight service, engineering construction, big data sharing and so on. With the gradual completion of data service platform, big data lake and cloud computing in China Railway, these foundations can support the railway block chain application. The paper analyzed the development status and existing problems of block chain at home and abroad. Through the multidimensional analysis for the mainstream block chain platform architecture, the thesis gets the architecture selection of the railway block chain platform. Based on the hyperledger fabric, we propose the technical architecture and overall scheme for the railway block chain service platform respectively. The paper also designs the implementation path for the platform application construction. This research plays an important role and significance in promoting the block chain technology applying and developing in the railway field.","publicationDate":"2020-12-13T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3437359.3465567","title":"research-article ","type":"Building Tapis v3 Streams API Support for Real-Time Streaming Data Event-Driven Workflows","venue":"PEARC '21: Practice and Experience in Advanced Research Computing","authors":["Smruti Padhy","Anagha Jamthe","Sean B. Cleveland","Jack A. Smith","Joe Stubbs","Christian Garcia","Michael Packard","Steve Terry","Julia Looney","Richard Cardone","Maytal Dahan","Gwen A. Jacobs"],"abstract":"The Tapis framework, an NSF-funded project, is an open-source, scalable API platform that enables researchers to perform distributed computational experiments securely and achieve faster scientific results with increased reproducibility. Tapis Streams API focuses on supporting scientific use cases that require working with real-time sensor data. The Streams Service, built on the top of the CHORDS time-series data service, allows storing, processing, annotating, querying, and archiving time-series data. This paper focuses on the new Tapis Streams API functionality that enables researchers to design and execute real-time data-driven event workflow for their research. We describe the architecture and design choices towards achieving this new capability with Streams API. Specifically, we demonstrate the integration of Streams API with Kapacitor, a native data processing engine for time-series database InfluxDB, and Abaco, an NSF Funded project, web service, and distributed computing platform providing function-as-a-Service (FaaS). The Streams API, which includes a wrapper interface for the Kapacitor alerting system, can define and enable alerts. Finally, simulation results from the water-quality use case depict that Streams API’s new capabilities can support real-time streaming data event-driven workflows. ","publicationDate":"2021-07-16T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3341105.3374046","title":"research-article ","type":"Near real-time scheduling in cloud-edge platforms","venue":"SAC '20: Proceedings of the 35th Annual ACM Symposium on Applied Computing","authors":["Vasile-Daniel Balteanu","Alexandru Neculai","Catalin Negru","Florin Pop","Adrian Stoica"],"abstract":"As Cloud-Edge architectures are becoming more and more popular, due to their improvement on the battery life of the IoT devices and the high availability of data from the Cloud, this approach also creates new problems. As data gathered from the Edge has to be transferred to the Cloud in order to be processed, the result will be a decreased responsiveness of the system. Also, devices might have to process data by themselves, as the Cloud could be unreachable at random moments in time, resulting in a reduction in battery life. Therefore, we propose an architecture that solves these problems, by introducing an intermediate layer, called Fog, which uses a task scheduling algorithm to send data received from Edge to another device that has enough resources and the required hardware and software to complete the task. In addition, the architecture is based on microservices, hence improving scalability and flexibility. In the performance analysis, we used different values to find the best node that should receive the data for processing. In addition, we compared the microservice based architecture with a monolithic one in order to see how the throughput and responsiveness of the system are affected.","publicationDate":"2020-03-29T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3412841.3444962","title":"research-article ","type":"A federated fog-cloud framework for data processing and orchestration: a case study in smart cities","venue":"SAC '21: Proceedings of the 36th Annual ACM Symposium on Applied Computing","authors":["Dapeng Lan","Yu Liu","Amir Taherkordi","Frank Eliassen","Stéphane Delbruel","Liu Lei"],"abstract":"The fog computing paradigm has been proposed to alleviate the pressures on cloud platforms for data processing and enable computation-intensive and delay-sensitive applications in smart cities. However, state-of-the-art approaches mainly advocate either cloud-or fog-based data processing solutions, and they also lack a common framework for programming over the fog-cloud continuum. In this paper, we propose a distributed, fog-cloud data processing and orchestration framework, which is capable of exploiting the semantics of both fog platforms and the Cloud. Our framework can create on-demand process engine data flow (PEDF) spanning multiple device layers with various resource constraints. This will considerably help the developers rapidly develop and deploy data processing applications over the fog-cloud continuum. Our proposed framework is validated in a real-world scenario---IoT data streaming analytics for the smart green wall in a smart city---which demonstrates efficient resource usage and latency reduction.","publicationDate":"2021-03-21T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3382225.3382364","title":"research-article ","type":"An end-to-end scalable copyright detection system for online video sharing platforms","venue":"ASONAM '18: Proceedings of the 2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining","authors":["Daniel (Yue) Zhang","Jose Badilla","Herman Tong","Dong Wang"],"abstract":"Combating copyright infringing multimedia content has arisen as a critical undertaking in online video sharing platforms, such as YouTube and Twitch. In contrast to the traditional copyright detection problem that studies the static content (e.g., music, films, digital documents), the proposed system focuses on a much more challenging problem: detecting copyright infringements in live video streams. This is motivated by the observation that a large amount of copyright-infringing videos bypass the detector while many legal videos are taken down by mistake. In this paper, we present an end-to-end system that is dedicated to combating the copyright infringements in live video streams. The system to be demonstrated consists of 1) a web front-end for user interaction and customized video query, 2) a scalable and real-time video crawling system that can collect video metadata, live chat messages, and visual content of the live video streams on video sharing platforms, and 3) a novel supervised copyright detection engine that leverages the live chat messages of the audience to detect the copyright infringement of live videos.","publicationDate":"2018-08-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3291168.3291200","title":"Article ","type":"Pocket: elastic ephemeral storage for serverless analytics","venue":"OSDI'18: Proceedings of the 13th USENIX conference on Operating Systems Design and Implementation","authors":["Ana Klimovic","Yawen Wang","Patrick Stuedi","Animesh Trivedi","Jonas Pfefferle","Christos Kozyrakis"],"abstract":"Serverless computing is becoming increasingly popular, enabling users to quickly launch thousands of short-lived tasks in the cloud with high elasticity and fine-grain billing. These properties make serverless computing appealing for interactive data analytics. However exchanging intermediate data between execution stages in an analytics job is a key challenge as direct communication between serverless tasks is difficult. The natural approach is to store such ephemeral data in a remote data store. However, existing storage systems are not designed to meet the demands of serverless applications in terms of elasticity, performance, and cost. We present Pocket, an elastic, distributed data store that automatically scales to provide applications with desired performance at low cost. Pocket dynamically rightsizes resources across multiple dimensions (CPU cores, network bandwidth, storage capacity) and leverages multiple storage technologies to minimize cost while ensuring applications are not bottlenecked on I/O. We show that Pocket achieves similar performance to ElastiCache Redis for serverless analytics applications while reducing cost by almost 60%.","publicationDate":"2018-10-07T22:00:00.000Z","citationCount":29},{"url":"https://dl.acm.org/doi/10.1109/RCoSE/DDrEE.2019.00013","title":"research-article ","type":"GLT: Edge gateway ELT for data-driven intelligence placement","venue":"RCoSE-DDrEE '19: Proceedings of the Joint 4th International Workshop on Rapid Continuous Software Engineering and 1st International Workshop on Data-Driven Decisions, Experimentation and Evolution","authors":["Vasileios Theodorou","Nikos Diamantopoulos"],"abstract":"In this paper, we introduce the notion of Data Lagoons at the Edge, for the dynamic deployment and migration of analytics tasks at runtime. We present a novel, modular architecture that decouples data ingestion from data processing at the Edge, facilitating the rapid instantiation of data processing components or their offloading to the cloud. To this end, we analyze the requirements for the use cases of Internet Of Things (IoT) Platforms and Multimedia Content Distribution Applications and we present for the former a prototype architecture, based on open source components. Our approach can support the realization of reasoning mechanisms for trade-off analysis and adaptive task relocation, based on real-time monitored measures such as delay and throughput.","publicationDate":"2019-05-26T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3415958.3433082","title":"research-article ","type":"Scalable Execution of Big Data Workflows using Software Containers","venue":"MEDES '20: Proceedings of the 12th International Conference on Management of Digital EcoSystems","authors":["Yared Dejene Dessalk","Nikolay Nikolov","Mihhail Matskin","Ahmet Soylu","Dumitru Roman"],"abstract":"Big Data processing involves handling large and complex data sets, incorporating different tools and frameworks as well as other processes that help organisations make sense of their data collected from various sources. This set of operations, referred to as Big Data workflows, require taking advantage of the elasticity of cloud infrastructures for scalability. In this paper, we present the design and prototype implementation of a Big Data workflow approach based on the use of software container technologies and message-oriented middleware (MOM) to enable highly scalable workflow execution. The approach is demonstrated in a use case together with a set of experiments that demonstrate the practical applicability of the proposed approach for the scalable execution of Big Data workflows. Furthermore, we present a scalability comparison of our proposed approach with that of Argo Workflows - one of the most prominent tools in the area of Big Data workflows.","publicationDate":"2020-11-01T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3154448.3154455","title":"research-article ","type":"Opvis: extensible, cross-platform operational visibility and analytics for cloud","venue":"Middleware '17: Proceedings of the 18th ACM/IFIP/USENIX Middleware Conference: Industrial Track","authors":["Fábio Oliveira","Sahil Suneja","Shripad Nadgowda","Priya Nagpurkar","Canturk Isci"],"abstract":"Operational visibility is an important administrative capability and a critical factor in deciding the success or failure of a cloud service. It is becoming increasingly complex due to the need to (1) track both persistent and volatile system state across heterogeneous endpoints and (2) consider a broader range of data sources fueled by demand for sophisticated analytics. In this paper we present OpVis, a monitoring and analytics framework to provide operational visibility without the limitations of traditional fragmented monitoring solutions. We highlight OpVis' extensible data model, enabling custom data collection and analytics based on the cloud user's requirements, describe its monitoring and analytics capabilities, present performance measurements, and discuss our experiences while supporting operational visibility in our cloud.","publicationDate":"2017-12-10T23:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3452369.3463820","title":"short-paper ","type":"Data Science Workflows for the Cloud/Edge Computing Continuum","venue":"FRAME '21: Proceedings of the 1st Workshop on Flexible Resource and Application Management on the Edge","authors":["Valerio Grossi","Roberto Trasarti","Patrizio Dazzi"],"abstract":"Research infrastructures play a crucial role in the development of data science. In fact, the conjunction of data, infrastructures and analytical methods enable multidisciplinary scientists and innovators to extract knowledge and to make the knowledge and experiments reusable by the scientific community, innovators providing an impact on science and society. Resources such as data and methods, help domain and data scientists to transform research in an innovation question into a responsible data-driven analytical. On the other hands, Edge computing is a new computing paradigm that is spreading and developing at an incredible pace. Edge computing is based on the assumption that for certain applications is beneficial to bring the computation as much close as possible to data or end-users. This paper introduces an approach for writing data science workflows targeting research infrastructures that encompass resources located at the edge of the network.","publicationDate":"2020-06-24T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1109/MiSE.2019.00010","title":"research-article ","type":"Towards web collaborative modelling for the user requirements notation using eclipse che and theia IDE","venue":"MiSE '19: Proceedings of the 11th International Workshop on Modelling in Software Engineerings","authors":["Rijul Saini","Shivani Bali","Gunter Mussbacher"],"abstract":"Collaborative modelling has become a necessity when developing a complex system or in a team of modellers with a diverse set of expertise. Textual notations have a long history in software engineering because of their fast editing style, simple usage, and scalability. Therefore, we propose a novel collaborative modelling framework for the graphical User Requirements Notation (URN) which we call tColab. It uses the text-based TGRL (Textual Goal-oriented Requirement Language) to build URN goal models and then automatically generates corresponding graphical models. This framework is based on the architecture of Eclipse Che and Theia. On one side, Theia provides support for LSP (Language Server Protocol) so that textual models can be built and their corresponding graphical models can be generated in a browser IDE (Integrated Development Environment). On the other hand, Eclipse Che adds support for collaboration where multiple modellers can contribute to building the textual models in an online collaborative manner. This initiative aims to replace the jUCMNAV tool, which is the most comprehensive URN modelling tool to date but only supports a single user.","publicationDate":"2019-05-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3370272.3370294","title":"research-article ","type":"Optimizing serverless computing: introducing an adaptive function placement algorithm","venue":"CASCON '19: Proceedings of the 29th Annual International Conference on Computer Science and Software Engineering","authors":["Nima Mahmoudi","Changyuan Lin","Hamzeh Khazaei","Marin Litoiu"],"abstract":"The main concept behind serverless computing is to build and run applications without the need for server management. It refers to a fine-grained deployment model where applications, comprising of one or more functions, are uploaded to a platform and then executed, scaled, and billed in response to the exact demand needed at the moment. While elite cloud vendors such as Amazon, Google, Microsoft, and IBM are now providing serverless computing, their approach for the placement of functions, i.e. associated container or sandbox, on servers is oblivious to the workload which may lead to poor performance and/or higher operational cost for software owners. In this paper, using statistical machine learning, we design and evaluate an adaptive function placement algorithm which can be used by serverless computing platforms to optimize the performance of running functions while minimizing the operational cost. Given a fixed amount of resources, our smart spread function placement algorithm results in higher performance compared to existing approaches; this will be achieved by maintaining the users' desired quality of service for a longer time which prevents premature scaling of the cloud resources. Extensive experimental studies revealed that the proposed adaptive function placement algorithm can be easily adopted by serverless computing providers and integrated to container orchestration platforms without introducing any limiting side effects.","publicationDate":"2019-11-03T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3382025.3414981","title":"research-article ","type":"Variability management: re-engineering microservices with delta-oriented software product lines","venue":"SPLC '20: Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A","authors":["Maya R. A. Setyautami","Hafiyyan S. Fadhlillah","Daya Adianto","Ichlasul Affan","Ade Azurat"],"abstract":"Combining microservices and software product line engineering (SPLE) is a challenge in variability management. This paper proposes a solution to that challenge by re-engineering existing webshop systems into a product line application. We first perform feature identification to analyze the features of subject systems. We introduce a mechanism that models the variability and designs a software product line architecture based on existing features. We use a UML diagram with the UML-DOP profile to abstract microservice variability in SPLE. Then, a transformation into a product line application is conducted to generate running applications based on selected features. We utilize a preliminary framework of microservice variability based on delta-oriented programming.","publicationDate":"2020-10-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3053600.3053653","title":"short-paper ","type":"Performance Engineering for Microservices: Research Challenges and Directions","venue":"ICPE '17 Companion: Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion","authors":["Robert Heinrich","André van Hoorn","Holger Knoche","Fei Li","Lucy Ellen Lwakatare","Claus Pahl","Stefan Schulte","Johannes Wettinger"],"abstract":"Microservices complement approaches like DevOps and continuous delivery in terms of software architecture. Along with this architectural style, several important deployment technologies, such as container-based virtualization and container orchestration solutions, have emerged. These technologies allow to efficiently exploit cloud platforms, providing a high degree of scalability, availability, and portability for microservices.Despite the obvious importance of a sufficient level of performance, there is still a lack of performance engineering approaches explicitly taking into account the particularities of microservices. In this paper, we argue why new solutions to performance engineering for microservices are needed. Furthermore, we identify open issues and outline possible research directions with regard to performance-aware testing, monitoring, and modeling of microservices.","publicationDate":"2017-04-17T22:00:00.000Z","citationCount":38},{"url":"https://dl.acm.org/doi/10.1145/3314221.3314589","title":"research-article ","type":"Lightweight multi-language syntax transformation with parser parser combinators","venue":"PLDI 2019: Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation\n\t\t\t\t\n\t\t\t\t\tLightweight Multi-Language Syntax Transformation with Parser Parser Combinators: PLDI 2019 Artifact\n                \n            ","authors":["Rijnard van Tonder","Claire Le Goues"],"abstract":"Automatically transforming programs is hard, yet critical for automated program refactoring, rewriting, and repair. Multi-language syntax transformation is especially hard due to heterogeneous representations in syntax, parse trees, and abstract syntax trees (ASTs). Our insight is that the problem can be decomposed such that (1) a common grammar expresses the central context-free language (CFL) properties shared by many contemporary languages and (2) open extension points in the grammar allow customizing syntax (e.g., for balanced delimiters) and hooks in smaller parsers to handle language-specific syntax (e.g., for comments). Our key contribution operationalizes this decomposition using a Parser Parser combinator (PPC), a mechanism that generates parsers for matching syntactic fragments in source code by parsing declarative user-supplied templates. This allows our approach to detach from translating input programs to any particular abstract syntax tree representation, and lifts syntax rewriting to a modularly-defined parsing problem. A notable effect is that we skirt the complexity and burden of defining additional translation layers between concrete user input templates and an underlying abstract syntax representation. We demonstrate that these ideas admit efficient and declarative rewrite templates across 12 languages, and validate effectiveness of our approach by producing correct and desirable lightweight transformations on popular real-world projects (over 50 syntactic changes produced by our approach have been merged into 40+). Our declarative rewrite patterns require an order of magnitude less code compared to analog implementations in existing, language-specific tools.","publicationDate":"2019-06-07T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3465480.3466926","title":"research-article ","type":"S2CE: a hybrid cloud and edge orchestrator for mining exascale distributed streams","venue":"DEBS '21: Proceedings of the 15th ACM International Conference on Distributed and Event-based Systems","authors":["Nicolas Kourtellis","Herodotos Herodotou","Maciej Grzenda","Piotr Wawrzyniak","Albert Bifet"],"abstract":"The explosive increase in volume, velocity, variety, and veracity of data generated by distributed and heterogeneous nodes such as IoT and other devices, continuously challenge the state of art in big data processing platforms and mining techniques. Consequently, it reveals an urgent need to address the ever-growing gap between this expected exascale data generation and the extraction of insights from these data. To address this need, this position paper proposes Stream to Cloud & Edge (S2CE), a first of its kind, optimized, multi-cloud and edge orchestrator, easily configurable, scalable, and extensible. S2CE will enable machine and deep learning over voluminous and heterogeneous data streams running on hybrid cloud and edge settings, while offering the necessary functionalities for practical and scalable processing: data fusion and preprocessing, sampling and synthetic stream generation, cloud and edge smart resource management, and distributed processing.","publicationDate":"2021-06-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3388440.3412414","title":"research-article ","type":"Integrative Deep Learning for PanCancer Molecular Subtype Classification Using Histopathological Images and RNAseq Data","venue":"BCB '20: Proceedings of the 11th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics","authors":["Fatima Zare","Javad Noorbakhsh","Tianyu Wang","Jeffrey H. Chuang","Sheida Nabavi"],"abstract":"Deep learning has recently become a key methodology for the study and interpretation of cancer histology images. The ability of convolutional neural networks (CNNs) to automatically learn features from raw data without the need for pathologist expert knowledge, as well as the availability of annotated histopathology datasets, have contributed to a growing interest in deep learning applications to histopathology. In clinical practice for cancer, histopathological images have been commonly used for diagnosis, prognosis, and treatment. Recently, molecular subtype classification has gained significant attention for predicting standard chemotherapy's outcomes and creating personalized targeted cancer therapy. Genomic profiles, especially gene expression data, are mostly used for molecular subtyping. In this study, we developed a novel, PanCancer CNN model based on Google Inception V3 transfer learning to classify molecular subtypes using histopathological images. We used 22,484 Haemotoxylin and Eosin (H&E) slides from 32 cancer types provided by The Cancer Genome Atlas (TCGA) to train and evaluate the model. We showed that by employing deep learning, H&E slides can be used for classification of molecular subtypes of solid tumor samples with the high area under curves (AUCs) (micro-average= 0.90; macro-average=0.90). In cancer studies, combining histopathological images with genomic data has rarely been explored. We investigated the relationship between features extracted from H&E images and features extracted from gene expression profiles. We observed that the features from these two different modalities (H&E images and gene expression values) for molecular subtyping are highly correlated. We, therefore, developed an integrative deep learning model that combines histological images and gene expression profiles. We showed that the integrative model improves the overall performance of the molecular subtypes classification ((AUCs) micro-average= 0.99; macro-average=0.97). These results show that integrating H&E images and gene expression profiles can enhance accuracy of molecular subtype classification.","publicationDate":"2020-09-20T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3423211.3425682","title":"research-article ","type":"Prebaking Functions to Warm the Serverless Cold Start","venue":"Middleware '20: Proceedings of the 21st International Middleware Conference","authors":["Paulo Silva","Daniel Fireman","Thiago Emmanuel Pereira"],"abstract":"Function-as-service (FaaS) platforms promise a simpler programming model for cloud computing, in which the developers concentrate on writing its applications. In contrast, platform providers take care of resource management and administration. As FaaS users are billed based on the execution of the functions, platform providers have a natural incentive not to keep idle resources running at the platform's expense. However, this strategy may lead to the cold start issue, in which the execution of a function is delayed because there is no ready resource to host the execution. Cold starts can take hundreds of milliseconds to seconds and have been a prohibitive and painful disadvantage for some applications. This work describes and evaluates a technique to start functions, which restores snapshots from previously executed function processes. We developed a prototype of this technique based on the CRIU process checkpoint/restore Linux tool. We evaluate this prototype by running experiments that compare its start-up time against the standard Unix process creation/start-up procedure. We analyze the following three functions: i) a \"do-nothing\" function, ii) an Image Resizer function, and iii) a function that renders Markdown files. The results attained indicate that the technique can improve the start-up time of function replicas by 40% (in the worst case of a \"do-nothing\" function) and up to 71% for the Image Resizer one. Further analysis indicates that the runtime initialization is a key factor, and we confirmed it by performing a sensitivity analysis based on synthetically generated functions of different code sizes. These experiments demonstrate that it is critical to decide when to create a snapshot of a function. When one creates the snapshots of warm functions, the speed-up achieved by the prebaking technique is even higher: the speed-up increases from 127.45% to 403.96%, for a small, synthetic function; and for a bigger, synthetic function, this ratio increases from 121.07% to 1932.49%.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3368089.3417058","title":"research-article ","type":"IntelliCode compose: code generation using transformer","venue":"ESEC/FSE 2020: Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","authors":["Alexey Svyatkovskiy","Shao Kun Deng","Shengyu Fu","Neel Sundaresan"],"abstract":"In software development through integrated development environments (IDEs), code completion is one of the most widely used features. Nevertheless, majority of integrated development environments only support completion of methods and APIs, or arguments. In this paper, we introduce IntelliCode Compose – a general-purpose multilingual code completion tool which is capable of predicting sequences of code tokens of arbitrary types, generating up to entire lines of syntactically correct code. It leverages state-of-the-art generative transformer model trained on 1.2 billion lines of source code in Python, C#, JavaScript and TypeScript programming languages. IntelliCode Compose is deployed as a cloud-based web service. It makes use of client-side tree-based caching, efficient parallel implementation of the beam search decoder, and compute graph optimizations to meet edit-time completion suggestion requirements in the Visual Studio Code IDE and Azure Notebook. Our best model yields an average edit similarity of 86.7% and a perplexity of 1.82 for Python programming language.","publicationDate":"2020-11-07T23:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3344948.3344961","title":"poster ","type":"The applicability of palladio for assessing the quality of cloud-based microservice architectures","venue":"ECSA '19: Proceedings of the 13th European Conference on Software Architecture - Volume 2","authors":["Floriment Klinaku","Dominik Bilgery","Steffen Becker"],"abstract":"When adopting microservices, software architects have to make several design decisions which impact the quality of the application in terms of scalability, elasticity and cost-efficiency. A prominent model-driven architectural simulator that aids software architects in analysing and predicting the quality of their architecture is Palladio. There is active work on extending Palladio to support new needs, however, there is lack of evidence for its applicability in the context of microservice architectures. Therefore, we conduct a case study at a partner company where we apply Palladio to analyse the performance as well as to assess scalability, elasticity and cost-efficiency aspects of a cloud-based microservice application. In this work, we highlight some of the results which show that Palladio is able to predict the application performance with a sufficient accuracy. However, when assessing scalability, elasticity and cost-efficiency the applicability of Palladio comes with several workarounds and not automated for all the chosen scenarios.","publicationDate":"2019-09-08T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.5555/3433701.3433804","title":"research-article ","type":"ANT-man: towards agile power management in the microservice era","venue":"SC '20: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","authors":["Xiaofeng Hou","Chao Li","Jiacheng Liu","Lu Zhang","Yang Hu","Minyi Guo"],"abstract":"The emerging trend of decomposing cloud applications into microservices has raised new questions about managing the performance/power trade-off of a datacenter at microsecond-scale. We introduce ANT-Man, an Auto, Native and Transparent power Management framework that can exploit fine-grained microservice variability for system efficiency. To achieve this, ANT-Man abstracts away two major sources of latency overhead in traditional hierarchical power management frameworks. First, ANT-Man proposes an auto power budgeting scheme for reducing the power coordination latency at the datacenter level. It can proactively determine the power budget tailored to each individual microservice. Second, ANT-Man proposes a native and transparent power control scheme to overcome the power configuration latency for each microservice. It enables super-fast power budget enforcement with nanosecond-scale performance scaling. Extensive experiments on our prototyped system show that ANT-Man could slash power consumption by 7.8~43.5%, and in the meantime reduce the 95th tail latency by 9.7~12.5% compared to existing techniques.","publicationDate":"2020-11-08T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3404835.3463251","title":"short-paper ","type":"Seer-Dock: A General-Purpose Dockerized Scholarly Document Collection and Management Framework","venue":"SIGIR '21: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval","authors":["Dina Sayed","Mohamed Nour","Heiko Schuldt"],"abstract":"The harvesting, management, and analysis of thematic document collections is a major challenge in a wide variety of applications. While the criteria for compiling such collections are individual, the entire process is largely standardized. Therefore, it is not efficient to build new systems over and over again to take over these tasks. In this work, we introduce Seer-Dock, a novel and easy-to deploy general-purpose dockerized framework to build a scholarly document harvesting and management system. It is based on CiteSeerX, the most widely used scholarly search engine. Seer-Dock uses docker containers for all components and thus enables its users to rapidly deploy a full-fledged document collection and management system on any operating system platform and tailor it to the specific needs of an application domain. Moreover, it is easy to scale, orchestrate, maintain, and recover. In this resource paper, we introduce the architecture of Seer-Dock and its components. Like its kernel CiteSeerX, Seer-Dock is available under an Apache 2 open source license.","publicationDate":"2021-07-10T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3337821.3337857","title":"research-article ","type":"Unleashing the Scalability Potential of Power-Constrained Data Center in the Microservice Era","venue":"ICPP 2019: Proceedings of the 48th International Conference on Parallel Processing","authors":["Xiaofeng Hou","Jiacheng Liu","Chao Li","Minyi Guo"],"abstract":"Recent scale-out cloud services have undergone a shift from monolithic applications to microservices by putting each functionality into lightweight software containers. Although traditional data center power optimization frameworks excel at per-server or per-rack management, they can hardly make informed decisions when facing microservices that have different QoS requirements on a per-service basis. In a power-constrained data center, blindly budgeting power usage could lead to a power unbalance issue: microservices on the critical path may not receive adequate power budget. This unavoidably hinders the growth of cloud productivity.To unleash the performance potential of cloud in the microservice era, this paper investigates microservice-aware data center resource management. We model microservice using a bipartite graph and propose a metric called microservice criticality factor (MCF) to measure the overall impact of performance scaling on a microservice from the whole application's perspective. We further devise ServiceFridge, a novel system framework that leverages MCF to jointly orchestrate software containers and control hardware power demand. Our detailed case study on a practical microservice application demonstrates that ServiceFridge allows data center to reduce its dynamic power by 25% with slight performance loss. It improves the mean response time by 25.2% and improves the 90th tail latency by 18.0% compared with existing schemes.","publicationDate":"2019-08-04T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3219819.3219834","title":"research-article ","type":"Corpus Conversion Service: A Machine Learning Platform to Ingest Documents at Scale","venue":"KDD '18: Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","authors":["Peter W J Staar","Michele Dolfi","Christoph Auer","Costas Bekas"],"abstract":"Over the past few decades, the amount of scientific articles and technical literature has increased exponentially in size. Consequently, there is a great need for systems that can ingest these documents at scale and make the contained knowledge discoverable. Unfortunately, both the format of these documents (e.g. the PDF format or bitmap images) as well as the presentation of the data (e.g. complex tables) make the extraction of qualitative and quantitive data extremely challenging. In this paper, we present a modular, cloud-based platform to ingest documents at scale. This platform, called the Corpus Conversion Service (CCS), implements a pipeline which allows users to parse and annotate documents (i.e. collect ground-truth), train machine-learning classification algorithms and ultimately convert any type of PDF or bitmap-documents to a structured content representation format. We will show that each of the modules is scalable due to an asynchronous microservice architecture and can therefore handle massive amounts of documents. Furthermore, we will show that our capability to gather groundtruth is accelerated by machine-learning algorithms by at least one order of magnitude. This allows us to both gather large amounts of ground-truth in very little time and obtain very good precision/recall metrics in the range of 99% with regard to content conversion to structured output. The CCS platform is currently deployed on IBM internal infrastructure and serving more than 250 active users for knowledge-engineering project engagements.","publicationDate":"2018-07-18T22:00:00.000Z","citationCount":16},{"url":"https://dl.acm.org/doi/10.1145/3461002.3473947","title":"research-article ","type":"Product-lining the elinvar wealthtech microservice platform","venue":"SPLC '21: Proceedings of the 25th ACM International Systems and Software Product Line Conference - Volume B","authors":["Marcus Pinnecke"],"abstract":"Software product lining is the act of providing different but related software products under the same brand, known as a software product line (SPL). As engineering, management and validation of SPLs is far from trivial, special solutions for software product line engineering (SPLE) have a continuous momentum in both academic and industry. In general, it is hard to judge when to reasonably favor SPLE over alternative solutions that are more common in the industry. In this paper, we illustrate how we as Elinvar manage variability within our WealthTech Platform as a Service (PaaS) at different granularity levels, and discuss methods for SPLE in this context. More in detail, we share our techniques and concepts to address configuration management, and show how we manage a single microservice SPL including inter-service communication. Finally, we provide insights into platform solutions by means of packages for our clients. We end with a discussion on SPLE techniques in context of service SPLs and our packaging strategy. We conclude that while we are good to go with industry-standard approaches for microservice SPLs, the variability modeling and analysis advantages within SPLE is promising for our packaging strategy.","publicationDate":"2021-09-05T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3425269.3425280","title":"research-article ","type":"Measuring Unique Changes: How do Distinct Changes Affect the Size and Lifetime of Pull Requests?","venue":"SBCARS '20: Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse","authors":["Daniel Augusto Nunes da Silva","Daricélio Moreira Soares","Silvana Andrade Gonçalves"],"abstract":"Size metrics are commonly cited features in studies that analyze influencing factors on pull request lifetime. These metrics are also important for integrators, as based on them, they may prefer to prioritize pull requests easy to assess. However, code changes that form pull requests may not be unique, and repetitive changes may represent less complexity than expected by considering size metrics like lines of code or source files. The goal of this study is to analyze the influence of unique changes over pull requests relative to its size and lifetime. We collected data from 83,000+ pull requests of 26 projects hosted on GitHub. Also, we proposed a metric called unique changes rate to measure the proportion of unique changes over the total changes made by a pull request. We conducted experiments with Random Forest regression models and association rules to examine the influence of unique changes rate. Results show that unique changes have more influence over the lifetime of large pull requests, is determined mainly by the number of source files, and low levels of unique changes rate affect more the relationship between pull request size and lifetime than high levels. We conclude that unique changes can figure as an interesting feature in the context of the pull request lifetime. Results indicate that unique changes may increase or decrease the influence of pull request size on its lifetime. Our work has implications for researchers and core team members in software projects since unique changes represent helpful information.","publicationDate":"2020-10-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3365109.3368765","title":"short-paper ","type":"Building Large-Scale Deep Learning System for Entity Recognition in E-Commerce Search","venue":"BDCAT '19: Proceedings of the 6th IEEE/ACM International Conference on Big Data Computing, Applications and Technologies","authors":["Musen Wen","Deepak Kumar Vasthimal","Alan Lu","Tian Wang","Aimin Guo"],"abstract":"Named-Entity-Recognition (NER) or Item Aspect Recognition task is fundamental to e-commerce marketplace. A structured listing (i.e. item aspect and catalog) is critical to the success of the marketplace - it helps the seller to put their listings to the right catalog and aspects so that the buyers can easily find the most relevant and accurate listings they are looking for. For e-commerce search engine, item aspects (brand, color, size, texture, etc.) should be automatically recognized from users' shopping queries in order to accurate understand their shopping intent. An accurate query and item aspect understanding helps to match seller's listing to buyer's purchase intend. However, in practice, this still remains challenge in e-commerce marketplace due to a couple reasons, e.g. the sparsity of the data - hundreds of millions of item aspect-name and aspect-value pairs (e.g. brand=Nike); noisy (low quality), not scalable but expensive label data that are obtained via human labeling \\citeb12 effort; the lack of context in generally very short search queries; the disperse of context and dis-orderedness in listing title or descriptions, etc. among others. All those imposes a big challenge that affect the performance of aspect recognition for e-commerce practice. In this paper, we introduce an end-to-end machine learning system to build an effective aspect recognition system for search engine that leverages the generated label data from different legacy systems and effort, without any extra human-label effort (and thus no incurred cost). The framework is constructed with multiple machine learning components that are built to optimize the search relevance and conversion as an end goal. We show that the proposed aspect recognition machine learning system improved search results quality and relevance greatly compared to the existing already strong baseline system for e-commerce search.","publicationDate":"2019-12-01T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3318216.3363311","title":"research-article ","type":"Quartz: time-as-a-service for coordination in geo-distributed systems","venue":"SEC '19: Proceedings of the 4th ACM/IEEE Symposium on Edge Computing","authors":["Sandeep D'souza","Heiko Koehler","Akhilesh Joshi","Satyam Vaghani","Ragunathan (Raj) Rajkumar"],"abstract":"Geo-distributed systems ranging from databases to cyber-physical applications increasingly rely on a shared and precise notion of time to achieve coordination. This is especially true for cyber-physical applications ranging from local-scale robotic-coordination and city-scale traffic management to regional/planetary-scale smart grids. Each of these applications utilizes event orderings and timing offsets to make real-time decisions, so as to perform coordinated action at their distributed endpoints. The emergence of edge computing, specifically to facilitate low-latency decision-making, is leveraging the trend where multiple cyber-physical and software applications with different timing requirements will coexist in both the cloud and at the edge. To enable such fault-tolerant time-based coordinated applications running on multi-tenant geo-scale infrastructure, we introduce the Quartz framework, which exposes Time-as-a-Service. Quartz allows geo-distributed application components to each specify its timing requirements, while it autonomously orchestrates the underlying infrastructure to meet them. Centered around a shared virtualized notion of time, based on the time-line abstraction [1], Quartz provides an API which makes it easy to develop time-based geo-distributed applications. Using this API, Quartz feeds back the timing uncertainty, i.e., the delivered Quality of Time (QoT) [1] back to each application, enabling it to be fault-tolerant in the face of clock-synchronization failure. Quartz is designed for containerized applications, features a distributed architecture and is implemented using containerized micro-services. Experimental evaluations on real-world embedded, edge and cloud platforms highlight the performance and scalability of our architecture.","publicationDate":"2019-11-06T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3301326.3301380","title":"research-article ","type":"Finding Impact Factors for Rejection of Pull Requests on GitHub","venue":"ICNCC 2018: Proceedings of the 2018 VII International Conference on Network, Communication and Computing","authors":["Panthip Pooput","Pornsiri Muenchaisri"],"abstract":"A pull request is an important method for code contributions in GitHub that will be submitted when the developers would like to merge their code changes from their local machine to the main repository on which all source code in the project are stored. Before merging the code changes into the main repository, the developers have to request for a permission. If their source code is allowed to merge, the pull request status is accepted. On the other hand, if their source code is not allowed to merge, the pull request status is rejected. The pull request status may be rejected due to several factors, such as code complexity, code quality, the number of changed files, etc. Fixing the rejected pull requests will take some extra effort and time which may affect the project cost and timeline. This paper aims at finding the impact factors that are associated with the rejection of pull requests on GitHub and also discovering the relationships among impact factors by using the association rules in data mining.","publicationDate":"2018-12-13T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3448016.3452823","title":"research-article ","type":"Why Do My Blockchain Transactions Fail?: A Study of Hyperledger Fabric","venue":"SIGMOD/PODS '21: Proceedings of the 2021 International Conference on Management of Data","authors":["Jeeta Ann Chacko","Ruben Mayer","Hans-Arno Jacobsen"],"abstract":"Permissioned blockchain systems promise to provide both decentralized trust and privacy. Hyperledger Fabric is currently one of the most wide-spread permissioned blockchain systems and is heavily promoted both in industry and academia. Due to its optimistic concurrency model, the transaction failure rates in Fabric can become a bottleneck. While there is active research to reduce failures, there is a lack of understanding on their root cause and, consequently, a lack of guidelines on how to configure Fabric optimally for different scenarios. To close this gap, in this paper, we first introduce a formal definition of the different types of transaction failures in Fabric. Then, we develop a comprehensive testbed and benchmarking system, HyperLedgerLab, along with four different chaincodes that represent realistic use cases and a chaincode/workload generator. Using HyperLedgerLab, we conduct exhaustive experiments to analyze the impact of different parameters of Fabric such as block size, endorsement policies, and others, on transaction failures. We further analyze three recently proposed optimizations from the literature, Fabric++, Streamchain and FabricSharp, and evaluate under which conditions they reduce the failure rates. Finally, based on our results, we provide recommendations for Fabric practitioners on how to configure the system and also propose new research directions.","publicationDate":"2021-06-08T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3468264.3473101","title":"research-article ","type":"Deployment coordination for cross-functional DevOps teams","venue":"ESEC/FSE 2021: Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","authors":["Daniel Sokolowski"],"abstract":"Software stability and reliability are the core concerns of DevOps. They are improved by tightening the collaboration between developers and operators in cross-functional teams on the one hand and by automating operations through continuous integration (CI) and infrastructure as code (IaC) on the other hand. Ideally, teams in DevOps are fully independent. Still, their applications often depend on each other in practice, requiring them to coordinate their deployment through centralization or manual coordination. With this work, we propose and implement the novel IaC solution µs ([mju:z] ”muse”), which automates deployment coordination in a decentralized fashion. µs is the first approach that is compatible with the DevOps goals as it enables truly independent operations of the DevOps teams. We define our research problem through a questionnaire survey with IT professionals and evaluate the solution by comparing it to other modern IaC approaches, assessing its performance, and applying it to existing IaC programs.","publicationDate":"2021-08-19T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3426425.3426947","title":"research-article ","type":"Modular and distributed IDE","venue":"SLE 2020: Proceedings of the 13th ACM SIGPLAN International Conference on Software Language Engineering\n\t\t\t\t\n                    Artifact for the Paper: Modular and distributed IDE\n                \n            ","authors":["Fabien Coulon","Alex Auvolat","Benoit Combemale","Yérom-David Bromberg","François Taïani","Olivier Barais","Noël Plouzeau"],"abstract":"Integrated Development Environments (IDEs) are indispensable companions to programming languages. They are increasingly turning towards Web-based infrastructure. The rise of a protocol such as the Language Server Protocol (LSP) that standardizes the separation between a language-agnostic IDE, and a language server that provides all language services (e.g., auto completion, compiler...) has allowed the emergence of high quality generic Web components to build the IDE part that runs in the browser. However, all language services require different computing capacities and response times to guarantee a user-friendly experience within the IDE. The monolithic distribution of all language services prevents to leverage on the available execution platforms (e.g., local platform, application server, cloud). In contrast with the current approaches that provide IDEs in the form of a monolithic client-server architecture, we explore in this paper the modularization of all language services to support their individual deployment and dynamic adaptation within an IDE. We evaluate the performance impact of the distribution of the language services across the available execution platforms on four EMF-based languages, and demonstrate the benefit of a custom distribution.","publicationDate":"2020-11-15T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.5555/3373669.3373690","title":"research-article ","type":"Cloud native transformation pattern language","venue":"PLoP '18: Proceedings of the 25th Conference on Pattern Languages of Programs","authors":["Pini Reznik"],"abstract":"Cloud computing offers tremendous opportunity to develop, deploy and update software faster than ever before. But if companies with older, pre-cloud systems simply shift operation to the cloud they obtain only minimal benefit. Maximizing the advantages of cloud infrastructure requires significant redesign of both organisational systems and culture. Cloud Native architecture emerged to support this transformation. Cloud Native itself is, however, very complex and people find it difficult to understand and use. A Cloud Native Pattern Language will create a set of patterns behind Cloud Native architecture and form a clear way to describe the system. This will allow engineers, developers and executives alike to discuss, disseminate and apply best practises in Cloud Native. In this document we will examine some of the Cloud Native design patterns that we've learned in the course of three years of guiding enterprises onto the Cloud as well as the contexts where they perform best.","publicationDate":"2018-10-23T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3291291.3291328","title":"research-article ","type":"Uncertainty quantification-as-a-service","venue":"CASCON '18: Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering","authors":["Małgorzata Zimoń","Vadim Elisseev","Robert Sawko","Samuel Antão","Kirk Jordan"],"abstract":"Uncertainty quantification (UQ), which enables non-destructive virtual testing, is the fast growing area of modern computational science. UQ methods are computationally intensive and require construction of complex work-flows, which rely on a number of different software components often coming from different projects. Therefore, there is a need for developing a portable and scalable UQ pipeline that will enable efficient stochastic modelling. Our paper introduces a strategy for UQ as a Service using high performance computing and hybrid cloud infrastructures and presents its application to a heat transfer study in nuclear reactors simulation and modelling of tsunami events.","publicationDate":"2018-10-28T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3429885.3429961","title":"short-paper ","type":"Filenail: Working with Incomplete Filesystem State","venue":"WOC'20: Proceedings of the 2020 6th International Workshop on Container Technologies and Container Clouds","authors":["Shripad Nadgowda"],"abstract":"The use of filesystems has become a standard, with a purpose well beyond just storing and accessing application data. For instance, common system security and compliance operations, sush as software or package installation, system and application configurations or process management also leverage a filesystem. Over decades, various system management and security tools have been designed to access system state and to implement their respective functions through a file interface. However, we observe that these tools do not require access to all the files in the filesystem and in some cases they can even work with incomplete file contents. Motivated by these observations, we propose filenail (or Filesystem Thumbnail) a system that exercises an incomplete filesystem state marshalling and un-marshalling protocol. We discuss the use of filenail to implement an effective and optimal disaggregated solution to perform common system security tasks for container clouds. In general, depending on the use-case not all the files in the filesystem are equal and that incomplete filesystem state can be often enough. The results of this paper show filenail is very efficient in capturing and transferring filesystem state of systems and enables implementing disaggregated security solutions in the cloud.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3407947.3407977","title":"research-article ","type":"A Survey of System Scheduling for HPC and Big Data","venue":"HP3C 2020: Proceedings of the 2020 4th International Conference on High Performance Compilation, Computing and Communications","authors":["Bo Wang","Zhiguang Chen","Nong Xiao"],"abstract":"In the rapidly expanding field of parallel processing, job schedulers act as the \"operating systems\" of the clusters, including modern big data architectures and supercomputing systems. Job schedulers manage and allocate system resources, dispatch the queued jobs, and control the execution of processes on the allocated resources. In this paper, we firstly make an introduction to the cluster schedulers. Then according to the scenarios, we make a comprehensive survey of schedulers for HPC and Big Data. We can conclude that most of these current schedulers are centralized, which means master assigns jobs to the slaves. We call this mode Push, which is different from our new idea that introduces Pull to the schedulers. We proposed a novel scheduling model that allow slaves to actively pull jobs from master to execute. By analyzing the execution time and resource requests of jobs in \"Tianhe-II\", we will clarify that scheduling based on Push & Pull is a direction worthy of in-depth study in the future.","publicationDate":"2020-06-26T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3149572.3149583","title":"research-article ","type":"An Agile Farm Management Information System Framework for Precision Agriculture","venue":"ICIME 2017: Proceedings of the 9th International Conference on Information Management and Engineering","authors":["Pradeep Hewage","Mark Anderson","Hui Fang"],"abstract":"Early Farm Management Information Systems (FMIS) implementations were focused on data entry and report generation within a farm. The growth in areas such as Precision Agriculture (PA) is changing the landscape and approach taken to develop such systems. The lack of standardised data formats to support the transfer of data between systems is one of the major concerns that have been raised relating to the development of FMIS. The modern FMIS based on the distributed systems which inherently supports the sharing of resources and data. Service-oriented architectures are more flexible in relation to the delivery of software packages; for example, cloud computing can be utilized to offer Software-as-a-Service (SaaS) to agriculturalists. In general, these systems are monolithic, which is built as a single unit of software. These monolithic systems have several challenges, especially scalability, rebuild, retesting and deployment issues. The modern microservice approach can be recognised as the solution for these issues. Microservice approach is organised a distributed application as a collection of services, where each service design, implement and run independently. The basic microservice concept is based on virtual machines and the Application Program Interface (API). The next level of container based microservice systems has less runtime overhead compared to virtual machine basic microsevices. This technology is also more efficient as many containers can be run in a single virtual machine. The container based system also comes with key features and tooling around to addressing microservice challenges. The researchers conclude the paper by recommending a container based microservice architecture for agile FMIS in precision agriculture.","publicationDate":"2017-10-08T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3094405.3094409","title":"research-article ","type":"Reproducible Distributed Clusters with Mutable Containers: To Minimize Cost and Provisioning Time","venue":"HotConNet '17: Proceedings of the Workshop on Hot Topics in Container Networking and Networked Systems","authors":["Hooman Peiro Sajjad","Kamal Hakimzadeh","Shelan Perera"],"abstract":"Reproducible and repeatable provisioning of large-scale distributed systems is laborious. The cost of virtual infrastructure and the provisioning complexity are two of the main concerns. The trade-offs between virtual machines (VMs) and containers, the most popular virtualization technologies, further complicate the problem. Although containers incur little overhead compared to VMs, VMs are required for their certain guarantees such as hardware isolation.In this paper, we present a mutable container provisioning solution, enabling users to switch infrastructure between VMs and containers seamlessly. Our solution allows for significant infrastructure-cost optimizations. We discuss that immutable containers come short for certain provisioning scenarios. However, mutable containers can incur a large time overhead. To reduce the time overhead, we propose multiple provisioning-time optimizations. We implement our solution in Karamel, an open-sourced reproducible provisioning system. Based on our evaluation results, we discuss the cost-optimization opportunities and the time-optimization challenges of our new model.","publicationDate":"2017-08-10T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3102980.3103003","title":"research-article ","type":"Return of the Runtimes: Rethinking the Language Runtime System for the Cloud 3.0 Era","venue":"HotOS '17: Proceedings of the 16th Workshop on Hot Topics in Operating Systems","authors":["Martin Maas","Krste Asanović","John Kubiatowicz"],"abstract":"The public cloud is moving to a Platform-as-a-Service model where services such as data management, machine learning or image classification are provided by the cloud operator while applications are written in high-level languages and leverage these services.Managed languages such as Java, Python or Scala are widely used in this setting. However, while these languages can increase productivity, they are often associated with problems such as unpredictable garbage collection pauses or warm-up overheads.We argue that the reason for these problems is that current language runtime systems were not initially designed for the cloud setting. To address this, we propose seven tenets for designing future language runtime systems for cloud data centers. We then outline the design of a general substrate for building such runtime systems, based on these seven tenets.","publicationDate":"2017-05-06T22:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3422392.3422467","title":"short-paper ","type":"Generating Adaptation Plans Based on Quality Models for Cloud Platforms","venue":"SBES '20: Proceedings of the 34th Brazilian Symposium on Software Engineering","authors":["Jorge Luiz Machado da Silva","Breno Bernard Nicolau de França","Cecília Mary Fischer Rubira"],"abstract":"Cloud computing brought up several benefits concerning cost and scale, offering support services for infrastructure provisioning targeting data processing and storage according to application demands. However, it is not trivial to ensure the trustworthiness of associated resources, i.e., the trust of a client in a cloud service and its provider. Hence, one of the main barriers is to warrant the nonfunctional properties of trustworthiness during runtime. This paper presents a new infrastructure to generate adaptation plans based on quality models to ensure different trustworthiness properties. On detecting the degradation of cloud resources regarding the monitored properties, an adaptation plan is generated and executed during runtime to ensure that cloud resources can work under proper trustworthiness levels. The proposed solution intends to be general, possibly being applied to several trustworthiness properties simultaneously. Finally, we evaluated the solution in a feasibility study under a scenario considering data privacy and performance as trustworthiness properties.","publicationDate":"2020-10-20T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3468264.3473936","title":"research-article ","type":"Intelligent container reallocation at Microsoft 365","venue":"ESEC/FSE 2021: Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","authors":["Bo Qiao","Fangkai Yang","Chuan Luo","Yanan Wang","Johnny Li","Qingwei Lin","Hongyu Zhang","Mohit Datta","Andrew Zhou","Thomas Moscibroda","Saravanakumar Rajmohan","Dongmei Zhang"],"abstract":"The use of containers in microservices has gained popularity as it facilitates agile development, resource governance, and software maintenance. Container reallocation aims to achieve workload balance via reallocating containers over physical machines. It affects the overall performance of microservice-based systems. However, container scheduling and reallocation remain an open issue due to their complexity in real-world scenarios. In this paper, we propose a novel Multi-Phase Local Search (MPLS) algorithm to optimize container reallocation. The experimental results show that our optimization algorithm outperforms state-of-the-art methods. In practice, it has been successfully applied to Microsoft 365 system to mitigate hotspot machines and balance workloads across the entire system.","publicationDate":"2021-08-19T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3429880.3430100","title":"research-article ","type":"Towards Federated Learning using FaaS Fabric","venue":"WoSC'20: Proceedings of the 2020 Sixth International Workshop on Serverless Computing","authors":["Mohak Chadha","Anshul Jindal","Michael Gerndt"],"abstract":"Federated learning (FL) enables resource-constrained edge devices to learn a shared Machine Learning (ML) or Deep Neural Network (DNN) model, while keeping the training data local and providing privacy, security, and economic benefits. However, building a shared model for heterogeneous devices such as resource-constrained edge and cloud makes the efficient management of FL-clients challenging. Furthermore, with the rapid growth of FL-clients, the scaling of FL training process is also difficult.In this paper, we propose a possible solution to these challenges: federated learning over a combination of connected Function-as-a-Service platforms, i.e., FaaS fabric offering a seamless way of extending FL to heterogeneous devices. Towards this, we present FedKeeper, a tool for efficiently managing FL over FaaS fabric. We demonstrate the functionality of FedKeeper by using three FaaS platforms through an image classification task with a varying number of devices/clients, different stochastic optimizers, and local computations (local epochs).","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3317550.3321447","title":"research-article ","type":"Granular Computing","venue":"HotOS '19: Proceedings of the Workshop on Hot Topics in Operating Systems","authors":["Collin Lee","John Ousterhout"],"abstract":"Granular computing is a new style of computing where applications are composed of large numbers (thousands to millions) of very short-lived (10-100μs) tasks. Today's systems and infrastructure were designed to support millisecond-scale operations and are inadequate to meet the demands of granular computing. In this position paper we discuss the challenges of supporting granular applications, such as handling extreme bursts of activity, and we present a few initial ideas about the infrastructure required to enable granular computing, such as new mechanisms for communication and persistence.","publicationDate":"2019-05-12T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3317550.3321436","title":"research-article ","type":"In-Network Compute: Considered Armed and Dangerous","venue":"HotOS '19: Proceedings of the Workshop on Hot Topics in Operating Systems","authors":["Theophilus A. Benson"],"abstract":"Programmable data planes promise unprecedented flexibility and innovation. But enormous management issues arise when these programmable data-planes, and the in-network compute functionality they enable, are deployed within production networks. In this paper, we present an overview of these management challenges, then explore the limitations of existing management techniques. Finally, we propose a system, Harmony, that encapsulates new abstractions and primitives to address these problems.","publicationDate":"2019-05-12T22:00:00.000Z","citationCount":8},{"url":"https://dl.acm.org/doi/10.1109/CCGRID.2017.51","title":"tutorial ","type":"4CeeD: Real-Time Data Acquisition and Analysis Framework for Material-related Cyber-Physical Environments","venue":"CCGrid '17: Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","authors":["Phuong Nguyen","Steven Konstanty","Todd Nicholson","Thomas O'brien","Aaron Schwartz-Duval","Timothy Spila","Klara Nahrstedt","Roy H. Campbell","Indranil Gupta","Michael Chan","Kenton McHenry","Normand Paquin"],"abstract":"In this paper, we present a data acquisition and analysis framework for materials-to-devices processes, named 4CeeD, that focuses on the immense potential of capturing, accurately curating, correlating, and coordinating materials-to-devices digital data in a real-time and trusted manner before fully archiving and publishing them for wide access and sharing. In particular, 4CeeD consists of novel services: a curation service for collecting data from microscopes and fabrication instruments, curating, and wrapping of data with extensive metadata in real-time and in a trusted manner, and a cloud-based coordination service for storing data, extracting meta-data, analyzing and finding correlations among the data. Our evaluation results show that our novel cloud framework can help researchers significantly save time and cost spent on experiments, and is efficient in dealing with high-volume and fast-changing workload of heterogeneous types of experimental data.","publicationDate":"2017-05-13T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3429885.3429965","title":"short-paper ","type":"Deepstitch: Deep Learning for Cross-Layer Stitching in Microservices","venue":"WOC'20: Proceedings of the 2020 6th International Workshop on Container Technologies and Container Clouds","authors":["Richard Li","Min Du","Hyunseok Chang","Sarit Mukherjee","Eric Eide"],"abstract":"While distributed application-layer tracing is widely used for performance diagnosis in microservices, its coarse granularity at the service level limits its applicability towards detecting more fine-grained system level issues. To address this problem, cross-layer stitching of tracing information has been proposed. However, all existing cross-layer stitching approaches either require modification of the kernel or need updates in the application-layer tracing library to propagate stitching information, both of which add further complex modifications to existing tracing tools. This paper introduces Deepstitch, a deep learning based approach to stitch cross-layer tracing information without requiring any changes to existing application layer tracing tools. Deepstitch leverages a global view of a distributed application composed of multiple services and learns the global system call sequences across all services involved. This knowledge is then used to stitch system call sequences with service-level traces obtained from a deployed application. Our proof of concept experiments show that the proposed approach successfully maps application-level interaction into the system call sequences and can identify thread-level interactions.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3277893.3277899","title":"research-article ","type":"Partitioning of CNN Models for Execution on Fog Devices","venue":"CitiFog'18: Proceedings of the 1st ACM International Workshop on Smart Cities and Fog Computing","authors":["Swarnava Dey","Arijit Mukherjee","Arpan Pal","P. Balamuralidhar"],"abstract":"Fog Computing has in recent times captured the imagination of industrial and research organizations working on various aspects of connected livelihood and governance of smart cities. Improvements in deep neural networks imply extensive use of such models for analytics and inferencing on large volume of data, including sensor observations, images, speech. A growing need for such inferencing to be run on devices closer to the data sources, i.e. devices which reside at the edge of the network, popularly known as fog devices exists, in order to reduce the upstream network traffic. However, being computationally constrained in nature, executing complex deep inferencing models on such devices has been proved difficult. This has led to several new approaches to partition/distribute the computation and/or data over multiple fog devices. In this paper we propose a novel depth-wise input partitioning scheme for CNN models and experimentally prove that it achieves better performance compared to row/column or grid based schemes.","publicationDate":"2018-11-03T23:00:00.000Z","citationCount":12},{"url":"https://dl.acm.org/doi/10.5555/3124497.3124517","title":"research-article ","type":"Patterns for software orchestration on the cloud","venue":"PLoP '15: Proceedings of the 22nd Conference on Pattern Languages of Programs","authors":["Tiago Boldt Sousa","Filipe Figueiredo Correia","Hugo Sereno Ferreira"],"abstract":"Software businesses are redirecting their expansion towards service-oriented businesses models, highly supported by cloud computing. While cloud computing is not a new research subject, there's a clear lack of documented best practices on how to orchestrate cloud environments, either public, private or hybrid. This paper is targeted at DevOps practitioners and explores solutions for cloud orchestration, describing them as three patterns: a) Software Containerization, providing resource sharing with minimal virtualization overhead, b) Local Reverse Proxy, allowing applications to access any service in a cluster abstracting its placement and c) Orchestration by Resource Offering, ensuring applications get orchestrated in a machine with the required resources to run it. The authors believe that these three DevOps patterns will help researchers and newcomers to cloud orchestration to identify and adopt existing best practices earlier, hence, simplifying software life cycle management.","publicationDate":"2015-10-23T22:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1109/TNET.2020.2981477","title":"research-article ","type":"HSOP: A Hybrid Service Orchestration Platform for Internet-Telephony Networks","venue":"IEEE/ACM Transactions on Networking","authors":["Bo Cheng","Shoulu Hou","Ming Wang","Shuai Zhao","Junliang Chen"],"abstract":"Nowadays Telecom service providers are seeking new paradigms of service creation and execution platform to reduce new services' time to market and increase profitability. However, the existing static services orchestration approaches cannot meet the dynamic complicated business demands. This paper proposes a hybrid service orchestration platform for Internet-Telephony networks. Firstly, designs a hybrid service orchestration language for developers to achieve dynamic and rapid orchestration of new hybrid services over the Internet-Telephony networks. Secondly, proposes an event-driven and component-based hybrid service orchestration container to meet the asynchronous dynamic interactions between hybrid services. Thirdly, proposes a cost-aware auto-scaling approach, including the pre-scaling and real-time scaling stages, to dynamically scale the required resources at different levels. Finally, illustrates the hybrid voice chatting services orchestration scenario, and also the effectiveness and practicability of the proposed platform are validated through extensive experiments.","publicationDate":"2020-05-31T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3336937.3336942","title":"research-article ","type":"Democratizing the Network Edge","venue":"ACM SIGCOMM Computer Communication Review","authors":["Larry Peterson","Tom Anderson","Sachin Katti","Nick McKeown","Guru Parulkar","Jennifer Rexford","Mahadev Satyanarayanan","Oguz Sunay","Amin Vahdat"],"abstract":"The cloud and telecommunications industry is in the midst of a transition towards the edge. There is a tremendous opportunity for the research community to influence this transformation, but doing so requires understanding industry momentum, and making a concerted effort to align with that momentum. We believe there are three keys to doing this: (1) focus on the intersection of the cloud and access networks, (2) contribute to the relevant open source projects, and (3) address the challenge of operationalizing the results. The paper puts forward a concrete proposal for all three, and discusses the opportunity to influence how the Internet evolves at the edge and enable innovative edge applications.","publicationDate":"2019-05-20T22:00:00.000Z","citationCount":13},{"url":"https://dl.acm.org/doi/10.1145/3379444","title":"survey ","type":"A Survey of Network Virtualization Techniques for Internet of Things Using SDN and NFV","venue":"ACM Computing Surveys","authors":["Iqbal Alam","Kashif Sharif","Fan Li","Zohaib Latif","M. M. Karim","Sujit Biswas","Boubakr Nour","Yu Wang"],"abstract":"Internet of Things (IoT) and Network Softwarization are fast becoming core technologies of information systems and network management for the next-generation Internet. The deployment and applications of IoT range from smart cities to urban computing and from ubiquitous healthcare to tactile Internet. For this reason, the physical infrastructure of heterogeneous network systems has become more complicated and thus requires efficient and dynamic solutions for management, configuration, and flow scheduling. Network softwarization in the form of Software Defined Networks and Network Function Virtualization has been extensively researched for IoT in the recent past. In this article, we present a systematic and comprehensive review of virtualization techniques explicitly designed for IoT networks. We have classified the literature into software-defined networks designed for IoT, function virtualization for IoT networks, and software-defined IoT networks. These categories are further divided into works that present architectural, security, and management solutions. Besides, the article highlights several short-term and long-term research challenges and open issues related to the adoption of software-defined Internet of Things.","publicationDate":"2020-04-15T22:00:00.000Z","citationCount":29},{"url":"https://dl.acm.org/doi/10.1145/3152529","title":"research-article ","type":"Titus: introducing containers to the Netflix cloud","venue":"Communications of the ACM","authors":["Andrew Leung","Andrew Spyker","Tim Bozarth"],"abstract":"Approaching container adoption in an already cloud-native infrastructure.","publicationDate":"2018-01-22T23:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3292500.3330701","title":"research-article ","type":"Optuna: A Next-generation Hyperparameter Optimization Framework","venue":"KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","authors":["Takuya Akiba","Shotaro Sano","Toshihiko Yanase","Takeru Ohta","Masanori Koyama"],"abstract":"The purpose of this study is to introduce new design-criteria for next-generation hyperparameter optimization software. The criteria we propose include (1) define-by-run API that allows users to construct the parameter search space dynamically, (2) efficient implementation of both searching and pruning strategies, and (3) easy-to-setup, versatile architecture that can be deployed for various purposes, ranging from scalable distributed computing to light-weight experiment conducted via interactive interface. In order to prove our point, we will introduce Optuna, an optimization software which is a culmination of our effort in the development of a next generation optimization software. As an optimization software designed with define-by-run principle, Optuna is particularly the first of its kind. We will present the design-techniques that became necessary in the development of the software that meets the above criteria, and demonstrate the power of our new design through experimental results and real world applications. Our software is available under the MIT license (https://github.com/pfnet/optuna/).","publicationDate":"2019-07-24T22:00:00.000Z","citationCount":172},{"url":"https://dl.acm.org/doi/10.1145/3190508.3190546","title":"research-article ","type":"Service fabric: a distributed platform for building microservices in the cloud","venue":"EuroSys '18: Proceedings of the Thirteenth EuroSys Conference","authors":["Gopal Kakivaya","Lu Xun","Richard Hasha","Shegufta Bakht Ahsan","Todd Pfleiger","Rishi Sinha","Anurag Gupta","Mihail Tarta","Mark Fussell","Vipul Modi","Mansoor Mohsin","Ray Kong","Anmol Ahuja","Oana Platon","Alex Wun","Matthew Snider","Chacko Daniel","Dan Mastrian","Yang Li","Aprameya Rao","Vaishnav Kidambi","Randy Wang","Abhishek Ram","Sumukh Shivaprakash","Rajeet Nair","Alan Warwick","Bharat S. Narasimman","Meng Lin","Jeffrey Chen","Abhay Balkrishna Mhatre","Preetha Subbarayalu","Mert Coskun","Indranil Gupta"],"abstract":"We describe Service Fabric (SF), Microsoft's distributed platform for building, running, and maintaining microservice applications in the cloud. SF has been running in production for 10+ years, powering many critical services at Microsoft. This paper outlines key design philosophies in SF. We then adopt a bottom-up approach to describe low-level components in its architecture, focusing on modular use and support for strong semantics like fault-tolerance and consistency within each component of SF. We discuss lessons learned, and present experimental results from production data.","publicationDate":"2018-04-22T22:00:00.000Z","citationCount":20},{"url":"https://dl.acm.org/doi/10.1145/3340301.3341130","title":"research-article ","type":"Can we containerize internet measurements?","venue":"ANRW '19: Proceedings of the Applied Networking Research Workshop","authors":["Chris Misa","Sudarsun Kannan","Ramakrishnan Durairajan"],"abstract":"Container systems (e.g., Docker) provide a well-defined, lightweight, and versatile foundation to streamline the process of tool deployment, to provide a consistent and repeatable experimental interface, and to leverage data centers in the global cloud infrastructure as measurement vantage points. However, the virtual network devices commonly used to connect containers to the Internet are known to impose latency overheads which distort the values reported by measurement tools running inside containers. In this study, we develop a tool called MACE to measure and remove the latency overhead of virtual network devices as used by Docker containers. A key insight of MACE is the fact that container functions all execute in the same kernel. Based on this insight, MACE is implemented as a Linux kernel module using the trace event subsystem to measure latency along the network stack code path. Using CloudLab, we evaluate MACE by comparing the ping measurements emitted from a slim-ping container to the ones emitted using the same tool running in the bare metal machine under varying traffic loads. Our evaluation shows that the MACE-adjusted RTT measurements are within 20 μs of the bare metal ping RTTs on average while incurring less than 25 μs RTT perturbation. We also compare RTT perturbation incurred by MACE with perturbation incurred by the built-in ftrace kernel tracing system and find that MACE incures less perturbation.","publicationDate":"2019-07-21T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3265639.3265652","title":"research-article ","type":"A Cloud-based Control System Architecture for Multi-UAV","venue":"ICRCA '18: Proceedings of the 3rd International Conference on Robotics, Control and Automation","authors":["Chen Hong","Dianxi Shi"],"abstract":"Unmanned aerial vehicle is considered one of the most promising technologies. Controlling UAV over the cloud is an emerging research area motivated by the emergence of Cloud Robotics and the Internet-of-Things (IoT). This paper presents a control system architecture based on cloud platform which has been developed in order to allow multiple users to control and monitor multiple UAVs simultaneously irrespective of the location. Furthermore, the system allows to build and allocate missions to UAV and analyze the execution data that collect by sensors. The architecture of the system is fully based on open source software and protocols. To demonstrate the effectiveness of the system architecture, we implemented and validated it using SITL (software in the loop) simulator. Experimental results show that the system is efficient in monitoring and controlling UAV remotely through the Internet.","publicationDate":"2018-08-10T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3448016.3457320","title":"research-article ","type":"Clonos: Consistent Causal Recovery for Highly-Available Streaming Dataflows","venue":"SIGMOD/PODS '21: Proceedings of the 2021 International Conference on Management of Data","authors":["Pedro F. Silvestre","Marios Fragkoulis","Diomidis Spinellis","Asterios Katsifodimos"],"abstract":"Stream processing lies in the backbone of modern businesses, being employed for mission critical applications such as real-time fraud detection, car-trip fare calculations, traffic management, and stock trading. Large-scale applications are executed by scale-out stream processing systems on thousands of long-lived operators, which are subject to failures. Recovering from failures fast and consistently are both top priorities, yet they are only partly satisfied by existing fault tolerance methods due to the strong assumptions these make. In particular, prior solutions fail to address consistency in the presence of nondeterminism, such as calls to external services, asynchronous timers and processing-time windows. This paper describes Clonos, a fault tolerance approach that achieves fast, local operator recovery with exactly-once guarantees and high availability by instantly switching to passive standby operators. Clonos enforces causally consistent recovery, including output deduplication, by tracking nondeterminism within the system through causal logging. To implement Clonos we re-engineered many of the internal subsystems of a state of the art stream processor. We evaluate Clonos' overhead and recovery on the Nexmark benchmark against Apache Flink. Clonos achieves instant recovery with negligible overhead and, unlike previous work, does not make assumptions on the deterministic nature of operators.","publicationDate":"2021-06-08T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/book/10.1145/3122865","title":"","type":"","venue":"","authors":[],"abstract":"","publicationDate":null,"citationCount":18000000110110},{"url":"https://dl.acm.org/doi/10.1145/3447545.3451185","title":"research-article ","type":"GradeML: Towards Holistic Performance Analysis for Machine Learning Workflows","venue":"ICPE '21: Companion of the ACM/SPEC International Conference on Performance Engineering","authors":["Tim Hegeman","Matthijs Jansen","Alexandru Iosup","Animesh Trivedi"],"abstract":"Today, machine learning (ML) workloads are nearly ubiquitous. Over the past decade, much effort has been put into making ML model-training fast and efficient, e.g., by proposing new ML frameworks (such as TensorFlow, PyTorch), leveraging hardware support (TPUs, GPUs, FPGAs), and implementing new execution models (pipelines, distributed training). Matching this trend, considerable effort has also been put into performance analysis tools focusing on ML model-training. However, as we identify in this work, ML model training rarely happens in isolation and is instead one step in a larger ML workflow. Therefore, it is surprising that there exists no performance analysis tool that covers the entire life-cycle of ML workflows. Addressing this large conceptual gap, we envision in this work a holistic performance analysis tool for ML workflows. We analyze the state-of-practice and the state-of-the-art, presenting quantitative evidence about the performance of existing performance tools. We formulate our vision for holistic performance analysis of ML workflows along four design pillars: a unified execution model, lightweight collection of performance data, efficient data aggregation and presentation, and close integration in ML systems. Finally, we propose first steps towards implementing our vision as GradeML, a holistic performance analysis tool for ML workflows. Our preliminary work and experiments are open source at https://github.com/atlarge-research/grademl.","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3409963.3410497","title":"research-article ","type":"Libservices: dynamic storage provisioning for multitenant I/O isolation","venue":"APSys '20: Proceedings of the 11th ACM SIGOPS Asia-Pacific Workshop on Systems","authors":["Giorgos Kappes","Stergios V. Anastasiadis"],"abstract":"Containers are commonly used to run the data-intensive applications of different tenants in cloud infrastructures. The storage I/O of the colocated tenants is typically handled by the shared system kernel of the container host. When a data-intensive container competes with a noisy neighbor, the kernel I/O services can cause performance variability and slowdown. This is a challenging problem for which several approaches have already been explored. Although the dynamic resource allocation, kernel structure replication, and hardware-level virtualization are helpful, they incur costs of high implementation complexity and execution overhead. As a realistic cost-effective alternative, we isolate the I/O path of each tenant by running dedicated storage systems at user level on reserved resources. We introduce the libservices as a unified user-level storage abstraction to dynamically provision per tenant container root filesystems, application data filesystems and image repositories. We outline several examples of container storage systems whose clients and servers can be composed from libservices. With an early prototype, we successfully demonstrate that the libservices combine the required efficiency and flexibility to build isolated I/O services on multitenant hosts with superior performance over existing user-level or kernel-level systems.","publicationDate":"2020-08-23T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3369756","title":"research-article ","type":"The reliability of enterprise applications","venue":"Communications of the ACM","authors":["Sanjay Sha"],"abstract":"Understanding enterprise reliability.","publicationDate":"2019-12-19T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3434770.3459736","title":"research-article ","type":"Towards a Computing Platform for the LEO Edge","venue":"EdgeSys '21: Proceedings of the 4th International Workshop on Edge Systems, Analytics and Networking","authors":["Tobias Pfandzelter","Jonathan Hasenburg","David Bermbach"],"abstract":"The new space race is heating up as private companies such as SpaceX and Amazon are building large satellite constellations in low-earth orbit (LEO) to provide global broadband internet access. As the number of subscribers connected to this access network grows, it becomes necessary to investigate if and how edge computing concepts can be applied to LEO satellite networks.In this paper, we discuss the unique characteristics of the LEO edge and analyze the suitability of three organization paradigms for applications considering developer requirements. We conclude that the serverless approach is the most promising solution, opening up the field for future research.","publicationDate":"2021-04-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3371595.3374665","title":"research-article ","type":"The Reliability of Enterprise Applications: Understanding enterprise reliability","venue":"Queue","authors":["Sanjay Sha"],"abstract":"Enterprise reliability is a discipline that ensures applications will deliver the required business functionality in a consistent, predictable, and cost-effective manner without compromising core aspects such as availability, performance, and maintainability. This article describes a core set of principles and engineering methodologies that enterprises can apply to help them navigate the complex environment of enterprise reliability and deliver highly reliable and cost-efficient applications.","publicationDate":"2019-09-30T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3291291.3291334","title":"research-article ","type":"Best practices and lessons learned in microservices","venue":"CASCON '18: Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering","authors":["Julia Rubin","Yingying Wang","Harshavardhan Kadiyala","John Steinbacher","Tony Erwin"],"abstract":"Microservice-based architecture is an approach to developing a single application as a suite of independent services. The services run in separate processes and communicate with each other via lightweight language-agnostic protocols, such as HTTP REST. The services are split following business capabilities; each service has a fully automated pipeline and is independently deployable.","publicationDate":"2018-10-28T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3374138.3374140","title":"research-article ","type":"Large-scale traffic simulation for smart city planning with mars","venue":"SummerSim '19: Proceedings of the 2019 Summer Simulation Conference","authors":["Julius Weyl","Ulfia A. Lenfers","Thomas Clemen","Daniel Glake","Fabian Panse","Norbert Ritter"],"abstract":"Understanding individual mobility in larger cities is an important success factor for future smart cities. Related simulation scenarios incorporate enormous numbers of agents, with the disadvantage of long run times. In order to provide large-scale and multimodal traffic simulations, we developed MARS V3. Adapting the Modeling and Simulation as a Service (MSaaS) paradigm, a seamless workflow can be provided to the modeling community. An integrated domain-specific language allows model descriptions without a technical overhead. For this study, selected parts of an individual-based traffic model of the City of Hamburg, Germany, were taken as an example. The entire workflow from model development, open data integration, simulation, and result analysis will be described and evaluated. Performance was measured for local and cloud-based simulation execution for up to one million agents. First results show that this concept can be utilized for building decision support systems for smart cities in the near future.","publicationDate":"2019-07-21T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.5555/3374138.3374140","title":"research-article ","type":"Large-scale traffic simulation for smart city planning with mars","venue":"SummerSim '19: Proceedings of the 2019 Summer Simulation Conference","authors":["Julius Weyl","Ulfia A. Lenfers","Thomas Clemen","Daniel Glake","Fabian Panse","Norbert Ritter"],"abstract":"Understanding individual mobility in larger cities is an important success factor for future smart cities. Related simulation scenarios incorporate enormous numbers of agents, with the disadvantage of long run times. In order to provide large-scale and multimodal traffic simulations, we developed MARS V3. Adapting the Modeling and Simulation as a Service (MSaaS) paradigm, a seamless workflow can be provided to the modeling community. An integrated domain-specific language allows model descriptions without a technical overhead. For this study, selected parts of an individual-based traffic model of the City of Hamburg, Germany, were taken as an example. The entire workflow from model development, open data integration, simulation, and result analysis will be described and evaluated. Performance was measured for local and cloud-based simulation execution for up to one million agents. First results show that this concept can be utilized for building decision support systems for smart cities in the near future.","publicationDate":"2019-07-21T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3445814.3446704","title":"research-article ","type":"PTEMagnet: fine-grained physical memory reservation for faster page walks in public clouds","venue":"ASPLOS 2021: Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems\n\t\t\t\t\n                    Artifact evaluation pack for PTEMagnet (paper #111 in ASPLOS'21)\n                \n            ","authors":["Artemiy Margaritov","Dmitrii Ustiugov","Amna Shahab","Boris Grot"],"abstract":"The last few years have seen a rapid adoption of cloud computing for data-intensive tasks. In the cloud environment, it is common for applications to run under virtualization and to share a virtual machine with other applications (e.g., in a virtual private cloud setup). In this setting, our work identifies a new address translation bottleneck caused by memory fragmentation stemming from the interaction of virtualization, colocation, and the Linux memory allocator. The fragmentation results in the effective cache footprint of the host PT being larger than that of the guest PT. The bloated footprint of the host PT leads to frequent cache misses during nested page walks, increasing page walk latency.  In response to these observations, we propose PTEMagnet, a new software-only approach for reducing address translation latency in a public cloud. PTEMagnet prevents memory fragmentation through a fine-grained reservation-based allocator in the guest OS. Our evaluation shows that PTEMagnet is free of performance overheads and can improve performance by up to 9% (4% on average). PTEMagnet is fully legacy-preserving, requiring no modifications to either user code or mechanisms for address translation and virtualization.","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3366423.3380173","title":"research-article ","type":"Valve: Securing Function Workflows on Serverless Computing Platforms","venue":"WWW '20: Proceedings of The Web Conference 2020","authors":["Pubali Datta","Prabuddha Kumar","Tristan Morris","Michael Grace","Amir Rahmati","Adam Bates"],"abstract":"Serverless Computing has quickly emerged as a dominant cloud computing paradigm, allowing developers to rapidly prototype event-driven applications using a composition of small functions that each perform a single logical task. However, many such application workflows are based in part on publicly-available functions developed by third-parties, creating the potential for functions to behave in unexpected, or even malicious, ways. At present, developers are not in total control of where and how their data is flowing, creating significant security and privacy risks in growth markets that have embraced serverless (e.g., IoT). As a practical means of addressing this problem, we present Valve, a serverless platform that enables developers to exert complete fine-grained control of information flows in their applications. Valve enables workflow developers to reason about function behaviors, and specify restrictions, through auditing of network-layer information flows. By proxying network requests and propagating taint labels across network flows, Valve is able to restrict function behavior without code modification. We demonstrate that Valve is able defend against known serverless attack behaviors including container reuse-based persistence and data exfiltration over cloud platform APIs with less than 2.8% runtime overhead, 6.25% deployment overhead and 2.35% teardown overhead.","publicationDate":"2020-04-19T22:00:00.000Z","citationCount":7},{"url":"https://dl.acm.org/doi/10.1145/3368235.3368839","title":"research-article ","type":"SWEEP: Accelerating Scientific Research Through Scalable Serverless Workflows","venue":"UCC '19 Companion: Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing Companion","authors":["Aji John","Kristiina Ausmees","Kathleen Muenzen","Catherine Kuhn","Amanda Tan"],"abstract":"Scientific and commercial applications are increasingly being executed in the cloud, but the difficulties associated with cluster management render on-demand resources inaccessible or inefficient to many users. Recently, the serverless execution model, in which the provisioning of resources is abstracted from the user, has gained prominence as an alternative to traditional cyberinfrastructure solutions. With its inherent elasticity, the serverless paradigm constitutes a promising computational model for scientific workflows, allowing domain specialists to develop and deploy workflows that are subject to varying workloads and intermittent usage without the overhead of infrastructure maintenance. We present the Serverless Workflow Enablement and Execution Platform (SWEEP), a cloud-agnostic workflow management system with a purely serverless execution model that allows users to define, run and monitor generic cloud-native workflows. We demonstrate the use of SWEEP on workflows from two disparate scientific domains and present an evaluation of performance and scaling.","publicationDate":"2019-12-01T23:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3406208","title":"survey ","type":"A Taxonomy and Survey of Power Models and Power Modeling for Cloud Servers","venue":"ACM Computing Surveys","authors":["Weiwei Lin","Fang Shi","Wentai Wu","Keqin Li","Guangxin Wu","Al-Alas Mohammed"],"abstract":"Due to the increasing demand of cloud resources, the ever-increasing number and scale of cloud data centers make their massive power consumption a prominent issue today. Evidence reveals that the behaviors of cloud servers make the major impact on data centers’ power consumption. Although extensive research can be found in this context, a systematic review of the models and modeling methods for the entire hierarchy (from underlying hardware components to the upper-layer applications) of the cloud server is still missing, which is supposed to cover the relevant studies on physical and virtual cloud server instances, server components, and cloud applications. In this article, we summarize a broad range of relevant studies from three perspectives: power data acquisition, power models, and power modeling methods for cloud servers (including bare-metal, virtual machine (VM), and container instances). We present a comprehensive taxonomy on the collection methods of server-level power data, the existing mainstream power models at multiple levels from hardware to software and application, and commonly used methods for modeling power consumption including classical regression analysis and emerging methods like reinforcement learning. Throughout the work, we introduce a variety of models and methods, illustrating their implementation, usability, and applicability while discussing the limitations of existing approaches and possible ways of improvement. Apart from reviewing existing studies on server power models and modeling methods, we further figure out several open challenges and possible research directions, such as the study on modeling the power consumption of lightweight virtual units like unikernel and the necessity of further explorations toward empowering server power estimation/prediction with machine learning. As power monitoring is drawing increasing attention from cloud service providers (CSPs), this survey provides useful guidelines on server power modeling and can be inspiring for further research on energy-efficient data centers.","publicationDate":"2020-09-27T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3163080.3163107","title":"research-article ","type":"SAAP: A State-Aware Adaptive Prediction Strategy for CPU Load of Desktops","venue":"ICSPS 2017: Proceedings of the 9th International Conference on Signal Processing Systems","authors":["Sikai Xing","Shiyou Qian","Jian Cao","Minglu Li","Guangtao Xue","Yanmin Zhu"],"abstract":"Most medium-scale above corporations usually construct their own private clouds, utilizing commodity servers to provide computing resources. With the increase in computing demand, more and more servers are required. On the other hand, in these corporations, there are hundreds or thousands of desktops (physical or virtual personal computers) that are running with low resource utilizations. With the availability of container technologies, such as Docker, it is currently feasible to utilize these potential computing resources. To do so, it is critical to predict the resource consumption of desktops accurately before scheduling jobs for them, in order to improve the execution of jobs. Although some approaches have been proposed to predict the resource utilization of servers, they can't be directly applied to desktops due to the dynamics of desktops. To address this problem, we propose SAAP, a State-Aware Adaptive Prediction strategy for CPU load of desktops. SAAP is capable of dynamically selecting appropriate prediction algorithms to predict the CPU load, adapting to the state of desktops. Besides, two patterns that can improve prediction accuracy are found. To evaluate the effectiveness of SAAP, extensive experiments are conducted. The experimental results demonstrate that SAAP behaves much better than the Box-Jenkins models (AR, MA, ARMA, ARIMA) in prediction accuracy.","publicationDate":"2017-11-26T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3205191.3205222","title":"research-article ","type":"Student contribution to HFOSS: challenges and opportunities","venue":"Journal of Computing Sciences in Colleges","authors":["Gregory W. Hislop","Heidi J. C. Ellis","Herman Jackson"],"abstract":"Free and open source software (FOSS) has become a significant segment of the software industry. All the major IT companies have a FOSS strategy and groups of people who work full-time on open source projects. Google has a large and long-standing presence in FOSS communities. Even Microsoft, which for years fought fiercely against FOSS, now supports FOSS including having a marketing campaign with the tag line \"Microsoft Loves Linux.\"","publicationDate":"2018-05-31T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3267809.3275469","title":"poster ","type":"Data-Driven Resource Shaping for Compute Clusters","venue":"SoCC '18: Proceedings of the ACM Symposium on Cloud Computing","authors":["F. Pace","D. Milios","D. Carra","D. Venzano","P. Michiardi"],"abstract":"No abstract available.","publicationDate":"2018-10-10T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3319647.3325857","title":"poster ","type":"Exploring and troubleshooting istio issues","venue":"SYSTOR '19: Proceedings of the 12th ACM International Conference on Systems and Storage","authors":["Tomer Lange","Aidan Shribman","Eran Raichstein","Katherine Barabash"],"abstract":"Cloud computing gave rise to a Cloud-native[1] approach for operating application software in the cloud, whereby applications are segmented into micro-services that can be designed and deployed independently of each other. This significantly increases application maintainability, reduces time to market, and helps leveraging cloud computing model. On the other hand, this approach increases the system level complexity of the application and poses new challenges, such as how services discover each other, and how application handles individual service upgrades. To support cloud-native paradigm, new development, deployment, and orchestration tools are created. One of such tools is Istio [2] service mesh, built to connect, secure, control, and observe services. While immensely useful to application developers, Istio is an additional layer in cloud compute platform software stack and is thus prone to failure or misuse.In this work, we address the question of how to explore and troubleshoot software systems managed by Istio, focusing on micro-services upgrades and versioning. Cloud native applications are not upgraded at once like monolithic applications are. Instead, individual micro-services are gradually upgraded over time, so that older service instances live side by side with newer ones, as part of a single application. Istio supports application upgrades by splitting traffic as defined in configurable resources named virtualservices. When everything is good, Istio relieves operators from overheads related to system upgrades. The question is what happens when something goes wrong, e.g. when Istio is misconfigured. Such errors are inherently hard to detect, especially as overall systems complexity and scale grow.We have extended a real-time network topology and protocol analyzer, Skydive [4], developed to explore and troubleshoot the physical, the virtual, and the application connectivity in the cloud. To support cloud-native environments, we have developed k8s [3] and Istio probes and contributed them to the community. These probes enrich Skydive object model with k8s objects, e.g. pods and services, as well as with Istio objects, e.g. virtualservices and destinationrules.We use Bookinfo, an online book store application, to demonstrate how Skydive helps exploring misconfiguration in Istio versioning. One of Bookinfo microservices, called Reviews, has two functionally different versions, and the user expects Istio to split traffic between them according to weights configured in the related virtualservice. Figure 1 presents Skydive's representation of the actual configuration, discovered at run-time by our probes. Using this representation, aided by querying and filtering capabilities of Skydive, one can explore Istio and k8s objects and relationships between them, to debug an undesired versioning behavior.In the future, we aim at supporting additional use cases, e.g security policies, circuit breakers, timeouts, and retries. We expect that the most value will be derived from multilayer exploration combined with Skydive's capability to capture/inject traffic.","publicationDate":"2019-05-21T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3049877.3049916","title":"research-article ","type":"The 8th CASCON Workshop on Cloud Computing","venue":"CASCON '16: Proceedings of the 26th Annual International Conference on Computer Science and Software Engineering","authors":["Marin Litoiu","Joe Wigglesworth","Radu Mateescu"],"abstract":"Hybrid clouds are private and public sub-clouds working together to mitigate privacy and security concerns while addressing the need for large computation and storage capacity. Academic research into hybrid clouds has focused on the middleware and abstraction layers for creating, managing, and using hybrid clouds. For example, researchers used the MapReduce paradigm to split a data-intensive workload into mapping tasks sorted by the sensitivity of the data, with the most sensitive data being processed locally and the least sensitive processed in a public cloud. Commercial support for hybrid clouds is growing in response to the business case for cloud federation. IBM offers both Pure Application System (to manage a private cloud) and Pure Application Service (a public cloud offering) and software to bridge the two at the Software-as-a-Service (SaaS) level. More recently, IBM Blue Mix Platform-as-a-Service (PaaS) enables integration of IBM Blue Mix cloud with on-premises private clouds.","publicationDate":"2016-10-30T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1109/CCGRID.2017.71","title":"tutorial ","type":"KPI-agnostic Control for Fine-Grained Vertical Elasticity","venue":"CCGrid '17: Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","authors":["Ewnetu Bayuh Lakew","Alessandro Vittorio Papadopoulos","Martina Maggio","Cristian Klein","Erik Elmroth"],"abstract":"Applications hosted in the cloud have become indispensable in several contexts, with their performance often being key to business operation and their running costs needing to be minimized. To minimize running costs, most modern virtualization technologies such as Linux Containers, Xen, and KVM offer powerful resource control primitives for individual provisioning -- that enable adding or removing of fraction of cores and/or megabytes of memory for as short as few seconds. Despite the technology being ready, there is a lack of proper techniques for fine-grained resource allocation, because there is an inherent challenge in determining the correct composition of resources an application needs, with varying workload, to ensure deterministic performance.This paper presents a control-based approach for the management of multiple resources, accounting for the resource consumption, together with the application performance, enabling fine-grained vertical elasticity. The control strategy ensures that the application meets the target performance indicators, consuming as less resources as possible. We carried out an extensive set of experiments using different applications -- interactive with response-time requirements, as well as non-interactive with throughput desires -- by varying the workload mixes of each application over time. The results demonstrate that our solution precisely provides guaranteed performance while at the same time avoiding both resource over- and under-provisioning.","publicationDate":"2017-05-13T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3053600.3053627","title":"short-paper ","type":"Model-driven Generation of Microservice Architectures for Benchmarking Performance and Resilience Engineering Approaches","venue":"ICPE '17 Companion: Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion","authors":["Thomas F. Düllmann","André van Hoorn"],"abstract":"Microservice architectures are steadily gaining adoption in industrial practice. At the same time, performance and resilience are important properties that need to be ensured. Even though approaches for performance and resilience have been developed (e.g., for anomaly detection and fault tolerance), there are no benchmarking environments for their evaluation under controlled conditions. In this paper, we propose a generative platform for benchmarking performance and resilience engineering approaches in microservice architectures, comprising an underlying metamodel, a generation platform, and supporting services for workload generation, problem injection, and monitoring.","publicationDate":"2017-04-17T22:00:00.000Z","citationCount":11},{"url":"https://dl.acm.org/doi/10.5555/3432601.3432616","title":"research-article ","type":"The weakest link: revealing and modeling the architectural patterns of microservice applications","venue":"CASCON '20: Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering","authors":["Vladimir Podolskiy","Maria Patrou","Panos Patros","Michael Gerndt","Kenneth B. Kent"],"abstract":"Cloud microservice applications comprise interconnected services packed into containers. Such applications generate complex communication patterns among their microservices. Studying such patterns can support assuring various quality attributes, such as autoscaling for satisfying performance, availability and scalability, or targeted penetration testing for satisfying security and correctness. We study the structure of containerized microservice applications via providing the methodology and the results of a structural graph-based analysis of 103 Docker Compose deployment files from open-sourced Github repositories. Our findings indicate the dominance of a power-law distribution of microservice interconnections. Further analysis highlights the suitability of the Barabási-Albert model for generating large random graphs that model the architecture of real microservice applications. The exhibited structures and their usage for engineering microservice applications are discussed.","publicationDate":"2020-11-09T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3338906.3340452","title":"research-article ","type":"Using microservices for non-intrusive customization of multi-tenant SaaS","venue":"ESEC/FSE 2019: Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","authors":["Phu H. Nguyen","Hui Song","Franck Chauvel","Roy Muller","Seref Boyar","Erik Levin"],"abstract":"Enterprise software vendors often need to support their customer companies to customize the enterprise software products deployed on-premises of customers. But when software vendors are migrating their products to cloud-based Software-as-a-Service (SaaS), deep customization that used to be done on-premises is not applicable to the cloud-based multi-tenant context in which all tenants share the same SaaS. Enabling tenant-specific customization in cloud-based multi-tenant SaaS requires a novel approach. This paper proposes a Microservices-based non-intrusive Customization framework for multi-tenant Cloud-based SaaS, called MiSC-Cloud. Non-intrusive deep customization means that the microservices for customization of each tenant are isolated from the main software product and other microservices for customization of other tenants. MiSC-Cloud makes deep customization possible via authorized API calls through API gateways to the APIs of the customization microservices and the APIs of the main software product. We have implemented a proof-of-concept of our approach to enable non-intrusive deep customization of an open-source cloud native reference application of Microsoft called eShopOnContainers. Based on this work, we provide some lessons learned and directions for future work.","publicationDate":"2019-08-11T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3155112.3158370","title":"research-article ","type":"Titus: Introducing Containers to the Netflix Cloud: Approaching container adoption in an already cloud-native infrastructure","venue":"Queue","authors":["Andrew Leung","Andrew Spyker","Tim Bozarth"],"abstract":"We believe our approach has enabled Netflix to quickly adopt and benefit from containers. Though the details may be Netflix-specific, the approach of providing low-friction container adoption by integrating with existing infrastructure and working with the right early adopters can be a successful strategy for any organization looking to adopt containers.","publicationDate":"2017-09-30T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3423459.3430760","title":"research-article ","type":"COVID-19 Joint Pandemic Modeling and Analysis Platform","venue":"COVID-19: Proceedings of the 1st ACM SIGSPATIAL International Workshop on Modeling and Understanding the Spread of COVID-19","authors":["Gautam Thakur","Kevin Sparks","Anne Berres","Varisara Tansakul","Supriya Chinthavali","Matthew Whitehead","Erik Schmidt","Haowen Xu","Junchuan Fan","Dustin Spears","Elton Cranfill"],"abstract":"The non-pharmaceutical intervention to reduce the impact and spread of COVID-19 requires the development of policies and guidance through a collaborative effort among government, academia, medicine, and citizens. To operationalize this effort, we have developed an all-encompassing situational awareness platform that can process multi-modal and multi-source data allowing informed decision making. Besides, showing the current spread of infection, the platform also captures the impact of human dynamics on the infection spread, location, and availability of critical infrastructure, prediction, and high-performance computing driven simulation. The platform is extensible, allowing third-party integration and services to consume the curated data and analytics in near real-time. We believe the platform will augment critical decision making for reducing the impact and spread of the pandemic.","publicationDate":"2020-11-02T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3241815.3241874","title":"poster ","type":"Student Participation in HFOSS: Challenges and Opportunities","venue":"SIGITE '18: Proceedings of the 19th Annual SIG Conference on Information Technology Education","authors":["Heidi J.C. Ellis","Gregory W. Hislop"],"abstract":"With the advent of cloud computing, containers, devops and other emerging IT technologies, there are increased opportunities for student learning. Many of these new technologies have their roots in open source as many of the major tools are open source such as Git (version control), Ansible (configuration management), Docker (containerization), and Jenkins (automation server). In addition, most major IT companies have a strategy for utilizing free and open source software (FOSS). Indeed, FOSS has become an important segment of the technology industry. Humanitarian FOSS (HFOSS) has the additional attraction of somehow benefiting the human condition. Given the rising emphasis on FOSS, it is important that IT students graduate with some understanding of FOSS. This poster presents an overview of HFOSS, summarizes recent research into student learning in HFOSS and also provides an overview of instructor experiences in teaching HFOSS.","publicationDate":"2018-09-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3470482.3479628","title":"research-article ","type":"DOP-MS: A Microservice-based Data Offloading Service with Support for Data Anonymisation","venue":"WebMedia '21: Proceedings of the Brazilian Symposium on Multimedia and the Web","authors":["Vitória R. N. Silvestre","Francisco A. A. Gomes","Adriano L. Cândido","Filipe Fernandes","Lincoln S. Rocha","Fernando A. M. Trinta"],"abstract":"Due to mobile devices' growing presence in our daily routine, mobile applications are becoming increasingly complex. They require more powerful processing capability and more extensive data storage, which characterizes a challenge when computational constraints of these devices are taken into account. Several software infrastructures proposed to help the development of mobile applications with data offloading features. However, they lack essential features for data offloading, such as configurable data synchronization policy models, privacy mechanisms for the offloaded data, and scalability and performance analyses. This work presents DOP, a solution to assist the development of mobile applications that use data migration, including contextual data, from mobile devices to a remote environment, based on a microservice architecture. The data offloading technique enables data migration into a remote environment, allowing (i) storage savings on the mobile device and (ii) sharing data among users. The experiments on DOP showed benefits in storage savings on mobile devices and new possibilities for inferring situations based on shared data from multiple users.","publicationDate":"2021-11-04T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3342280.3342323","title":"short-paper ","type":"Enabling Rapid Edge System Deployment with TinyEdge","venue":"SIGCOMM Posters and Demos '19: Proceedings of the ACM SIGCOMM 2019 Conference Posters and Demos","authors":["Wenzhao Zhang","Hongchang Fan","Yuxuan Zhang","Yi Gao","Wei Dong"],"abstract":"","publicationDate":"2019-08-18T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1109/CCGrid.2015.122","title":"research-article ","type":"HPC-ABDS high performance computing enhanced apache big data stack","venue":"CCGRID '15: Proceedings of the 15th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing","authors":["Geoffrey C. Fox","Judy Qiu","Supun Kamburugamuve","Shantenu Jha","Andre Luckow"],"abstract":"We review the High Performance Computing Enhanced Apache Big Data Stack HPC-ABDS and summarize the capabilities in 21 identified architecture layers. These cover Message and Data Protocols, Distributed Coordination, Security & Privacy, Monitoring, Infrastructure Management, DevOps, Interoperability, File Systems, Cluster & Resource management, Data Transport, File management, NoSQL, SQL (NewSQL), Extraction Tools, Object-relational mapping, In-memory caching and databases, Inter-process Communication, Batch Programming model and Runtime, Stream Processing, High-level Programming, Application Hosting and PaaS, Libraries and Applications, Workflow and Orchestration. We summarize status of these layers focusing on issues of importance for data analytics. We highlight areas where HPC and ABDS have good opportunities for integration.","publicationDate":"2015-05-03T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.5555/3049877.3049914","title":"research-article ","type":"Hands-on: build and package a highly scalable microservice application using docker containers","venue":"CASCON '16: Proceedings of the 26th Annual International Conference on Computer Science and Software Engineering","authors":["Serjik Dikaleh","Salman Moghal","Ozair Sheikh","Chris Felix","Dharmesh Mistry"],"abstract":"Developing and running applications require a number of supporting runtimes and services. We all have been part of or know about the extensive amount of effort that goes into setting up development, test and production environments. There are different levels of dependency and concerns such as OS configuration, platform/runtime installations and ultimately deploying the application itself. Each task is performed by different teams, spanning the combined effort across multiple departments, which adds to the deployment time. There is also the challenge of recreating the same configuration throughout separate environments in a consistent manner, which means several hours of scripting effort across different systems.","publicationDate":"2016-10-30T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3447548.3467082","title":"research-article ","type":"MPCSL - A Modular Pipeline for Causal Structure Learning","venue":"KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining","authors":["Johannes Huegle","Christopher Hagedorn","Michael Perscheid","Hasso Plattner"],"abstract":"The examination of causal structures is crucial for data scientists in a variety of machine learning application scenarios. In recent years, the corresponding interest in methods of causal structure learning has led to a wide spectrum of independent implementations, each having specific accuracy characteristics and introducing implementation-specific overhead in the runtime. Hence, considering a selection of algorithms or different implementations in different programming languages utilizing different hardware setups becomes a tedious manual task with high setup costs. Consequently, a tool that enables to plug in existing methods from different libraries into a single system to compare and evaluate the results is substantial support for data scientists in their research efforts.In this work, we propose an architectural blueprint of a pipeline for causal structure learning and outline our reference implementation MPCSL that addresses the requirements towards platform independence and modularity while ensuring the comparability and reproducibility of experiments. Moreover, we demonstrate the capabilities of MPCSL within a case study, where we evaluate existing implementations of the well-known PC-Algorithm concerning their runtime performance characteristics.","publicationDate":"2021-08-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3349266.3351393","title":"abstract ","type":"CHEESE: Cyber Human Ecosystem of Engaged Security Education","venue":"SIGITE '19: Proceedings of the 20th Annual SIG Conference on Information Technology Education","authors":["Baijian Yang","Rajesh Kalyanam","Craig Willis","Mike Lambert","Christine Kirkpatrick"],"abstract":"The CHEESE project supplements and enhances traditional cybersecurity education with hands-on, practical experience in common cybersecurity flaws and solutions. CHEESE requires only a web browser, allowing users to develop cybersecurity skills without compromising their own computer or spending hours setting up a complex virtual machine (VM) or sandbox environment. In this tutorial we will conduct a hands-on walkthrough of a couple of cybersecurity demonstrations on CHEESE and present an overview of the platform and the community-driven contribution and development process.","publicationDate":"2019-09-25T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3447786.3456259","title":"research-article ","type":"Take it to the limit: peak prediction-driven resource overcommitment in datacenters","venue":"EuroSys '21: Proceedings of the Sixteenth European Conference on Computer Systems","authors":["Noman Bashir","Nan Deng","Krzysztof Rzadca","David Irwin","Sree Kodak","Rohit Jnagal"],"abstract":"To increase utilization, datacenter schedulers often overcommit resources where the sum of resources allocated to the tasks on a machine exceeds its physical capacity. Setting the right level of overcommitment is a challenging problem: low overcommitment leads to wasted resources, while high overcommitment leads to task performance degradation. In this paper, we take a first principles approach to designing and evaluating overcommit policies by asking a basic question: assuming complete knowledge of each task's future resource usage, what is the safest overcommit policy that yields the highest utilization? We call this policy the peak oracle. We then devise practical overcommit policies that mimic this peak oracle by predicting future machine resource usage. We simulate our overcommit policies using the recently-released Google cluster trace, and show that they result in higher utilization and less overcommit errors than policies based on per-task allocations. We also deploy these policies to machines inside Google's datacenters serving its internal production workload. We show that our overcommit policies increase these machines' usable CPU capacity by 10-16% compared to no overcommitment.","publicationDate":"2021-04-20T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3284014.3284016","title":"short-paper ","type":"A Distributed Analysis and Benchmarking Framework for Apache OpenWhisk Serverless Platform","venue":"Middleware '18: Proceedings of the 19th International Middleware Conference (Posters)","authors":["Aleksandr Kuntsevich","Pezhman Nasirifard","Hans-Arno Jacobsen"],"abstract":"Serverless computing simplifies the life cycle of scalable web applications, through delegating most of the operational concerns to the cloud providers. One prominent serverless platform is Apache OpenWhisk which is employed by IBM Cloud. Despite the apparent benefits of serverless computing, some limitations of the serverless platform, such as the state-less nature of serverless functions, can introduce scalability bottlenecks. In this work, we propose an analysis and benchmarking approach for investigating potential bottlenecks and limitations of Apache OpenWhisk serverless platform.","publicationDate":"2018-12-09T23:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.5555/3291656.3291707","title":"research-article ","type":"Dynamically negotiating capacity between on-demand and batch clusters","venue":"SC '18: Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis","authors":["Feng Liu","Kate Keahey","Pierre Riteau","Jon Weissman"],"abstract":"In the era of rapid experimental expansion data analysis needs are rapidly outpacing the capabilities of small institutional clusters and looking to integrate HPC resources into their workflow. We propose one way of reconciling on-demand needs of experimental analytics with the batch managed HPC resources within a system that dynamically moves nodes between an on-demand cluster configured with cloud technology (OpenStack) and a traditional HPC cluster managed by a batch scheduler (Torque). We evaluate this system experimentally both in the context of real-life traces representing two years of a specific institutional need, and via experiments in the context of synthetic traces that capture generalized characteristics of potential batch and on-demand workloads. Our results for the real-life scenario show that our approach could reduce the current investment in on-demand infrastructure by 82% while at the same time improving the mean batch wait time almost by an order of magnitude (8x).","publicationDate":"2018-11-10T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1109/SC.2018.00041","title":"research-article ","type":"Dynamically negotiating capacity between on-demand and batch clusters","venue":"SC '18: Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis","authors":["Feng Liu","Kate Keahey","Pierre Riteau","Jon Weissman"],"abstract":"In the era of rapid experimental expansion data analysis needs are rapidly outpacing the capabilities of small institutional clusters and looking to integrate HPC resources into their workflow. We propose one way of reconciling on-demand needs of experimental analytics with the batch managed HPC resources within a system that dynamically moves nodes between an on-demand cluster configured with cloud technology (OpenStack) and a traditional HPC cluster managed by a batch scheduler (Torque). We evaluate this system experimentally both in the context of real-life traces representing two years of a specific institutional need, and via experiments in the context of synthetic traces that capture generalized characteristics of potential batch and on-demand workloads. Our results for the real-life scenario show that our approach could reduce the current investment in on-demand infrastructure by 82% while at the same time improving the mean batch wait time almost by an order of magnitude (8x).","publicationDate":"2018-11-10T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3284014.3284016","title":"short-paper ","type":"A Distributed Analysis and Benchmarking Framework for Apache OpenWhisk Serverless Platform","venue":"Middleware '18: Proceedings of the 19th International Middleware Conference (Posters)","authors":["Aleksandr Kuntsevich","Pezhman Nasirifard","Hans-Arno Jacobsen"],"abstract":"Serverless computing simplifies the life cycle of scalable web applications, through delegating most of the operational concerns to the cloud providers. One prominent serverless platform is Apache OpenWhisk which is employed by IBM Cloud. Despite the apparent benefits of serverless computing, some limitations of the serverless platform, such as the state-less nature of serverless functions, can introduce scalability bottlenecks. In this work, we propose an analysis and benchmarking approach for investigating potential bottlenecks and limitations of Apache OpenWhisk serverless platform.","publicationDate":"2018-12-09T23:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3137133.3137151","title":"research-article ","type":"Democratizing authority in the built environment","venue":"BuildSys '17: Proceedings of the 4th ACM International Conference on Systems for Energy-Efficient Built Environments","authors":["Michael P Andersen","John Kolb","Kaifei Chen","David E. Culler","Randy Katz"],"abstract":"Operating systems and applications in the built environment have relied upon central authorization and management mechanisms which restrict their scalability, especially with respect to administrative overhead. We propose a new set of primitives encompassing syndication, security, and service execution that unifies the management of applications and services across the built environment, while enabling participants to individually delegate privilege across multiple administrative domains with no loss of security or manageability. We show how to leverage a decentralized authorization syndication platform to extend the design of building operating systems beyond the single administrative domain of a building. The authorization system leveraged is based on blockchain smart contracts to permit decentralized and democratized delegation of authorization without central trust. Upon this, a publish/subscribe syndication tier and a containerized service execution environment are constructed. Combined, these mechanisms solve problems of delegation, federation, device protection and service execution that arise throughout the built environment. We leverage a high-fidelity city-scale emulation to verify the scalability of the authorization tier, and briefly describe a prototypical democratized operating system for the built environment using this foundation.","publicationDate":"2017-11-07T23:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3209914.3209938","title":"research-article ","type":"Fixit - A Semi-Automatic Software Deployment Tool for Arbitrary Targets","venue":"ICISS '18: Proceedings of the 2018 International Conference on Information Science and System","authors":["E. Loseva","A. Obeid","H. Richter","R. Backes","D. Eichhorn"],"abstract":"The deployment of software packages becomes more and more difficult. Thus Canonical Ltd. has created a framework called \"JuJu\" that serves as a DevOps toolchain. JuJu allows an integrated software development, deployment and operation of software packages. Additionally Canocial provided hundreds of open-source JuJu-maintained software packages in an own online store for download. However, our tests revealed that only 14 % of 35 picked packages from the Canonical's JuJu charm store really be installed as they are. The reason is that many of them are sensitive against mismatches of what is contained in the relevant JuJu files and what exists as target hardware at the customer. Because of that, a new concept and tool called Fixit was created by us for the semi-automatic software-deployment of JuJu software packages onto arbitrary hardware and software environments such as Windows and Linux operating systems. Fixit improves the quota of successful first-try installations from 14 to 69 %. This is accomplished by semi-automatic analysis and transformation of the package source codes.","publicationDate":"2018-04-26T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3464994.3465001","title":"research-article ","type":"Great educators in computer networking: Bruce Davie","venue":"ACM SIGCOMM Computer Communication Review","authors":["Matthew Caesar","Bruce Davie"],"abstract":"This interview is part of a series on Great Educators in Computer Networking, where we interview some of the most impactful and skilled educators in our field. Here, we interviewed Australian Bruce Davie, the self-described computer scientist/engineer/runner/cyclist, who agreed to talk to us about his thoughts on computer networking education, his role in it, his thoughts about the big ideas in our field, and how the pandemic is changing our work. Bruce has over 30 years of industry experience and is well known for a broad spectrum of educational initiatives such as co-authoring several textbooks, as well as his contributions to many networking standards and technologies, including IP quality of service, network virtualization, software defined networking, and more","publicationDate":"2021-05-09T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3299869.3314046","title":"research-article ","type":"CFS: A Distributed File System for Large Scale Container Platforms","venue":"SIGMOD '19: Proceedings of the 2019 International Conference on Management of Data","authors":["Haifeng Liu","Wei Ding","Yuan Chen","Weilong Guo","Shuoran Liu","Tianpeng Li","Mofei Zhang","Jianxing Zhao","Hongyin Zhu","Zhengyi Zhu"],"abstract":"We propose CFS, a distributed file system for large scale container platforms. CFS supports both sequential and random file accesses with optimized storage for both large files and small files, and adopts different replication protocols for different write scenarios to improve the replication performance. It employs a metadata subsystem to store and distribute the file metadata across different storage nodes based on the memory usage. This metadata placement strategy avoids the need of data rebalancing during capacity expansion. CFS also provides POSIX-compliant APIs with relaxed semantics and metadata atomicity to improve the system performance. We performed a comprehensive comparison with Ceph, a widely-used distributed file system on container platforms. Our experimental results show that, in testing 7 commonly used metadata operations, CFS gives around 3 times performance boost on average. In addition, CFS exhibits better random-read/write performance in highly concurrent environments with multiple clients and processes.","publicationDate":"2019-06-24T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3324884.3415283","title":"short-paper ","type":"Automated generation of client-specific backends utilizing existing microservices and architectural knowledge","venue":"ASE '20: Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering","authors":["Nils Wieber"],"abstract":"The design and development of production-grade microservice backends is a tedious and error-prone task. In particular, they must be capable of handling all Functional Requirements (FRs) and all Non-Functional Requirements (NFRs) (like security) including all operational requirements (like monitoring). This becomes even more difficult if there are many clients with different roles, linked to diverse (non-)functional requirements and many existing services are involved, which have to consider these in a consistent way. In this paper we present a model-driven approach that automatically generates client-specific production-grade backends by incorporating previously expressed architectural knowledge out of an interpretable specification of the targeted APIs and the NFRs.","publicationDate":"2020-12-20T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3394486.3406714","title":"tutorial ","type":"Building Recommender Systems with PyTorch","venue":"KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","authors":["Dheevatsa Mudigere","Maxim Naumov","Joe Spisak","Geeta Chauhan","Narine Kokhlikyan","Amanpreet Singh","Vedanuj Goswami"],"abstract":"In this tutorial we show how to build deep learning recommendation systems and resolve the associated interpretability, integrity and privacy challenges. We start with an overview of the PyTorch framework, features that it offers and a brief review of the evolution of recommendation models. We delineate their typical components and build a proxy deep learning recommendation model (DLRM) in PyTorch. Then, we discuss how to interpret recommendation system results as well as how to address the corresponding integrity and quality challenges.","publicationDate":"2020-08-22T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3404397.3404415","title":"research-article ","type":"E-LAS: Design and Analysis of Completion-Time Agnostic Scheduling for Distributed Deep Learning Cluster","venue":"ICPP '20: 49th International Conference on Parallel Processing - ICPP","authors":["Abeda Sultana","Li Chen","Fei Xu","Xu Yuan"],"abstract":"With the prosperity of deep learning, enterprises, and large platform providers, such as Microsoft, Amazon, and Google, have built and provided GPU clusters to facilitate distributed deep learning training. As deep learning training workloads are heterogeneous, with a diverse range of characteristics and resource requirements, it becomes increasingly crucial to design an efficient and optimal scheduler for distributed deep learning jobs in the GPU cluster. This paper aims to propose a simple and yet effective scheduler, called E-LAS, with the objective of reducing the averaged training completion time of deep learning jobs. Without relying on the estimation or prior knowledge of the job running time, E-LAS leverages the real-time epoch progress rate, unique for distributed deep learning training jobs, as well as the attained services from temporal and spatial domains, to guide the scheduling decisions. The theoretical analysis for E-LAS is conducted to offer a deeper understanding on the components of scheduling criteria. Furthermore, we present a placement algorithm to achieve better resource utilization without involving much implementation overhead, complementary to the scheduling algorithm. Extensive simulations have been conducted, demonstrating that E-LAS improves the averaged job completion time (JCT) by 10 × over an Apache YARN-based resource manager used in production. Moreover, E-LAS outperforms Tiresias, the state-of-the-art scheduling algorithm customized for deep learning jobs, by almost 1.5 × for the average JCT as well as queuing time.","publicationDate":"2020-08-16T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3429358.3429371","title":"short-paper ","type":"Given 2n Eyeballs, All Quality Flaws Are Shallow","venue":"Middleware '20 Demos and Posters: Proceedings of the 21st International Middleware Conference Demos and Posters","authors":["Panagiotis Gkikopoulos","Cristian Mateos","Josef Spillner","Alfredo Teyseyre"],"abstract":"We demonstrate the capabilities of the Microservice Artefact Observatory (MAO), a federated software quality assessment middleware. MAO's extensible assessment tools continuously scan for quality flaws, defects and inconsistencies in microservice artefacts and observe runtime behaviour. The federation reduces bias and also increases the resilience and overcomes per-site failures, leading to a single, merged timeline of software quality. Already serving concurrently by n = 3 observant operators in Argentina and Switzerland, the federation is designed to become a community-wide consensus voting-based ground truth repository with query interfaces for large-scale software quality and evolution insights. These insights can be exploited for excluding buggy software before or after deployment, for optimised resource allocation, and further software management tasks.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3427921.3450236","title":"research-article ","type":"Network Performance Influences of Software-defined Networks on Micro-service Architectures","venue":"ICPE '21: Proceedings of the ACM/SPEC International Conference on Performance Engineering","authors":["Axel Busch","Martin Kammerer"],"abstract":"Modern business applications are increasingly developed as micro-services and deployed in the cloud. Due to many components involved micro-services need a flexible and high-performance network infrastructure. To ensure highly available and high performance applications, operators are increasingly relying on cloud service platforms such as the OpenShift Container Platform on Z. In such environments modern software-defined network technologies such as Open vSwitch (OVS) are used. However, the impact of their architecture on network performance has not yet been sufficiently researched although networking performance is particularly critical for the quality of the service. In this paper, we analyse the impact of the OVS pipeline and selected OVS operations in detail. We define different scenarios used in the industry and analyse the performance of different OVS configurations using an IBM z14 mainframe system. Our analysis showed the OVS pipeline and its operations can affect network performance by up to factor 3. Our results show that even the use of virtual switches such as OVS, network performance can be significantly improved by optimizing the OVS pipeline architecture.","publicationDate":"2021-04-08T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3123779.3123804","title":"research-article ","type":"Decision guidance models for microservices: service discovery and fault tolerance","venue":"ECBS '17: Proceedings of the Fifth European Conference on the Engineering of Computer-Based Systems","authors":["Stefan Haselböck","Rainer Weinreich","Georg Buchgeher"],"abstract":"Introducing a microservice system is a challenging task and requires the exploration and documentation of several related areas of design. Exploration and documentation of software architecture design is supported by decision guidance models in software architecture. In this paper, we present such guidance models for several microservice system design areas, including service discovery and fault tolerance. The presented models have been created based on existing microservice literature and have been validated and refined in design workshops with business partners as part of a technical action research (TAR) study.","publicationDate":"2017-08-30T22:00:00.000Z","citationCount":7},{"url":"https://dl.acm.org/doi/10.1145/3381052.3381315","title":"research-article ","type":"Blending containers and virtual machines: a study of firecracker and gVisor","venue":"VEE '20: Proceedings of the 16th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments","authors":["Anjali","Tyler Caraza-Harter","Michael M. Swift"],"abstract":"With serverless computing, providers deploy application code and manage resource allocation dynamically, eliminating infrastructure management from application development.Serverless providers have a variety of virtualization platforms to choose from for isolating functions, ranging from native Linux processes to Linux containers to lightweight isolation platforms, such as Google gVisor [7] and AWS Firecracker [5]. These platforms form a spectrum as they move functionality out of the host kernel and into an isolated guest environment. For example, gVisor handles many system calls in a user-mode Sentry process while Firecracker runs a full guest operating system in each microVM. A common theme across these platforms are the twin goals of strong isolation and high performance.In this paper, we perform a comparative study of Linux containers (LXC), gVisor secure containers, and Firecracker microVMs to understand how they use Linux kernel services differently: how much does their use of host kernel functionality vary? We also evaluate the performance costs of the designs with a series of microbenchmarks targeting different kernel subsystems.Our results show that despite moving much functionality out of the kernel, both Firecracker and gVisor execute substantially more kernel code than native Linux. gVisor and Linux containers execute substantially the same code, although with different frequency.","publicationDate":"2020-03-16T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1109/MSR.2017.67","title":"research-article ","type":"An empirical analysis of the docker container ecosystem on GitHub","venue":"MSR '17: Proceedings of the 14th International Conference on Mining Software Repositories","authors":["Jürgen Cito","Gerald Schermann","John Erik Wittern","Philipp Leitner","Sali Zumberi","Harald C. Gall"],"abstract":"Docker allows packaging an application with its dependencies into a standardized, self-contained unit (a so-called container), which can be used for software development and to run the application on any system. Dockerfiles are declarative definitions of an environment that aim to enable reproducible builds of the container. They can often be found in source code repositories and enable the hosted software to come to life in its execution environment. We conduct an exploratory empirical study with the goal of characterizing the Docker ecosystem, prevalent quality issues, and the evolution of Dockerfiles. We base our study on a data set of over 70000 Dockerfiles, and contrast this general population with samplings that contain the Top-100 and Top-1000 most popular Docker-using projects. We find that most quality issues (28.6%) arise from missing version pinning (i.e., specifying a concrete version for dependencies). Further, we were not able to build 34% of Dockerfiles from a representative sample of 560 projects. Integrating quality checks, e.g., to issue version pinning warnings, into the container build process could result into more reproducible builds. The most popular projects change more often than the rest of the Docker population, with 5.81 revisions per year and 5 lines of code changed on average. Most changes deal with dependencies, that are currently stored in a rather unstructured manner. We propose to introduce an abstraction that, for instance, could deal with the intricacies of different package managers and could improve migration to more light-weight images.","publicationDate":"2017-05-19T22:00:00.000Z","citationCount":16},{"url":"https://dl.acm.org/doi/10.1145/3405837.3411371","title":"poster ","type":"AnnaBellaDB: a key value store for stateless network functions","venue":"SIGCOMM '20: Proceedings of the SIGCOMM '20 Poster and Demo Sessions","authors":["Márk Szalay","Péter Mátray","László Toka"],"abstract":"The cloud-native paradigm has become a widely applied approach to ensure elasticity and reliability of applications running in the cloud. One recurrent motif is the stateless design of applications, which aims to decouple the life-cycle of application states from the life-cycle of individual application instances. Application data is written to and read from cloud databases, deployed close to the application code to ensure low latency bounds on state access. When applying a stateless design, the performance of the cloud service is often limited by the cloud database. In order not to become a bottleneck, database instances are distributed on multiple hosts, and strive to ensure data locality for all application instances. However, the shared nature of certain states, and the inevitable dynamics of the application workload necessarily lead to inter-host data access within the data center or even across data centers and edge servers, if the service is geographically distributed. To minimize the service performance loss due to the stateless design of applications, we propose a latency and access pattern aware state storage design and adapt it to Anna, a key-value store from academia to showcase a proof-of-concept that is ideal to store network function states. To foster further research in this area, we make our solution open-source.","publicationDate":"2020-08-09T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3401025.3401764","title":"research-article ","type":"Managing geo-distributed stream processing pipelines for the IIoT with StreamPipes edge extensions","venue":"DEBS '20: Proceedings of the 14th ACM International Conference on Distributed and Event-based Systems","authors":["Patrick Wiener","Philipp Zehnder","Dominik Riemer"],"abstract":"The industrial IoT and its promise to realize data-driven decision-making by analyzing industrial event streams is an important innovation driver in the industrial sector. Due to an enormous increase of generated data and the development of specialized hardware, new decentralized paradigms such as fog computing arised to overcome shortcomings of centralized cloud-only approaches. However, current undertakings are focused on static deployments of standalone services, which is insufficient for geo-distributed applications that are composed of multiple event-driven functions. In this paper, we present StreamPipes Edge Extensions (SEE), a novel contribution to the open source IIoT toolbox Apache StreamPipes. With SEE, domain experts are able to create stream processing pipelines in a graphical editor and to assign individual pipeline elements to available edge nodes, while underlying provisioning and deployment details are abstracted by the framework. The main contributions are (i) a fog cluster management model to represent computing node characteristics, (ii) a node controller for pipeline element life cycle management and (iii) a management framework to deploy event-driven functions to registered nodes. Our approach was validated in a real industrial setup showing low overall overhead of SEE as part of a robot-assisted product quality inspection use case.","publicationDate":"2020-07-12T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3359997.3365732","title":"abstract ","type":"Containerisation as a method for supporting multiple VR visualisation platforms from a single data source","venue":"VRCAI '19: The 17th International Conference on Virtual-Reality Continuum and its Applications in Industry","authors":["Theodor Wyeld","Haifeng Shen","Tomasz Bednarz"],"abstract":"This paper discusses a proof-of-concept context-aware container server for exposing multiple VR devices to a single data source. The data source was a real-time streamed reconstruction of a combat simulation generated in NetLogo. The devices included a mobile, tablet, PC, data wall, HMD and dataglove interaction. Each device had its specific requirements and user restrictions. Initial testing of this system suggests it is an efficient method for supporting diverse user needs whilst maintaining data integrity and synchronicity. The overall server architecture is discussed as well as future directions for this research.","publicationDate":"2019-11-13T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3465074.3465080","title":"research-article ","type":"Applied AI matters: AI4Code: applying artificial intelligence to source code","venue":"AI Matters","authors":["Kartik Talamadupula"],"abstract":"The marriage of Artificial Intelligence (AI) techniques to problems surrounding the generation, maintenance, and use of source code has come to the fore in recent years as an important AI application area1. A large chunk of this recent attention can be attributed to contemporaneous advancements in Natural Language Processing (NLP) techniques and sub-fields. The naturalness hypothesis, which states that \"software is a form of human communication\" and that code exhibits patterns that are similar to (human) natural languages (Devanbu, 2015; Hindle, Barr, Gabel, Su, & Devanbu, 2016), has allowed for the application of many of these NLP advances to code-centric usecases. This development has contributed to a spate of work in the community --- much of it captured in a survey by Allamanis, Barr, Devanbu, and Sutton (2018) that focuses on classifying these approaches by the type of probabilistic model applied to source code.This increase in the variety of AI techniques applied to source code has found various manifestations in the industry at large. Code and software form the backbone that underpins almost all modern technical advancements: it is thus natural that breakthroughs in this area should reflect in the emergence of real world deployments.","publicationDate":"2021-07-19T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3366424.3382670","title":"research-article ","type":"Data Aware Web-Assembly Function Placement","venue":"WWW '20: Companion Proceedings of the Web Conference 2020","authors":["Mayank Tiwary","Pritish Mishra","Shashank Jain","Deepak Puthal"],"abstract":"Existing container based serverless computing systems are limited by cold-start problems and complex architecture for stateful services, multi-tenancy, etc. This paper presents serverless functions to be placed as per data locality and executed as a web-assembly sandbox, which results better execution latency and reduced network usage as compared to the existing architectures. The designed serverless runtime features resource isolation in terms of CPU, Memory, and file-system isolation and falicitates multi-tenancy executions. The proposed architecture is evaluated using IoT workloads with different performance metrics.","publicationDate":"2020-04-19T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3328905.3332513","title":"poster ","type":"A Real-World Distributed Infrastructure for Processing Financial Data at Scale","venue":"DEBS '19: Proceedings of the 13th ACM International Conference on Distributed and Event-based Systems","authors":["Sebastian Frischbier","Mario Paic","Alexander Echler","Christian Roth"],"abstract":"Financial markets are event- and data-driven to an extremely high degree. For making decisions and triggering actions stakeholders require notifications about significant events and reliable background information that meet their individual requirements in terms of timeliness, accuracy, and completeness. As one of Europe's leading providers of financial data and regulatory solutions vwd: processes an average of 18 billion event notifications from 500+ data sources for 30 million symbols per day. Our large-scale distributed event-based systems handle daily peak rates of 1+ million event notifications per second and additional load generated by singular pivotal events with global impact.In this poster we give practical insights into our IT systems. We outline the infrastructure we operate and the event-driven architecture we apply at vwd. In particular we showcase the (geo)distributed publish/subscribe broker network we operate across locations and countries to provide market data to our customers with varying quality of information (QoI) properties.","publicationDate":"2019-06-23T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3383583.3398501","title":"tutorial ","type":"Introduction to Digital Libraries","venue":"JCDL '20: Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020","authors":["Edward A. Fox","William A. Ingram"],"abstract":"This tutorial is a thorough and deep introduction to the Digital Libraries (DL) field, providing a firm foundation: covering key concepts and terminology, as well as services, systems, technologies, methods, standards, projects, issues, and practices. It introduces and builds upon a firm theoretical foundation (starting with the '5S' set of intuitive aspects: Streams, Structures, Spaces, Scenarios, Societies), giving careful definitions and explanations of all the key parts of a 'minimal digital library', and expanding from that basis to cover key DL issues. Illustrations come from a set of case studies, including from multiple current projects, including with webpages, tweets, and social networks. Attendees will be exposed to four Morgan and Claypool books that elaborate on 5S, published 2012--2014. Complementing the coverage of 5S will be an overview of key aspects of the DELOS Reference Model and DL.org activities. Further, new material will be added on building digital libraries using container and cloud services, on developing a digital library for electronic theses and dissertations, and methods to integrate UX and DL design approaches.","publicationDate":"2020-07-31T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3377813.3381364","title":"research-article ","type":"The forgotten case of the dependency bugs: on the example of the robot operating system","venue":"ICSE-SEIP '20: Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering in Practice","authors":["Anders Fischer-Nielsen","Zhoulai Fu","Ting Su","Andrzej Wąsowski"],"abstract":"A dependency bug is a software fault that manifests itself when accessing an unavailable asset. Dependency bugs are pervasive and we all hate them. This paper presents a case study of dependency bugs in the Robot Operating System (ROS), applying mixed methods: a qualitative investigation of 78 dependency bug reports, a quantitative analysis of 1354 ROS bug reports against 19553 reports in the top 30 GitHub projects, and a design of three dependency linters evaluated on 406 ROS packages.The paper presents a definition and a taxonomy of dependency bugs extracted from data. It describes multiple facets of these bugs and estimates that as many as 15% (!) of all reported bugs are dependency bugs. We show that lightweight tools can find dependency bugs efficiently, although it is challenging to decide which tools to build and difficult to build general tools. We present the research problem to the community, and posit that it should be feasible to eradicate it from software development practice.","publicationDate":"2020-06-26T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3126908.3126933","title":"research-article ","type":"Topology-aware GPU scheduling for learning workloads in cloud environments","venue":"SC '17: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","authors":["Marcelo Amaral","Jordà Polo","David Carrera","Seetharami Seelam","Malgorzata Steinder"],"abstract":"Recent advances in hardware, such as systems with multiple GPUs and their availability in the cloud, are enabling deep learning in various domains including health care, autonomous vehicles, and Internet of Things. Multi-GPU systems exhibit complex connectivity among GPUs and between GPUs and CPUs. Workload schedulers must consider hardware topology and workload communication requirements in order to allocate CPU and GPU resources for optimal execution time and improved utilization in shared cloud environments.This paper presents a new topology-aware workload placement strategy to schedule deep learning jobs on multi-GPU systems. The placement strategy is evaluated with a prototype on a Power8 machine with Tesla P100 cards, showing speedups of up to ≈1.30x compared to state-of-the-art strategies; the proposed algorithm achieves this result by allocating GPUs that satisfy workload requirements while preventing interference. Additionally, a large-scale simulation shows that the proposed strategy provides higher resource utilization and performance in cloud systems.","publicationDate":"2017-11-11T23:00:00.000Z","citationCount":18},{"url":"https://dl.acm.org/doi/10.1145/3342280.3342341","title":"short-paper ","type":"λ-NIC: Interactive Serverless Compute on SmartNICs","venue":"SIGCOMM Posters and Demos '19: Proceedings of the ACM SIGCOMM 2019 Conference Posters and Demos","authors":["Sean Choi","Muhammad Shahbaz","Balaji Prabhakar","Mendel Rosenblum"],"abstract":"No abstract available.","publicationDate":"2019-08-18T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3132211.3132451","title":"demonstration ","type":"CIRCE - a runtime scheduler for DAG-based dispersed computing: demo","venue":"SEC '17: Proceedings of the Second ACM/IEEE Symposium on Edge Computing","authors":["Aleksandra Knezevic","Quynh Nguyen","Jason A. Tran","Pradipta Ghosh","Pranav Sakulkar","Bhaskar Krishnamachari","Murali Annavaram"],"abstract":"CIRCE (Centralized Runtime sChedulEr) is a runtime scheduling software tool for dispersed computing. It can deploy pipelined computations described in the form of a Directed Acyclic Graph (DAG) on multiple geographically dispersed compute nodes at the edge and in the cloud. A key innovation in this scheduler compared to prior work is the incorporation of a run-time network profiler which accounts for the network performance among nodes when scheduling. This demo will show an implementation of CIRCE deployed on a testbed of tens of nodes, from both an edge computing testbed and a geographically distributed cloud, with real-time evaluation of the task processing performance of different scheduling algorithms.","publicationDate":"2017-10-11T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3450623.3464680","title":"invited-talk ","type":"Cartoons in the Cloud","venue":"SIGGRAPH '21: ACM SIGGRAPH 2021 Talks","authors":["Yun Lien","Michael K. O'Brien","Laura Savidge"],"abstract":" The SparkShorts program at Pixar Animation Studios allows for directors to try new and different looks. Our short, Twenty Something is a 2d, hand-drawn animated film. When the pandemic forced all of our artist to work from home, we scrambled to create a workflow for managing, sharing, and reviewing 2d assets. While we have a long history of collaborating on 3d films, we did not have a solution for 2d imagery. We created a cloud-based pipeline based around on-premises bucket storage, microservices, and event-driven workflows. The result was Toontown, a suite of technologies that allowed our artists to complete Twenty Something working from home.","publicationDate":"2021-07-30T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1109/SEmotion.2019.00017","title":"research-article ","type":"Empirical analysis of affect of merged issues on GitHub","venue":"SEmotion '19: Proceedings of the 4th International Workshop on Emotion Awareness in Software Engineering","authors":["Marco Ortu","Michele Marchesi","Roberto Tonelli"],"abstract":"Pull-request based workflows are popular trends of modern software development platform such as GitHub. A pull-request notifies other developers that new changes are proposed, a code review process follows the pull-request that may be merged in the main branch if other developers accept the changes. Many factors influence the acceptance of pull-requests. Since open source software is based on collaboration, it is essential to discover how the affect expressed by developer discussing pull-request issues, namely how they collaborate, influences the acceptance of the pull-request proposed. In this study we analysed the relations with the affect expressed in pull-request issues' comments and whether an issue is merged in the main branch or not. We focused on pull-request issues and we found that issues with higher level anger, sadness, arousal and valence are less likely to be merged while issues with higher level of valence, joy are more likely to be merged. Positive affect indicates a good collaboration environment, and our finding shows that this healthy collaboration is likely to increase the acceptance of pull-requests.","publicationDate":"2019-05-27T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3126908.3126933","title":"research-article ","type":"Topology-aware GPU scheduling for learning workloads in cloud environments","venue":"SC '17: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","authors":["Marcelo Amaral","Jordà Polo","David Carrera","Seetharami Seelam","Malgorzata Steinder"],"abstract":"Recent advances in hardware, such as systems with multiple GPUs and their availability in the cloud, are enabling deep learning in various domains including health care, autonomous vehicles, and Internet of Things. Multi-GPU systems exhibit complex connectivity among GPUs and between GPUs and CPUs. Workload schedulers must consider hardware topology and workload communication requirements in order to allocate CPU and GPU resources for optimal execution time and improved utilization in shared cloud environments.This paper presents a new topology-aware workload placement strategy to schedule deep learning jobs on multi-GPU systems. The placement strategy is evaluated with a prototype on a Power8 machine with Tesla P100 cards, showing speedups of up to ≈1.30x compared to state-of-the-art strategies; the proposed algorithm achieves this result by allocating GPUs that satisfy workload requirements while preventing interference. Additionally, a large-scale simulation shows that the proposed strategy provides higher resource utilization and performance in cloud systems.","publicationDate":"2017-11-11T23:00:00.000Z","citationCount":18},{"url":"https://dl.acm.org/doi/10.1145/3274694.3274720","title":"research-article ","type":"A Measurement Study on Linux Container Security: Attacks and Countermeasures","venue":"ACSAC '18: Proceedings of the 34th Annual Computer Security Applications Conference","authors":["Xin Lin","Lingguang Lei","Yuewu Wang","Jiwu Jing","Kun Sun","Quan Zhou"],"abstract":"Linux container mechanism has attracted a lot of attention and is increasingly utilized to deploy industry applications. Though it is a consensus that the container mechanism is not secure due to the kernel-sharing property, it lacks a concrete and systematical evaluation on its security using real world exploits. In this paper, we collect an attack dataset including 223 exploits that are effective on the container platform, and classify them into different categories using a two-dimensional attack taxonomy. Then we evaluate the security of existing Linux container mechanism using 88 typical exploits filtered out from the dataset. We find 50 (56.82%) exploits can successfully launch attacks from inside the container with the default configuration. Since the privilege escalation exploits can completely disable the container protection mechanism, we conduct an in-depth analysis on these exploits. We find the kernel security mechanisms such as Capability, Seccomp, and MAC play a more important role in preventing privilege escalation than the container isolation mechanisms (i.e., Namespace and Cgroup). However, the interdependence and mutual-influence relationship among these kernel security mechanisms may make them fall into the \"short board effect\" and impair their protection capability. By studying the 11 exploits that still can successfully break the isolation provided by container and achieve privilege escalation, we identify a common 4-step attack model followed by all 11 exploits. Finally, we propose a defense mechanism to effectively defeat those identified privilege escalation attacks.","publicationDate":"2018-12-02T23:00:00.000Z","citationCount":19},{"url":"https://dl.acm.org/doi/10.1145/3305218.3305251","title":"research-article ","type":"AlloX: Allocation across Computing Resources for Hybrid CPU/GPU clusters","venue":"ACM SIGMETRICS Performance Evaluation Review","authors":["Tan N. Le","Xiao Sun","Mosharaf Chowdhury","Zhenhua Liu"],"abstract":"GPUs are considered as the accelerators for CPUs. We call these applications GPU applications. Some machine learning frameworks like Tensorflow support their machine learning (ML) jobs running either on CPUs or GPUs. Nvidia claims that Titan GPU K80 12GB can speed up 5-10x on average. Although GPUs offer the advantages on performance, they are very expensive. For example, a GPU K80 roughly costs $4000 while an Intel Xeon E5 Quad cores costs $350.The coexist of traditional CPU and GPU applications urges cloud computing operators to build hybrid CPU/GPU clusters. While the traditional applications are executed on CPUs, the GPU applications can run on either CPUs or GPUs. In the CPU/GPU clusters, how to provision the hybrid CPU/GPU clusters for CPU and GPU applications and how to allocate the resources across CPUs and GPUs?Interchangeable resources like CPUs and GPUs are not rare in large clusters. Some network I/O cards like wireless, ethernet, infinityband with different bandwidths can also be interchangeable.In this paper, we focus on CPU/GPU systems. We develop a tool that estimates the performance and resource for an ML job in an online manner (§2). We implement AlloX system that supports resource allocation and places applications on right resources (CPU or GPU) to maximize the use of computational resource (§3). The proposed AlloX policy achieves up to 35% progress improvement compared to default DRF [2]. We build a model that minimizes the total cost of ownership for CPU/GPU data centers (§4).","publicationDate":"2019-01-16T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3318216.3363325","title":"poster ","type":"A system for operating energy-aware cloudlets: demo","venue":"SEC '19: Proceedings of the 4th ACM/IEEE Symposium on Edge Computing","authors":["Thomas Rausch","Philipp Raith","Padmanabhan Pillai","Schahram Dustdar"],"abstract":"We present an end-to-end system for operating energy-aware cloudlets with a low-footprint cluster manager and an adaptive client-side load balancing approach. Our system is designed for small-scale high-density compute clusters that host stateless services and have stringent energy resource constraints. It features cluster and service management, runtime monitoring, adaptive load balancing and cluster reconfiguration policies. Furthermore, we present an experimentation and analytics system that allows coordinated execution of complex workload experiments to evaluate different operational strategies.","publicationDate":"2019-11-06T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3147213.3149210","title":"poster ","type":"Exploring the Potential of FreeBSD Virtualization in Containerized Environments","venue":"UCC '17: Proceedings of the10th International Conference on Utility and Cloud Computing","authors":["Francesc-Xavier Puig","J.J. Villalobos","Ivan Rodero","Manish Parashar"],"abstract":"Enterprise and Cloud environments are rapidly evolving with the use of lightweight virtualization mechanisms such as containers. Containerization allow users to deploy applications in any environment faster and more efficiently than using virtual machines. However, most of the work in this area focused on Linux-based containerization such as Docker and LXC and other mature solutions such as FreeBSD Jails have not been adopted by production-ready environments. In this work we explore the use of FreeBSD virtualization and provide a comparative study with respect to Linux containerization using Apache Spark. Preliminary results show that, while Linux containers provide better performance, FreeBSD solutions provide more stable and consistent results.","publicationDate":"2017-12-04T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3405837.3411395","title":"poster ","type":"A proof-of-concept 5G mobile gateway with eBPF","venue":"SIGCOMM '20: Proceedings of the SIGCOMM '20 Poster and Demo Sessions","authors":["Federico Parola","Sebastiano Miano","Fulvio Risso"],"abstract":"In this poster we propose the first proof-of-concept open-source implementation of a 5G Mobile Gateway based on eBPF/XDP and present benchmarks that compare its performance with alternative technologies. We show how it outperforms other in-kernel solutions (e.g., OvS) and is comparable with DPDK-based platforms.","publicationDate":"2020-08-09T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3342280.3342288","title":"short-paper ","type":"Towards Automated Inter-Service Authorization for Microservice Applications","venue":"SIGCOMM Posters and Demos '19: Proceedings of the ACM SIGCOMM 2019 Conference Posters and Demos","authors":["Xing Li","Yan Chen","Zhiqiang Lin"],"abstract":"","publicationDate":"2019-08-18T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3328433.3328435","title":"short-paper ","type":"The issue of monorepo and polyrepo in large enterprises","venue":"Programming '19: Proceedings of the Conference Companion of the 3rd International Conference on Art, Science, and Engineering of Programming","authors":["Nicolas Brousse"],"abstract":"Product and engineering teams' speed of producing high-quality results is critical to ensuring enterprise competitiveness. Additionally, one can observe an increase in IT systems complexity driven by the adoption of service-oriented architecture, micro-services, and serverless. Therefore, many large enterprises benefit from a mono-repository for source code management because of the improved team cognition that results from eroding barriers between teams and from influencing enhanced teamwork quality. This paper, first, reviews the characteristics of a multi-repositories structure, a mono-repository structure, and a hybrid model. Second, it discusses why some manage source code in a multi-repositories structure, either by choice or because of the organic evolution of large enterprises. Third, it reviews how mono-repositories in large teams, beyond the technical arguments, can drive high efficiency and enhanced product quality through improved team cognition.","publicationDate":"2019-03-31T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3412841.3442037","title":"research-article ","type":"SNAPPY: programmable kernel-level policies for containers","venue":"SAC '21: Proceedings of the 36th Annual ACM Symposium on Applied Computing","authors":["Maxime Bélair","Sylvie Laniepce","Jean-Marc Menaud"],"abstract":"Compared to full virtualization, containerization reduces virtualization overhead and resource usage, offers reduced deployment latency and improves reusability. For these reasons, containerization is massively used in an increasing number of applications.However, because containers share a full kernel with the host, they are more vulnerable to attacks that may compromise the host and the other containers on the system.In this paper, we present SNAPPY (Safe Namespaceable And Programmable PolicY), a new framework that allows even unprivileged processes such as containers to safely and dynamically enforce in the kernel fine-grained, stackable and programmable eBPF security policies at runtime. This is done by making working coordinately a new LSM (Linux Security Module) Module, a new security Linux namespace abstraction (policy_NS) and eBPF policies enriched with 'dynamic helpers'. This design especially allows to minimize containers' attack surface. Our design may be applied to any processes but is particularly suitable for container-based use cases.We show that SNAPPY can effectively increase the security level of containers for different use cases, can be easily integrated with the most relevant norms (OCI, Open Container Initiative) and containerization engines (Docker and runC) and has a performance overhead lower than 0.09% in realistic scenarios.","publicationDate":"2021-03-21T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3332186.3332244","title":"research-article ","type":"Leveraging Public Cloud Services for CLIA-Certified Personalized Medicine Pipelines","venue":"PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning)","authors":["Evan F. Bollig","Christine Henzler","Ham C. Lam","Sarah A. Munro","Rebecca LaRue","Getiria Onsongo","Sophia Yohe","Andrew C. Nelson","Matthew Bower","Matthew Schomaker","Bharat Thyagarajan"],"abstract":"Dating back to 2012, a joint effort between Fairview Hospital's Molecular Diagnostic Lab and the Minnesota Supercomputing Institute introduced the Next-Generation Sequencing Diagnostic Pipeline (NGSDP) [17, 20], a novel cloud-based analysis pipeline that was validated for clinical use to be compliant with the Clinical Laboratory Improvement Amendments (CLIA). Since then, the partnership has grown the portfolio of active pipelines to seven, and expanded the available gene panels to over 6700 genes. Likewise, the design of the backing cloud infrastructure has been significantly overhauled for efficiency, scalability, automation, and fault tolerance.This document introduces our revised cloud-native, scheduled infrastructure solution for containerized applications. The cloud-native infrastructure, deployed on Amazon Web Services, has two core components: a compute cluster of virtual machines, and a simple queue-based job scheduler. The cluster runs analysis pipelines packaged as Docker containers; each with their own resource requirements. The scheduler, akin to products for traditional HPC, allows batch submission of patient samples with a persistent job queue. The scheduler also orchestrates cluster scale-out and -in to match job needs in an effort to minimize idle servers and reduce the cost of computing on a public cloud.Our solution has been successfully running as CLIA-validated pipelines since 2016. Two variants of the solution are presented to address the need for such architecture in both the traditional public cloud space, as well as in Amazon's GovCloud where fewer cloud services are available to handle sensitive or controlled-access data. Furthermore, the innovative solution is driven by a traditional research computing environment; details of which are presented with emphasis on security, monitoring, and user workflow.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3171583","title":"research-article ","type":"Going serverless","venue":"Communications of the ACM","authors":["Neil Savage"],"abstract":"Serverless computing lets businesses and application developers focus on the program they need to run, without worrying about the machine on which it runs, or the resources it requires.","publicationDate":"2018-01-22T23:00:00.000Z","citationCount":11},{"url":"https://dl.acm.org/doi/10.1145/2950290.2950328","title":"research-article ","type":"A discrete-time feedback controller for containerized cloud applications","venue":"FSE 2016: Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering","authors":["Luciano Baresi","Sam Guinea","Alberto Leva","Giovanni Quattrocchi"],"abstract":" Modern Web applications exploit Cloud infrastructures to scale their resources and cope with sudden changes in the workload. While the state of practice is to focus on dynamically adding and removing virtual machines, we advocate that there are strong benefits in containerizing the applications and in scaling the containers.  In this paper we present an autoscaling technique that allows containerized applications to scale their resources both at the VM level and at the container level. Furthermore, applications can combine this infrastructural adaptation with platform-level adaptation. The autoscaling is made possible by our planner, which consists of a grey-box discrete-time feedback controller.  The work has been validated using two application benchmarks deployed to Amazon EC2. Our experiments show that our planner outperforms Amazon's AutoScaling by 78% on average without containers; and that the introduction of containers allows us to improve by yet another 46% on average. ","publicationDate":"2016-10-31T23:00:00.000Z","citationCount":42},{"url":"https://dl.acm.org/doi/10.1145/3299869.3314045","title":"research-article ","type":"Apache Hive: From MapReduce to Enterprise-grade Big Data Warehousing","venue":"SIGMOD '19: Proceedings of the 2019 International Conference on Management of Data","authors":["Jesús Camacho-Rodríguez","Ashutosh Chauhan","Alan Gates","Eugene Koifman","Owen O'Malley","Vineet Garg","Zoltan Haindrich","Sergey Shelukhin","Prasanth Jayachandran","Siddharth Seth","Deepak Jaiswal","Slim Bouguerra","Nishant Bangarwa","Sankar Hariappan","Anishek Agarwal","Jason Dere","Daniel Dai","Thejas Nair","Nita Dembla","Gopal Vijayaraghavan","Günther Hagleitner"],"abstract":"Apache Hive is an open-source relational database system for analytic big-data workloads. In this paper we describe the key innovations on the journey from batch tool to fully fledged enterprise data warehousing system. We present a hybrid architecture that combines traditional MPP techniques with more recent big data and cloud concepts to achieve the scale and performance required by today's analytic applications. We explore the system by detailing enhancements along four main axis: Transactions, optimizer, runtime, and federation. We then provide experimental results to demonstrate the performance of the system for typical workloads and conclude with a look at the community roadmap.","publicationDate":"2019-06-24T22:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3422392.3422480","title":"research-article ","type":"Teaching Development of Distributed Software during COVID-19: An experience report in Brazil","venue":"SBES '20: Proceedings of the 34th Brazilian Symposium on Software Engineering","authors":["Fernando Trinta","Paulo A. L. Rego","Windson Viana"],"abstract":"In 2020, the COVID-19 pandemic affected all sectors of society worldwide, including education. Due to the social isolation requirement, several educational institutions used the Emergency Remote Teaching (ERT) approach to keep their courses active, at least partially. This document provides an experience report about using ERT in two courses (Distributed Systems and Software Development for the Cloud) that deal with the Development of Distributed Software Systems. In these two courses, we used three main approaches: synchronous online classes, asynchronous learning videos, and online material available on a Git repository. In some classes, we also adopted active methodologies such as problem-based learning and flipped classroom. Students were evaluated by seminars, tests, and programming activities. In the end, we collected their feedback from an online survey. Forty-two (42) graduate and undergraduate students reported a good level of acceptance of our ERT model. Part of the students had difficulties in doing their programming homework, and the main obstacles reported by them were: (i) their psychological context and (ii) to reconcile the course activities with home tasks as well as the demands of their jobs. Once practical experiences in ERT will be essential for a while given the uncertainty about how long COVID-19 pandemic will remain active, we expect the highlights and drawbacks of our experience could help other professors in planning their courses.","publicationDate":"2020-10-20T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.14778/3407790.3407836","title":"research-article ","type":"Cloudburst: stateful functions-as-a-service","venue":"Proceedings of the VLDB Endowment","authors":["Vikram Sreekanti","Chenggang Wu","Xiayue Charles Lin","Johann Schleier-Smith","Joseph E. Gonzalez","Joseph M. Hellerstein","Alexey Tumanov"],"abstract":"Function-as-a-Service (FaaS) platforms and \"serverless\" cloud computing are becoming increasingly popular due to ease-of-use and operational simplicity. Current FaaS offerings are targeted at stateless functions that do minimal I/O and communication. We argue that the benefits of serverless computing can be extended to a broader range of applications and algorithms while maintaining the key benefits of existing FaaS offerings. We present the design and implementation of Cloudburst, a stateful FaaS platform that provides familiar Python programming with low-latency mutable state and communication, while maintaining the autoscaling benefits of serverless computing. Cloudburst accomplishes this by leveraging Anna, an autoscaling key-value store, for state sharing and overlay routing combined with mutable caches co-located with function executors for data locality. Performant cache consistency emerges as a key challenge in this architecture. To this end, Cloudburst provides a combination of lattice-encapsulated state and new definitions and protocols for distributed session consistency. Empirical results on benchmarks and diverse applications show that Cloudburst makes stateful functions practical, reducing the state-management overheads of current FaaS platforms by orders of magnitude while also improving the state of the art in serverless consistency.","publicationDate":"2020-06-30T22:00:00.000Z","citationCount":16},{"url":"https://dl.acm.org/doi/10.1145/3460231.3474604","title":"abstract ","type":"You Do Not Need a Bigger Boat: Recommendations at Reasonable Scale in a (Mostly) Serverless and Open Stack","venue":"RecSys '21: Fifteenth ACM Conference on Recommender Systems","authors":["Jacopo Tagliabue"],"abstract":" We argue that immature data pipelines are preventing a large portion of industry practitioners from leveraging the latest research on recommender systems. We propose our template data stack for machine learning at “reasonable scale”, and show how many challenges are solved by embracing a serverless paradigm. Leveraging our experience, we detail how modern open source tools can provide a pipeline processing terabytes of data with minimal infrastructure work.","publicationDate":"2021-09-12T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3360468.3366781","title":"extended-abstract ","type":"Exploiting content similarity to address cold start in container deployments","venue":"CoNEXT '19 Companion: Proceedings of the 15th International Conference on emerging Networking EXperiments and Technologies","authors":["Kunal Mahajan","Saket Mahajan","Vishal Misra","Dan Rubenstein"],"abstract":"Serverless computing is an emerging Cloud paradigm that allows users to claim and pay for resources only when their jobs are executing. While this paradigm offers several advantages, the phenomenon of \"cold start\" reduces its inherent efficiency with respect to the utilization of compute, storage and network resources that support its existing virtualization deployment systems. We analyze current modes of deployment and identify data similarities across applications. Based on these observations, we propose a new deployment system that is built atop a peer-to-peer network, virtual file-system and content-addressable storage, which will increase compute availability, reduce storage requirement, and prevent network bottlenecks.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3328905.3332506","title":"poster ","type":"Benchmarking Financial Data Feed Systems","venue":"DEBS '19: Proceedings of the 13th ACM International Conference on Distributed and Event-based Systems","authors":["Manuel Coenen","Christoph Wagner","Alexander Echler","Sebastian Frischbier"],"abstract":"Data-driven solutions for the investment industry require event-based backend systems to process high-volume financial data feeds with low latency, high throughput, and guaranteed delivery modes.At vwd we process an average of 18 billion incoming event notifications from 500+ data sources for 30 million symbols per day and peak rates of 1+ million notifications per second using custom-built platforms that keep audit logs of every event.We currently assess modern open source event-processing platforms such as Kafka, NATS, Redis, Flink or Storm for the use in our ticker plant to reduce the maintenance effort for cross-cutting concerns and leverage hybrid deployment models. For comparability and repeatability we benchmark candidates with a standardized workload we derived from our real data feeds.We have enhanced an existing light-weight open source benchmarking tool in its processing, logging, and reporting capabilities to cope with our workloads. The resulting tool wrench can simulate workloads or replay snapshots in volume and dynamics like those we process in our ticker plant. We provide the tool as open source.As part of ongoing work we contribute details on (a) our workload and requirements for benchmarking candidate platforms for financial feed processing; (b) the current state of the tool wrench.","publicationDate":"2019-06-23T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/2830903.2830913","title":"invited-talk ","type":"The rise of cloud computing systems","venue":"SOSP '15: SOSP History Day 2015","authors":["Jeff Dean"],"abstract":"In this talk I will describe the development of systems that underlie modern cloud computing systems. This development shares much of its motivation with the related fields of transaction processing systems and high performance computing, but because of scale, these systems tend to have more emphasis on fault tolerance using software techniques. Important developments in the development of modern cloud systems include very high performance distributed file system, such as the Google File System (Ghemawat et al., SOSP 2003), reliable computational frameworks such as MapReduce (Dean & Ghemawat, OSDI 2004) and Dryad (Isard et al., 2007), and large scale structured storage systems such as BigTable (Chang et al. 2006), Dynamo (DeCandia et al., 2007), and Spanner (Corbett et al., 2012). Scheduling computations can either be done using virtual machines (exemplified by VMWare's products), or as individual processes or containers. The development of public cloud platforms such as AWS, Microsoft Azure, and Google Cloud Platform, allow external developers to utilize these large-scale services to build new and interesting services and products, benefiting from the economies of scale of large datacenters and the ability to grow and shrink computing resources on demand across millions of customers.","publicationDate":"2015-10-03T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3339363.3339369","title":"research-article ","type":"Design and Implementation of B2B E-commerce Platform Based on Microservices Architecture","venue":"CSSE 2019: Proceedings of the 2nd International Conference on Computer Science and Software Engineering","authors":["Meng Wu","Xiangqian Ding","Ruichun Hou"],"abstract":"\"Government Work 2018\" report proposed the development of industrial Internet, manufacturing industry transformation driving B2B transformation. In recent years, the concept of industry 4.0 and B2B Industry Internet have developed in coordination, and the accelerated transformation of manufacturing industry has also ushered in a new service concept for B2B industry. In order to meet the increasing demand of business expansion and concurrency performance of modern e-commerce platform, we propose a B2B e-commerce platform based on microservices and Spring Cloud [1] is used as the basic framework of microservices.","publicationDate":"2019-05-23T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3204949.3208112","title":"demonstration ","type":"Fast and easy live video service setup using lightweight virtualization","venue":"MMSys '18: Proceedings of the 9th ACM Multimedia Systems Conference","authors":["Antti Heikkinen","Pekka Pääkkönen","Marko Viitanen","Jarno Vanne","Tommi Riikonen","Kagan Bakanoglu"],"abstract":"The service broker provides service providers with virtualized services that can be initialized rapidly and scaled up or down on demand. This demonstration paper describes how a service provider can set up a new video distribution service to end users with a diminutive effort. Our proposal makes use of Docker lightweight virtualization technologies that pack services in containers. This makes it possible to implement video coding and content delivery networks that are scalable and consume resources only when needed. The demonstration showcases a scenario where a video service provider sets up a new live video distribution service to end users. After the setup, live 720p30 video camera feed is encoded in real-time, streamed in HEVC MPEG-DASH format over CDN network, and accessed with a HbbTV compatible set-top-box. This end-to-end system illustrates that virtualization causes no significant resource or performance overhead but is a perfect match for online video services.","publicationDate":"2018-06-11T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3460319.3464796","title":"research-article ","type":"Finding data compatibility bugs with JSON subschema checking","venue":"ISSTA 2021: Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis","authors":["Andrew Habib","Avraham Shinnar","Martin Hirzel","Michael Pradel"],"abstract":"JSON is a data format used pervasively in web APIs, cloud computing, NoSQL databases, and increasingly also machine learning. To ensure that JSON data is compatible with an application, one can define a JSON schema and use a validator to check data against the schema. However, because validation can happen only once concrete data occurs during an execution, it may detect data compatibility bugs too late or not at all. Examples include evolving the schema for a web API, which may unexpectedly break client applications, or accidentally running a machine learning pipeline on incorrect data. This paper presents a novel way of detecting a class of data compatibility bugs via JSON subschema checking. Subschema checks find bugs before concrete JSON data is available and across all possible data specified by a schema. For example, one can check if evolving a schema would break API clients or if two components of a machine learning pipeline have incompatible expectations about data. Deciding whether one JSON schema is a subschema of another is non-trivial because the JSON Schema specification language is rich. Our key insight to address this challenge is to first reduce the richness of schemas by canonicalizing and simplifying them, and to then reason about the subschema question on simpler schema fragments using type-specific checkers. We apply our subschema checker to thousands of real-world schemas from different domains. In all experiments, the approach is correct whenever it gives an answer (100% precision and correctness), which is the case for most schema pairs (93.5% recall), clearly outperforming the state-of-the-art tool. Moreover, the approach reveals 43 previously unknown bugs in popular software, most of which have already been fixed, showing that JSON subschema checking helps finding data compatibility bugs early.","publicationDate":"2021-07-10T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3267809.3267819","title":"research-article ","type":"Stratus: cost-aware container scheduling in the public cloud","venue":"SoCC '18: Proceedings of the ACM Symposium on Cloud Computing","authors":["Andrew Chung","Jun Woo Park","Gregory R. Ganger"],"abstract":"Stratus is a new cluster scheduler specialized for orchestrating batch job execution on virtual clusters, dynamically allocated collections of virtual machine instances on public IaaS platforms. Unlike schedulers for conventional clusters, Stratus focuses primarily on dollar cost considerations, since public clouds provide effectively unlimited, highly heterogeneous resources allocated on demand. But, since resources are charged-for while allocated, Stratus aggressively packs tasks onto machines, guided by job runtime estimates, trying to make allocated resources be either mostly full (highly utilized) or empty (so they can be released to save money). Simulation experiments based on cluster workload traces from Google and TwoSigma show that Stratus reduces cost by 17-44% compared to state-of-the-art approaches to virtual cluster scheduling.","publicationDate":"2018-10-10T22:00:00.000Z","citationCount":22},{"url":"https://dl.acm.org/doi/10.1145/3204949.3208112","title":"demonstration ","type":"Fast and easy live video service setup using lightweight virtualization","venue":"MMSys '18: Proceedings of the 9th ACM Multimedia Systems Conference","authors":["Antti Heikkinen","Pekka Pääkkönen","Marko Viitanen","Jarno Vanne","Tommi Riikonen","Kagan Bakanoglu"],"abstract":"The service broker provides service providers with virtualized services that can be initialized rapidly and scaled up or down on demand. This demonstration paper describes how a service provider can set up a new video distribution service to end users with a diminutive effort. Our proposal makes use of Docker lightweight virtualization technologies that pack services in containers. This makes it possible to implement video coding and content delivery networks that are scalable and consume resources only when needed. The demonstration showcases a scenario where a video service provider sets up a new live video distribution service to end users. After the setup, live 720p30 video camera feed is encoded in real-time, streamed in HEVC MPEG-DASH format over CDN network, and accessed with a HbbTV compatible set-top-box. This end-to-end system illustrates that virtualization causes no significant resource or performance overhead but is a perfect match for online video services.","publicationDate":"2018-06-11T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3419944.3440727","title":"research-article ","type":"Centralizing Server and Workstation Provisioning, Configuration, and Management with Foreman and Puppet.","venue":"SIGUCCS '21: ACM SIGUCCS Annual Conference","authors":["Kyle Vonblohn"],"abstract":"As a lone system administrator, efficiency is key. As our Computer Science and Digital Forensics programs grew, and student enrollment continued to increase, one thing became clear: I needed a better way to control the provision / configure / management lifecycle of our servers and workstations. This paper will chronicle the journey from several disparate systems to a single console capable of managing the entire lifecycle of both servers and workstations. From Zero-touch provisioning of bare metal and virtual machines, to ensuring up-to-date configurations, as well as software deployment across both Windows and Linux systems alike.","publicationDate":"2021-03-11T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3213763","title":"opinion ","type":"Is software the result of top-down intelligent design or evolution?","venue":"Communications of the ACM","authors":["Edward A. Lee"],"abstract":"Considering the potential danger to individuals of rapid coevolution.","publicationDate":"2018-08-21T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3104028","title":"research-article ","type":"Architectural Principles for Cloud Software","venue":"ACM Transactions on Internet Technology","authors":["Claus Pahl","Pooyan Jamshidi","Olaf Zimmermann"],"abstract":"A cloud is a distributed Internet-based software system providing resources as tiered services. Through service-orientation and virtualization for resource provisioning, cloud applications can be deployed and managed dynamically. We discuss the building blocks of an architectural style for cloud-based software systems. We capture style-defining architectural principles and patterns for control-theoretic, model-based architectures for cloud software. While service orientation is agreed on in the form of service-oriented architecture and microservices, challenges resulting from multi-tiered, distributed and heterogeneous cloud architectures cause uncertainty that has not been sufficiently addressed. We define principles and patterns needed for effective development and operation of adaptive cloud-native systems.","publicationDate":"2018-02-01T23:00:00.000Z","citationCount":40},{"url":"https://dl.acm.org/doi/10.1145/2949689.2949700","title":"demonstration ","type":"SciServer Compute: Bringing Analysis Close to the Data","venue":"SSDBM '16: Proceedings of the 28th International Conference on Scientific and Statistical Database Management","authors":["Dmitry Medvedev","Gerard Lemson","Mike Rippin"],"abstract":"SciServer Compute uses Jupyter notebooks running within server-side Docker containers attached to large relational databases and file storage to bring advanced analysis capabilities close to the data. SciServer Compute is a component of SciServer, a big-data infrastructure project developed at Johns Hopkins University that will provide a common environment for computational research.SciServer Compute integrates with large existing databases in the fields of astronomy, cosmology, turbulence, genomics, oceanography and materials science. These are accessible through the CasJobs service for direct SQL queries. SciServer Compute adds interactive server-side computational capabilities through notebooks in Python, R and MATLAB, an API for running asynchronous tasks, and a very large (hundreds of terabytes) scratch space for storing intermediate results. Science-ready results can be stored on a Dropbox-like service, SciDrive, for sharing with collaborators and dissemination to the public. Notebooks and batch jobs run inside Docker containers owned by the users. This provides security and isolation and allows flexible configuration of computational contexts through domain specific images and mounting of domain specific data sets.We present a demo that illustrates the capabilities of SciServer Compute: using Jupyter notebooks, performing analyses on data selections from diverse scientific fields, and running asynchronous jobs in a Docker container. The demo will highlight the data flow between file storage, database, and compute components.","publicationDate":"2016-07-17T22:00:00.000Z","citationCount":11},{"url":"https://dl.acm.org/doi/10.1145/3447786.3456239","title":"research-article ","type":"OFC: an opportunistic caching system for FaaS platforms","venue":"EuroSys '21: Proceedings of the Sixteenth European Conference on Computer Systems","authors":["Djob Mvondo","Mathieu Bacou","Kevin Nguetchouang","Lucien Ngale","Stéphane Pouget","Josiane Kouam","Renaud Lachaize","Jinho Hwang","Tim Wood","Daniel Hagimont","Noël De Palma","Bernabé Batchakui","Alain Tchana"],"abstract":"Cloud applications based on the \"Functions as a Service\" (FaaS) paradigm have become very popular. Yet, due to their stateless nature, they must frequently interact with an external data store, which limits their performance. To mitigate this issue, we introduce OFC, a transparent, vertically and horizontally elastic in-memory caching system for FaaS platforms, distributed over the worker nodes. OFC provides these benefits cost-effectively by exploiting two common sources of resource waste: (i) most cloud tenants overprovision the memory resources reserved for their functions because their footprint is non-trivially input-dependent and (ii) FaaS providers keep function sandboxes alive for several minutes to avoid cold starts. Using machine learning models adjusted for typical function input data categories (e.g., multimedia formats), OFC estimates the actual memory resources required by each function invocation and hoards the remaining capacity to feed the cache. We build our OFC prototype based on enhancements to the OpenWhisk FaaS platform, the Swift persistent object store, and the RAM-Cloud in-memory store. Using a diverse set of workloads, we show that OFC improves by up to 82 % and 60 % respectively the execution time of single-stage and pipelined functions.","publicationDate":"2021-04-20T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3300061.3345431","title":"research-article ","type":"vrAIn: A Deep Learning Approach Tailoring Computing and Radio Resources in Virtualized RANs","venue":"MobiCom '19: The 25th Annual International Conference on Mobile Computing and Networking","authors":["Jose A. Ayala-Romero","Andres Garcia-Saavedra","Marco Gramaglia","Xavier Costa-Perez","Albert Banchs","Juan J. Alcaraz"],"abstract":"The virtualization of radio access networks (vRAN) is the last milestone in the NFV revolution. However, the complex dependencies between computing and radio resources make vRAN resource control particularly daunting. We present vrAIn, a dynamic resource controller for vRANs based on deep reinforcement learning. First, we use an autoencoder to project high-dimensional context data (traffic and signal quality patterns) into a latent representation. Then, we use a deep deterministic policy gradient (DDPG) algorithm based on an actor-critic neural network structure and a classifier to map (encoded) contexts into resource control decisions. We have implemented vrAIn using an open-source LTE stack over different platforms. Our results show that vrAIn successfully derives appropriate compute and radio control actions irrespective of the platform and context: (i) it provides savings in computational capacity of up to 30% over CPU-unaware methods; (ii) it improves the probability of meeting QoS targets by 25% over static allocation policies using similar CPU resources in average; (iii) upon CPU capacity shortage, it improves throughput performance by 25% over state-of-the-art schemes; and (iv) it performs close to optimal policies resulting from an offline oracle. To the best of our knowledge, this is the first work that thoroughly studies the computational behavior of vRANs, and the first approach to a model-free solution that does not need to assume any particular vRAN platform or system conditions.","publicationDate":"2019-10-10T22:00:00.000Z","citationCount":21},{"url":"https://dl.acm.org/doi/10.1145/3229710.3229744","title":"short-paper ","type":"BAUSPACE: A Scalable Infrastructure for Soft Sensors Development","venue":"ICPP '18: Proceedings of the 47th International Conference on Parallel Processing Companion","authors":["Daniel Hernández","Francisco Arcas-Túnez","Andrés Muñoz","José M. Cecilia"],"abstract":"The Internet of Things (IoT) is driving the next economic revolution where the main actors are both the data volume and the immediacy. However, the IoT world is increasingly generating vast amounts of data classified as a \"dark data\", since most of them are generated but never analysed. Therefore, efficient big data analysis in IoT infrastructure is becoming mandatory to transform this data deluge into meaningful information. Even after enabling this analysis, the quantitative information provided by traditional \"hard\" sensors is not enough to deal with some scenarios where human observations are required. These observations could be targeted through \"soft sensors\", where people's opinion in social networks, posts, news or comments may be analyzed to create dynamic observation resources. Combining both sources-of-information (devices and humans) automatically would provide a very powerful tool that could represent a step forward in the data understanding science. However, the development of soft sensors implies the use of many services for crawling text sources and mashup Web-based content, storage it, understanding the language or inferring information, just to mention a few. Therefore, a novel cloud-based distributed system is mandatory to be able to develop such frameworks. In this paper we introduce a work-in-progress for a distributed and modular framework to develop soft sensors in a scalable manner and transparently to the cloud provider.","publicationDate":"2018-08-12T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3231104.3231106","title":"short-paper ","type":"Partisan: Enabling Real-World Protocol Evaluation","venue":"ApPLIED '18: Proceedings of the 2018 Workshop on Advanced Tools, Programming Languages, and PLatforms for Implementing and Evaluating Algorithms for Distributed systems","authors":["Christopher S. Meiklejohn"],"abstract":"We present the design and implementation of Partisan, an Erlang library for enabling real-world experiments of dis- tributed protocols and applications. Partisan is a \\batteries- included\"library facilitating internode communication in Er- lang, runtime selection of cluster topology, pluggable layers that provide additional functionality such as causal delivery and reliable message delivery, and a mechanism for perform- ing deterministic fault injection. Partisan has been used in the evaluation of one research prototype, two real-world ap- plications, and has seen industry adoption in the Erlang and Elixir communities.","publicationDate":"2018-07-22T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3287299","title":"research-article ","type":"SQL is no excuse to avoid DevOps","venue":"Communications of the ACM","authors":["Thomas A. Limoncelli"],"abstract":"Automation and a little discipline allow better testing, shorter release cycles, and reduced business risk.","publicationDate":"2018-12-18T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3291276.3300018","title":"column ","type":"SQL is No Excuse to Avoid DevOps: Automation and a little discipline allow better testing, shorter release cycles, and reduced business risk.","venue":"Queue","authors":["Thomas A. Limoncelli"],"abstract":"Using SQL databases is not an impediment to doing DevOps. Automating schema management and a little developer discipline enables more vigorous and repeatable testing, shorter release cycles, and reduced business risk. When you can confidently deploy new releases, you do it more frequently. New features that previously sat unreleased for weeks or months now reach users sooner. Bugs are fixed faster. Security holes are closed sooner. It enables the company to provide better value to customers.","publicationDate":"2018-09-30T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3241403.3241448","title":"short-paper ","type":"Guaranteed latency applications in edge-cloud environment","venue":"ECSA '18: Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings","authors":["Petr Hnetynka","Petr Kubat","Rima Al-Ali","Ilias Gerostathopoulos","Danylo Khalyeyev"],"abstract":"Modern Cyber-Physical Systems combine distributed embedded devices with computation in cloud. The inclusion of cloud increases the smartness of the systems by allowing computationally-and data-intensive tasks such as complex data analytics, optimization and decision making, learning and predictions. However, an important implication of interacting with the physical world is the presence of real-time requirements. It puts the cloud in the loop and requires the cloud to participate in the overall real-time guarantees, which poses a difficult problem. In this paper, we address the problem of providing real-time guarantees (in particular statistical guarantees on response time) by combining edge-cloud processing with runtime performance awareness and adaptation.","publicationDate":"2018-09-23T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3083187.3083227","title":"demonstration ","type":"Unified Remix: a Server Side Solution for Adaptive Bit-Rate Streaming with Inserted and Edited Media Content","venue":"MMSys'17: Proceedings of the 8th ACM on Multimedia Systems Conference","authors":["Arjen Wagenaar","Dirk Griffioen","Rufael Mekuria"],"abstract":"We present Unified Remix, our solution for adaptive bit-rate streaming of video presentations with inserted or edited content. The solution addresses three important challenges encountered when streaming personalized media presentations. First, it reduces vulnerability to ad blocking technologies and client-side playback deviations encountered when using manifest manipulation based methods. Second, it reduces storage and computational costs associated with alternative server side solutions such as brute force re-encoding or duplicate storage towards levels comparable to linear video streaming (VoD or Live). Third, it handles the multi-source, multi-DRM and multi-protocol aspects for modern video streaming natively in the workflow. The solution is based on a combination of existing proven streaming technologies such as Unified Origin and newly designed components such as the Remix MPEG-4 module. The framework uses standardized technologies such as MPEG-4 ISOBMFF, SMIL and MPEG-DASH. The components work together in a micro service architecture enabling flexible deployment using a (container) orchestration framework on premises or in the cloud. The solution is demonstrated in two use cases: content pre-/post/mid roll and Live Archive to VoD conversion. As many use cases can be implemented based upon Unified Remix, we envision it as a key component of professional video streaming platforms.","publicationDate":"2017-06-19T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3328905.3334135","title":"brief-report ","type":"The DEBS 2019 Grand Challenge","venue":"DEBS '19: Proceedings of the 13th ACM International Conference on Distributed and Event-based Systems","authors":["Oleh Bodunov","Vincenzo Gulisano","Hannaneh Najdataei","Zbigniew Jerzak","André Martin","Pavel Smirnov","Martin Strohbach","Holger Ziekow"],"abstract":"The ACM DEBS 2019 Grand Challenge is the ninth in a series of challenges which seek to provide a common ground and evaluation criteria for a competition aimed at both research and industrial event-based systems. The focus of the 2019 Grand Challenge is on the application of machine learning to LiDAR data. The goal of the challenge is to perform classification of objects found in urban environments and sensed in several 3D scenes by the LiDAR. The applications of LIDAR and object detection go well beyond autonomous vehicles and are suitable for use in agriculture, waterway maintenance and flood prevention, and construction. This paper describes the specifics of the data streams provided in the challenge as well as the benchmarking platform that supports the testing of corresponding solutions.","publicationDate":"2019-06-23T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3318464.3384688","title":"short-paper ","type":"PROUD: PaRallel OUtlier Detection for Streams","venue":"SIGMOD '20: Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data","authors":["Theodoros Toliopoulos","Christos Bellas","Anastasios Gounaris","Apostolos Papadopoulos"],"abstract":"We introduce PROUD, standing for PaRallel OUtlier Detection for streams, which is an extensible engine for continuous multi-parameter parallel distance-based outlier (or anomaly) detection tailored to big data streams. PROUD is built on top of Flink. It defines a simple API for data ingestion. It supports a variety of parallel techniques, including novel ones, for continuous outlier detection that can be easily configured. In addition, it graphically reports metrics of interest and stores main results into a permanent store to enable future analysis. It can be easily extended to support additional techniques. Finally, it is publicly provided in open-source.","publicationDate":"2020-06-10T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3286490.3286562","title":"extended-abstract ","type":"Object Storage for Deep Learning Frameworks","venue":"DIDL '18: Proceedings of the Second Workshop on Distributed Infrastructures for Deep Learning","authors":["Or Ozeri","Effi Ofer","Ronen Kat"],"abstract":"The advent of big datasets and high speed GPUs is fueling the growth in machine and deep learning techniques. In this paper we explore storing the training data in object storage and demonstrate how this can be done effectively while providing sufficient throughput to high performance GPUs.","publicationDate":"2018-12-09T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3342195.3387555","title":"research-article ","type":"Balancing efficiency and fairness in heterogeneous GPU clusters for deep learning","venue":"EuroSys '20: Proceedings of the Fifteenth European Conference on Computer Systems","authors":["Shubham Chaudhary","Ramachandran Ramjee","Muthian Sivathanu","Nipun Kwatra","Srinidhi Viswanatha"],"abstract":"We present Gandivafair, a distributed, fair share scheduler that balances conflicting goals of efficiency and fairness in GPU clusters for deep learning training (DLT). Gandivafair provides performance isolation between users, enabling multiple users to share a single cluster, thus, maximizing cluster efficiency. Gandivafair is the first scheduler that allocates cluster-wide GPU time fairly among active users.Gandivafair achieves efficiency and fairness despite cluster heterogeneity. Data centers host a mix of GPU generations because of the rapid pace at which newer and faster GPUs are released. As the newer generations face higher demand from users, older GPU generations suffer poor utilization, thus reducing cluster efficiency. Gandivafair profiles the variable marginal utility across various jobs from newer GPUs, and transparently incentivizes users to older GPUs by a novel resource trading mechanism that maximizes cluster efficiency without affecting fairness guarantees of any user. With a prototype implementation and evaluation in a heterogeneous 200-GPU cluster, we show that Gandivafair achieves both fairness and efficiency under realistic multi-user workloads.","publicationDate":"2020-04-14T22:00:00.000Z","citationCount":14},{"url":"https://dl.acm.org/doi/10.1145/3468264.3468575","title":"research-article ","type":"Automating serverless deployments for DevOps organizations","venue":"ESEC/FSE 2021: Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering\n\t\t\t\t\n                    Automating Serverless Deployments for DevOps Organizations: Root Artifact\n                \n            ","authors":["Daniel Sokolowski","Pascal Weisenburger","Guido Salvaneschi"],"abstract":"DevOps unifies software development and operations in cross-functional teams to improve software delivery and operations (SDO) performance. Ideally, cross-functional DevOps teams independently deploy their services, but the correct operation of a service often demands other services, requiring coordination to ensure the correct deployment order. This issue is currently solved either with a central deployment or manual out-of-band communication across teams, e.g., via phone, chat, or email. Unfortunately, both contradict the independence of teams, hindering SDO performance—the reason why DevOps is adopted in the first place. In this work, we conduct a study on 73 IT professionals, showing that, in practice, they resort to manual coordination for correct deployments even if they expect better SDO performance with fully automated approaches. To address this issue, we propose µs ([mju:z] “muse”), a novel IaC system automating deployment coordination in a fully decentralized fashion, still retaining compatibility with DevOps practice—in contrast to today’s solutions. We implement µs, demonstrate that it effectively enables automated coordination, introduces negligible definition overhead, has no performance overhead, and is broadly applicable, as shown by the migration of 64 third-party IaC projects.","publicationDate":"2021-08-19T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3442381.3450050","title":"research-article ","type":"Towards Realistic and ReproducibleWeb Crawl Measurements","venue":"WWW '21: Proceedings of the Web Conference 2021","authors":["Jordan Jueckstock","Shaown Sarker","Peter Snyder","Aidan Beggs","Panagiotis Papadopoulos","Matteo Varvello","Benjamin Livshits","Alexandros Kapravelos"],"abstract":"Accurate web measurement is critical for understanding and improving security and privacy online. Such measurements implicitly assume that automated crawls generalize to typical web user experience. But anecdotal evidence suggests the web behaves differently when seen via well-known measurement endpoints or measurement automation frameworks, for various reasons. Our work improves the state of web privacy and security by investigating how key measurements differ when using naive crawling tool defaults vs. careful attempts to match “real” users across the Tranco top 25k web domains. We find web privacy and security measurements significantly affected by vantage point and browser configuration. We conclude that unless researchers ensure their web measurement tools match real world user experience, the research community is likely missing important signals systematically. For example, we find browser configuration alone causing shifts in 19% of known ad and tracking domains encountered and altering the loading frequency of up to 10% of distinct JavaScript code units executed. We find network vantage point having similar, though less dramatic, effects on the same web metrics. To ensure reproducibility, we carefully document our methodology and publish both our code and collected data. ","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1109/ISCA45697.2020.00049","title":"research-article ","type":"BabelFish: fusing address translations for containers","venue":"ISCA '20: Proceedings of the ACM/IEEE 47th Annual International Symposium on Computer Architecture","authors":["Dimitrios Skarlatos","Umur Darbaz","Bhargava Gopireddy","Nam Sung Kim","Josep Torrellas"],"abstract":"Cloud computing has begun a transformation from using virtual machines to containers. Containers are attractive because multiple of them can share a single kernel, and add minimal performance overhead. Cloud providers leverage the lean nature of containers to run hundreds of them on a few cores. Furthermore, containers enable the serverless paradigm, which leads to the creation of short-lived processes.In this work, we identify that containerized environments create page translations that are extensively replicated across containers in the TLB and in page tables. The result is high TLB pressure and redundant kernel work during page table management. To remedy this situation, this paper proposes BabelFish, a novel architecture to share page translations across containers in the TLB and in page tables. We evaluate BabelFish with simulations of an 8-core processor running a set of Docker containers in an environment with conservative container co-location. On average, under BabelFish, 53% of the translations in containerized workloads and 93% of the translations in serverless workloads are shared. As a result, BabelFish reduces the mean and tail latency of containerized data-serving workloads by 11% and 18%, respectively. It also lowers the execution time of containerized compute workloads by 11%. Finally, it reduces serverless function bring-up time by 8% and execution time by 10%-55%.","publicationDate":"2020-05-29T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3412569.3412571","title":"research-article ","type":"Recommending Tasks to Newcomers in OSS Projects: How Do Mentors Handle It?","venue":"OpenSym 2020: Proceedings of the 16th International Symposium on Open Collaboration","authors":["Sogol Balali","Umayal Annamalai","Hema Susmita Padala","Bianca Trinkenreich","Marco A. Gerosa","Igor Steinmacher","Anita Sarma"],"abstract":"Software developers who want to start contributing to an Open Source Software (OSS) project often struggle to find appropriate first tasks. The voluntary, self-organizing distribution of decentralized labor and the distinct nature of some OSS projects intensifies this challenge. Mentors, who work closely with newcomers, develop strategies to recommend tasks. However, to date neither the challenges mentors face in recommending tasks nor their strategies have been formally documented or studied. In this paper, we interviewed mentors of well-established OSS projects (n=10) and qualitatively analyzed their answers to identify both challenges and strategies related to recommending tasks for newcomers. Then, we employed a survey (n=30) to map the strategies to challenges and collect additional strategies. Our study identified 7 challenges and 13 strategies related to task recommendation. Strategies such as \"tagging the issues based on difficulty,\" \"adding documentation,\" \"assigning a small task first and then challenge the newcomers with bigger tasks,\" and \"dividing tasks into smaller pieces\" were frequently mentioned as ways to overcome multiple challenges. Our results provide insights for mentors about the strategies OSS communities can use to guide their mentors and for tool builders who design automated support for task assignment.","publicationDate":"2020-08-24T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3196398.3196456","title":"short-paper ","type":"Structured information on state and evolution of dockerfiles on github","venue":"MSR '18: Proceedings of the 15th International Conference on Mining Software Repositories","authors":["Gerald Schermann","Sali Zumberi","Jürgen Cito"],"abstract":"Docker containers are standardized, self-contained units of applications, packaged with their dependencies and execution environment. The environment is defined in a Dockerfile that specifies the steps to reach a certain system state as infrastructure code, with the aim of enabling reproducible builds of the container. To lay the groundwork for research on infrastructure code, we collected structured information about the state and the evolution of Dockerfiles on GitHub and release it as a PostgreSQL database archive (over 100,000 unique Dockerfiles in over 15,000 GitHub projects). Our dataset enables answering a multitude of interesting research questions related to different kinds of software evolution behavior in the Docker ecosystem.","publicationDate":"2018-05-27T22:00:00.000Z","citationCount":14},{"url":"https://dl.acm.org/doi/10.1145/3351917.3351982","title":"research-article ","type":"Enabling Robot Selective Trained Deep Neural Networks for Object Detection Through Intelligent Infrastructure","venue":"CACRE2019: Proceedings of the 2019 4th International Conference on Automation, Control and Robotics Engineering","authors":["Christian Poss","Thomas Irrenhauser","Marco Prueglmeier","Daniel Goehring","Firas Zoghlami","Vahid Salehi","Olimjon Ibragimov"],"abstract":"To save costs in logistics, handling steps are going to be automated by robots in the future. Due to the complex industrial conditions prevailing there, this is only possible with a sufficient degree of intelligence in the respective systems. Despite advances in artificially intelligent algorithms, the latest neural networks reveal significant weaknesses in performance and transferability to other applications. In order to enable a holistic autonomous material flow, the paper presents an infrastructure concept, which makes it possible to identify and train the most suitable networks robot-selectively with very limited effort. Using two practical examples, the functionality of the designed algorithms for the industrial implementation of a new use case as well as the updating and improvement of an existing system is finally outlined. It will be shown that with measures such as the automated collection of training data, the AI-supported labeling process, the intuitive validation of the trained networks via a mobile application and the automated retraining of robots already integrated, a further step can be taken towards holistically automated logistics process chains.","publicationDate":"2019-07-18T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3005680","title":"research-article ","type":"Containers push toward the mayfly server","venue":"Communications of the ACM","authors":["Chris Edwards"],"abstract":"The container revolution represents a large-scale shift in thinking about multitasking systems.","publicationDate":"2016-11-30T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3377816.3381742","title":"short-paper ","type":"A container-based infrastructure for fuzzy-driven root causing of flaky tests","venue":"ICSE-NIER '20: Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: New Ideas and Emerging Results","authors":["Valerio Terragni","Pasquale Salza","Filomena Ferrucci"],"abstract":"Intermittent test failures (test flakiness) is common during continuous integration as modern software systems have become inherently non-deterministic. Understanding the root cause of test flakiness is crucial as intermittent test failures might be the result of real non-deterministic defects in the production code, rather than mere errors in the test code. Given a flaky test, existing techniques for root causing test flakiness compare the runtime behavior of its passing and failing executions. They achieve this by repetitively executing the flaky test on an instrumented version of the system under test. This approach has two fundamental limitations: (i) code instrumentation might prevent the manifestation of test flakiness; (ii) when test flakiness is rare passively re-executing a test many times might be inadequate to trigger intermittent test outcomes. To address these limitations, we propose a new idea for root causing test flakiness that actively explores the non-deterministic space without instrumenting code. Our novel idea is to repetitively execute a flaky test, under different execution clusters. Each cluster explores a certain non-deterministic dimension (e.g., concurrency, I/O, and networking) with dedicated software containers and fuzzy-driven resource load generators. The execution cluster that manifests the most balanced (or unbalanced) sets of passing and failing executions is likely to explain the broad type of test flakiness.","publicationDate":"2020-06-26T22:00:00.000Z","citationCount":7},{"url":"https://dl.acm.org/doi/10.1145/3005680","title":"research-article ","type":"Containers push toward the mayfly server","venue":"Communications of the ACM","authors":["Chris Edwards"],"abstract":"The container revolution represents a large-scale shift in thinking about multitasking systems.","publicationDate":"2016-11-30T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3452413.3464788","title":"short-paper ","type":"Distributed Parallel Analysis Engine for High Energy Physics Using AWS Lambda","venue":"HiPS '21: Proceedings of the 1st Workshop on High Performance Serverless Computing","authors":["Jacek Kuśnierz","Maciej Malawski","Vincenzo Eduardo Padulano","Enric Tejedor Saavedra","Pedro Alonso-Jorda"],"abstract":"The High-Energy Physics experiments at CERN produce a high volume of data. It is not possible to analyze big chunks of it within a reasonable time by any single machine. The ROOT framework was recently extended with the distributed computing capabilities for massively parallelized RDataFrame applications. This approach, using the MapReduce pattern underneath, made the heavy computations much more approachable even for the newcomers.This paper explores the possibility of running such analyses on serverless services in public cloud using a purely stateless environment. So far, the distributed approaches used by RDataFrame relied on stateful, fully managed computing frameworks like Apache Spark. Here we show that our newly developed tool is able to use perfectly stateless cloud functions, demonstrating the excellent speedup in parallel stage of processing in our benchmarks.","publicationDate":"2020-06-24T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3093338.3104185","title":"poster ","type":"Managing dbGaP Data with Stratus, a Research Cloud for Protected Data","venue":"PEARC17: Proceedings of the Practice and Experience in Advanced Research Computing 2017 on Sustainability, Success and Impact","authors":["Evan F. Bollig","Graham T. Allan","Benjamin J. Lynch","Yectli Huerta","Mathew Mix","Brent Swartz","Edward A. Munsell","Joshua Leibfried","Naomi Hospodarsky"],"abstract":"Modern research computing needs at academic institutions are evolving. While traditional HPC has and continues to satisfy most workflows, a new generation of researchers has emerged looking for sophisticated, on-demand, and self-service control of compute infrastructure in a cloud-like environment. Furthermore, many also seek policy-complaint safe spaces to compute on sensitive or protected data.To cater to these modern users, the Minnesota Supercomputing Institute is deploying a cloud service for research computing called Stratus. In its initial iteration, Stratus is designed expressly to satisfy the requirements set forth by the NIH Genomic Data Sharing (GDS) Policy for data from the Database of Genotypes and Phenotypes (dbGaP) [8].Stratus is powered by the Newton version of the OpenStack cloud platform, and backed by Ceph storage. The subscription-based service is currently running in beta-test mode. In addition to data protection and compliance, the service offers three features not available on traditional HPC systems: a) on-demand availability of compute resources; b) long-running jobs (i.e., > 30 days); and c) container-based computing with Docker.This document surveys the design of Stratus with emphasis on security and compliance related to managing dbGaP data. Additionally, we highlight end-user workflows for processing large data in the presence of multi-tiered cloud storage (including a special \"dbGaP Cache\" for staged data).","publicationDate":"2017-07-08T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3199665","title":"research-article ","type":"Democratizing Authority in the Built Environment","venue":"ACM Transactions on Sensor Networks","authors":["Michael P. Andersen","John Kolb","Kaifei Chen","Gabe Fierro","David E. Culler","Randy Katz"],"abstract":"Operating systems and applications in the built environment have relied upon central authorization and management mechanisms that restrict their scalability, especially with respect to administrative overhead. We propose a new set of primitives encompassing syndication, security, and service execution that unifies the management of applications and services across the built environment, while enabling participants to individually delegate privilege across multiple administrative domains with no loss of security or manageability. We show how to leverage a decentralized authorization syndication platform to extend the design of building operating systems beyond the single administrative domain of a building. The authorization system leveraged is based on blockchain smart contracts to permit decentralized and democratized delegation of authorization without central trust. Upon this, a publish/subscribe syndication tier and a containerized service execution environment are constructed. Combined, these mechanisms solve problems of delegation, federation, device protection and service execution that arise throughout the built environment. We leverage a high-fidelity city-scale emulation to verify the scalability of the authorization tier, and briefly describe a prototypical democratized operating system for the built environment using this foundation.This is an extension of work presented in Ref. [3].","publicationDate":"2018-12-03T23:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3437120.3437290","title":"research-article ","type":"A Hierarchical Fog-based Architecture for IoT-enabled Intelligent Traffic Lights System Services","venue":"PCI 2020: 24th Pan-Hellenic Conference on Informatics","authors":["Leontios Sotiriadis","Basilis Mamalis"],"abstract":"Intelligent transport / traffic systems have evolved into highly important smart cities applications. In this paper a hierarchical multi-agent architecture is proposed that appropriately exploits the fog computing paradigm and Akka framework to provide the necessary structures and semantics for implementing urban demand responsive intelligent traffic system services. The proposed architecture mainly consists of a distributed hierarchical network of Akka Actors that act as traffic controllers in a geographical urban zone. The reduction of delays for emergency vehicles, the minimization of total vehicle and pedestrian delays, and accidents prevention are the main optimization goals of the system. The proposed architecture is properly documented whereas specific use case scenarios and implementation issues are presented and analyzed.","publicationDate":"2020-11-19T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3323503.3345027","title":"course ","type":"A reliable architecture based on reactive microservices for IoT applications","venue":"WebMedia '19: Proceedings of the 25th Brazillian Symposium on Multimedia and the Web","authors":["Cleber Santana","Leandro Andrade","Brenno Mello","Ernando Batista","José Vitor Sampaio","Cássio Prazeres"],"abstract":"Microservices has recently been employed in Cloud Computing to support the construction of large-scale systems that are resilient, elastic and best suited to meet today's demands. In Internet of Things (IoT) a set of smart applications can be built in the most different scenarios and that can impact the daily routine of people's lives. The development of applications and services at IoT brings challenges such as deployment, elasticity and resilience. Microservices developed with the characteristics of resilience, elasticity and addressed to messages are considered reactive Microservices. Thus, this paper proposes an architectural model based on reactive Microservices to improve the reliability of IoT applications from the perspective of availability.","publicationDate":"2019-10-28T23:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3340531.3417416","title":"short-paper ","type":"Inside Quasimodo: Exploring Construction and Usage of Commonsense Knowledge","venue":"CIKM '20: Proceedings of the 29th ACM International Conference on Information & Knowledge Management","authors":["Julien Romero","Simon Razniewski"],"abstract":"Quasimodo is an open-source commonsense knowledge base that significantly advanced the state of salient commonsense knowledge base construction. It introduced a pipeline that gathers, normalizes, validates and scores statements coming from query log and question answering forums. In this demonstration, we present a companion web portal which allows (i) to explore the data, (ii) to run and analyze the extraction pipeline live, and (iii) inspect the usage of Quasimodo's knowledge in several downstream use cases. The web portal is available at https://quasimodo.r2.enst.fr.","publicationDate":"2020-10-18T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3477083.3480153","title":"research-article ","type":"Decentralized modular architecture for live video analytics at the edge","venue":"HotEdgeVideo '21: Proceedings of the 3rd ACM Workshop on Hot Topics in Video Analytics and Intelligent Edges","authors":["Sri Pramodh Rachuri","Francesco Bronzino","Shubham Jain"],"abstract":"Live video analytics have become a key technology to support surveillance, security, traffic control, and even consumer multimedia applications in real time. The continuous growth in number of networked video cameras will further increase their widespread adoption. Yet, until now, developments in video analytics have largely focused on using fixed cameras, omitting the ever-growing presence of mobile cameras such as car dash-cams, drones, and smartphones. Edge computing, coupled with centralized clouds, has helped alleviate the network traffic and processing load, reducing latency and data transmissions. However, the current approach of processing video feeds through a hierarchy of clusters across a somewhat predictable path in the network will not be sufficient to support the integration of mobile feeds into the video analytics architecture. In this paper, we argue that a crucial step towards supporting heterogeneous camera sources is the adoption of a flat edge computing architecture. Such architecture should enable the dynamic distribution of processing loads through distributed computing points of presence, rapidly adapting to sudden changes in traffic conditions. In support of this hypothesis, we present exploratory results that show that smartly distributing and processing vision modules in parallel across available edge compute nodes can ultimately lead to better resource utilization and improved performance.","publicationDate":"2021-10-24T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3195870.3195872","title":"demonstration ","type":"Towards Model-Driven Application Security across Clouds","venue":"CrossCloud'18: Proceedings of the 5th Workshop on CrossCloud Infrastructures & Platforms","authors":["Manos Papoutsakis","Kyriakos Kritikos","Kostas Magoutis","Sotiris Ioannidis"],"abstract":"In this paper we present a security meta-model for describing security requirements of cloud applications as well as a platform architecture to drive perimeter security and continuous risk assessment tools and processes supporting application deployments across regions and clouds. We demonstrate a case study of a geo-distributed cloud deployment with a specifically configured intrusion detection solution to handle DDoS attacks via cloud resource elasticity actions.","publicationDate":"2018-04-22T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3442705.3442714","title":"research-article ","type":"Research on Big Data Storage Method based on IPFS and Blockchain","venue":"VSIP '20: 2020 2nd International Conference on Video, Signal and Image Processing","authors":["Jing Tang","Tao Jia","Haibo Chen","Chuncheng Wei"],"abstract":"With the popularity of digital cryptocurrency such as bitcoin, blockchain, as a new distributed framework with decentralization, non rewriting and traceability, has sprung up rapidly and has been applied in many industries such as finance, medical treatment, information security, etc. In order to ensure the security of transaction data, all key information in the business needs to enter the blockchain network. In the field of artificial intelligence, model data (i.e. effective feature point data set) will be the key information and will be used frequently. However, these feature point datasets may be megabytes, auspicious, or even terahertz. Then, the performance of big data transaction in blockchain network will be a problem worthy of study. Therefore, this paper proposes a blockchain big data storage method based on IPFs. This method mainly solves the transaction performance problem of large text data in the blockchain network. The data larger than 100 megabytes are stored in IPFs to obtain the hash certificate of text. The hash code is the only transaction voucher in the blockchain network. It greatly improves the transaction efficiency of blockchain network. In this paper, a comparative experiment is set up to further prove the efficiency of our method.","publicationDate":"2020-12-03T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3427510.3427525","title":"research-article ","type":"Comparison of container-based platforms for quantum computing simulation","venue":"SummerSim '20: Proceedings of the 2020 Summer Simulation Conference","authors":["Ginés Carrascal","Guillermo Botella","Alberto A. Del Barrio"],"abstract":"Quantum Computing allows for substantial speed-ups e.g. for integer factorization or database search, compared to conventional computation. However, since real quantum computers are an emerging technology, a significant amount of research in this domain still relies on simulations of quantum computations on conventional machines. This paper proposes a containerized environment to simulate quantum circuits, making this environment quick and easy to share within research teams. Also test the environment implementing an arithmetic circuit (Vedral's adder) and compares the performance of two of the current more used environments: IBM QISKit and Google Cirq.","publicationDate":"2020-07-19T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3366610.3368098","title":"short-paper ","type":"SORRIR: A Resilient Self-organizing Middleware for IoT Applications [Position Paper]","venue":"M4IoT '19: Proceedings of the 6th International Workshop on Middleware and Applications for the Internet of Things","authors":["Jörg Domaschka","Christian Berger","Hans P. Reiser","Philipp Eichhammer","Frank Griesinger","Jakob Pietron","Matthias Tichy","Franz J. Hauck","Gerhard Habiger"],"abstract":"The increasing societal pervasion and importance of the Internet-of-Things (IoT) raises questions regarding the fault tolerance and robustness of IoT applications as these increasingly become part of critical infrastructures. In this position paper, we outline novel ideas that focus on the design of a resilient and self-organizing execution platform for IoT applications called SORRIR. Its main ambition is to simplify, alleviate and accelerate the development, configuration and operation of resilient IoT systems. We follow a holistic approach which is based on a novel design process, a library containing resilience mechanisms and a robust execution platform that is equipped with monitoring and self-organizing capabilities. The goal is that developers only need to specify the desired resilience degree without having to worry about the technical, implementation-level details of employed resilience mechanisms.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3314545.3314567","title":"research-article ","type":"Anomaly Detection for Container Cluster based on JointCloud Platform","venue":"ICCDA 2019: Proceedings of the 2019 3rd International Conference on Compute and Data Analysis","authors":["Zhengmin Li","Zhaoxin Zhang","Xinran Liu","Chunge Zhu"],"abstract":"In order to accurately discover container exception data of large-scale container clusters to guide the maintenance of container clusters, a new anomaly detection model for container clusters is proposed in this article. The model combines the advantages of supervised learning and unsupervised learning to accurately and efficiently label container anomaly data in a large-scale data environment. Experiments show that the labeling rate of the raw data is as high as 95.6%, and the accuracy of anomaly detection is as high as 87.0%. Simultaneously, the common five classification algorithms are used to compare the anomaly detection effect between the labeled data and the raw data, and the validity of the model is further verified.","publicationDate":"2019-03-13T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3474624.3474630","title":"short-paper ","type":"Main Differences of DevOps on IoT Systems","venue":"SBES '21: Brazilian Symposium on Software Engineering","authors":["Igor Pereira","Tiago Carneiro","Eduardo Figueiredo"],"abstract":" IoT systems have barriers related to the different areas that involve their development. Hence, the scientific literature and industry practices investigate approaches that enable continuous interaction of these areas. Through semi-structured interviews with thirty-one professionals working in industry, this study investigated how DevOps is applied to make the development of IoT projects continuous and meet the demands of the industry. Through group discussions, we categorized the results of this study. As a preliminary contribution to this work, we investigate the contrasts between using DevOps in IoT system projects and using rigid, plan-oriented processes to develop embedded systems.","publicationDate":"2021-09-26T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3404687.3404692","title":"research-article ","type":"A Near Metal Platform for Intensive Big Data Processing Using A Novel Approach: Persistent Distributed Channels","venue":"ICBDC 2020: Proceedings of the 2020 5th International Conference on Big Data and Computing","authors":["Noussair Fikri","Mohamed Rida","Noureddine Abghour","Khalid Moussaid","Amina El Omri"],"abstract":"In this paper we present a new Golang based framework for distributed intensive data processing and also micro batching. It uses a novel approach, the persistent distributed channels, based on the concept of Share memory by communicating, and inspired from Resilient distributed datasets of Apache Spark. The architecture of our proposed system is considered as near-metal platform for Big Data operations in order to enhance the speed of massive data processing.","publicationDate":"2020-05-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3344948.3344952","title":"research-article ","type":"Towards service discovery and autonomic version management in self-healing microservices architecture","venue":"ECSA '19: Proceedings of the 13th European Conference on Software Architecture - Volume 2","authors":["Yuwei Wang"],"abstract":"Microservices architectures (MSAs) contribute to building complex distributed systems by decomposing monolithic systems into a set of independent microservices. This makes it possible to design, develop and deploy scalable and flexible systems. However, various unexpected changes could happen during execution, such as a service upgrade, a sudden increase of traffic, or an infrastructural failure. In this cases, how to react autonomously to these changes without outages becomes a challenge to consider. A PhD project has been launched to propose a self-healing microservices architecture, which can adapt dynamically to inside and outside changes without human intervention. In this paper, we present the first results of a systematic state of the art in the field of self-healing MSA systems. As an entry point of our research, we focus on self-healing triggered by upgrade changes. The initial contribution is a new component of a version manager in our self-healing MSA solution, in relation with service discovery elements. This approach can provide an autonomic version management on both the application level and the system level, and helps to control services upgrading changes. We plan to validate our proposition in a company project use case by deploying it in an emulated production environment, and applying a chaos engineering approach.","publicationDate":"2019-09-08T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3440840.3440860","title":"research-article ","type":"Efficient Low-Latency Dynamic Licensing for Deep Neural Network Deployment on Edge Devices","venue":"CIIS 2020: 2020 The 3rd International Conference on Computational Intelligence and Intelligent Systems","authors":["Toan Van Pham","Ngoc Ngo Quang Tran","Hoang Minh Pham","Tam Minh Nguyen","Thanh Ta Minh"],"abstract":" Along with the rapid development in the field of artificial intelligence (AI), especially deep learning, deep neural network (DNN) applications are becoming more and more popular in reality. To be able to withstand the heavy load from mainstream users, deployment techniques are essential in bringing neural network models from research to production. Among the two popular computing topologies for deploying neural network models in production are cloud-computing and edge-computing. Recent advances in communication technologies, along with the great increase in the number of mobile devices, has made edge-computing gradually become an inevitable trend. In this paper, we propose an architecture to solve deploying and processing deep neural networks on edge-devices by leveraging their synergy with the cloud and the access-control mechanisms of the database. Adopting this architecture allows low-latency DNN model updates on devices. At the same time, with only one model deployed, we can easily make different versions of it by setting access permissions on the model weights. This method allows for dynamic model licensing, which benefits commercial applications.","publicationDate":"2020-11-12T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.14778/3352063.3352105","title":"research-article ","type":"GRANO: interactive graph-based root cause analysis for cloud-native distributed data platform","venue":"Proceedings of the VLDB Endowment","authors":["Hanzhang Wang","Phuong Nguyen","Jun Li","Selcuk Kopru","Gene Zhang","Sanjeev Katariya","Sami Ben-Romdhane"],"abstract":"We demonstrate Grano1, an end-to-end anomaly detection and root cause analysis (or RCA for short) system for cloud-native distributed data platform by providing a holistic view of the system component topology, alarms and application events. Grano provides: a Detection Layer to process large amount of time-series monitoring data to detect anomalies at logical and physical system components; an Anomaly Graph Layer with novel graph modeling and algorithms for leveraging system topology data and detection results to identify the root cause relevance at the system component level; and an Application Layer that automatically notifies on-call personnel and presents real-time and on-demand RCA support through an interactive graph interface. The system is deployed and evaluated using eBay's production data to help on-call personnel to shorten the identification of root cause from hours to minutes.","publicationDate":"2019-07-31T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/2904354.2904368","title":"short-paper ","type":"Exploring the impact of situational context: a case study of a software development process for a microservices architecture","venue":"ICSSP '16: Proceedings of the International Conference on Software and Systems Process","authors":["Rory V. O'Connor","Peter Elger","Paul M. Clarke"],"abstract":"Over the decades, a variety of software development processes have been proposed, each with their own advantages and disadvantages. It is however widely accepted that there is no single process that is perfectly suited to all settings, thus a software process should be molded to the needs of its situational context. In previous work, we have consolidated a substantial body of related research into an initial reference framework of the situational factors affecting the software development process. Practitioners can consult this framework in order to profile their context, a step necessary for effective software process decision making. In this paper, we report on the findings from a case study involving process discovery in a small but successful and growing software development firm. In this organization, which has a focus on continuous software evolution and delivery, we also applied the situational factors reference framework, finding that context is a complex and key informant for software process decisions. Studies of this type highlight the role of situational context in software process definition and evolution, and they raise awareness not just of the importance of situational context, but also of the complexity surrounding software process contexts, a complexity which may not be fully appreciated in all software development settings.","publicationDate":"2016-05-13T22:00:00.000Z","citationCount":32},{"url":"https://dl.acm.org/doi/10.1145/3366375","title":"research-article ","type":"Mortar: An Open Testbed for Portable Building Analytics","venue":"ACM Transactions on Sensor Networks","authors":["Gabe Fierro","Marco Pritoni","Moustafa Abdelbaky","Daniel Lengyel","John Leyden","Anand Prakash","Pranav Gupta","Paul Raftery","Therese Peffer","Greg Thomson","David E. Culler"],"abstract":"Access to large amounts of real-world data has long been a barrier to the development and evaluation of analytics applications for the built environment. Open datasets exist, but they are limited in their span (how much data is available) and context (what kind of data is available and how it is described). Evaluation of such analytics is also limited by how the analytics themselves are implemented, often using hard-coded names of building components, points and locations, or unique input data formats.To advance the methodology for how such analytics are implemented and evaluated, we present Mortar: an open testbed for portable building analytics, currently spanning 90 buildings and containing over 9.1 billion data points. All buildings in the testbed are described using Brick, a recently developed metadata schema, providing rich functional descriptions of building assets and subsystems. We also propose a simple architecture for writing portable analytics applications that are robust to the diversity of buildings and can configure themselves based on context. We demonstrate the utility of Mortar by implementing 11 applications from the literature.","publicationDate":"2019-12-05T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3440943.3444725","title":"research-article ","type":"Toward Software-Defined Moving Target Defense for Secure Service Deployment Enhanced with a User-Defined Orchestration","venue":"ACM ICEA '20: Proceedings of the 2020 ACM International Conference on Intelligent Computing and its Emerging Applications","authors":["Ki-Wan Kang","Ki-Woong Park"],"abstract":"In recent years, cloud native computing, which involves the deployment of scalable applications enhanced with containers, microservices, and serverless functions, has been actively studied to maximize its efficiency, flexibility, and economic feasibility. In this regard, studies on the security of the cloud native computing environment have been conducted. Among various studies on the security of these systems, moving target defense (MTD), which is an area of research that blocks various security threats in advance by actively changing the main properties of the protected target to deceive attackers, has been actively studied and developed. However, cloud native computing is highly dynamic; it is difficult to apply MTD technologies that actively change static system properties. Therefore, a software-defined MTD framework was designed for easier application of MTD technology to the cloud native environment. In this study, the user-defined adaptability of the software-defined MTD framework was implemented, and it was verified that the properties of the target service were changed according to previously defined mutation properties.","publicationDate":"2020-12-11T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3437359.3465601","title":"short-paper ","type":"Comprehensive Evaluation of XSEDE’s Scientific Impact using Semantic Scholar Data","venue":"PEARC '21: Practice and Experience in Advanced Research Computing","authors":["Gregor von Laszewski","Fugang Wang","Geoffrey C. Fox"],"abstract":" The United States science and engineering community faces multiple challenges related to funding and funding policies for science and engineering. A framework is needed to evaluate the impact of scientific facilities and instruments. In this paper, we demonstrate such an activity through our comprehensive work evaluating the scientific impact of XSEDE using the Semantic Scholar Data. In contrast to other studies, our study includes the bibliographic references of all recorded papers related to XSEDE over the entire performance period till March of 2021. This makes this study unique and distinguishes it from our earlier work while using (a) over 180 million papers as a comparison to our peer analysis, (b) include all publications reported, and (c) conduct the study repeatedly over several years.","publicationDate":"2021-07-16T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3340531.3417441","title":"short-paper ","type":"UWKGM: A Modular Platform for Knowledge Graph Management","venue":"CIKM '20: Proceedings of the 29th ACM International Conference on Information & Knowledge Management","authors":["Natthawut Kertkeidkachorn","Rungsiman Nararatwong","Ryutaro Ichise"],"abstract":"A knowledge graph becomes a central data hub in the enterprise and the research communities. Nevertheless, the development of knowledge graphs is challenging due to the insufficient functionalities of knowledge graph management platforms. In this paper, we develop a knowledge graph management platform (UWKGM). This platform enables users to integrate arbitrary functionalities as RESTful API services in order to facilitate the knowledge graph development process. In the demonstration, we highlight the main features of UWKGM and its use cases on knowledge graph management tasks.","publicationDate":"2020-10-18T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3344948.3344997","title":"demonstration ","type":"An exploration and experiment tool suite for code to architecture mapping techniques","venue":"ECSA '19: Proceedings of the 13th European Conference on Software Architecture - Volume 2","authors":["Tobias Olsson","Morgan Ericsson","Anna Wingkvist"],"abstract":"Reflexion modeling can be used to validate that source code conforms to an intended architecture. However, it requires a mapping of source code modules (e.g., classes) to (software) architecture elements. We have developed a tool suite that allows for evaluation and exploration of automatic techniques to map source code modules to architecture elements. The suite includes a reusable core component and tools to define the architecture, define and run experiments with mapping strategies, and explore the results of these experiments. The experiments can be executed locally or in a remote high-performance computing environment.","publicationDate":"2019-09-08T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3344948.3344987","title":"short-paper ","type":"Towards an architecture for big data analytics leveraging edge/fog paradigms","venue":"ECSA '19: Proceedings of the 13th European Conference on Software Architecture - Volume 2","authors":["Josu Díaz-de-Arcaya","Raül Miñon","Ana I. Torre-Bastida"],"abstract":"An industry transformation is being boosted by Big Data and Cloud technologies. We present a Big Data architecture, which expands the life cycle of data processing through the Edge, Fog and Cloud computing layers. The proposed architecture takes advantage of the strengths of each: the Cloud layer executes heavy analytical processes, the Fog is responsible for the ingestion and performing aggregations, and the Edge manages devices and actuators. The proposed architecture tackles two main goals, 1) latencies and response times can be reduced by bringing the analytics closer to where the data is generated and 2) the use of computing resources is optimised. In order to conceptualise this architecture, an orchestration module is proposed with the goal of optimising the deployment of analytical workloads across the three layers, by evaluating their computing resources. In addition to this, another module is designed to monitor the performance of such workloads allowing the redistribution of tasks assigned to each node. These modules will be implemented in a real case scenario in the train domain.","publicationDate":"2019-09-08T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3447545.3451190","title":"short-paper ","type":"How to Measure Scalability of Distributed Stream Processing Engines?","venue":"ICPE '21: Companion of the ACM/SPEC International Conference on Performance Engineering","authors":["Sören Henning","Wilhelm Hasselbring"],"abstract":"Scalability is promoted as a key quality feature of modern big data stream processing engines. However, even though research made huge efforts to provide precise definitions and corresponding metrics for the term scalability, experimental scalability evaluations or benchmarks of stream processing engines apply different and inconsistent metrics. With this paper, we aim to establish general metrics for scalability of stream processing engines. Derived from common definitions of scalability in cloud computing, we propose two metrics: a load capacity function and a resource demand function. Both metrics relate provisioned resources and load intensities, while requiring specific service level objectives to be fulfilled. We show how these metrics can be employed for scalability benchmarking and discuss their advantages in comparison to other metrics, used for stream processing engines and other software systems.","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3364228.3364682","title":"short-paper ","type":"Spack meets singularity: creating movable in-situ analysis stacks with ease","venue":"ISAV '19: Proceedings of the Workshop on In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization","authors":["Sergei Shudler","Nicola Ferrier","Joseph Insley","Michael E. Papka","Silvio Rizzi"],"abstract":"In-situ data analysis and visualization is a promising technique to handle the enormous amount of data an extreme-scale application produces. One challenge users often face in adopting in-situ techniques is setting the right environment on a target machine. Platforms such as SENSEI require complex software stacks that consist of various analysis packages and visualization applications. The user has to make sure all these prerequisites exist on the target machine, which often involves compiling and setting them up from scratch. In this paper, we leverage the containers technology (e.g., light-weight virtualization images) and provide users with Singularity containers that encapsulate ready-to-use, movable in-situ software stacks. Moreover, we make use of Spack to ease the process of creating these containers. Finally, we evaluate this solution by running in-situ analysis from within a container on an HPC system.","publicationDate":"2019-11-17T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3350546.3352554","title":"short-paper ","type":"Agent-based Business Process Orchestration for IoT","venue":"WI '19: IEEE/WIC/ACM International Conference on Web Intelligence","authors":["Timotheus Kampik","Avleen Malhi","Kary Främling"],"abstract":"The so-called Internet of Things is of increasing importance for facilitating productivity across industries, i.e., by connecting sensors with manufacturing lines and IT system landscapes with an increasing degree of autonomy. In this context, a common challenge is enabling reasonable trade-offs between structure and control on the one hand and flexibility and human-like intelligent behavior on the other hand. To address this challenge, we establish the need for and requirements of a hybrid IoT-/agent-based business process orchestration architecture that utilizes open standards. We propose a four-layered architecture, which integrates autonomous agents and business process orchestration for IoT/agents, and provide a running example for a supply chain management (purchasing) use case.","publicationDate":"2019-10-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3429351.3431747","title":"short-paper ","type":"Minimizing Cost and Maximizing Performance for Cloud Platforms","venue":"Middleware'20 Doctoral Symposium: Proceedings of the 21st International Middleware Conference Doctoral Symposium","authors":["Jashwant Raj Gunasekaran"],"abstract":"We are witnessing the rapid growth of cloud computing with the proliferation of tenants adopting cloud for elasticity, availability, and flexibility for a plethora of applications. To efficiently cater for different tenant requirements, cloud providers have steadily evolved to offer a myriad of resource and service types which inherently complicates the cloud adoption process. On the other hand, the perpetuating growth of cloud tenants in turn impel providers to expand datacenters to cope with the tenant demand. The objective of this proposal is to maximize the performance and minimize the cost for both tenants and cloud providers, by providing efficient means of managing resource allocations for their applications. Towards this, the proposal comprises of three intertwined tasks. First, we start from a tenant perspective, with the first two tasks aimed at investigating the primary reasons for performance-cost inefficiency. Second, from a provider perspective, the third task investigates the primary reasons for performance-energy inefficiency in datacenters. All the three tasks can collectively improve the performance and cost efficiency of emerging applications in next generation cloud platforms.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1109/ICSE-SEET.2019.00011","title":"research-article ","type":"Industry-academy collaboration in teaching DevOps and continuous delivery to software engineering students: towards improved industrial relevance in higher education","venue":"ICSE-SEET '19: Proceedings of the 41st International Conference on Software Engineering: Software Engineering Education and Training","authors":["Kati Kuusinen","Sofus Albertsen"],"abstract":"Global industrial demand for highly skilled professional software engineers is increasing. Many countries already experience shortage of developer workforce and it is predicted that the industrial need for software engineers will grow on a higher rate than educational institutes are able to train new workforce. The main reasons for this deficit are in the education system's inability to adapt to current market needs and in difficulties in matching available skills with existing jobs. Therefore, increasing the industrial and market relevance of the education can be a key solution. Another significant contributor is teaching more efficient working methods such as automating repetitive parts of developer work to help to concentrate on tasks that directly create customer and business value. This paper presents the design and execution of a Continuous Delivery and DevOps course organized in company-university collaboration. The objective is to investigate how university courses requiring multidisciplinary lecturer skills and complex execution architectures can be organized in industry-academia collaboration to improve the industrial relevance of higher education.","publicationDate":"2019-05-26T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3183440.3183497","title":"demonstration ","type":"When the testing gets tough, the tough get ElasTest","venue":"ICSE '18: Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings","authors":["Antonia Bertolino","Antonello Calabró","Guglielmo De Angelis","Micael Gallego","Boni García","Francisco Gortázar"],"abstract":"We present ElasTest, an open-source generic and extensible platform supporting end-to-end testing of large complex cloud systems, including web, mobile, network and WebRTC applications. ElasTest is developed following a fully transparent and open agile process around which a community of developers, contributors and users is collected. We demonstrate ElasTest in action by testing the FullTeaching application: the video is available from http://elastest.io/videos/icse2018-demo.","publicationDate":"2018-05-26T22:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3185768.3186308","title":"research-article ","type":"A SPEC RG Cloud Group's Vision on the Performance Challenges of FaaS Cloud Architectures","venue":"ICPE '18: Companion of the 2018 ACM/SPEC International Conference on Performance Engineering","authors":["Erwin van Eyk","Alexandru Iosup","Cristina L. Abad","Johannes Grohmann","Simon Eismann"],"abstract":"As a key part of the serverless computing paradigm, Function-as-a-Service (FaaS) platforms enable users to run arbitrary functions without being concerned about operational issues. However, there are several performance-related issues surrounding the state-of-the-art FaaS platforms that can deter widespread adoption of FaaS, including sizeable overheads, unreliable performance, and new forms of the cost-performance trade-off. In this work we, the SPEC RG Cloud Group, identify six performance-related challenges that arise specifically in this FaaS model, and present our roadmap to tackle these problems in the near future. This paper aims at motivating the community to solve these challenges together.","publicationDate":"2018-04-01T22:00:00.000Z","citationCount":20},{"url":"https://dl.acm.org/doi/10.1109/TCBB.2019.2916810","title":"research-article ","type":"End-to-End Security for Local and Remote Human Genetic Data Applications at the EGA","venue":"IEEE/ACM Transactions on Computational Biology and Bioinformatics","authors":["Alexander Senf"],"abstract":"Sensitive genomic data should remain secure - whether on disk for storage, or analysis, or in transport. However, secure storage, delivery, and usage of genomic data is complicated by the size of files and diversity of workflows. This paper presents solutions developed by GA4GH and EGA to use custom-ized encryption, encrypted file formats, toolchain integration, and intelligent APIs to help solve this problem.","publicationDate":"2019-06-30T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3177851","title":"survey ","type":"A Comprehensive Perspective on Pilot-Job Systems","venue":"ACM Computing Surveys","authors":["Matteo Turilli","Mark Santcroos","Shantenu Jha"],"abstract":"Pilot-Job systems play an important role in supporting distributed scientific computing. They are used to execute millions of jobs on several cyberinfrastructures worldwide, consuming billions of CPU hours a year. With the increasing importance of task-level parallelism in high-performance computing, Pilot-Job systems are also witnessing an adoption beyond traditional domains. Notwithstanding the growing impact on scientific research, there is no agreement on a definition of Pilot-Job system and no clear understanding of the underlying abstraction and paradigm. Pilot-Job implementations have proliferated with no shared best practices or open interfaces and little interoperability. Ultimately, this is hindering the realization of the full impact of Pilot-Jobs by limiting their robustness, portability, and maintainability. This article offers a comprehensive analysis of Pilot-Job systems critically assessing their motivations, evolution, properties, and implementation. The three main contributions of this article are as follows: (1) an analysis of the motivations and evolution of Pilot-Job systems; (2) an outline of the Pilot abstraction, its distinguishing logical components and functionalities, its terminology, and its architecture pattern; and (3) the description of core and auxiliary properties of Pilot-Jobs systems and the analysis of six exemplar Pilot-Job implementations. Together, these contributions illustrate the Pilot paradigm, its generality, and how it helps to address some challenges in distributed scientific computing.","publicationDate":"2018-04-16T22:00:00.000Z","citationCount":21},{"url":"https://dl.acm.org/doi/10.1145/3477091.3482763","title":"research-article ","type":"Internet islands: first class networked communities in isolated regions","venue":"MobiArch '21: Proceedings of the 16th ACM Workshop on Mobility in the Evolving Internet Architecture","authors":["Abdullahi Kutiriko Abubakar","Nishanth Sastry","Mohamed Kassem"],"abstract":"For disconnected communities, the associated cost of backhaul network infrastructure is seen as one of the most significant challenges of accessing connectivity services. To help mitigate this challenge, we propose the Internet Island Architecture. The Architecture provides room for a large class of so-called ``sharing economy'' applications such as temporary labour, dating service, market services and transport services supported by local connectivity alone. We show the feasibility of the system and discuss the advantages of the proposed architecture","publicationDate":"2021-10-24T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3478905.3479005","title":"research-article ","type":"Multi-malicious nodes double-spending attack blacklist management model","venue":"DSIT 2021: 2021 4th International Conference on Data Science and Information Technology","authors":["Qiang Liu","Song Yan","Jie Wan","Ruiqiang Ma","Jianhang Xu"],"abstract":" The double-spending attack on the blockchain has been extensively studied, and many research results have been obtained. However, most of these researches are the improvement and prevention for current attack algorithms, and the double-spending attack among multiple malicious nodes is also a valuable research direction. This article further analyzes on the basis of current researches, and proposes a multi-malicious node double-spending attack blacklist management model based on the malicious behavior from different malicious nodes. Firstly, studying the double-spending attacks model to get the mathematical rules between multiple malicious nodes. Then, electing credible nodes to build a blacklist management model. Finally, malicious nodes are extracted through the blacklist single-judgment and double-judgment strategies, which fundamentally block the nodes from further doing evil. Simulation experiments show that the blacklist management model can effectively resist double-spending attacks from multi-malicious nodes.","publicationDate":"2021-07-22T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/2949550.2949562","title":"research-article ","type":"Containers in Research: Initial Experiences with Lightweight Infrastructure","venue":"XSEDE16: Proceedings of the XSEDE16 Conference on Diversity, Big Data, and Science at Scale","authors":["Spencer Julian","Michael Shuey","Seth Cook"],"abstract":"HPC environments have traditionally existed installed directly on hardware or through virtual machine environments. Linux Containers, and Docker specifically, have gained extensive popularity; we believe this current trend toward containers and microservices can be applied to HPC to improve efficiency and quality of development and deployment. User interest in Docker is rising, with several communities planning production deployments. We describe some of our site's experiences, along with an autoscaling web cluster and an autoscaling PBS-based computational cluster we have developed that are currently in a pre-production testing phase. Some basic performance tests are covered, comparing network and filesystem performance between a native Docker environment and a traditional Red Hat-based environment. In our tests, we noticed negligible differences in computational performance when run out of the box, approximately 0.4%, but we required some minor tweaking in the form of additional docker plugins to achieve similar or better performance in the network and filesystem tests. While additional testing is needed for some aspects of computational clusters, particularly RDMA performance, we believe initial testing indicates Docker containers are ready for broader adoption at larger-scale production environments.","publicationDate":"2016-07-16T22:00:00.000Z","citationCount":14},{"url":"https://dl.acm.org/doi/10.1145/3363347.3363365","title":"short-paper ","type":"Privacy is What We Care About: Experimental Investigation of Federated Learning on Edge Devices","venue":"AIChallengeIoT'19: Proceedings of the First International Workshop on Challenges in Artificial Intelligence and Machine Learning for Internet of Things","authors":["Anirban Das","Thomas Brunschwiler"],"abstract":"Federated Learning enables training of a general model through edge devices without sending raw data to the cloud. Hence, this approach is attractive for digital health applications, where data is sourced through edge devices and users care about privacy. Here, we report on the feasibility to train deep neural networks on the Raspberry Pi4s as edge devices. A CNN, a LSTM and a MLP was successfully trained on the MNIST data-set. Further, federated learning was demonstrated experimentally on IID and non-IID samples in a parametric study, to benchmark the model convergence. The weight updates from the workers are shared with the cloud to train the general model through federated learning. With the CNN and the non-IID samples a test-accuracy of up to 85% could be achieved within a training time of 2 minutes, while exchanging less than 10 MB data per device. In addition, we discuss federated learning from an use-case standpoint, elaborating on privacy risks and labeling requirements for the application of emotion detection from sound. Based on the experimental findings, we discuss possible research directions to improve model and system performance. Finally, we provide best practices for a practitioner, considering the implementation of federated learning.","publicationDate":"2019-11-09T23:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3036331.3050422","title":"research-article ","type":"Cloud SLA relationships in multi-cloud environment: models and practices","venue":"ICCMS '17: Proceedings of the 8th International Conference on Computer Modeling and Simulation","authors":["Seokho Son","Hyun-Hwa Choi","Byeong Thaek Oh","Sun Wook Kim","Byoung Seob Kim"],"abstract":"In the past few years, cloud computing has been realized and has achieved advancement. Sincemany cloud systems and providers have been deployed in this world, various models and platforms have been developed to support multiple cloud (i.e., multi-cloud) environments (e.g., inter-cloud, federated cloud, distributed cloud, hybrid cloud, multi-cloud management platform, and cloud service brokerageplatform). Whereas those models provide a multi-cloud environment, they are different according to their objectives, service models, SLA (service level agreement) models, and so on. Even though SLA is considered as a very important issue in cloud computing, SLA relationships in multi-cloud models are not formally described yet. Therefore, in this paper, we introduce various multi-cloud models and analyze the multi-cloud models in term of SLA relationship based on the proposed SLA relationship description model. In addition, this paper introduces open source multi-cloud projects to understand practices in cloud SLA relationships.","publicationDate":"2017-01-19T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3471274.3471284","title":"Article ","type":"Task scheduling based on computing resource usage prediction in large-scale cluster","venue":"HP3C'21: 2021 5th International Conference on High Performance Compilation, Computing and Communications","authors":["Weijie Liu","Linhui Xu","Yuanlong Chen"],"abstract":"To further improve the computing performance of the cloud for complex computing environments, efficient task scheduling strategies suitable for container deployment can improve the computing performance of the system. The current task scheduling algorithm is based on the current situation of the computing environment and the internal logical relationship between tasks to ensure that performance indicators are met. In this article, we first use lstm and attention algorithms to extract features from the historical data of processor operation to obtain better scheduling strategies in different states, and improve the existing processor scheduling strategies based on this. The method proposed in this paper has been experimentally verified in kubernate, which proves that the method in this paper is reasonable and effective.","publicationDate":"2021-06-17T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3437359.3465586","title":"short-paper ","type":"CloudBank: Managed Services to Simplify Cloud Access for Computer Science Research and Education","venue":"PEARC '21: Practice and Experience in Advanced Research Computing","authors":["Michael Norman","Vince Kellen","Shava Smallen","Brian DeMeulle","Shawn Strande","Ed Lazowska","Naomi Alterman","Rob Fatland","Sarah Stone","Amanda Tan","Katherine Yelick","Eric Van Dusen","James Mitchell"],"abstract":" CloudBank is a cloud access entity founded to enable the computer science research and education communities to harness the profound computational potential of public clouds. By delivering a set of managed services designed to alleviate common points of friction associated with cloud adoption, Cloudbank serves as an integrated service provider to the research and education community. These services include front-line help desk support, cloud solution consulting, training, account management, cost monitoring and optimization support, and automated billing. CloudBank has a multi-cloud pay-per-use billing model and aims to serve the spectrum of cloud users from novice to advanced.","publicationDate":"2021-07-16T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3479529","title":"research-article ","type":"\"@alex, this fixes #9\": Analysis of Referencing Patterns in Pull Request Discussions","venue":"Proceedings of the ACM on Human-Computer Interaction","authors":["Ashish Chopra","Morgan Mo","Samuel Dodson","Ivan Beschastnikh","Sidney S. Fels","Dongwook Yoon"],"abstract":"Pull Requests (PRs) are a frequently used method for proposing changes to source code repositories. When discussing proposed changes in a PR discussion, stakeholders often reference a wide variety of information objects for establishing shared awareness and common ground. Previous work has not considered how the referential behavior impacts collaborative software development via PRs. This knowledge gap is the major barrier in evaluating the current support for referencing in PRs and improving them. We conducted an explorative analysis of \\textasciitilde7K references, collected from 450 public PRs on GitHub, and constructed taxonomies of referent types and expressions. Using our annotated dataset, we identified several patterns in the use of references. Referencing source code elements was prevalent but the authoring interface lacks support for it. Three classes of contextual factors influence referencing behaviors: referent type, discussion thread, and project attributes. Referencing patterns may indicate PR outcomes (e.g., merged PRs frequently reference issues, users, and tests). We conclude with design implications to support more effective referencing in PR discussion interfaces.","publicationDate":"2021-10-17T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3452369.3463824","title":"short-paper ","type":"A Methodological Perspective on Lawful Internet Surveillance","venue":"FRAME '21: Proceedings of the 1st Workshop on Flexible Resource and Application Management on the Edge","authors":["Massimo Coppola","Mauro Iacono","Mauro Migliardi","Francesco Palmieri"],"abstract":"In this paper we discuss research issues, practical matters and legal constraints driving the design and development of lawful tools and frameworks for a real-time, automated analysis of Internet traffic, supporting detection and recovery of hidden traffic and botnets, as well as preserving the integrity and confidentiality of evidences. We propose a methodological perspective and lines of development that in our vision are the basic pillars of such a framework, to address a multi-stakeholder, multinational scenario.","publicationDate":"2020-06-24T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3374138.3374171","title":"research-article ","type":"A microservice-based approach for fine-grained simulation in MSaaS platforms","venue":"SummerSim '19: Proceedings of the 2019 Summer Simulation Conference","authors":["Paolo Bocciarelli","Andrea D'Ambrogio","Andrea Giglio","Emiliano Paglia"],"abstract":"M&S as a Service (MSaaS) is an increasingly adopted paradigm that brings the benefits of service-oriented architectures and cloud computing into the M&S field. The design and implementation of MSaaS platforms typically address the provision of coarse-grained M&S services, which offer the user easy access and orchestration of M&S components consisting of entire environments, applications and/or tools. This paper introduces an approach to the provision of fine-grained M&S services, which are defined by use of a microservice-based architecture, according to which applications are developed as a suite of small-sized services. The proposed approach extends an already available MSaaS platform, named SOASim. The paper shows how the integration and mutual use of fine-grained and coarse-grained services (e.g., modeling services, transformation services, presentation services etc.) significantly enhance the benefits of SOASim. An example application to the microservice-based setup of a discrete event simulation is used to describe and discuss the proposed approach.","publicationDate":"2019-07-21T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3363554","title":"survey ","type":"Scalable Deep Learning on Distributed Infrastructures: Challenges, Techniques, and Tools","venue":"ACM Computing Surveys","authors":["Ruben Mayer","Hans-Arno Jacobsen"],"abstract":"Deep Learning (DL) has had an immense success in the recent past, leading to state-of-the-art results in various domains, such as image recognition and natural language processing. One of the reasons for this success is the increasing size of DL models and the proliferation of vast amounts of training data being available. To keep on improving the performance of DL, increasing the scalability of DL systems is necessary. In this survey, we perform a broad and thorough investigation on challenges, techniques and tools for scalable DL on distributed infrastructures. This incorporates infrastructures for DL, methods for parallel DL training, multi-tenant resource scheduling, and the management of training and model data. Further, we analyze and compare 11 current open-source DL frameworks and tools and investigate which of the techniques are commonly implemented in practice. Finally, we highlight future research trends in DL systems that deserve further research.","publicationDate":"2020-02-04T23:00:00.000Z","citationCount":25},{"url":"https://dl.acm.org/doi/10.1145/3447555.3466581","title":"research-article ","type":"Towards a Holistic Controller: Reinforcement Learning for Data Center Control","venue":"e-Energy '21: Proceedings of the Twelfth ACM International Conference on Future Energy Systems","authors":["Albin Heimerson","Rickard Brännvall","Johannes Sjölund","Johan Eker","Jonas Gustafsson"],"abstract":"The increased use of cloud and other large scale datacenter IT services and the associated power usage has put the spotlight on more energy-efficient datacenter management. In this paper, a simple model was developed to represent the heat rejection system and energy usage in a small DC setup. The model was then controlled by a reinforcement learning agent that handles both the load balancing of the IT workload, as well as cooling system setpoints. The main contribution is the holistic approach to datacenter control where both facility metrics, IT hardware metric and cloud service logs are used as inputs. The application of reinforcement learning in the proposed holistic setup is feasible and achieves results that outperform standard algorithms. The paper presents both the simplified DC model and the reinforcement learning agent in detail and discusses how this work can be extended towards a richer datacenter model.","publicationDate":"2021-06-21T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3311790.3396670","title":"research-article ","type":"Design and Deployment of Photo2Building: A Cloud-based Procedural Modeling Tool as a Service","venue":"PEARC '20: Practice and Experience in Advanced Research Computing","authors":["Manush Bhatt","Rajesh Kalyanam","Gen Nishida","Liu He","Christopher May","Dev Niyogi","Daniel Aliaga"],"abstract":"We present a Photo2Building tool to create a plausible 3D model of a building from only a single photograph. Our tool is based on a prior desktop version which, as described in this paper, is converted into a client-server model, with job queuing, web-page support, and support of concurrent usage. The reported cloud-based web-accessible tool can reconstruct a building in 40 seconds on average and costing only 0.60 USD with current pricing. This provides for an extremely scalable and possibly widespread tool for creating building models for use in urban design and planning applications. With the growing impact of rapid urbanization on weather and climate and resource availability, access to such a service is expected to help a wide variety of users such as city planners, urban meteorologists worldwide in the quest to improved prediction of urban weather and designing climate-resilient cities of the future. ","publicationDate":"2020-07-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3366623.3368137","title":"research-article ","type":"FaaS Orchestration of Parallel Workloads","venue":"WOSC '19: Proceedings of the 5th International Workshop on Serverless Computing","authors":["Daniel Barcelona-Pons","Pedro García-López","Álvaro Ruiz","Amanda Gómez-Gómez","Gerard París","Marc Sánchez-Artigas"],"abstract":"Function as a Service (FaaS) is based on a reactive programming model where functions are activated by triggers in response to cloud events (e.g., objects added to an object store). The inherent elasticity and the pay-per-use model of serverless functions make them very appropriate for embarrassingly parallel tasks like data preprocessing, or even the execution of MapReduce jobs in the cloud.But current Serverless orchestration systems are not designed for managing parallel fork-join workflows in a scalable and efficient way. We demonstrate in this paper that existing services like AWS Step Functions or Azure Durable Functions incur in considerable overheads, and only Composer at IBM Cloud provides suitable performance.Successively, we analyze the architecture of OpenWhisk as an open-source FaaS systems and its orchestration features (Composer). We outline its architecture problems and propose guidelines for orchestrating massively parallel workloads using serverless functions.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3209087.3209091","title":"short-paper ","type":"Introducing a Deployment Pipeline for Continuous Delivery in a Software Architecture Course","venue":"ECSEE'18: Proceedings of the 3rd European Conference of Software Engineering Education","authors":["Lucas Greising","Alexander Bartel","Georg Hagel"],"abstract":"Continuous Delivery (CD) has emerged to an important concept of software architecture in the last few years. The goal of a CD strategy is to decrease the time to market of an application while increasing the quality of that software. However, literature shows that teaching CD practices in higher education is in an infancy stage. Therefore a new concept for teaching CD practices is developed and demonstrated. In this concept students have to master several different tools and technologies to create an automated software delivery system. This can be achieved by guiding the students through a hands-on project, in which they develop stage by stage a CD pipeline. This paper introduces necessary background information as well as the CD teaching concept with its scaffolded learning approach for implementing a CD pipeline in a software architecture course.","publicationDate":"2018-06-13T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3311790.3396670","title":"research-article ","type":"Design and Deployment of Photo2Building: A Cloud-based Procedural Modeling Tool as a Service","venue":"PEARC '20: Practice and Experience in Advanced Research Computing","authors":["Manush Bhatt","Rajesh Kalyanam","Gen Nishida","Liu He","Christopher May","Dev Niyogi","Daniel Aliaga"],"abstract":"We present a Photo2Building tool to create a plausible 3D model of a building from only a single photograph. Our tool is based on a prior desktop version which, as described in this paper, is converted into a client-server model, with job queuing, web-page support, and support of concurrent usage. The reported cloud-based web-accessible tool can reconstruct a building in 40 seconds on average and costing only 0.60 USD with current pricing. This provides for an extremely scalable and possibly widespread tool for creating building models for use in urban design and planning applications. With the growing impact of rapid urbanization on weather and climate and resource availability, access to such a service is expected to help a wide variety of users such as city planners, urban meteorologists worldwide in the quest to improved prediction of urban weather and designing climate-resilient cities of the future. ","publicationDate":"2020-07-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3366623.3368137","title":"research-article ","type":"FaaS Orchestration of Parallel Workloads","venue":"WOSC '19: Proceedings of the 5th International Workshop on Serverless Computing","authors":["Daniel Barcelona-Pons","Pedro García-López","Álvaro Ruiz","Amanda Gómez-Gómez","Gerard París","Marc Sánchez-Artigas"],"abstract":"Function as a Service (FaaS) is based on a reactive programming model where functions are activated by triggers in response to cloud events (e.g., objects added to an object store). The inherent elasticity and the pay-per-use model of serverless functions make them very appropriate for embarrassingly parallel tasks like data preprocessing, or even the execution of MapReduce jobs in the cloud.But current Serverless orchestration systems are not designed for managing parallel fork-join workflows in a scalable and efficient way. We demonstrate in this paper that existing services like AWS Step Functions or Azure Durable Functions incur in considerable overheads, and only Composer at IBM Cloud provides suitable performance.Successively, we analyze the architecture of OpenWhisk as an open-source FaaS systems and its orchestration features (Composer). We outline its architecture problems and propose guidelines for orchestrating massively parallel workloads using serverless functions.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3209087.3209091","title":"short-paper ","type":"Introducing a Deployment Pipeline for Continuous Delivery in a Software Architecture Course","venue":"ECSEE'18: Proceedings of the 3rd European Conference of Software Engineering Education","authors":["Lucas Greising","Alexander Bartel","Georg Hagel"],"abstract":"Continuous Delivery (CD) has emerged to an important concept of software architecture in the last few years. The goal of a CD strategy is to decrease the time to market of an application while increasing the quality of that software. However, literature shows that teaching CD practices in higher education is in an infancy stage. Therefore a new concept for teaching CD practices is developed and demonstrated. In this concept students have to master several different tools and technologies to create an automated software delivery system. This can be achieved by guiding the students through a hands-on project, in which they develop stage by stage a CD pipeline. This paper introduces necessary background information as well as the CD teaching concept with its scaffolded learning approach for implementing a CD pipeline in a software architecture course.","publicationDate":"2018-06-13T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3166094.3166111","title":"research-article ","type":"Novel approach to network function development","venue":"CEE-SECR '17: Proceedings of the 13th Central & Eastern European Software Engineering Conference in Russia","authors":["Ilya Philippov","Areg Melik-Adamyan"],"abstract":"This article considers a novel approach to network function development. Transmitting speed and amount of data in the networks are exponentially increasing, which makes middle-boxes to be less efficient due to cost, deployment, inflexibility, scalability and other issues. Network function virtualization technology, on the other hand, was proposed to solve this problem by moving hardware functionality to be developed as a software and deployed to commodity hardware. However, this approach brought several new problems: slow speed of network functions' development, lower performance compared to the middle-boxes, virtual machines scaling and deployment issues. Our approach presents a framework for rapid development of performant, scalable virtualized network functions.","publicationDate":"2017-10-19T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3094405.3094410","title":"research-article ","type":"Container-based Emulation of Network Control Plane","venue":"HotConNet '17: Proceedings of the Workshop on Hot Topics in Container Networking and Networked Systems","authors":["Hui Kang","Shu Tao"],"abstract":"An ongoing challenge in network system development is in evaluating the design and implementation of its control plane, without actually deploying it at production scale. Existing approaches based on simulation or emulation have various limitations. The emergence of containers offers a new way of emulating network control plane. In this paper, we design a container-based emulation framework, and introduce its implementation with two concrete use cases: a centralized SDN control plane design in Open Virtual Network (OVN) and a decentralized design in Docker's libnetwork. Through sample scalability studies on these two designs, we demonstrate the effectiveness of the proposed approach.","publicationDate":"2017-08-10T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3430984.3431027","title":"short-paper ","type":"Evaluation of Causal Inference Techniques for AIOps","venue":"CODS COMAD 2021: 8th ACM IKDD CODS and 26th COMAD","authors":["Vijay Arya","Karthikeyan Shanmugam","Pooja Aggarwal","Qing Wang","Prateeti Mohapatra","Seema Nagar"],"abstract":"Inferring causality of events from log data is critical to IT operations teams who continuously strive to identify probable root causes of events in order to quickly resolve incident tickets so that downtimes and service interruptions are kept to a minimum. Although prior work has applied some specific causal inference techniques on proprietary log data, they fail to benchmark the performance of different techniques on a common system or dataset. In this work, we evaluate the performance of multiple state-of-the-art causal inference techniques using log data obtained from a publicly available benchmark microservice system. We model log data both as a timeseries of error counts and as a temporal event sequence and evaluate 3 families of Granger causal techniques: regression based, independence testing based, and event models. Our preliminary results indicate that event models yield causal graphs that have high precision and recall in comparison to regression and independence testing based Granger methods.","publicationDate":"2021-01-01T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3417310.3431396","title":"research-article ","type":"The security framework of Fed4IoT","venue":"CCIoT '20: Proceedings of the Workshop on Cloud Continuum Services for Smart IoT Systems","authors":["Pedro Gonzalez-Gil","Antonio F. Skarmeta","Juan Antonio Martinez"],"abstract":"The high number of IoT devices, and also their availability through the Internet, has made the topic of IoT virtualisation an emerging topic, which has gained a lot of interest from both academia and industry points of view. Fed4IoT is an H2020 EU-JPN Research Project, whose aim is precisely this one. Nevertheless, security, and more specifically authorisation or access control is a fundamental aspect that must be addressed, motivated by the increase of threats and attacks that the IoT domain has suffered. In this paper we propose the use of a distributed authorisation mechanism based on DCapBAC technology, to specifically deal with the IoT virtualisation aspect, in the scope of this project. This technology has proven its validity in the IoT domain because of its distributed nature and the flexibility of their authorisation policies.","publicationDate":"2020-11-15T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3371120","title":"research-article ","type":"Synthesizing replacement classes","venue":"Proceedings of the ACM on Programming Languages","authors":["Malavika Samak","Deokhwan Kim","Martin C. Rinard"],"abstract":"We present a new technique for automatically synthesizing replacement classes. The technique starts with an original class O and a potential replacement class R, then uses R to synthesize a new class that implements the same interface and provides the same functionality as O. Critically, our technique works with a synthe- sized inter-class equivalence predicate between the states of O and R. It uses this predicate to ensure that original and synthesized methods leave corresponding O and R objects in equivalent states. The predicate therefore enables the technique to synthesize individual replacement methods in isolation while still obtain- ing a replacement class that leaves the original and replacement objects in equivalent states after arbitrarily long method invocation sequences. We have implemented the technique as part of a tool, named Mask, and evaluated it using open-source Java classes. The results highlight the effectiveness of Mask in synthesizing replacement classes.","publicationDate":"2019-12-19T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3411170.3411236","title":"research-article ","type":"Sustainable Infrastructure Monitoring for Security-Oriented Purposes","venue":"GoodTechs '20: Proceedings of the 6th EAI International Conference on Smart Objects and Technologies for Social Good","authors":["Davide Berardi","Franco Callegati","Andrea Melis","Marco Prandini"],"abstract":"As computing and communication infrastructures have gained an ever-increasing role in everybody's life, guaranteeing their reliability has become a critical endeavor. In the face of threats that grow more and more sophisticated, we must turn our attention to the techniques that have the potential to match them and scale with the infrastructure complexity. The current trend in the telecommunication industry towards \"softwarized infrastructures\" by means of new technologies such as Software Defined Networking and Network Function Virtualization may provide a innovative and effective solutions from this point of view.In this work, we outline a network security monitoring architecture aimed at striking the best trade-off between effectiveness and efficiency. This result is achieved by exploiting the possibility, already enabled by state-of-the-art, yet well tested components for infrastructural orchestration, of dynamic instantiation and composition of functions. We conclude that efficient detection of some classes of network-based denial-of-service attacks is possible, and open the path to mitigation strategies that optimize the usage of resources by deploying and re-configuring them as needed in real-time.","publicationDate":"2020-09-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3338840.3355655","title":"research-article ","type":"Container-based load balancing for WebRTC applications","venue":"RACS '19: Proceedings of the Conference on Research in Adaptive and Convergent Systems","authors":["Yung-Feng Lu","Hung-Ming Chen","Chin-Fu Kuo","Bo-Kai Tseng","Shih-Chun Chou"],"abstract":"Nowadays, the progress of the communication technology is fast. With the popularity of smart phones, tablets and computers, social networking sites or social software have also developed rapidly, changing the user's habit of using network communication software. The demand for streaming audio and video communication has increased dramatically, resulting in the maturity of the Internet today. At present, we can know that there are a variety of applications that can be talked on the market, such as LINE, Skype, Hangouts, etc., which can make instant calls. In the era of the Internet, the communication software has shortened the dispersion in the world. The distance between people everywhere.This research implements a web-based instant messaging architecture of WebRTC (Web Real-Time Communication, WebRTC) built on a container. We solved the concatenation problem caused by constructing WebRTC services on the container and sought to improve the performance. WebRTC can directly provide instant video and audio communication technology, and cooperate with ICE mechanism to communicate on different domains. No additional Plug-in is needed, only web browser can realize instant messaging function through web browser. It saves a lot of complicated steps, such as: install the user user, and so on. Our system also implements a load balancing mechanism that distributes traffic across the TURN Server, improving overall system performance.","publicationDate":"2019-09-23T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3400397.3400622","title":"research-article ","type":"Towards a deadline-based simulation experimentation framework using micro-services auto-scaling approach","venue":"WSC '19: Proceedings of the Winter Simulation Conference","authors":["Anastasia Anagnostou","Simon J. E. Taylor","Nura Tijjani Abubakar","Tamas Kiss","James DesLauriers","Gregoire Gesmier","Gabor Terstyanszky","Peter Kacsuk","Jozsef Kovacs"],"abstract":"There is growing number of research efforts in developing auto-scaling algorithms and tools for cloud resources. Traditional performance metrics such as CPU, memory and bandwidth usage for scaling up or down resources are not sufficient for all applications. For example, modeling and simulation experimentation is usually expected to yield results within a specific timeframe. In order to achieve this often the quality of experiments is compromised either by restricting the parameter space to be explored or by limiting the number of replications required to give statistical confidence. In this paper, we present early stages of a deadline-based simulation experimentation framework using a micro-services auto-scaling approach. A case study of an agent-based simulation of a population physical activity behavior is used to demonstrate our framework.","publicationDate":"2019-12-07T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3331542.3342572","title":"research-article ","type":"Scaling Erlang distribution: going beyond the fully connected mesh","venue":"Erlang 2019: Proceedings of the 18th ACM SIGPLAN International Workshop on Erlang","authors":["Adam Lindberg","Sébastien Merle","Peer Stritzinger"],"abstract":"Distributed Erlang, the process of transparently running Erlang programs over networks, has a long history of immense usefulness but has problems when distributed systems reach certain scales. We explain the issues and show research done towards the goal of transparently enhancing Erlang distribution, so that changes to existing applications and systems can be avoided. We propose several research directions together with prototype implementations that all serve the purpose of improving the current status quo. This includes using different transport protocols, generalizing implementation efforts and incorporating routing protocols for more dynamic node constellations. We then describe some background and history of various work to solve Erlang distribution scalability issues. We show that there is much room for improvement on the Erlang distribution layer without breaking abstractions that developers are used to and rely on.","publicationDate":"2019-08-17T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3473714.3473729","title":"research-article ","type":"Research on Task Collaboration Framework of Mobile Intelligent Sensor Cluster Based on Edge Computing Architecture","venue":"ICCIR 2021: Proceedings of the 2021 International Conference on Control and Intelligent Robotics","authors":["Guanghao Bai","Yawen He","Changming Zhao"],"abstract":"In this paper, it introduces a novel task framework for intelligent mobile sensor clusters, named Mobile Cluster Task Collaboration Framework (MCTCF). The core content of the framework is to build environment information interaction channels between mobile sensors and edge computing center via Collaborative Task Frame (CTF) in the highly virtualized environment. Therefore, it is able to train the offloading decision tree model for the current task in edge data center, and transmit the training result back to the mobile sensors. The theoretical analysis indicates that the it improves the sensors cluster processing efficiency effectively. The HWIL simulation results show that the performance of MCTCF is agreement with the theoretical analysis.","publicationDate":"2021-06-17T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3447080.3447091","title":"research-article ","type":"Development of a configuration management course for computing operations students","venue":"Journal of Computing Sciences in Colleges","authors":["Charles Border"],"abstract":"The Operations side of deploying a modern computing application necessarily involves multiple groups working in concert to develop the application and the server side configuration that will support that application. This paper reports on efforts to develop a course that encourages students to dig into issues related to configuration management, security policy development, application auditing, business control issues, and most importantly, team work. While the course is entitled \"Configuration Management\" it is much more about students creating a process for secure iterative application deployment that borrows extensively from the DevOps movement.Ansible, our chosen configuration management tool, is relatively easy to work with at the level of complexity that can be reached in an undergraduate class. What made this class different was the attempt made to create a process that would more closely mimic the Operations side of a DevOps workflow. Initial results from the class were encouraging and many lessons were learned.","publicationDate":"2020-09-30T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3429885.3429964","title":"short-paper ","type":"Cheetah: A fast unsupervised learning technique to provision next generation network services","venue":"WOC'20: Proceedings of the 2020 6th International Workshop on Container Technologies and Container Clouds","authors":["Laaziz Lahlou","Nadjia Kara","Mohssine Arouch","Claes Edstrom"],"abstract":"Recently, attributed graphs have been extensively employed in modeling, studying and analyzing complex interactions in real world systems. A myriad of techniques have been proposed to partition these graphs into clusters that exhibit small entropy with respect to both compositional attributes and the structural properties of the graph. In cloud network infrastructures, they play an important role to understand end users, compute nodes and their interactions. One of the main challenges in today's large scale cloud infrastructures is to categorize these compute nodes into clusters that share similar attributes. Existing unsupervised machine learning techniques such as k-Means and DBSCAN, are inadequate to partition large scale computer network infrastructures due to their non suitability for such contexts and their algorithmic complexities that prevent them from being scalable to such sizes in a reasonable time. In this paper, we first formulate the problem of partitioning attributed graphs in the context of cloud infrastructures as a Quadratic Assignment Problem to solve small to medium scale instances and show its NP-Hardness. We then propose Cheetah a fast and scalable multi-objective topology-aware unsupervised machine learning technique that is tailored to effectively partition large scale cloud network infrastructures. Yet, in terms of complexity, Cheetah is linear as it leverages Breadth First Search algorithm. Experimental results demonstrate its ability to quickly construct good-quality clusters (≈ 1.63 seconds) given 1000 nodes compared to K-Means (≈ 2.78 seconds) and DBSCAN (≈ 24.76 seconds), respectively, and reveal its suitability for large scale infrastructures making it an appealing solution to be integrated into orchestration systems.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3332186.3332212","title":"research-article ","type":"StashCache: A Distributed Caching Federation for the Open Science Grid","venue":"PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning)","authors":["Derek Weitzel","Marian Zvada","Ilija Vukotic","Rob Gardner","Brian Bockelman","Mats Rynge","Edgar Fajardo Hernandez","Brian Lin","Mátyás Selmeci"],"abstract":"Data distribution for opportunistic users is challenging as they neither own the computing resources they are using or any nearby storage. Users are motivated to use opportunistic computing to expand their data processing capacity, but they require storage and fast networking to distribute data to that processing. Since it requires significant management overhead, it is rare for resource providers to allow opportunistic access to storage. Additionally, in order to use opportunistic storage at several distributed sites, users assume the responsibility to maintain their data.In this paper we present StashCache, a distributed caching federation that enables opportunistic users to utilize nearby opportunistic storage. StashCache is comprised of four components: data origins, redirectors, caches, and clients. StashCache has been deployed in the Open Science Grid for several years and has been used by many projects. Caches are deployed in geographically distributed locations across the U.S. and Europe. We will present the architecture of StashCache, as well as utilization information of the infrastructure. We will also present performance analysis comparing distributed HTTP Proxies vs StashCache.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3287324.3287433","title":"research-article ","type":"Facing Backwards While Stumbling Forwards: The Future of Teaching Web Development","venue":"SIGCSE '19: Proceedings of the 50th ACM Technical Symposium on Computer Science Education","authors":["Randy Connolly"],"abstract":"Web development continues to grow as an essential skill and knowledge area for employed computer science graduates. Yet within the ACM CS2013 curriculum recommendation and within computing education research in general, web development has been shrinking or even disappearing all together. This paper uses an informal systematic literature review methodology to answer three research questions: what approaches are being advocated in existing web development education research, what are current trends in industry practice, and how should web development be taught in light of these current trends. Results showed a significant mismatch between the type of web development typically taught in higher education settings in comparison to web development in industry practice. Consequences for the pedagogy of web development courses, computer science curriculum in general, and for computing education research are also discussed","publicationDate":"2019-02-21T23:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3445970.3451155","title":"short-paper ","type":"An Empirical Evaluation of Automated Machine Learning Techniques for Malware Detection","venue":"IWSPA '21: Proceedings of the 2021 ACM Workshop on Security and Privacy Analytics","authors":["Partha Pratim Kundu","Lux Anatharaman","Tram Truong-Huu"],"abstract":"Nowadays, it is increasingly difficult even for a machine learning expert to incorporate all of the recent best practices into their modeling due to the fast development of state-of-the-art machine learning techniques. For the applications that handle big data sets, the complexity of the problem of choosing the best performing model with the best hyper-parameter setting becomes harder. In this work, we present an empirical evaluation of automated machine learning (AutoML) frameworks or techniques that aim to optimize hyper-parameters for machine learning models to achieve the best achievable performance. We apply AutoML techniques to the malware detection problem, which requires achieving the true positive rate as high as possible while reducing the false positive rate as low as possible. We adopt two AutoML frameworks, namely AutoGluon-Tabular and Microsoft Neural Network Intelligence (NNI) to optimize hyper-parameters of a Light Gradient Boosted Machine (LightGBM) model for classifying malware samples. We carry out extensive experiments on two data sets. The first data set is a publicly available data set (EMBER data set), that has been used as a benchmarking data set for many malware detection works. The second data set is a private data set we have acquired from a security company that provides recently-collected malware samples. We provide empirical analysis and performance comparison of the two AutoML frameworks. The experimental results show that AutoML frameworks could identify the set of hyper-parameters that significantly outperform the performance of the model with the known best performing hyper-parameter setting and improve the performance of a LightGBM classifier with respect to the true positive rate from $86.8%$ to $90%$ at $0.1%$ of false positive rate on EMBER data set and from $80.8%$ to $87.4%$ on the private data set.","publicationDate":"2021-04-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3378064","title":"research-article ","type":"How to transition incrementally to microservice architecture","venue":"Communications of the ACM","authors":["Karoly Bozan","Kalle Lyytinen","Gregory M. Rose"],"abstract":"A field study examines technological advances that have created versatile software ecosystems to develop and deploy microservices.","publicationDate":"2020-12-16T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3422604.3425944","title":"research-article ","type":"Solver-Aided Multi-Party Configuration","venue":"HotNets '20: Proceedings of the 19th ACM Workshop on Hot Topics in Networks","authors":["Kevin Dackow","Andrew Wagner","Tim Nelson","Shriram Krishnamurthi","Theophilus A. Benson"],"abstract":"Configuring a service mesh often involves multiple parties, each of whom is responsible for separate portions of the overall system. This can result in miscommunication, silent and sudden errors, or a failure to meet goals.We identify two distinct modes of configuration that call for different solutions. We use synthesis algorithms to extract a set of properties---the envelope ---that each party needs the other to obey. Administrators can use the envelope to aid verification and synthesis or to support fault-localization and negotiation when goals conflict.This paper introduces the problem, lays out the modes, presents algorithms for to each, and gives a prototype implementation. We use this to show the feasibility of the approach in the microservices access-control domain and raise new research questions.","publicationDate":"2020-11-03T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3311790.3396622","title":"research-article ","type":"NCSA Internship Program for Cyberinfrastructure Professionals","venue":"PEARC '20: Practice and Experience in Advanced Research Computing","authors":["Daniel Lapine","Volodymyr Kindratenko","Luisa-Maria Rosu"],"abstract":"In 2017, National Center for Supercomputing Applications (NCSA) at the University of Illinois at Urbana-Champaign (UIUC) established a pilot internship program for cyberinfrastructure (CI) professionals. The program, funded by NSF’s Office of Advanced Cyberinfrastructure (OAC) (award 1730519), was designed to address the shortage of a workforce with the specialized skills needed to support advanced CI operations. The program was envisioned to provide internship opportunities for individuals who want to gain first-hand experience in the CI operations at a supercomputing center, and develop and refine instructional materials to serve as a template that is openly distributed for use by other centers and institutions to train CI professionals. Program interns are selected from a pool of applicants with the main selection criteria of having a completed classwork equivalent to an associate degree and a demonstrated interest in a career in CI operations. Interns work directly with a group of NCSA engineers in one of the areas of CI focus to gain hands-on experience in the deployment and operation of high-performance computing (HPC) infrastructure at a leading HPC center. The expectation is that interns will enter a workforce that will develop, deploy, manage and support advanced CI at other universities, centers, and industry to meet the needs of the national computational science research community across academia and industry.","publicationDate":"2020-07-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3366626.3368129","title":"research-article ","type":"Enabling Enterprise Blockchain Interoperability with Trusted Data Transfer (Industry Track)","venue":"Middleware '19: Proceedings of the 20th International Middleware Conference Industrial Track","authors":["Ermyas Abebe","Dushyant Behl","Chander Govindarajan","Yining Hu","Dileban Karunamoorthy","Petr Novotny","Vinayaka Pandit","Venkatraman Ramakrishna","Christian Vecchiola"],"abstract":"The adoption of permissioned blockchain networks in enterprise settings has seen an increase in growth over the past few years. While encouraging, this is leading to the emergence of new data, asset and process silos limiting the potential value these networks bring to the broader ecosystem. Mechanisms for enabling network interoperability help preserve the benefits of independent sovereign networks, while allowing for the transfer or sharing of data, assets and processes across network boundaries. However, a naive approach to interoperability based on traditional point-to-point integration is insufficient for preserving the underlying trust decentralized networks provide. In this paper, we lay the foundation for an approach to interoperability based on a communication protocol that derives trust from the underlying network consensus protocol. We present an architecture and a set of building blocks that can be adapted for use in a range of network implementations and demonstrate a proof-of-concept for trusted data-sharing between two independent trade finance and supply-chain networks, each running on Hyperledger Fabric. We show how existing blockchain deployments can be adapted for interoperation and discuss the security and extensibility of our architecture and mechanisms.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3230833.3232854","title":"research-article ","type":"A reference architecture for the container ecosystem","venue":"ARES 2018: Proceedings of the 13th International Conference on Availability, Reliability and Security","authors":["Madiha H. Syed","Eduardo B. Fernandez"],"abstract":"Containers have gained immense popularity as a portable and lightweight virtualization solution. They facilitate application development, deployment and distribution across computing environments. Their success is also attributed to the support they offer for DevOps teams and for applications developed using a microservices architecture style. Containers are not the only components in the environment but work closely with other components for managing and supporting them, forming an ecosystem. Architectural modeling can be used as a powerful tool to represent ecosystems which helps understand, build and secure such complex systems. We describe in this paper several models we have created for container ecosystem components. These models are abstract, and they help generalize the systems to handle complexity and heterogeneity; they provide a common vocabulary and build holistic and unified views of the systems. The use of UML for modeling improves precision. This can lead to better implementations with respect to reliability, security and interoperability compared to ad hoc methods. A reference architecture will not just facilitate the work of developers and security engineers but also of anyone who aims to ensure compliance, privacy, safety, reliability and/or governance for container ecosystems and we show how to build one. We also describe relationships between container, cloud and IoT ecosystems. This paper is part of our work on developing a security reference architecture for container ecosystems.","publicationDate":"2018-08-26T22:00:00.000Z","citationCount":10},{"url":"https://dl.acm.org/doi/10.1145/3007203.3007214","title":"research-article ","type":"FRED: A Hosted Data Flow Platform for the IoT","venue":"MOTA '16: Proceedings of the 1st International Workshop on Mashups of Things and APIs","authors":["Michael Blackstock","Rodger Lea"],"abstract":"IoT developers need to integrate a variety of protocols, backend components and services; they often need to pre and post-process data as well as react to changes in the real world. Data flow programming tools have been introduced in a number of related domains to provide a flexible, but easy to use visual programming environment for rapid development. The open source Node-RED system provides such a tool for IoT applications, but is limited to executing a single flow file in a single thread. In this paper we describe the design of our system called the Front-End for Node-RED (FRED) that manages multiple instances of Node-RED for logged in users, allowing Node-RED to be used as a cloud-hosted data flow mashup tool for the IoT. We present some examples of how some of our 1800+ users are using FRED for IoT mashups, and some of the challenged we faced in implementing the FRED system.","publicationDate":"2016-12-11T23:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3458336.3465294","title":"research-article ","type":"Unix shell programming: the next 50 years","venue":"HotOS '21: Proceedings of the Workshop on Hot Topics in Operating Systems","authors":["Michael Greenberg","Konstantinos Kallas","Nikos Vasilakis"],"abstract":"The Unix shell is a powerful, ubiquitous, and reviled tool for managing computer systems. The shell has been largely ignored by academia and industry. While many replacement shells have been proposed, the Unix shell persists. Two recent threads of formal and practical research on the shell enable new approaches. We can help manage the shell's essential shortcomings (dynamism, power, and abstruseness) and address its inessential ones. Improving the shell holds much promise for development, ops, and data processing.","publicationDate":"2021-05-31T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3007203.3007214","title":"research-article ","type":"FRED: A Hosted Data Flow Platform for the IoT","venue":"MOTA '16: Proceedings of the 1st International Workshop on Mashups of Things and APIs","authors":["Michael Blackstock","Rodger Lea"],"abstract":"IoT developers need to integrate a variety of protocols, backend components and services; they often need to pre and post-process data as well as react to changes in the real world. Data flow programming tools have been introduced in a number of related domains to provide a flexible, but easy to use visual programming environment for rapid development. The open source Node-RED system provides such a tool for IoT applications, but is limited to executing a single flow file in a single thread. In this paper we describe the design of our system called the Front-End for Node-RED (FRED) that manages multiple instances of Node-RED for logged in users, allowing Node-RED to be used as a cloud-hosted data flow mashup tool for the IoT. We present some examples of how some of our 1800+ users are using FRED for IoT mashups, and some of the challenged we faced in implementing the FRED system.","publicationDate":"2016-12-11T23:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3447851.3458739","title":"research-article ","type":"Examining Raft's behaviour during partial network failures","venue":"HAOC '21: Proceedings of the 1st Workshop on High Availability and Observability of Cloud Systems","authors":["Chris Jensen","Heidi Howard","Richard Mortier"],"abstract":"State machine replication protocols such as Raft are widely used to build highly-available strongly-consistent services, maintaining liveness even if a minority of servers crash. As these systems are implemented and optimised for production, they accumulate many divergences from the original specification. These divergences are poorly documented, resulting in operators having an incomplete model of the system's characteristics, especially during failures. In this paper, we look at one such Raft model used to explain the November Cloudflare outage and show that etcd's behaviour during the same failure differs. We continue to show the specific optimisations in etcd causing this difference and present a more complete model of the outage based on etcd's behaviour in an emulated deployment using reckon. Finally, we highlight the upcoming PreVote optimisation in etcd, which might have prevented the outage from happening in the first place.","publicationDate":"2021-04-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3292500.3330699","title":"research-article ","type":"Pythia: AI-assisted Code Completion System","venue":"KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","authors":["Alexey Svyatkovskiy","Ying Zhao","Shengyu Fu","Neel Sundaresan"],"abstract":"In this paper, we propose a novel end-to-end approach for AI-assisted code completion called Pythia. It generates ranked lists of method and API recommendations which can be used by software developers at edit time. The system is currently deployed as part of Intellicode extension in Visual Studio Code IDE. Pythia exploits state-of-the-art large-scale deep learning models trained on code contexts extracted from abstract syntax trees. It is designed to work at a high throughput predicting the best matching code completions on the order of 100 ms. We describe the architecture of the system, perform comparisons to frequency-based approach and invocation-based Markov Chain language model, and discuss challenges serving Pythia models on lightweight client devices. The offline evaluation results obtained on 2700 Python open source software GitHub repositories show a top-5 accuracy of 92%, surpassing the baseline models by 20% averaged over classes, for both intra and cross-project settings.","publicationDate":"2019-07-24T22:00:00.000Z","citationCount":12},{"url":"https://dl.acm.org/doi/10.5555/3172795.3172821","title":"research-article ","type":"Deployment Specification challenges in the context of large scale systems","venue":"CASCON '17: Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering","authors":["Miguel Jiménez","Norha M. Villegas","Gabriel Tamura","Hausi A. Müller"],"abstract":"Traditionally, the focus of software deployment has been mainly on the infrastructure to realise deployment and configuration (D&C) of complex and distributed systems, with an increasing interest in deployment of internet of things and cyber-physical systems. Advances in job scheduling, storage orchestration, containerized applications, along with agile practices such as continuous integration and microservices architecture, have improved the state of the practice. However, little effort has been devoted to the need for D&C specifications to support the various levels of detail and abstraction present in large-scale systems. The understanding of the software components hierarchy has shifted from the comprehension of design artefacts, usually specified with static diagrams, to the understanding of runtime concepts. The DevOps movement has dramatically influenced how and when deployment is realised, but little has been done from the software perspective in terms of documentation and linkage between design and runtime artefacts in the sense of software specification as such. This paper presents an overview of the state of the art of deployment requirements for large-scale, distributed and complex software and its automation and characterises a set of deployment specification challenges intended as starting points for advancing the field of software deployment.","publicationDate":"2017-11-05T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.5555/3432601.3432628","title":"research-article ","type":"Evaluating the effectiveness of static word embeddings on the classification of IT support tickets","venue":"CASCON '20: Proceedings of the 30th Annual International Conference on Computer Science and Software Engineering","authors":["Yasmen Wahba","Nazim H. Madhavji","John Steinbacher"],"abstract":"Support tickets are service requests, initiated by a system's end-users when they encounter issues with their system. With a wide user-base and system issues, there will be an ongoing influx of generated support tickets. Manual classification and prioritization is effortful and error-prone, that can lead to incorrect routing and delays in the resolution of the issues.Recently, various state-of-the-art machine learning and deep learning methods have been applied to automate the process of text classification. Because the quality of these methods highly depends on the quality of the associated \"features\", in this paper we focus on the \"feature engineering\" step in the classification process. In particular, we evaluate the effectiveness of using different static word embeddings on the accuracy of classifying IT support tickets.In collaboration with an industrial partner, we were able to train and evaluate our machine learning model on 1.6 million support tickets and 32 ticket categories.The experimental results show that the traditional Term Frequency Inverse Document Frequency (TFIDF) bag-of-words along with Support Vector Machines (SVM) provides competitive results and sometimes outperforms static word embedding models such as word2vec while maintaining low computational cost.","publicationDate":"2020-11-09T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3359993.3366765","title":"research-article ","type":"Execution Plans for Serverless Computing in Information Centric Networking","venue":"ENCP '19: Proceedings of the 1st ACM CoNEXT Workshop on Emerging in-Network Computing Paradigms","authors":["Christopher Scherb","Claudio Marxer","Christian Tschudin"],"abstract":"Information Centric Networking (ICN) is a modern networking concept which enables users to address named data directly by their name, without knowing the location where the data is stored. Since requesting static data is only a special case of requesting processed data, Named Function Networking (NFN) is a generalization of ICN by providing the possibility to define how data should be processed before they are delivered. Thereby, the network decides, where to process the data. The decision where to process data is crucial for the performance and the load on the network, especially when NFN is used within a data center. In this paper we discuss how NFN forwarding decisions can be improved and how to plan an execution of a computation in a name-based network to improve the execution performance. A plan is a list of instruction how and where to execute a computation. To create a plan, the network finds the best way to execute a computation regarding to a predefined metric. Furthermore, we present an extension for reusing plans and creating templates.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3053600.3053602","title":"research-article ","type":"Elastic Provisioning of Virtual Machines for Container Deployment","venue":"ICPE '17 Companion: Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion","authors":["Matteo Nardelli","Christoph Hochreiner","Stefan Schulte"],"abstract":"Docker containers enable to package an application together with all its dependencies and easily run it in any environment. Thanks to their ease of use and portability, containers are gaining an increasing interest and promise to change the way how Cloud platforms are designed and managed. For their execution in the Cloud, we need to solve the container deployment problem, which deals with the identification of an elastic set of computing machines that can host and execute those containers, while considering the diversity of their requirements.In this paper, we provide a general formulation of the Elastic provisioning of Virtual machines for Container Deployment (for short, EVCD) as an Integer Linear Programming problem, which takes explicitly into account the heterogeneity of container requirements and virtual machine resources. Besides optimizing multiple QoS metrics, EVCD can reallocate containers at runtime, when a QoS improvement can be achieved. Using the proposed formulation as benchmark, we evaluate two well-known heuristics, i.e., greedy first-fit and round-robin, that are usually adopted for solving the container deployment problem.","publicationDate":"2017-04-17T22:00:00.000Z","citationCount":19},{"url":"https://dl.acm.org/doi/10.1145/3338840.3355659","title":"research-article ","type":"Case study on data communication in microservice architecture","venue":"RACS '19: Proceedings of the Conference on Research in Adaptive and Convergent Systems","authors":["Antonin Smid","Ruolin Wang","Tomas Cerny"],"abstract":"Microservice Architecture is becoming a design standard for modern cloud-based software systems. However, data communication management remains a challenge. This is especially apparent when migrating from an existing monolithic system into microservices. In this paper, we report on data synchronization and improvement of the data-source performance. We faced these challenges in production-level development. Two case studies illustrate and describe our approach. To address data synchronization we propose using an automated data streaming system between databases. To improve the performance of a data-source we introduced a solution with the distributed cache. We discuss the balance between the performance and coupling and point out situations where our architectures are appropriate.","publicationDate":"2019-09-23T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3332186.3332211","title":"research-article ","type":"Scaling R Shiny Apps to Multiple Concurrent Users in a Secured HPC Environment Using Open OnDemand","venue":"PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning)","authors":["Eric Franz","Hatice G. Ozer","Trey Dockendorf","Venkat S. Gadepalli","Amy Webb","Alan Chalker","Maciej Pietrzak","Morgan Rodgers","Doug Johnson","David E. Hudak"],"abstract":"Open OnDemand is an open source project to provide web based access to HPC resources (https://openondemand.org). OnDemand's \"Interactive Apps\" support launching web applications like Jupyter and RStudio on cluster compute nodes, proxying HTTP requests to those apps, and secure user separation of both app and data access enforced at the OS level [5]. This paper describes leveraging OnDemand to enable the deployment of R Shiny applications that can be launched in OnDemand's interactive HPC environment by multiple analysts at the same time to visualize different datasets. Dataset and app authorization is managed using network file system (NFS) file access lists (ACLs). A custom OnDemand app was built to enable admins to manage who has access to specific apps and what datasets can be loaded by those apps. By using OnDemand to facilitate the use of an HPC batch scheduler as the process manager and OnDemand as the proxy we can support multiple analysts launching Shiny apps to access their data in a scalable and secure manner without the need for managing a separate dedicated installation of RStudio or Shiny Server.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3282278.3282279","title":"research-article ","type":"FAST: A MapReduce Consensus for High Performance Blockchains","venue":"BlockSys'18: Proceedings of the 1st Workshop on Blockchain-enabled Networked Sensor Systems","authors":["Nida Khan"],"abstract":"Blockchain platforms when used as a database for IoT systems can resolve data reliability fault-tolerance, consistency and non-repudiation issues. However, their inherent shortcomings related to their throughput in terms of processed transactions, limit their applicability in such environments in a decentralized way as the underlying network is unable to sustain high workloads. In this paper a fully decentralized high performance consensus mechanism, named FAST, is proposed for a public blockchain. FAST is based on mapreduce paradigm for aggregating and adding transactions on blockchain blocks. FAST was implemented and evaluated in a basic blockchain prototype. A light client for FAST using IPFS, was developed to bring about a reduction in the data stored locally. The obtained results from tests conducted on the prototype depict that FAST exceeds the performance of not just other existing blockchain platforms but comes very close to the throughput of traditional electronic payment networks such as Visa.","publicationDate":"2018-11-03T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.5555/3291291.3291321","title":"research-article ","type":"Adaptation as a service","venue":"CASCON '18: Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering","authors":["Hamzeh Khazaei","Alireza Ghanbari","Marin Litoiu"],"abstract":"Current and emerging complex systems of many types including but not limited to big data systems, web-based systems, data centers and cloud infrastructure, social networks and the Internet of Things (IoT) have increasingly distributed and dynamic architecture that provide unprecedented flexibility in creating and supporting applications. However, such highly distributed architecture also increases the complexity of end-to-end management of such systems. Due to the sheer complexity, uncertainty and at the same time programmability of cloud environments, microservices and finally big data analytics, it is now required, and possible, to enable autonomic management in distributed systems in a dependable manner. In this paper, we argue that building autonomic management systems is a challenging task and requires its own set of expertise and knowledge. Therefore, in the light of current challenges, available enablers and recent successful stories, we propose the idea of moving from self-adaptation to ADaptation-as-a-Service (ADaaS).","publicationDate":"2018-10-28T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3154448.3154453","title":"research-article ","type":"Usable declarative configuration specification and validation for applications, systems, and cloud","venue":"Middleware '17: Proceedings of the 18th ACM/IFIP/USENIX Middleware Conference: Industrial Track","authors":["Salman Baset","Sahil Suneja","Nilton Bila","Ozan Tuncer","Canturk Isci"],"abstract":"Diagnosing misconfiguration across modern software stacks is increasingly difficult. These stacks comprise multiple micro-services which are deployed across a combination of containers and hosts (VMs, physical machines) in a cloud or a data center. The existing approaches for detecting misconfiguration, whether rule-based or inference, are highly specialized (e.g., security only), cumbersome to write and maintain, geared towards a host (instead of container images), and can result into false-positives or false-negatives.This paper introduces configuration validation language (CVL), a declarative language for writing rules to detect misconfigurations that can, for instance, impact security, performance, functionality. We have built a system, ConfigValidator, which applies the CVL rules across a multitude of environments such as Docker images, running containers, host, and cloud. The system is running in production and has scanned thousands of Docker images and running containers for identifying misconfigurations.","publicationDate":"2017-12-10T23:00:00.000Z","citationCount":10},{"url":"https://dl.acm.org/doi/10.1145/3167020.3167048","title":"research-article ","type":"Hybrid Cloud Architecture for Connected Thai Government Agency","venue":"MEDES '17: Proceedings of the 9th International Conference on Management of Digital EcoSystems","authors":["Tuul Triyason","Anuchart Tassanaviboon","Chonlamenth Arpnikanondt"],"abstract":"Currently, the IT infrastructure architecture of Thai government agencies mostly use the silo-based design. This is because IT budgets were granted for projects where the application software and hardware are bundled together. It causes difficulty for data center resources to be shared across multiple projects, leading to inefficient resource utilization and the lack of data integration. Since data integration is the core concept of Thailand's IT strategy, cloud computing is a cutting-edge technology that focuses on resource sharing and seamless data integration. However, there lacks evident research about a cloud architecture that is suitable for Thai government agencies because the limitations of Thai government policies and a wide variety of cloud services in Thailand. Henceforth, the purpose of this work aims to study and compare existing cloud architectures and its services in terms of security, privacy, pricing, flexibility, reliability, and management. The study also attempts to design and define the Hybrid Community Cloud model in order to apply cloud computing as a blueprint for Thai government agencies. The result of this study indicated that the proposed model appears to be the most appropriate model for government agencies in Thailand. Moreover, this study also presents the implementation of the hybrid model for the Ministry of Social Development and Human Security of Thailand.","publicationDate":"2017-11-06T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3447545.3451201","title":"research-article ","type":"Towards Extraction of Message-Based Communication in Mixed-Technology Architectures for Performance Model","venue":"ICPE '21: Companion of the ACM/SPEC International Conference on Performance Engineering","authors":["Snigdha Singh","Yves Richard Kirschner","Anne Koziolek"],"abstract":"Software systems architected using multiple technologies are becoming popular. Many developers use these technologies as it offers high service quality which has often been optimized in terms of performance. In spite of the fact that performance is a key to the technology-mixed software applications, still there a little research on performance evaluation approaches explicitly considering the extraction of architecture for modelling and predicting performance.In this paper, we discuss the opportunities and challenges in applying existing architecture extraction approaches to support model-driven performance prediction for technology-mixed software. Further, we discuss how it can be extended to support a message-based system. We describe how various technologies deriving the architecture can be transformed to create the performance model. In order to realise the work, we used a case study from the energy system domain as an running example to support our arguments and observations throughout the paper.","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3332186.3332231","title":"research-article ","type":"Scalable Parallel Programming in Python with Parsl","venue":"PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning)","authors":["Yadu Babuji","Anna Woodard","Zhuozhao Li","Daniel S. Katz","Ben Clifford","Ian Foster","Michael Wilde","Kyle Chard"],"abstract":"Python is increasingly the lingua franca of scientific computing. It is used as a higher level language to wrap lower-level libraries and to compose scripts from various independent components. However, scaling and moving Python programs from laptops to supercomputers remains a challenge. Here we present Parsl, a parallel scripting library for Python. Parsl makes it straightforward for developers to implement parallelism in Python by annotating functions that can be executed asynchronously and in parallel, and to scale analyses from a laptop to thousands of nodes on a supercomputer or distributed system. We examine how Parsl is implemented, focusing on syntax and usage. We describe two scientific use cases in which Parsl's intuitive and scalable parallelism is used.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3314212.3314217","title":"research-article ","type":"The Dagstuhl beginners guide to reproducibility for experimental networking research","venue":"ACM SIGCOMM Computer Communication Review","authors":["Vaibhav Bajpai","Anna Brunstrom","Anja Feldmann","Wolfgang Kellerer","Aiko Pras","Henning Schulzrinne","Georgios Smaragdakis","Matthias Wählisch","Klaus Wehrle"],"abstract":"Reproducibility is one of the key characteristics of good science, but hard to achieve for experimental disciplines like Internet measurements and networked systems. This guide provides advice to researchers, particularly those new to the field, on designing experiments so that their work is more likely to be reproducible and to serve as a foundation for follow-on work by others.","publicationDate":"2019-02-19T23:00:00.000Z","citationCount":15},{"url":"https://dl.acm.org/doi/10.1145/3102980.3102986","title":"research-article ","type":"Verification in the Age of Microservices","venue":"HotOS '17: Proceedings of the 16th Workshop on Hot Topics in Operating Systems","authors":["Aurojit Panda","Mooly Sagiv","Scott Shenker"],"abstract":"Many large applications are now built using collections of microservices, each of which is deployed in isolated containers and which interact with each other through the use of remote procedure calls (RPCs). The use of microservices improves scalability -- each component of an application can be scaled independently -- and deployability. However, such applications are inherently distributed and current tools do not provide mechanisms to reason about and ensure their global behavior. In this paper we argue that recent advances in formal methods and software packet processing pave the path towards building mechanisms that can ensure correctness for such systems, both when they are being built and at runtime. These techniques impose minimal runtime overheads and are amenable to production deployments.","publicationDate":"2017-05-06T22:00:00.000Z","citationCount":15},{"url":"https://dl.acm.org/doi/10.1145/3411170.3411242","title":"research-article ","type":"A Geo-distributed Architectural Approach Favouring Smart Tourism Development in the 5G Era","venue":"GoodTechs '20: Proceedings of the 6th EAI International Conference on Smart Objects and Technologies for Social Good","authors":["Armir Bujari","Claudio Bergamini","Antonio Corradi","Luca Foschini","Claudio E. Palazzi","Andrea Sabbioni"],"abstract":"The fast-paced evolution of ICT technology is revolutionizing our every day life, endowing us with a seamless digital assistant accessible through smart-devices. In this context, even the way we approach tourism and holidays has undergone many changes. In fact, most of us nowadays exploit smart devices to plan, book and manage the experience. This different approach to tourism is often called Smart Tourism and it is acquiring more and more importance for business, public administrations, and tourists themselves. The idea behind our proposal is to further enhance existing structure and services of a city, promoting and encouraging the smart tourism concept while satisfying the ever increasing necessity, dynamicity and stringent Quality of Service (QoS) requirements future application scenarios embody. To this end, we propose a conceptual architectural model following a Mobile Edge Computing (MEC) approach, exploiting virtualization and multiple geographically distributed Function as a Service (FaaS) edge clouds equipped with storage capabilities. While preserving the general aspect of our study and without loss of generality, we envision a reference scenario where users consume and produce data that are geographically bound to a location of interest. This modus operandi could help unlock smart tourism potential, focusing on local communal phenomena, harvesting socio-technical data which would otherwise not be possible on a global scale through traditional centralized information systems. Along with the proposal, we discuss some preliminary evaluation of the envisioned platform, outlining some research directions.","publicationDate":"2020-09-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3360664.3360676","title":"research-article ","type":"Network Forensic Investigation in OpenContrail Environments","venue":"CECC 2019: Proceedings of the Third Central European Cybersecurity Conference","authors":["Alexander Heckel","Daniel Spiekermann"],"abstract":"The requirements of today's data center networks include scalability, multi-tenancy and isolation from the underlying infrastructure, which are primarily achieved through the use of network virtualization. As a downside, the overall complexity increases with the number of technologies involved, which has a significant impact upon network forensic investigation. In this context we investigated OpenContrail, an open source framework for network virtualization that provides built-in methods for collecting network traffic. In our research, we concluded that these methods work in principle, but are not suitable to capture network traffic that can be used in court. The packet mirroring turned out to be incomplete and the capture process can be detected by the virtual machine under investigation. Based on these findings, we developed a more flexible agent that especially ensures the transparency of the capture process for the suspicious virtual machine.","publicationDate":"2019-11-13T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3332186.3332191","title":"research-article ","type":"GenApp, Containers and Abaco: Technical Paper","venue":"PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning)","authors":["Emre Brookes","Joe Stubbs"],"abstract":"GenApp is an NSF-funded framework for rapid generation of applications including feature rich science gateways. GenApp is being successfully used to produce science gateways wrapping scientific programs. Its organization is designed to simplify the process of adding new features and capabilities to generated applications. A limited set of definition files define application generation. To bring a new executable into GenApp, one creates a single \"module\" definition file. The executable must run on some compute resource accessible by the generated application. Installations of the executable on target resources may be complex. To simplify portability of execution, we introduce automatic containerization of defined modules and integration of container execution. Abaco is an NSF-funded web service and distributed computing platform providing functions-as-a-service (FaaS) to the research computing community. Abaco implements functions using the Actor Model of concurrent computation. We introduce GenApp integration of execution with Abaco as a resource.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3316782.3322751","title":"research-article ","type":"Drive by maintenance: towards adaptive work environments with improved industrial HCI","venue":"PETRA '19: Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments","authors":["Andrei Miclaus","Erik Pescara","Alexander Mädche","Michael Beigl"],"abstract":"Although automation is the backbone of the modern industrial complex, humans remain the indispensable shepherds of the machine park. One operator may be responsible for several machines that need to run continuously. Unfortunately, the complexity of the machines and processes increased faster than the improvement in the corresponding interaction technologies. We propose a multi-modal adaptive human computer interface system for the modern industry that relies on position, activity and other relevant contextual information, in order to provide a more flexible interaction in industrial scenarios. Information about the machine, is transmitted to the worker using a vibrotactile display on his wrist whenever the line of sight is broken. The context in which the user and the machine currently reside in, are determined by software artefacts (Apps). We leverage modern software concepts and an App based eco-system platform on the manufacturing shop floor to organize the software systems described in this paper. We evaluate transmitting arbitrary information via vibrotactile displays and come to the conclusion that such a system is feasible in industrial settings and may be beneficial as it has a very low distraction rate.","publicationDate":"2019-06-04T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3229607.3229615","title":"research-article ","type":"Data Analytics Service Composition and Deployment on Edge Devices","venue":"Big-DAMA '18: Proceedings of the 2018 Workshop on Big Data Analytics and Machine Learning for Data Communication Networks","authors":["Jianxin Zhao","Tudor Tiplea","Richard Mortier","Jon Crowcroft","Liang Wang"],"abstract":"Data analytics on edge devices has gained rapid growth in research, industry, and different aspects of our daily life. This topic still faces many challenges such as limited computation resource on edge devices. In this paper, we further identify two main challenges: the composition and deployment of data analytics services on edge devices. We present the Zoo system to address these two challenge: on one hand, it provides simple and concise domain-specific language to enable easy and and type-safe composition of different data analytics services; on the other, it utilises multiple deployment backends, including Docker container, JavaScript, and MirageOS, to accommodate the heterogeneous edge deployment environment. We show the expressiveness of Zoo with a use case, and thoroughly compare the performance of different deployment backends in evaluation.","publicationDate":"2018-08-06T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3175684.3175709","title":"research-article ","type":"Auto-scaling Applications in Edge Computing: Taxonomy and Challenges","venue":"BDIOT2017: Proceedings of the International Conference on Big Data and Internet of Thing","authors":["Salman Taherizadeh","Vlado Stankovski"],"abstract":"The perspective of online services such as Internet of Things (IoT) applications has impressively evolved over the last recent years as they are becoming more and more time-sensitive, maintained at decentralized locations and easily affected by the changing workload intensity at runtime. As a consequence, an up-and-coming trend has been emerging from previously centralized computation to distributed edge computing in order to address these new concerns. The goal of the present paper is therefore twofold. At first, to analyze modern types of edge computing applications and their auto-scaling challenges to offer desirable performance in conditions where the workload dynamically changes. Secondly, to present a new taxonomy of auto-scaling applications. This taxonomy thoroughly considers edge computing paradigm and its complementary technologies such as container-based visualization.","publicationDate":"2017-12-19T23:00:00.000Z","citationCount":8},{"url":"https://dl.acm.org/doi/10.1145/3442518","title":"research-article ","type":"Always-on time-series database: keeping up where there's no way to catch up","venue":"Communications of the ACM","authors":["Theo Schlossnagle","Justin Sheehy","Chris McCubbin"],"abstract":"A discussion with Theo Schlossnagle, Justin Sheehy, and Chris McCubbin.","publicationDate":"2021-06-20T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3311790.3396634","title":"research-article ","type":"Building an Interactive Workbench Environment for Single Cell Genomics Applications","venue":"PEARC '20: Practice and Experience in Advanced Research Computing","authors":["D Balamurugan","Kristina Plazonic","Kevin Abbey","Seema Husain","Neeraja Syed"],"abstract":"We discuss the procedure to build an interactive workbench environment for single cell genomics applications with the Open OnDemand (OOD) science gateway. In our approach, an end-user submits a complex single cell RNA sequencing (scRNA) pipeline, checks the status of the job, and visualizes the output results. All of these tasks are accomplished through a web browser, relieving the users from the complexities involved in developing and handling a large-scale workflow. Our approach helped researchers in processing several input data sets of scRNA in the campus HPC cluster. Although the current work is focused on scRNA analysis, the same approach can be extended for any workflow.","publicationDate":"2020-07-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3382025.3414979","title":"research-article ","type":"Can microservice-based online-retailers be used as an SPL?: a study of six reference architectures","venue":"SPLC '20: Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A","authors":["Benjamin Benni","Sébastien Mosser","Jean-Philippe Caissy","Yann-Gaël Guéhéneuc"],"abstract":"Microservices are deployable software artifacts that combine a set of business features and expose them to other microservices. Ideally, the reuse and interchanging of microservices should be easy as they are supposed to be independent of each other, both conceptually and technologically. Selecting a service to fulfill a given feature (e.g., managing a cart in a website) recalls the way Software Product Lines (SPL) allow variability. However, in practice, interchanging microservices requires knowing the features that the services propose, how they communicate with other services and their types. In this work, we propose to analyze service dependencies as feature dependencies, at the feature, structural, technological, and versioning level, to assess the interchangeability of services. We analyze six community-selected use-cases and report that services are non-interchangeable systematically.","publicationDate":"2020-10-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3368308.3415377","title":"research-article ","type":"The Necessity of Interdisciplinary Software Development for Building Viable Research Platforms: Case Study in Automated Drug Delivery in Diabetes","venue":"SIGITE '20: Proceedings of the 21st Annual Conference on Information Technology Education","authors":["Jeremy Hajek","Mudassir Rashid","Mert Sevil","Ali Cinar","Pablo Angel Alvarez Fernandez","Dhiraj Jain"],"abstract":"Developing viable and robust software is an inescapable artifact of graduate research. The challenges lie in the complexities of developing, deploying, and securing software to support the research objectives. Combined with the transitive nature of students, the management of the software development and launch process is an arduous task. A standardized framework for developing and launching complex software is required. Within a university, individual departments do not typically possess the expertise, resources, software and infrastructure to translate research results to a viable product or tool. Extending upon the research of Hilton et al., [5] we designed a software development pipeline in an integrated multi-disciplinary research context. The integrated and collaborative software pipeline formulated from the onset of the project streamlines the development phase and provides an iterative feedback and testing environment. This approach is applied to the development of automated insulin delivery systems, with the synergistic efforts of interdisciplinary teams yielding a mobile application and server software solutions, and a framework for the iterative advancement of the software capabilities into the future.","publicationDate":"2020-10-06T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3339252.3340505","title":"research-article ","type":"A Study of Network Forensic Investigation in Docker Environments","venue":"ARES '19: Proceedings of the 14th International Conference on Availability, Reliability and Security","authors":["Daniel Spiekermann","Tobias Eggendorfer","Jörg Keller"],"abstract":"Cyber-criminals harness more and more techniques like virtual machines or container-based infrastructures for their malicious activities. The inherent dynamic of these virtual environments simplifies the fast creation of vicious services and hide the involved systems like no other technology before. The primary use of virtualisation and especially containers facilitates software developers and administrators to create new applications, perform tests, debug their code and install pre-defined services based on provided container images. Docker as the most notable container technique provides a great variety of existing container templates, which pave the way for implementing highly dynamic environments. As virtual machines, container-based environments are mostly a short-living on-demand infrastructure, which might be used by cyber-criminals to perform their malicious activities. Especially the virtual layer and the ephemeral nature of the container impede any kind of digital investigation or forensic analysis. In this paper we analyze different methods for network forensic investigation in Docker environments. The virtualisation demands for adapted techniques of packet capture like iptables-manipulation, accessing the internal network bridges or vNICs and the use of software-based techniques. We propose the use of further monitoring processes in Docker swarms to implement a valid packet capture and to collect all relevant network packets. As a result, we define appropriate techniques of packet captures based on parameters of the related container.","publicationDate":"2019-08-25T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3429309.3429318","title":"research-article ","type":"ClimAlign: Unsupervised statistical downscaling of climate variables via normalizing flows","venue":"CI2020: Proceedings of the 10th International Conference on Climate Informatics","authors":["Brian Groenke","Luke Madaus","Claire Monteleoni"],"abstract":" Downscaling is a common task in climate science and meteorology in which the goal is to use coarse scale, spatio-temporal data to infer values at finer scales. Statistical downscaling aims to approximate this task using statistical patterns gleaned from an existing dataset of downscaled values, often obtained from observations or physical models. In this work, we investigate the application of domain alignment to the task of statistical downscaling. We present ClimAlign, a novel method for unsupervised, generative downscaling using adaptations of recent work in normalizing flows for variational inference. We evaluate the viability of our method using several different metrics on two datasets consisting of daily temperature and precipitation values gridded at low (1° latitude/longitude) and high ( and ) resolutions. We show that our method achieves comparable predictive performance to existing supervised statistical downscaling methods while simultaneously allowing for both conditional and unconditional sampling from the joint distribution over high and low resolution spatial fields. To the best of our knowledge, this is the first proposed method for unsupervised statistical downscaling, and one of very few proposed methods that allows for efficient sampling of synthetic data.","publicationDate":"2020-09-21T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3411505.3418439","title":"short-paper ","type":"Short Paper: Automatic Configuration for an Optimal Channel Protection in Virtualized Networks","venue":"CYSARM'20: Proceedings of the 2nd Workshop on Cyber-Security Arms Race","authors":["Daniele Bringhenti","Guido Marchetto","Riccardo Sisto","Fulvio Valenza"],"abstract":"Data confidentiality, integrity and authentication are security properties which are often enforced with the generation of secure channels, such as Virtual Private Networks, over unreliable network infrastructures. Traditionally, the configuration of the systems responsible of encryption operations is performed manually. However, the advent of software-based paradigms, such as Software-Defined Networking and Network Functions Virtualization, has introduced new arms races. In particular, even though network management has become more flexible, the increased complexity of virtual networks is making manual operations unfeasible and leading to errors which open the path to a large number of cyber attacks. A possible solution consists in reaching a trade-off between flexibility and complexity, by automatizing the configuration of the channel protection systems through policy refinement. In view of these considerations, this paper proposes a preliminary study for an innovative methodology to automatically allocate and configure channel protection systems in virtualized networks. The proposed approach would be based on the formulation of a MaxSMT problem and it would be the first to combine automation, formal verification and optimality in a single technique.","publicationDate":"2020-11-12T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3407947.3407957","title":"research-article ","type":"Delay-guaranteed Task Allocation in Mobile Edge Computing with Balanced Resource Utilization","venue":"HP3C 2020: Proceedings of the 2020 4th International Conference on High Performance Compilation, Computing and Communications","authors":["Zijie Li","Jinghui Qin","Wushao Wen"],"abstract":"Mobile edge computing (MEC) can alleviate computation and power limitation of user equipments (UEs) by offloading tasks to MEC servers or the remote cloud. Delays of finishing tasks are the most important indicators for a MEC system. However, existing researches in MEC on task allocation problems are decided by UEs or by centralized algorithms, imposing burden to UEs or centralize controllers. Most of them neglect real-time resource utilization of MEC system, which may affect the performance of executing offloaded tasks. To address the above problems, we propose a distributed game-theoretic task-offloading allocation (GTOA) algorithm by transforming a task allocation problem into a strategy game, turning the goal of maximizing deadline satisfaction and resource usage into a payoff function, which MEC server is eager to obtain. Simulations with a different number of MEC servers of system handling tasks for UEs showed that the algorithm can improve system resource utilization while meeting delay limit of most offloaded tasks.","publicationDate":"2020-06-26T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3341525.3387430","title":"research-article ","type":"Automated Assessment of Android Exercises with Cloud-native Technologies","venue":"ITiCSE '20: Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education","authors":["Daniel Bruzual","Maria L. Montoya Freire","Mario Di Francesco"],"abstract":"Mobile applications are very challenging to test as they usually have a complex graphical user interface and advanced functionality that involves interacting with remote services. Due to these features, student assessment in courses about mobile application development usually relies on assignments or projects that are manually checked by teaching assistants for grading. This approach clearly does not scale to large classrooms, especially for online courses. This article presents a novel system for automated assessment of Android exercises with cloud-native technologies. Different from the state of the art, the proposed solution leverages a mobile app testing framework that is largely used in the industry instead of custom libraries. Furthermore, the devised system employs software containers and scales with the availability of resources in a data center, which is essential for massive open online courses. The system design and implementation is detailed, together with the results from a deployment within a master-level course with 120 students. The received feedback demonstrates that the proposed solution was effective, as it provided insightful feedback and supported independent learning of mobile application development.","publicationDate":"2020-06-14T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3358505.3358522","title":"research-article ","type":"DECIDE: An Extended DevOps Framework for Multi-cloud Applications","venue":"ICCBDC 2019: Proceedings of the 2019 3rd International Conference on Cloud and Big Data Computing","authors":["Juncal Alonso","Kyriakos Stefanidis","Leire Orue-Echevarria","Lorenzo Blasi","Michael Walker","Marisa Escalante","María José López","Simon Dutkowski"],"abstract":"DevOps represents a model for application development that enables close collaboration between software developers and IT operations with the objective of implementing continuous integration, continuous delivery and continuous development of software applications. This paper proposes an approach for extending the DevOps philosophy with the objective of supporting the development and operation of multi-cloud native applications deployed over heterogeneous cloud resources. The authors present the extended DECIDE DevOps framework and the supporting tool suite developed in the context of the DECIDE H2020 action","publicationDate":"2019-08-27T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3301418.3313941","title":"research-article ","type":"ExEC: Elastic Extensible Edge Cloud","venue":"EdgeSys '19: Proceedings of the 2nd International Workshop on Edge Systems, Analytics and Networking","authors":["Aleksandr Zavodovski","Nitinder Mohan","Suzan Bayhan","Walter Wong","Jussi Kangasharju"],"abstract":"Edge computing (EC) extends the centralized cloud computing paradigm by bringing computation into close proximity to the end-users, to the edge of the network, and is a key enabler for applications requiring low latency such as augmented reality or content delivery. To make EC pervasive, the following challenges must be tackled: how to satisfy the growing demand for edge computing facilities, how to discover the nearby edge servers, and how to securely access them? In this paper, we present ExEC, an open framework where edge providers can offer their capacity and be discovered by application providers and end-users. ExEC aims at the unification of interaction between edge and cloud providers so that cloud providers can utilize services of third-party edge providers, and any willing entity can easily become an edge provider. In ExEC, the unfolding of initially cloud-deployed application towards edge happens without administrative intervention, since ExEC discovers available edge providers on the fly and monitors incoming end-user traffic, determining the near-optimal placement of edge services. ExEC is a set of loosely coupled components and common practices, allowing for custom implementations needed to embrace the diverse needs of specific EC scenarios. ExEC leverages only existing protocols and requires no modifications to the deployed infrastructure. Using real-world topology data and experiments on cloud platforms, we demonstrate the feasibility of ExEC and present results on its expected performance.","publicationDate":"2019-03-24T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3442381.3449837","title":"research-article ","type":"Cookie Swap Party: Abusing First-Party Cookies for Web Tracking","venue":"WWW '21: Proceedings of the Web Conference 2021","authors":["Quan Chen","Panagiotis Ilia","Michalis Polychronakis","Alexandros Kapravelos"],"abstract":"As a step towards protecting user privacy, most web browsers perform some form of third-party HTTP cookie blocking or periodic deletion by default, while users typically have the option to select even stricter blocking policies. As a result, web trackers have shifted their efforts to work around these restrictions and retain or even improve the extent of their tracking capability. In this paper, we shed light into the increasingly used practice of relying on first-party cookies that are set by third-party JavaScript code to implement user tracking and other potentially unwanted capabilities. Although unlike third-party cookies, first-party cookies are not sent automatically by the browser to third-parties on HTTP requests, this tracking is possible because any included third-party code runs in the context of the parent page, and thus can fully set or read existing first-party cookies—which it can then leak to the same or other third parties. Previous works that survey user privacy on the web in relation to cookies, third-party or otherwise, have not fully explored this mechanism. To address this gap, we propose a dynamic data flow tracking system based on Chromium to track the leakage of first-party cookies to third parties, and used it to conduct a large-scale study of the Alexa top 10K websites. In total, we found that 97.72% of the websites have first-party cookies that are set by third-party JavaScript, and that on 57.66% of these websites there is at least one such cookie that contains a unique user identifier that is diffused to multiple third parties. Our results highlight the privacy-intrusive capabilities of first-party cookies, even when a privacy-savvy user has taken mitigative measures such as blocking third-party cookies, or employing popular crowd-sourced filter lists such as EasyList/EasyPrivacy and the Disconnect list. ","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3366706","title":"research-article ","type":"Rateless Codes for Near-Perfect Load Balancing in Distributed Matrix-Vector Multiplication","venue":"Proceedings of the ACM on Measurement and Analysis of Computing Systems","authors":["Ankur Mallick","Malhar Chaudhari","Utsav Sheth","Ganesh Palanikumar","Gauri Joshi"],"abstract":"Large-scale machine learning and data mining applications require computer systems to perform massive matrix-vector and matrix-matrix multiplication operations that need to be parallelized across multiple nodes. The presence of straggling nodes -- computing nodes that unpredictably slowdown or fail -- is a major bottleneck in such distributed computations. Ideal load balancing strategies that dynamically allocate more tasks to faster nodes require knowledge or monitoring of node speeds as well as the ability to quickly move data. Recently proposed fixed-rate erasure coding strategies can handle unpredictable node slowdown, but they ignore partial work done by straggling nodes thus resulting in a lot of redundant computation. We propose a rateless fountain coding strategy that achieves the best of both worlds -- we prove that its latency is asymptotically equal to ideal load balancing, and it performs asymptotically zero redundant computations. Our idea is to create linear combinations of the m rows of the matrix and assign these encoded rows to different worker nodes. The original matrix-vector product can be decoded as soon as slightly more than m row-vector products are collectively finished by the nodes. We conduct experiments in three computing environments: local parallel computing, Amazon EC2, and Amazon Lambda, which show that rateless coding gives as much as 3x speed-up over uncoded schemes.","publicationDate":"2019-12-16T23:00:00.000Z","citationCount":13},{"url":"https://dl.acm.org/doi/10.1145/3472163.3472185","title":"research-article ","type":"A Zone-Based Data Lake Architecture for IoT, Small and Big Data","venue":"IDEAS 2021: 25th International Database Engineering & Applications Symposium","authors":["Yan Zhao","Imen Megdiche","Franck Ravat","Vincent-nam Dang"],"abstract":" Data lakes are supposed to enable analysts to perform more efficient and efficacious data analysis by crossing multiple existing data sources, processes and analyses. However, it is impossible to achieve that when a data lake does not have a metadata governance system that progressively capitalizes on all the performed analysis experiments. The objective of this paper is to have an easily accessible, reusable data lake that capitalizes on all user experiences. To meet this need, we propose an analysis-oriented metadata model for data lakes. This model includes the descriptive information of datasets and their attributes, as well as all metadata related to the machine learning analyzes performed on these datasets. To illustrate our metadata solution, we implemented a web application of data lake metadata management. This application allows users to find and use existing data, processes and analyses by searching relevant metadata stored in a NoSQL data store within the data lake. To demonstrate how to easily discover metadata with the application, we present two use cases, with real data, including datasets similarity detection and machine learning guidance.","publicationDate":"2021-07-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3339252.3340502","title":"research-article ","type":"Leveraging Kernel Security Mechanisms to Improve Container Security: a Survey","venue":"ARES '19: Proceedings of the 14th International Conference on Availability, Reliability and Security","authors":["Maxime Bélair","Sylvie Laniepce","Jean-Marc Menaud"],"abstract":"Containerization is a lightweight virtualization technique reducing virtualization overhead and deployment latency compared to full VM; its popularity is quickly increasing.However, due to kernel sharing, containers provide less isolation than full VM. Thus, a compromised container may break out of its isolated context and gain root access to the host server. This is a huge concern, especially in multi-tenant cloud environments where we can find running on a single server containers serving very different purposes, such as banking microservices, compute nodes or honeypots. Thus, containers with specific security needs should be able to tune their own security level.Because OS-level defense approaches inherited from time-sharing OS generally requires administrator rights and aim to protect the entire system, they are not fully suitable to protect usermode containers. Research recently made several contributions to deliver enhanced security to containers from host OS level to (partially) solve these challenges.In this survey, we propose a new taxonomy on container defense at the infrastructure level with a particular focus on the virtualization boundary, where interactions between kernel and containers take place. We then classify the most promising defense frameworks into these categories.","publicationDate":"2019-08-25T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3185768.3186294","title":"research-article ","type":"Package-Aware Scheduling of FaaS Functions","venue":"ICPE '18: Companion of the 2018 ACM/SPEC International Conference on Performance Engineering","authors":["Cristina L. Abad","Edwin F. Boza","Erwin van Eyk"],"abstract":"We consider the problem of scheduling small cloud functions on serverless computing platforms. Fast deployment and execution of these functions is critical, for example, for microservices architectures. However, functions that require large packages or libraries are bloated and start slowly. A solution is to cache packages at the worker nodes instead of bundling them with the functions. However, existing FaaS schedulers are vanilla load balancers, agnostic of any packages that may have been cached in response to prior function executions, and cannot reap the benefits of package caching (other than by chance). To address this problem, we propose a package-aware scheduling algorithm that tries to assign functions that require the same package to the same worker node. Our algorithm increases the hit rate of the package cache and, as a result, reduces the latency of the cloud functions. At the same time, we consider the load sustained by the workers and actively seek to avoid imbalance beyond a configurable threshold. Our preliminary evaluation shows that, even with our limited exploration of the configuration space so-far, we can achieve 66% performance improvement at the cost of a (manageable) higher node imbalance.","publicationDate":"2018-04-01T22:00:00.000Z","citationCount":7},{"url":"https://dl.acm.org/doi/10.1145/3458336.3465304","title":"research-article ","type":"User-defined cloud","venue":"HotOS '21: Proceedings of the Workshop on Hot Topics in Operating Systems","authors":["Yiying Zhang","Ardalan Amiri Sani","Guoqing Harry Xu"],"abstract":"Since its creation, cloud computing has always taken a provider-dictated approach, where cloud providers define and manage the cloud to accommodate the user needs they deem important. We propose \"User-Defined Cloud\", or UDC, a new cloud scheme that allows users to define their own \"clouds\", by defining hardware resource needs, system software features, and security requirements of their applications, and to do so without the need to build or manage low-level systems.","publicationDate":"2021-05-31T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3125719.3125726","title":"research-article ","type":"Virtualized ICN (vICN): towards a unified network virtualization framework for ICN experimentation","venue":"ICN '17: Proceedings of the 4th ACM Conference on Information-Centric Networking","authors":["Mauro Sardara","Luca Muscariello","Jordan Augé","Marcel Enguehard","Alberto Compagno","Giovanna Carofiglio"],"abstract":"To assess the feasibility and potential for deployment of new networking paradigms such as ICN, being able to carry out large scale experimentation and tests in real operational networks is crucial. Various platforms have been developed by the research community to support design and evaluation of specific aspects of ICN architecture. Most of them provide ICN-dedicated, small scale or application-specific environments and ad-hoc testing tools, non reusable in other contexts nor in real-world IP deployments.The goal of this paper is to contribute vICN (virtualized ICN), a unified open-source framework for network configuration and management that uses recent progresses in resource isolation and virtualization techniques. It offers a single, flexible and scalable platform to serve different purposes, ranging from reproducible large-scale research experimentation, to demonstrations with emulated and/or physical devices and network resources and to real deployments of ICN in existing IP networks. In the paper, we describe the rationale for vICN and its components, highlighting programmability, scalability and reliability as its core principles. Illustration of vICN properties is provided through concrete examples.","publicationDate":"2017-09-25T22:00:00.000Z","citationCount":10},{"url":"https://dl.acm.org/doi/10.1145/2805789.2805791","title":"research-article ","type":"Cooperative group provisioning with latency guarantees in multi-cloud deployments","venue":"ACM SIGCOMM Computer Communication Review","authors":["Sean Yaw","Eben Howard","Brendan Mumey","Mike P. Wittie"],"abstract":"Given a set of datacenters and groups of application clients, well-connected datacenters can be rented as traffic proxies to reduce client latency. Rental costs must be minimized while meeting the application specific latency needs. Here, we formally define the Cooperative Group Provisioning problem and show it is NP-hard to approximate within a constant factor. We introduce a novel greedy approach and demonstrate its promise through extensive simulation using real cloud network topology measurements and realistic client churn. We find that multi-cloud deployments dramatically increase the likelihood of meeting group latency thresholds with minimal cost increase compared to single-cloud deployments.","publicationDate":"2015-07-12T22:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1109/DataCloud.2014.6","title":"research-article ","type":"Skyport: container-based execution environment management for multi-cloud scientific workflows","venue":"DataCloud '14: Proceedings of the 5th International Workshop on Data-Intensive Computing in the Clouds","authors":["Wolfgang Gerlach","Wei Tang","Kevin Keegan","Travis Harrison","Andreas Wilke","Jared Bischof","Mark D'Souza","Scott Devoid","Daniel Murphy-Olson","Narayan Desai","Folker Meyer"],"abstract":"Recently, Linux container technology has been gaining attention as it promises to transform the way software is developed and deployed. The portability and ease of deployment makes Linux containers an ideal technology to be used in scientific workflow platforms. Skyport utilizes Docker Linux containers to solve software deployment problems and resource utilization inefficiencies inherent to all existing scientific workflow platforms. As an extension to AWE/Shock, our data analysis platform that provides scalable workflow execution environments for scientific data in the cloud, Skyport greatly reduces the complexity associated with providing the environment necessary to execute complex workflows.","publicationDate":"2014-11-15T23:00:00.000Z","citationCount":15},{"url":"https://dl.acm.org/doi/10.1145/3297663.3309674","title":"short-paper ","type":"Behavior-driven Load Testing Using Contextual Knowledge - Approach and Experiences","venue":"ICPE '19: Proceedings of the 2019 ACM/SPEC International Conference on Performance Engineering","authors":["Henning Schulz","Dušan Okanović","André van Hoorn","Vincenzo Ferme","Cesare Pautasso"],"abstract":"Load testing is widely considered a meaningful technique for performance quality assurance. However, empirical studies reveal that in practice, load testing is not applied systematically, due to the sound expert knowledge required to specify, implement, and execute load tests.Our Behavior-driven Load Testing (BDLT) approach eases load test specification and execution for users with no or little expert knowledge. It allows a user to describe a load test in a template-based natural language and to rely on an automated framework to execute the test. Utilizing the system's contextual knowledge such as workload-influencing events, the framework automatically determines the workload and test configuration. We investigated the applicability of our approach in an industrial case study, where we were able to express four load test concerns using BDLT and received positive feedback from our industrial partner. They understood the BDLT definitions well and proposed further applications, such as the usage for software quality acceptance criteria.","publicationDate":"2019-04-03T22:00:00.000Z","citationCount":11},{"url":"https://dl.acm.org/doi/10.1145/3219104.3229280","title":"research-article ","type":"Evaluation of Docker Containers for Scientific Workloads in the Cloud","venue":"PEARC '18: Proceedings of the Practice and Experience on Advanced Research Computing","authors":["Pankaj Saha","Angel Beltre","Piotr Uminski","Madhusudhan Govindaraju"],"abstract":"The HPC community is actively researching and evaluating tools to support execution of scientific applications in cloud-based environments. Among the various technologies, containers have recently gained importance as they have significantly better performance compared to full-scale virtualization, support for microservices and DevOps, and work seamlessly with workflow and orchestration tools. Docker is currently the leader in containerization technology because it offers low overhead, flexibility, portability of applications, and reproducibility. Singularity is another container solution that is of interest as it is designed specifically for scientific applications. It is important to conduct performance and feature analysis of the container technologies to understand their applicability for each application and target execution environment.This paper presents a (1) performance evaluation of Docker and Singularity on bare metal nodes in the Chameleon cloud (2) mechanism by which Docker containers can be mapped with InfiniBand hardware with RDMA communication and (3) analysis of mapping elements of parallel workloads to the containers for optimal resource management with container-ready orchestration tools. Our experiments are targeted toward application developers so that they can make informed decisions on choosing the container technologies and approaches that are suitable for their HPC workloads on cloud infrastructure. Our performance analysis shows that scientific workloads for both Docker and Singularity based containers can achieve near-native performance.Singularity is designed specifically for HPC workloads. However, Docker still has advantages over Singularity for use in clouds as it provides overlay networking and an intuitive way to run MPI applications with one container per rank for fine-grained resources allocation. Both Docker and Singularity make it possible to directly use the underlying network fabric from the containers for coarsegrained resource allocation.","publicationDate":"2018-07-21T22:00:00.000Z","citationCount":13},{"url":"https://dl.acm.org/doi/10.1145/3462513","title":"research-article ","type":"A Survey on Resilience in the IoT: Taxonomy, Classification, and Discussion of Resilience Mechanisms","venue":"ACM Computing Surveys","authors":["Christian Berger","Philipp Eichhammer","Hans P. Reiser","Jörg Domaschka","Franz J. Hauck","Gerhard Habiger"],"abstract":"Internet-of-Things (IoT) ecosystems tend to grow both in scale and complexity, as they consist of a variety of heterogeneous devices that span over multiple architectural IoT layers (e.g., cloud, edge, sensors). Further, IoT systems increasingly demand the resilient operability of services, as they become part of critical infrastructures. This leads to a broad variety of research works that aim to increase the resilience of these systems. In this article, we create a systematization of knowledge about existing scientific efforts of making IoT systems resilient. In particular, we first discuss the taxonomy and classification of resilience and resilience mechanisms and subsequently survey state-of-the-art resilience mechanisms that have been proposed by research work and are applicable to IoT. As part of the survey, we also discuss questions that focus on the practical aspects of resilience, e.g., which constraints resilience mechanisms impose on developers when designing resilient systems by incorporating a specific mechanism into IoT systems.","publicationDate":"2021-09-16T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3434642","title":"article ","type":"The future is big graphs: a community view on graph processing systems","venue":"Communications of the ACM","authors":["Sherif Sakr","Angela Bonifati","Hannes Voigt","Alexandru Iosup","Khaled Ammar","Renzo Angles","Walid Aref","Marcelo Arenas","Maciej Besta","Peter A. Boncz","Khuzaima Daudjee","Emanuele Della Valle","Stefania Dumbrava","Olaf Hartig","Bernhard Haslhofer","Tim Hegeman","Jan Hidders","Katja Hose","Adriana Iamnitchi","Vasiliki Kalavri","Hugo Kapp","Wim Martens","M. Tamer Özsu","Eric Peukert","Stefan Plantikow","Mohamed Ragab","Matei R. Ripeanu","Semih Salihoglu","Christian Schulz","Petra Selmer","Juan F. Sequeda","Joshua Shinavier","Gábor Szárnyas","Riccardo Tommasini","Antonino Tumeo","Alexandru Uta","Ana Lucia Varbanescu","Hsiang-Yun Wu","Nikolay Yakovets","Da Yan","Eiko Yoneki"],"abstract":"Ensuring the success of big graph processing for the next decade and beyond.","publicationDate":"2021-08-23T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3308560.3316509","title":"research-article ","type":"MAMS: Multi-Agent MicroServices✱","venue":"WWW '19: Companion Proceedings of The 2019 World Wide Web Conference","authors":["Rem W. Collier","Eoin O'Neill","David Lillis","Gregory O'Hare"],"abstract":"This paper explores the intersection between microservices and Multi-Agent Systems (MAS), introducing the notion of a new approach to building MAS known as Multi-Agent MicroServices (MAMS). Our approach is illustrated through a worked example of a Vickrey Auction implemented as a microservice.","publicationDate":"2019-05-12T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/2755979.2755984","title":"research-article ","type":"Integrating Containers into Workflows: A Case Study Using Makeflow, Work Queue, and Docker","venue":"VTDC '15: Proceedings of the 8th International Workshop on Virtualization Technologies in Distributed Computing","authors":["Charles Zheng","Douglas Thain"],"abstract":"Workflows are a widely used abstraction for representing large scientific applications and executing them on distributed systems such as clusters, clouds, and grids. However, workflow systems have been largely silent on the question of precisely what environment each task in the workflow is expected to run in. As a result, a workflow may run correctly in the environment in which it was designed, but when moved to another machine, is highly likely to fail due to differences in the operating system, installed applications, available data, and so forth. Lightweight container technology has recently arisen as a potential solution to this problem, by providing a well-defined execution environments at the operating system level. In this paper, we consider how to best integrate container technology into an existing workflow system, using Makeflow, Work Queue, and Docker as examples of current technology. A brief performance study of Docker shows very little overhead in CPU and I/O performance, but significant costs in creating and deleting containers. Taking this into account, we describe four different methods of connecting containers to different points of the infrastructure, and explain several methods of managing the container images that must be distributed to executing tasks. We explore the performance of a large bioinformatics workload on a Docker-enabled cluster, and observe the best configuration to be locally-managed containers that are shared between multiple tasks.","publicationDate":"2015-06-14T22:00:00.000Z","citationCount":39},{"url":"https://dl.acm.org/doi/10.1145/3406011","title":"research-article ","type":"What serverless computing is and should become: the next phase of cloud computing","venue":"Communications of the ACM","authors":["Johann Schleier-Smith","Vikram Sreekanti","Anurag Khandelwal","Joao Carreira","Neeraja J. Yadwadkar","Raluca Ada Popa","Joseph E. Gonzalez","Ion Stoica","David A. Patterson"],"abstract":"The evolution that serverless computing represents, the economic forces that shape it, why it could fail, and how it might fulfill its potential.","publicationDate":"2021-04-25T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/2755979.2755984","title":"research-article ","type":"Integrating Containers into Workflows: A Case Study Using Makeflow, Work Queue, and Docker","venue":"VTDC '15: Proceedings of the 8th International Workshop on Virtualization Technologies in Distributed Computing","authors":["Charles Zheng","Douglas Thain"],"abstract":"Workflows are a widely used abstraction for representing large scientific applications and executing them on distributed systems such as clusters, clouds, and grids. However, workflow systems have been largely silent on the question of precisely what environment each task in the workflow is expected to run in. As a result, a workflow may run correctly in the environment in which it was designed, but when moved to another machine, is highly likely to fail due to differences in the operating system, installed applications, available data, and so forth. Lightweight container technology has recently arisen as a potential solution to this problem, by providing a well-defined execution environments at the operating system level. In this paper, we consider how to best integrate container technology into an existing workflow system, using Makeflow, Work Queue, and Docker as examples of current technology. A brief performance study of Docker shows very little overhead in CPU and I/O performance, but significant costs in creating and deleting containers. Taking this into account, we describe four different methods of connecting containers to different points of the infrastructure, and explain several methods of managing the container images that must be distributed to executing tasks. We explore the performance of a large bioinformatics workload on a Docker-enabled cluster, and observe the best configuration to be locally-managed containers that are shared between multiple tasks.","publicationDate":"2015-06-14T22:00:00.000Z","citationCount":39},{"url":"https://dl.acm.org/doi/10.1145/3219104.3219165","title":"research-article ","type":"Leveraging OpenStack and Ceph for a Controlled-Access Data Cloud","venue":"PEARC '18: Proceedings of the Practice and Experience on Advanced Research Computing","authors":["Evan F. Bollig","Graham T. Allan","Benjamin J. Lynch","Yectli A. Huerta","Mathew Mix","Edward A. Munsell","Raychel M. Benson","Brent Swartz"],"abstract":"While traditional HPC has and continues to satisfy most workflows, a new generation of researchers has emerged looking for sophisticated, scalable, on-demand, and self-service control of compute infrastructure in a cloud-like environment. Many also seek safe harbors to operate on or store sensitive and/or controlled-access data in a high capacity environment.To cater to these modern users, the Minnesota Supercomputing Institute designed and deployed Stratus, a locally-hosted cloud environment powered by the OpenStack platform, and backed by Ceph storage. The subscription-based service complements existing HPC systems by satisfying the following unmet needs of our users: a) on-demand availability of compute resources; b) long-running jobs (i.e., > 30 days); c) container-based computing with Docker; and d) adequate security controls to comply with controlled-access data requirements.This document provides an in-depth look at the design of Stratus with respect to security and compliance with the NIH's controlled-access data policy. Emphasis is placed on lessons learned while integrating OpenStack and Ceph features into a so-called \"walled garden\", and how those technologies influenced the security design. Many features of Stratus, including tiered secure storage with the introduction of a controlled-access data \"cache\", fault-tolerant live-migrations, and fully integrated two-factor authentication, depend on recent OpenStack and Ceph features.","publicationDate":"2018-07-21T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3410992.3411015","title":"research-article ","type":"Elastic resource management and network slicing for IoT over edge clouds","venue":"IoT '20: Proceedings of the 10th International Conference on the Internet of Things","authors":["Akos Recse","Robert Szabo","Balazs Nemeth"],"abstract":"The Internet of Things (IoT) application ecosystem is driven by third party developers outside of the telecom domain. Edge infrastructure of communication service providers will therefore be accessible to third party application providers and developers and will host a multitude of application each with different characteristics. We foresee that multiple business actors will contribute to an IoT and edge-ecosystem including Hyperscale Cloud Providers (HCPs), Operation Technology (OT) vendors, communication service providers, and application developers. To reduce cost, efficient use of resources are needed across all business actors. End users, especially in IoT deployment, will look for pay-as-use (elasticity) service offerings similar to IT cloud offerings. Therefore, the layers of orchestration services must be able to elastically resize their respective resource pools by the means of initiating re-configurations via the underlay providers' orchestration services. We propose a workload placement algorithm, which can reconfigure both cloud (e.g., Infrastructure as a Service) and network (e.g., Virtual Private Network) resource underlays during resource orchestration. Our proposed method ensures that different business actors can exercise elastic control of their resources, so their committed services and bought resources are in better (best) alignment. The proposed method is functionally evaluated with 5G network slicing with local break-out to an IoT stack in the network edge.","publicationDate":"2020-10-05T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3415958.3433072","title":"research-article ","type":"A Meta Learning Approach for Automating Model Selection in Big Data Environments using Microservice and Container Virtualization Technologies","venue":"MEDES '20: Proceedings of the 12th International Conference on Management of Digital EcoSystems","authors":["Shadi Shahoud","Hatem Khalloof","Moritz Winter","Clemens Duepmeier","Veit Hagenmeyer"],"abstract":"For a given specific machine learning task, very often several machine learning algorithms and their right configurations are tested in a trial-and-error approach, until an adequate solution is found. This wastes human resources for constructing multiple models, requires a data analytics expert and is time-consuming, since a variety of learning algorithms are proposed in literature and the non-expert users do not know which one to use in order to obtain good performance results. Meta learning addresses these problems and supports non-expert users by recommending a promising learning algorithm based on meta features computed from a given dataset. In the present paper, a new generic microservice-based framework for realizing the concept of meta learning in Big Data environments is introduced. This framework makes use of a powerful Big Data software stack, container visualization, modern web technologies and a microservice architecture for a fully manageable and highly scalable solution. In this demonstration and for evaluation purpose, time series model selection is taken into account. The performance and usability of the new framework is evaluated on state-of-the-art machine learning algorithms for time series forecasting: it is shown that the proposed microservice-based meta learning framework introduces an excellent performance in assigning the adequate forecasting model for the chosen time series datasets. Moreover, the recommendation of the most appropriate forecasting model results in a well acceptable low overhead demonstrating that the framework can provide an efficient approach to solve the problem of model selection in context of Big Data.","publicationDate":"2020-11-01T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3415958.3433046","title":"research-article ","type":"Event Management and Monitoring Framework for HPC Environments using ServiceNow and Prometheus","venue":"MEDES '20: Proceedings of the 12th International Conference on Management of Digital EcoSystems","authors":["Nitin Sukhija","Elizabeth Bautista","Owen James","Daniel Gens","Siqi Deng","Yulok Lam","Tony Quan","Basil Lalli"],"abstract":"The challenge of monitoring and event response management of a high performance computing facility grows significantly as the facilities employs and orchestrates more complex and heterogeneous systems and infrastructure. As the computational components encompassing the HPC facility system increases, the computational staff experiences rise in alert fatigue due to the false alarms and noise related to the similar events generated by monitoring tools. The National Energy Research Scientific Computing Center (NERSC) at the Lawrence Berkeley National Laboratory (LBNL) has begun to address the issues of duplication of alerts and alert remediation. However, more automation and integration is needed for collecting, aggregating, correlating, analyzing, managing and visualizing the scale of events that will be generated by the emergent hybrid computing infrastructures. In this paper, we present an event management and monitoring framework that addresses the operational needs of the future pre-exascale systems at the Lawrence Berkeley National Laboratory's National Energy Research Scientific Computing Center (NERSC). The framework integrates the Operations Monitoring and Notification Infrastructure (OMNI) at NERSC with the Prometheus, Grafana and ServiceNow platforms to help identify, diagnose, and resolve incidents in real-time, as well as conduct more thorough post-incident reviews enabled by the intuitive dashboards that provides a single pane of glass console for an efficient operations management and real-time proactive monitoring.","publicationDate":"2020-11-01T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3395032.3395323","title":"research-article ","type":"Automated system performance testing at MongoDB","venue":"DBTest '20: Proceedings of the workshop on Testing Database Systems","authors":["Henrik Ingo","David Daly"],"abstract":"Distributed Systems Infrastructure (DSI) is MongoDB's framework for running fully automated system performance tests in our Continuous Integration (CI) environment. To run in CI it needs to automate everything end-to-end: provisioning and deploying multinode clusters, executing tests, tuning the system for repeatable results, and collecting and analyzing the results. Today DSI is MongoDB's most used and most useful performance testing tool. It runs almost 200 different benchmarks in daily CI, and we also use it for manual performance investigations. As we can alert the responsible engineer in a timely fashion, all but one of the major regressions were fixed before the 4.2.0 release. We are also able to catch net new improvements, of which DSI caught 17. We open sourced DSI in March 2020.","publicationDate":"2020-06-18T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1109/CHASE.2019.00011","title":"research-article ","type":"Activity-based analysis of open source software contributors: roles and dynamics","venue":"CHASE '19: Proceedings of the 12th International Workshop on Cooperative and Human Aspects of Software Engineering","authors":["Jinghui Cheng","Jin L. C. Guo"],"abstract":"Contributors to open source software (OSS) communities assume diverse roles to take different responsibilities. One major limitation of the current OSS tools and platforms is that they provide a uniform user interface regardless of the activities performed by the various types of contributors. This paper serves as a non-trivial first step towards resolving this challenge by demonstrating a methodology and establishing knowledge to understand how the contributors' roles and their dynamics, reflected in the activities contributors perform, are exhibited in OSS communities. Based on an analysis of user action data from 29 GitHub projects, we extracted six activities that distinguished four Active roles and five Supporting roles of OSS contributors, as well as patterns in role changes. Through the lens of the Activity Theory, these findings provided rich design guidelines for OSS tools to support diverse contributor roles.","publicationDate":"2019-05-26T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.5555/3233397.3233413","title":"research-article ","type":"Cloud orchestration features: are tools fit for purpose?","venue":"UCC '15: Proceedings of the 8th International Conference on Utility and Cloud Computing","authors":["Daniel Baur","Daniel Seybold","Frank Griesinger","Athanasios Tsitsipas","Christopher B. Hauser","Jörg Domaschka"],"abstract":"Even though the cloud era has begun almost one decade ago, many problems of the first hour are still around. Vendor lock-in and poor tool support hinder users from taking full advantage of main cloud features: dynamic and scale. This has given rise to tools that target the seamless management and orchestration of cloud applications. All these tools promise similar capabilities and are barely distinguishable what makes it hard to select the right tool. In this paper, we objectively investigate required and desired features of such tools and give a definition of them. We then select three open-source tools (Brooklyn, Cloudify, Stratos) and compare them according to the features they support using our experience gained from deploying and operating a standard three-tier application. This exercise leads to a fine-grained feature list that enables the comparison of such tools based on objective criteria as well as a rating of three popular cloud orchestration tools. In addition, it leads to the insight that the tools are on the right track, but that further development and particularly research is necessary to satisfy all demands.","publicationDate":"2015-12-06T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3238147.3240470","title":"research-article ","type":"RUDSEA: recommending updates of Dockerfiles via software environment analysis","venue":"ASE 2018: Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering","authors":["Foyzul Hassan","Rodney Rodriguez","Xiaoyin Wang"],"abstract":"Dockerfiles are configuration files of docker images which package all dependencies of a software to enable convenient software deployment and porting. In other words, dockerfiles list all environment assumptions of a software application's build and / or execution, so they need to be frequently updated when the environment assumptions change during fast software evolution. In this paper, we propose RUDSEA, a novel approach to recommend updates of dockerfiles to developers based on analyzing changes on software environment assumptions and their impacts. Our evaluation on 1,199 real-world instruction updates shows that RUDSEA can recommend correct update locations for 78.5% of the updates, and correct code changes for 44.1% of the updates.","publicationDate":"2018-09-02T22:00:00.000Z","citationCount":16},{"url":"https://dl.acm.org/doi/10.1145/3474085.3475176","title":"research-article ","type":"SINGA-Easy: An Easy-to-Use Framework for MultiModal Analysis","venue":"MM '21: Proceedings of the 29th ACM International Conference on Multimedia","authors":["Naili Xing","Sai Ho Yeung","Cheng-Hao Cai","Teck Khim Ng","Wei Wang","Kaiyuan Yang","Nan Yang","Meihui Zhang","Gang Chen","Beng Chin Ooi"],"abstract":"Deep learning has achieved great success in a wide spectrum of multimedia applications such as image classification, natural language processing and multimodal data analysis. Recent years have seen the development of many deep learning frameworks that provide a high-level programming interface for users to design models, conduct training and deploy inference. However, it remains challenging to build an efficient end-to-end multimedia application with most existing frameworks. Specifically, in terms of usability, it is demanding for non-experts to implement deep learning models, obtain the right settings for the entire machine learning pipeline, manage models and datasets, and exploit external data sources all together. Further, in terms of adaptability, elastic computation solutions are much needed as the actual serving workload fluctuates constantly, and scaling the hardware resources to handle the fluctuating workload is typically infeasible. To address these challenges, we introduce SINGA-Easy, a new deep learning framework that provides distributed hyper-parameter tuning at the training stage, dynamic computational cost control at the inference stage, and intuitive user interactions with multimedia contents facilitated by model explanation. Our experiments on the training and deployment of multi-modality data analysis applications show that the framework is both usable and adaptable to dynamic inference loads. We implement SINGA-Easy on top of Apache SINGA and demonstrate our system with the entire machine learning life cycle.","publicationDate":"2021-10-16T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3486605.3486788","title":"research-article ","type":"Analysing the performance and costs of reactive programming libraries in Java","venue":"REBLS 2021: Proceedings of the 8th ACM SIGPLAN International Workshop on Reactive and Event-Based Languages and Systems","authors":["Julien Ponge","Arthur Navarro","Clément Escoffier","Frédéric Le Mouël"],"abstract":"Modern services running in cloud and edge environments need to be resource-efficient to increase deployment density and reduce operating costs. Asynchronous I/O combined with asynchronous programming provides a solid technical foundation to reach these goals. Reactive programming and reactive streams are gaining traction in the Java ecosystem. However, reactive streams implementations tend to be complex to work with and maintain. This paper discusses the performance of the three major reactive streams compliant libraries used in Java applications: RxJava, Project Reactor, and SmallRye Mutiny. As we will show, advanced optimization techniques such as operator fusion do not yield better performance on realistic I/O-bound workloads, and they significantly increase development and maintenance costs.","publicationDate":"2021-10-17T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3394486.3412861","title":"research-article ","type":"Effective Transfer Learning for Identifying Similar Questions: Matching User Questions to COVID-19 FAQs","venue":"KDD '20: Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","authors":["Clara H. McCreery","Namit Katariya","Anitha Kannan","Manish Chablani","Xavier Amatriain"],"abstract":"People increasingly search online for answers to their medical questions but the rate at which medical questions are asked online significantly exceeds the capacity of qualified people to answer them. This leaves many questions unanswered or inadequately answered. Many of these questions are not unique, and reliable identification of similar questions would enable more efficient and effective question answering schema. COVID-19 has only exacerbated this problem. Almost every government agency and healthcare organization has tried to meet the informational need of users by building online FAQs, but there is no way for people to ask their question and know if it is answered on one of these pages. While many research efforts have focused on the problem of general question similarity, these approaches do not generalize well to domains that require expert knowledge to determine semantic similarity, such as the medical domain. In this paper, we show how a double fine-tuning approach of pretraining a neural network on medical question-answer pairs followed by fine-tuning on medical question-question pairs is a particularly useful intermediate task for the ultimate goal of determining medical question similarity. While other pretraining tasks yield an accuracy below 78.7% on this task, our model achieves an accuracy of 82.6% with the same number of training examples, an accuracy of 80.0% with a much smaller training set, and an accuracy of 84.5% when the full corpus of medical question-answer data is used. We also describe a currently live system that uses the trained model to match user questions to COVID-related FAQs.","publicationDate":"2020-08-22T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3460866.3461768","title":"research-article ","type":"FogBus2: a lightweight and distributed container-based framework for integration of IoT-enabled systems with edge and cloud computing","venue":"BiDEDE '21: Proceedings of the International Workshop on Big Data in Emergent Distributed Environments","authors":["Qifan Deng","Mohammad Goudarzi","Rajkumar Buyya"],"abstract":"Edge/Fog computing is a novel computing paradigm that provides resource-limited Internet of Things (IoT) devices with scalable computing and storage resources. Compared to cloud computing, edge/fog servers have fewer resources, but they can be accessed with higher bandwidth and less communication latency. Thus, integrating edge/fog and cloud infrastructures can support the execution of diverse latency-sensitive and computation-intensive IoT applications. Although some frameworks attempt to provide such integration, there are still several challenges to be addressed, such as dynamic scheduling of different IoT applications, scalability mechanisms, multi-platform support, and supporting different interaction models. To overcome these challenges, we propose a lightweight and distributed container-based framework, called FogBus2. It provides a mechanism for scheduling heterogeneous IoT applications and implements several scheduling policies. Also, it proposes an optimized genetic algorithm to obtain fast convergence to well-suited solutions. Besides, it offers a scalability mechanism to ensure efficient responsiveness when either the number of IoT devices increases or the resources become overburdened. Also, the dynamic resource discovery mechanism of FogBus2 assists new entities to quickly join the system. We have also developed two IoT applications, called Conway's Game of Life and Video Optical Character Recognition to demonstrate the effectiveness of FogBus2 for handling real-time and non-real-time IoT applications. Experimental results show FogBus2's scheduling policy improves the response time of IoT applications by 53% compared to other policies. Also, the scalability mechanism can reduce up to 48% of the queuing waiting time compared to frameworks that do not support scalability.","publicationDate":"2021-06-19T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3332186.3333058","title":"research-article ","type":"PULSAR: Deploying Network Monitoring and Intrusion Detection for the Science DMZ","venue":"PEARC '19: Proceedings of the Practice and Experience in Advanced Research Computing on Rise of the Machines (learning)","authors":["Shivam Trivedi","Lauren Featherstun","Nathan DeMien","Callum Gunlach","Sagar Narayan","Jacob Sharp","Brian Werts","Lipu Wu","Carolyn Ellis","Lev Gorenstein","Erik Gough","Alex Younts","Xiao Zhu"],"abstract":"The Purdue Live Security Analyzer (PULSAR) is a state-of-the-art, high speed network monitoring and intrusion detection system designed to enhance the security of Purdue University's research cyberinfrastructure. PULSAR project goals include empowering domain scientists to conduct research at Purdue with heightened cybersecurity requirements and engaging undergraduate students through the design, deployment and operation of advanced cyberinfrastructure. Deployment strategies and design decisions are discussed, ultimately providing a recipe book for other institutions to use as a guide for effective implementation of a large scale intrusion detection system for Science DMZs.","publicationDate":"2019-07-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3442632.3442634","title":"case-study ","type":"Always-on Time-series Database: Keeping Up Where There's No Way to Catch Up: A discussion with Theo Schlossnagle, Justin Sheehy, and Chris McCubbin","venue":"Queue","authors":["Theo Schlossnagle","Justin Sheehy","Chris McCubbin"],"abstract":"What if you found you needed to provide for the capture of data from disconnected operations, such that updates might be made by different parties at the same time without conflicts? And what if your service called for you to receive massive volumes of data almost continuously throughout the day, such that you couldn't really afford to interrupt data ingest at any point for fear of finding yourself so far behind present state that there would be almost no way to catch up?","publicationDate":"2020-12-13T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3412451.3428497","title":"research-article ","type":"The Quantum software lifecycle","venue":"APEQS 2020: Proceedings of the 1st ACM SIGSOFT International Workshop on Architectures and Paradigms for Engineering Quantum Software","authors":["Benjamin Weder","Johanna Barzen","Frank Leymann","Marie Salm","Daniel Vietz"],"abstract":"Quantum computing is an emerging paradigm that enables to solve a variety of problems more efficiently than it is possible on classical computers. As the first quantum computers are available, quantum algorithms can be implemented and executed on real quantum hardware. However, the capabilities of today’s quantum computers are very limited and quantum computations are always disturbed by some error. Thus, further research is needed to develop or improve quantum algorithms, quantum computers, or required software tooling support. Due to the interdisciplinary nature of quantum computing, a common understanding of how to develop and execute a quantum software application is needed. However, there is currently no methodology or lifecycle comprising all relevant phases that can occur during the development and execution process. Hence, in this paper, we introduce the quantum software lifecycle consisting of ten phases a gate-based quantum software application should go through. We analyze the purpose of each phase, the available methods and tools that can be applied, and the open problems or research questions. Therefore, the lifecycle can be used as a baseline for discussions and future research.","publicationDate":"2020-11-12T23:00:00.000Z","citationCount":8},{"url":"https://dl.acm.org/doi/10.1145/3297280.3297292","title":"research-article ","type":"A programming model and middleware for high throughput serverless computing applications","venue":"SAC '19: Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing","authors":["Alfonso Pérez","Germán Moltó","Miguel Caballer","Amanda Calatrava"],"abstract":"Serverless computing has introduced unprecedented levels of scalability and parallelism for the execution of High Throughput Computing tasks. This represents a challenge and an opportunity for different scientific workloads to be adapted to upcoming programming models that simplify the usage of such platforms. In this paper we introduce a serverless model for highly-parallel file-processing applications. We also describe a middleware implementation that supports the execution of customized execution environments based on Docker images on AWS Lambda, the leading serverless computing platform. Moreover, this middleware offers tools to manage the input/output of the serverless infrastructure and the creation of HTTP endpoints in a transparent way to the user. To test the programming model proposed and the middleware, this paper describes two case studies. The first one analyzes medical images with a high degree of parallelism. The second one presents an architecture to process video keyframes. The results from both case studies are discussed and a cost analysis of the medical image architecture comparing different Cloud options is carried out. The results show that the combination of a high-level programming model with the scalable capabilities of AWS Lambda makes it easy for end users to efficiently exploit serverless computing for the optimized and cost-effective execution of loosely-coupled tasks.","publicationDate":"2019-04-07T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3167132.3167286","title":"research-article ","type":"Enabling temporal-aware contexts for adaptative distributed systems","venue":"SAC '18: Proceedings of the 33rd Annual ACM Symposium on Applied Computing","authors":["Ludovic Mouline","Amine Benelallam","Thomas Hartmann","François Fouquet","Johann Bourcier","Brice Morin","Olivier Barais"],"abstract":"Distributed adaptive systems are composed of federated entities offering remote inspection and reconfiguration abilities. This is often realized using a MAPE-K loop, which constantly evaluates system and environmental parameters and derives corrective actions if necessary. The OpenStack Watcher project uses such a loop to implement resource optimization services for multi-tenant clouds. To ensure a timely reaction in the event of failures, the MAPE-K loop is executed with a high frequency. A major drawback of such reactivity is that many actions, e.g., the migration of containers in the cloud, take more time to be effective and their effects to be measurable than the MAPE-k loop execution frequency. Unfinished actions as well as their expected effects over time are not taken into consideration in MAPE-K loop processes, leading upcoming analysis phases potentially take sub-optimal actions. In this paper, we propose an extended context representation for MAPE-K loop that integrates the history of planned actions as well as their expected effects over time into the context representations. This information can then be used during the upcoming analysis and planning phases to compare measured and expected context metrics. We demonstrate on a cloud elasticity manager case study that such temporal action-aware context leads to improved reasoners while still be highly scalable.","publicationDate":"2018-04-08T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3341105.3373915","title":"research-article ","type":"QoE-aware auto-scaling of heterogeneous containerized services (and its application to health services)","venue":"SAC '20: Proceedings of the 35th Annual ACM Symposium on Applied Computing","authors":["Guilherme Santos","Hervé Paulino","Tomé Vardasca"],"abstract":"Containerized service is currently a widely adopted solution to deploy services in the cloud. However, many companies offer a very diverse set of Web accessible services that are subjected to very distinctive workloads. Consequently, to correctly provision the right amount of resources for each of these services is a challenge. In this paper we propose the Autonomic ConTainerized Service Scaler (ACTS), an autonomic system able to horizontally and vertically scale a set of heterogeneous containerized services subjected to different workloads. The adaptation decisions depended on a set of high-level Quality of Experience (QoE) metrics centered on the services' end-user. We have applied ACTS to some of the digital services of the Shared Services of the Ministry of Health (SPMS) public company. The experimental results show that our solution is able to adequately adapt the configuration of each service, as a direct response to alterations on its workload.","publicationDate":"2020-03-29T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3359993.3366647","title":"research-article ","type":"Trigger-Action Computing in Local Broadcast Beaconing Networks","venue":"ENCP '19: Proceedings of the 1st ACM CoNEXT Workshop on Emerging in-Network Computing Paradigms","authors":["Teemu Kärkkäinen","L. Fuchsloch","Jörg Ott"],"abstract":"Computational elements---often in the form of microcontrollers---are increasingly embedded in and controlling the appliances that we use and the environments in which we live. In typical deployments a set of these elements, connected by an infrastructure network, comprises a distributed system under a cloud or edge based control. This introduces a number of inefficiencies: 1) cloud servers and edge gateways are points of indirection that increase latencies over direct interactions, 2) infrastructure networks incur monetary costs for the equipment, as well as energy and complexity costs, and 3) the resulting systems tend to be centralized and siloed, reducing their ability to interact, interoperate and share resources. As one possible way to solve these problems, we propose and evaluate a system integrating the trigger-action model of computing and highly constrained local broadcast beaconing based networking (e.g., Bluetooth LE, LoRa, VLC). The system requires no gateways or servers, minimizes inter-device latencies, and enables dynamic instantiation of local services by orchestrating nearby devices via trigger-action programs.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3472456.3473520","title":"research-article ","type":"Exploring HW/SW Co-Optimizations for Accelerating Large-scale Texture Identification on Distributed GPUs","venue":"ICPP 2021: 50th International Conference on Parallel Processing","authors":["Junsong Wang","Xiaofan Zhang","Yubo Li","Yonghua Lin"],"abstract":" Texture identification has been developed recently to support one-to-one verification and one-to-many search, which provides much broader support than texture classification in real-life applications. It has demonstrated great potentials to enable product traceability by identifying the unique texture information on the surface of the targeted objects. However, existing hardware acceleration schemes are not enough to support a large-scale texture identification, especially for the search task, where the number of texture images being searched can reach millions, creating enormous compute and memory demands and making real-time texture identification infeasible. To address these problems, we propose a comprehensive toolset with jointly optimization strategies from both hardware and software to deliver optimized GPU acceleration and leverage large-scale texture identification with real-time responses. Novel technologies include: 1) a highly-optimized cuBLAS implementation for efficiently running 2-nearest neighbors algorithm; 2) a hybrid cache design to incorporate host memory for streaming data toward GPUs, which delivers a 5 × larger memory capacity while running the targeted workloads; 3) a batch process to fully exploit the data reuse opportunities by considering available compute resources and memory bandwidth constraints. 4) an asymmetric local feature extraction to reduce the memory footprint for keeping feature matrices of reference texture images. To the best of our knowledge, this work is the first implementation to provide real-time large-scale texture identification on GPUs. By exploring the co-optimizations from both hardware and software, we can deliver 31 × faster search and 20 × larger feature cache capacity compared to a conventional CUDA implementation. We also demonstrate our proposed designs by proposing a distributed texture identification system with 14 Nvidia Tesla P100 GPUs which can complete 872,984 texture similarity comparisons in just one second.","publicationDate":"2021-08-08T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3150928.3150937","title":"research-article ","type":"On dimensioning Cloud-RAN systems","venue":"VALUETOOLS 2017: Proceedings of the 11th EAI International Conference on Performance Evaluation Methodologies and Tools","authors":["Veronica Quintuna","Fabrice Guillemin"],"abstract":"We investigate in this paper the implementation of a Cloud-RAN architecture, where several software-based Base Band Units (BBUs) are collocated in a cloud data center. We specifically study several scheduling strategies in order to accelerate the runtime of virtualized BBU functions, and thus, to increase the span of a Cloud-RAN system, given that there are fixed deadlines for the execution of these functions. The main goal of this work is to obtain a simple model for dimensioning a Cloud-RAN infrastructure. For this purpose, we introduce the M[X]/M/C model to capture the behavior of a BBU-pool running on a multi-core platform. The theoretical approach is validated by simulation when performing a Cloud-RAN system hosting one hundred of base stations.","publicationDate":"2017-12-04T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3456727.3463770","title":"research-article ","type":"Jumpgate: automating integration of network connected accelerators","venue":"SYSTOR '21: Proceedings of the 14th ACM International Conference on Systems and Storage","authors":["Craig Mustard","Swati Goswami","Niloofar Gharavi","Joel Nider","Ivan Beschastnikh","Alexandra Fedorova"],"abstract":"Network-connected accelerators (NCA), such as programmable switches, ASICs, and FPGAs can speed up operations in data analytics. But so far, integration of NCAs into data analytics systems required manual effort.We present Jumpgate, a system that simplifies integration of existing NCA code into data analytics systems, such as Apache Spark or Presto. Jumpgate places most of the integration code into the analytics system, which needs to be written once, leaving NCA programmers to write only a couple hundred lines of code to integrate new NCAs. Jumpgate relies on dataflow graphs that most analytics systems use internally, and takes care of the invocation of NCAs, the necessary format conversion, and orchestration of their execution via novel staged network pipelines.Our implementation of Jumpgate in Apache Spark made it possible, for the first time, to study the benefits and drawbacks of using NCAs across the entire range of queries in the TPC-DS benchmark. Since we lack hardware that can accelerate all analytics operations, we implemented NCAs in software. We report on how and when analytics workloads will benefit from NCAs to motivate future designs.","publicationDate":"2021-06-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3447548.3467110","title":"research-article ","type":"A Semi-Personalized System for User Cold Start Recommendation on Music Streaming Apps","venue":"KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining","authors":["Léa Briand","Guillaume Salha-Galvan","Walid Bendada","Mathieu Morlon","Viet-Anh Tran"],"abstract":"Music streaming services heavily rely on recommender systems to improve their users' experience, by helping them navigate through a large musical catalog and discover new songs, albums or artists. However, recommending relevant and personalized content to new users, with few to no interactions with the catalog, is challenging. This is commonly referred to as the user cold start problem. In this applied paper, we present the system recently deployed on the music streaming service Deezer to address this problem. The solution leverages a semi-personalized recommendation strategy, based on a deep neural network architecture and on a clustering of users from heterogeneous sources of information. We extensively show the practical impact of this system and its effectiveness at predicting the future musical preferences of cold start users on Deezer, through both offline and online large-scale experiments. Besides, we publicly release our code as well as anonymized usage data from our experiments. We hope that this release of industrial resources will benefit future research on user cold start recommendation.","publicationDate":"2021-08-13T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1109/UCC.2014.38","title":"Article ","type":"Metaheuristics-Based Planning and Optimization for SLA-Aware Resource Management in PaaS Clouds","venue":"UCC '14: Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing","authors":["Edwin Yaqub","Ramin Yahyapour","Philipp Wieder","Ali Imran Jehangiri","Kuan Lu","Constantinos Kotsokalis"],"abstract":"The Platform as a Service (PaaS) model of Cloud Computing has emerged as an enabling yet disruptive paradigm for accelerated development of applications on the Cloud. PaaS hides administration complexities of the underlying infrastructure such as the physical or virtual machines. This abstraction is achieved through advanced automation and OS-level multi-tenant containers. However, the on-demand procurement, unpredictable workloads and auto-scaling result in rapid increase and decrease of containers. This causes undesired utilization of Cloud resources and energy wastage that can be avoided with real time planning. Hence, the main challenge of a PaaS Cloud provider is to regularly plan and optimize the placement of containers on Cloud machines. However, the service-driven constraints regarding containers and spatial constraints regarding machines make SLA-aware resource allocation non-trivial. This relatively novel \"Service Consolidation\" problem is a variant of multi-dimensional bin-packing and hence NP-hard. In this work, we concretely frame this problem by leveraging the definition of Machine Reassignment model proposed by Google for the ROADEF/EURO challenge and characterize it for Open Shift PaaS. We apply Metaheuristic search to discover best (re) allocation solutions on Clouds of varying scales. We compare four state of the art algorithms as problem properties change in datasets and evaluate their performance against a variety of metrics including objective function score, machines used, utilization, resource contention, SLA violations, migrations and energy consumption. Finally, we present a policy-led ranking of solutions to obscure the complexity of individual metrics and decide for the most preferred solution. Hence, we provide valuable insights for SLA-aware resource management in PaaS Clouds.","publicationDate":"2014-12-07T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3425269.3425277","title":"research-article ","type":"Microservice Architecture: A Tertiary Study","venue":"SBCARS '20: Proceedings of the 14th Brazilian Symposium on Software Components, Architectures, and Reuse","authors":["Diego Ivo Campos Costa","Eduardo Pereira e Silva Filho","Reginaldo Florencio da Silva","Thiago Dias de C. Quaresma Gama","Mariela I. Cortés"],"abstract":"Context. The large-scale use of microservices and their increasing adoption in the industry in recent years has motivated researches on the most diverse aspects related to microservice-based development. However, as it is a relatively new topic, there is still no consolidated body of knowledge in the area. Objective. The present work intends to investigate the current state of research on microservices based on the formulation of six research questions covering fundamental aspects, such as: main interest topics and adopted standards, techniques and tools have been used and application areas. Method. From four digital libraries, 22 secondary studies were selected as a data source, which were analyzed and synthesized in the present study following the proposed research protocol. Results. Among the main topics of interest addressed, we highlight researches related to the applicability of microservice architecture, both by industry and academia. Results indicated that standards focus on challenges related to communication have been the most commonly considered by researchers of the area. Finally, the predominance in the use of the Docker container and the presence of DevOps practices in the automation of operations are noteworthy. Conclusions. The present mapping study points to some directions of research based on the identified gaps, such as modeling and testing of microservice applications, and addressing security aspects. Another promising point to be explored involves the combined use of microservice architecture with other related concepts such as IoT, smart cities, FOG computing and reactive systems, in order to reinforce the use of microservices, as well as creating new solutions and challenges to be researched.","publicationDate":"2020-10-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3292500.3330680","title":"research-article ","type":"Time-Series Anomaly Detection Service at Microsoft","venue":"KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","authors":["Hansheng Ren","Bixiong Xu","Yujing Wang","Chao Yi","Congrui Huang","Xiaoyu Kou","Tony Xing","Mao Yang","Jie Tong","Qi Zhang"],"abstract":"Large companies need to monitor various metrics (for example, Page Views and Revenue) of their applications and services in real time. At Microsoft, we develop a time-series anomaly detection service which helps customers to monitor the time-series continuously and alert for potential incidents on time. In this paper, we introduce the pipeline and algorithm of our anomaly detection service, which is designed to be accurate, efficient and general. The pipeline consists of three major modules, including data ingestion, experimentation platform and online compute. To tackle the problem of time-series anomaly detection, we propose a novel algorithm based on Spectral Residual (SR) and Convolutional Neural Network (CNN). Our work is the first attempt to borrow the SR model from visual saliency detection domain to time-series anomaly detection. Moreover, we innovatively combine SR and CNN together to improve the performance of SR model. Our approach achieves superior experimental results compared with state-of-the-art baselines on both public datasets and Microsoft production data.","publicationDate":"2019-07-24T22:00:00.000Z","citationCount":32},{"url":"https://dl.acm.org/doi/10.1145/3326285.3329046","title":"research-article ","type":"Elastic, geo-distributed RAFT","venue":"IWQoS '19: Proceedings of the International Symposium on Quality of Service","authors":["Zichen Xu","Christopher Stewart","Jiacheng Huang"],"abstract":"Raft is a protocol to maintain strong consistency across data replicas in cloud. It is widely used, especially by workloads that span geographically distributed sites. As these workloads grow, Raft's costs should grow, as least proportionally. However, auto scaling approaches for Raft inflate costs by provisioning at all sites when one site exhausts its local resources. This paper presents Geo-Raft, a scale-out mechanism that enables precise auto scaling for Raft. Geo-Raft extends Raft with the following abstractions: (1) secretaries which takes log processing for the leader and (2) observers which process read requests for followers. These abstractions are stateless, allowing for elastic auto scaling, even on unreliable spot instances. Geo-Raft provably preserves strong consistency guarantees provided by Raft. We implemented and evaluated Geo-Raft with multiple auto scaling techniques on Amazon EC2. Geo-Raft scales in resource footprint increments 5-7X smaller than Multi-Raft, the state of the art. Using spot instances, Geo-Raft reduces costs by 84.5% compared to Multi-Raft. Geo-Raft improves goodput of 95th-percentile SLO by 9X.Geo-Raft operates key-value services for 6 months without losing data or crash.","publicationDate":"2019-06-23T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3275219.3275220","title":"research-article ","type":"D-Tagger: A Tag Recommendation Approach for Docker Repositories","venue":"Internetware '18: Proceedings of the Tenth Asia-Pacific Symposium on Internetware","authors":["Kang Yin","Jiahong Zhou","Wei Chen","Guoquan Wu","Jiaxin Zhu","Jun Wei"],"abstract":"Docker repositories usually contain Docker images and Dockerfiles, where Docker images are a kind of off-the-shelf artifact and Dockerfiles specify how to automatically build Docker images following the notion of Infrastructure-as-Code. Given a huge number of Docker repositories, tag recommendation is essential to ensure that relevant ones can be easily retrieved, because tagging is practical in describing, bookmarking, navigating and searching software objects. However, in Docker Hub, tags are not well supported to semantically describing the repositories, and manually tagging is still an exhausting and time-consuming task.Dockerfile specifies Docker repository in a rigorous and compact way. Thus, based on Dockerfile analysis, this paper proposes D-Tagger, a tag recommendation approach to addressing the problem of multi-labeling Docker repositories. When taking Dockerfile as specific description, D-Tagger models a repository with its labeled tags and the terms extracted from its Dockerfile, and employs Labeled Latent Dirichlet Allocation algorithm to make tag recommendation. When regarding Dockerfile as configuration code, D-Tagger constructs a feature model based on key instructions that identify the Dockerfile, and then recommends tags with a similarity-based ranking method. D-Tagger finally makes a combination by considering both of the two perspectives. We evaluate D-Tagger on over 100,000 repositories of Docker Hub (accessed until Aug. 15, 2017). The experimental results show that the accuracy of D-Tagger, in terms of [email protected] and [email protected], achieve 0.675 and 0.712 respectively. In addition, D-Tagger outperforms the state-of-the-art approach when tagging repositories without description documents.","publicationDate":"2018-09-15T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3122865.3122878","title":"bibliography ","type":"Bibliography","venue":"Frontiers of Multimedia Research","authors":[],"abstract":"","publicationDate":"2017-12-18T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3472456.3473520","title":"research-article ","type":"Exploring HW/SW Co-Optimizations for Accelerating Large-scale Texture Identification on Distributed GPUs","venue":"ICPP 2021: 50th International Conference on Parallel Processing","authors":["Junsong Wang","Xiaofan Zhang","Yubo Li","Yonghua Lin"],"abstract":" Texture identification has been developed recently to support one-to-one verification and one-to-many search, which provides much broader support than texture classification in real-life applications. It has demonstrated great potentials to enable product traceability by identifying the unique texture information on the surface of the targeted objects. However, existing hardware acceleration schemes are not enough to support a large-scale texture identification, especially for the search task, where the number of texture images being searched can reach millions, creating enormous compute and memory demands and making real-time texture identification infeasible. To address these problems, we propose a comprehensive toolset with jointly optimization strategies from both hardware and software to deliver optimized GPU acceleration and leverage large-scale texture identification with real-time responses. Novel technologies include: 1) a highly-optimized cuBLAS implementation for efficiently running 2-nearest neighbors algorithm; 2) a hybrid cache design to incorporate host memory for streaming data toward GPUs, which delivers a 5 × larger memory capacity while running the targeted workloads; 3) a batch process to fully exploit the data reuse opportunities by considering available compute resources and memory bandwidth constraints. 4) an asymmetric local feature extraction to reduce the memory footprint for keeping feature matrices of reference texture images. To the best of our knowledge, this work is the first implementation to provide real-time large-scale texture identification on GPUs. By exploring the co-optimizations from both hardware and software, we can deliver 31 × faster search and 20 × larger feature cache capacity compared to a conventional CUDA implementation. We also demonstrate our proposed designs by proposing a distributed texture identification system with 14 Nvidia Tesla P100 GPUs which can complete 872,984 texture similarity comparisons in just one second.","publicationDate":"2021-08-08T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3150928.3150937","title":"research-article ","type":"On dimensioning Cloud-RAN systems","venue":"VALUETOOLS 2017: Proceedings of the 11th EAI International Conference on Performance Evaluation Methodologies and Tools","authors":["Veronica Quintuna","Fabrice Guillemin"],"abstract":"We investigate in this paper the implementation of a Cloud-RAN architecture, where several software-based Base Band Units (BBUs) are collocated in a cloud data center. We specifically study several scheduling strategies in order to accelerate the runtime of virtualized BBU functions, and thus, to increase the span of a Cloud-RAN system, given that there are fixed deadlines for the execution of these functions. The main goal of this work is to obtain a simple model for dimensioning a Cloud-RAN infrastructure. For this purpose, we introduce the M[X]/M/C model to capture the behavior of a BBU-pool running on a multi-core platform. The theoretical approach is validated by simulation when performing a Cloud-RAN system hosting one hundred of base stations.","publicationDate":"2017-12-04T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3483899.3483900","title":"research-article ","type":"Mining Evidences of Internet of Robotic Things (IoRT) Software from Open Source Projects","venue":"SBCARS '21: 15th Brazilian Symposium on Software Components, Architectures, and Reuse","authors":["Michel Albonico","Adair Rohling","Juliano Santos","Paulo Varela"],"abstract":" The current world scenario is heading to contactless technologies, where robots are in the center. These systems usually benefit from Internet of Things (IoT) sensing, being named Internet of Robotics Things (IoRT) systems. Developing IoRT software naturally involves high levels of complexity, which may be softened with well-established architectural evidence. In this paper, we aim at mining IoRT software architectural evidence from open source IoRT software repositories. For this, we (i) extract a dataset from GitHub repositories containing real open-source IoRT systems, (ii) mine relevant information from those repositories, (iii) and compile a catalog of architectural software characteristics. The catalog from our study can then be used by practitioners architects.","publicationDate":"2021-09-26T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3001913.3001918","title":"research-article ","type":"Bringing the Cloud to Rural and Remote Areas via Cloudlets","venue":"ACM DEV '16: Proceedings of the 7th Annual Symposium on Computing for Development","authors":["Sven Helmer","Claus Pahl","Julian Sanin","Lorenzo Miori","Stefan Brocanelli","Filippo Cardano","Daniele Gadler","Daniel Morandini","Alessandro Piccoli","Saifur Salam","Alam Mahabub Sharear","Angelo Ventura","Pekka Abrahamsson","Tosin Daniel Oyetoyan"],"abstract":"Instead of relying on huge and expensive data centers for rolling out cloud-based services to rural and remote areas, we propose a hardware platform based on small single-board computers. The role of these micro-data centers is twofold. On the one hand, they act as intermediaries between cloud services and clients, improving availability in the case of network or power outages. On the other hand, they run community-based services on local infrastructure. We illustrate how to build such a system without incurring high costs, high power consumption, or single points of failure. Additionally, we opt for a system that is extendable and scalable as well as easy to deploy, relying on an open design.","publicationDate":"2016-11-17T23:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3419634","title":"research-article ","type":"A Survey on IoT Big Data: Current Status, 13 V’s Challenges, and Future Directions","venue":"ACM Computing Surveys","authors":["Maggi Bansal","Inderveer Chana","Siobhán Clarke"],"abstract":"Driven by the core technologies, i.e., sensor-based autonomous data acquisition and the cloud-based big data analysis, IoT automates the actuation of data-driven intelligent actions on the connected objects. This automation enables numerous useful real-life use-cases, such as smart transport, smart living, smart cities, and so on. However, recent industry surveys reflect that data-related challenges are responsible for slower growth of IoT in recent years. For this reason, this article presents a systematic and comprehensive survey on IoT Big Data (IoTBD) with the aim to identify the uncharted challenges for IoTBD. This article analyzes the state-of-the-art academic works in IoT and big data management across various domains and proposes a taxonomy for IoTBD management. Then, the survey explores the IoT portfolio of major cloud vendors and provides a classification of vendor services for the integration of IoT and IoTBD on their cloud platforms. After that, the survey identifies the IoTBD challenges in terms of 13 V’s challenges and envisions IoTBD as “Big Data 2.0.” Then the survey provides comprehensive analysis of recent works that address IoTBD challenges by highlighting their strengths and weaknesses to assess the recent trends and future research directions. Finally, the survey concludes with discussion on open research issues for IoTBD.","publicationDate":"2020-12-05T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3428690.3429176","title":"research-article ","type":"APOLLO: a platform for experimental analysis of time sensitive multimedia IoT applications","venue":"MoMM '20: Proceedings of the 18th International Conference on Advances in Mobile Computing & Multimedia","authors":["Harindu Korala","Prem Prakash Jayaraman","Ali Yavari","Dimitrios Georgakopoulos"],"abstract":"The Internet of Things (IoT) is growing fast and is gaining significant adoption in areas such as smart cities and manufacturing. The variety and low-cost of IoT devices with excellent audio/visual sensors is fueling the growth of multimedia IoT applications, many of which are bandwidth-hungry and time-sensitive (i.e., must produce their results within an application specific time-sensitive requirement). While a large body of related work has studied distribution of such Time Sensitive Multimedia IoT (TS-MIoT) applications in simulated environments, there is lack of a platform that can be used to experiment with techniques for meeting their time-sensitive and computing resource requirements on real-world IoT infrastructure, i.e., a combination of IoT devices, close by computers and a cloud data centre connected by a variety of networks. This paper proposes APOLLO, a platform for experimental analysis of TS-MIoT applications. APOLLO provides mechanisms to load TS-MIoT application execution plans and execute the plans on available IoT infrastructure. We describe a proof-of-concept implementation using Orleans and present experimental evaluations to validate APOLLO's ability to support the experimental analysis of TS-MIoT applications.","publicationDate":"2020-11-29T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3318464.3383130","title":"short-paper ","type":"Le Taureau: Deconstructing the Serverless Landscape & A Look Forward","venue":"SIGMOD '20: Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data","authors":["Anurag Khandelwal","Arun Kejariwal","Karthikeyan Ramasamy"],"abstract":"Akin to the natural evolution of programming in assembly language to high-level languages, serverless computing represents the next frontier in the evolution of cloud computing: bare metal -> virtual machines -> containers -> serverless. The genesis of serverless computing can be traced back to the fundamental need of enabling a programmer to singularly focus on writing application code in a high-level language and isolating all facets of system management (for example, but not limited to, instance selection, scaling, deployment, logging, monitoring, fault tolerance and so on). This is particularly critical in light of today's, increasingly tightening, time-to-market constraints. Currently, serverless computing is supported by leading public cloud vendors, such as AWS Lambda, Google Cloud Functions, Azure Cloud Functions and others. While this is an important step in the right direction, there are many challenges going forward. For instance, but not limited to, how to enable support for dynamic optimization, how to extend support for stateful computation, how to efficiently bin-pack applications, how to support hardware heterogeneity (this will be key especially in light of the emergence of hardware accelerators for deep learning workloads). Inspired by Picasso's Le Taureau, in the tutorial proposed herein, we shall deconstruct evolution of serverless --- the overarching intent being to facilitate better understanding of the serverless landscape. This, we hope, would help push the innovation frontier on both fronts, the paradigm itself and the applications built atop of it.","publicationDate":"2020-06-10T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3392350.3392351","title":"research-article ","type":"On cloud computing infrastructure for existing code-clone detection algorithms","venue":"ACM SIGAPP Applied Computing Review","authors":["Andrew Walker","Tomas Cerny"],"abstract":"Microservice Architecture (MSA) is becoming a design standard for modern cloud-based software systems. However, even though cloud-based applications have been thoroughly explored with regards to networking, scalability, and decomposition of existing monolithic applications into MSA based applications, not much research has been done showing the viability of MSA in new problem domains. In this paper, we explore the application of MSA to the code-clone detection problem domain to identify any improvements that can be made over existing local code-clone detection applications. A fragment of source code that is identical or similar to another is a code-clone. Code-clones make it difficult to maintain applications as they create multiple points within the code that bugs must be fixed, new rules enforced, or design decisions imposed. As applications grow larger and larger, the pervasiveness of code-clones likewise grows. To face the code-clone related issues, many tools and algorithms have been proposed to find and document code-clones within an application. In this paper, we show that many improvements can be made by utilizing emerging cloud-based technologies.","publicationDate":"2020-04-01T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1109/CCGRID.2017.9","title":"tutorial ","type":"Deploying High Throughput Scientific Workflows on Container Schedulers with Makeflow and Mesos","venue":"CCGrid '17: Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","authors":["Chao Zheng","Ben Tovar","Douglas Thain"],"abstract":"Workflows are a widely used abstraction for describing large scientific applications and running them on distributed systems. However, most workflow systems have been silent on the question of what execution environment each task in the workflow is expected to run in. Consequently, a workflow may run successfully in the environment it was created, but fail on other platforms due to the differences in execution environment. Container-based schedulers have recently arisen as a potential solution to this problem, adopting containers to distribute computing resources and deliver well-defined execution environments to applications. In this paper, we consider how to connect workflow system to container schedulers with minimal performance loss and higher system efficiency. As an example of current technology, we use Makeflow and Mesos. We present five design challenges, and address them by using four configurations that connecting workflow system to container scheduler from different level of the infrastructure. In order to take full advantage of the resource sharing schema of Mesos, we enable the resource monitor of Makeflow to dynamically update the task resource requirement. We explore the performance of a large bioinformatics workflow, and observe that using Makeflow, Work Queue and the Resource monitor together not only increase the transfer throughput but also achieves highest resource usage rate.","publicationDate":"2017-05-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3447548.3467150","title":"research-article ","type":"Would Your Tweet Invoke Hate on the Fly? Forecasting Hate Intensity of Reply Threads on Twitter","venue":"KDD '21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining","authors":["Snehil Dahiya","Shalini Sharma","Dhruv Sahnan","Vasu Goel","Emilie Chouzenoux","Víctor Elvira","Angshul Majumdar","Anil Bandhakavi","Tanmoy Chakraborty"],"abstract":"Curbing hate speech is undoubtedly a major challenge for online microblogging platforms like Twitter. While there have been studies around hate speech detection, it is not clear how hate speech finds its way into an online discussion. It is important for a content moderator to not only identify which tweet is hateful but also to predict which tweet will be responsible for accumulating hate speech. This would help in prioritizing tweets that need constant monitoring. Our analysis reveals that for hate speech to manifest in an ongoing discussion, the source tweet may not necessarily be hateful; rather, there are plenty of such non-hateful tweets which gradually invoke hateful replies, resulting in the entire reply threads becoming provocative.In this paper, we define a novel problem -- given a source tweet and a few of its initial replies, the task is to forecast the hate intensity of upcoming replies. To this end, we curate a novel dataset constituting approx. 4.5k contemporary tweets and their entire reply threads. Our preliminary analysis confirms that the evolution patterns along time of hate intensity among reply threads have highly diverse patterns, and there is no significant correlation between the hate intensity of the source tweets and that of their reply threads. We employ seven state-of-the-art dynamic models (either statistical signal processing or deep learning-based) and show that they fail badly to forecast the hate intensity. We then propose DESSERT, a novel deep state-space model that leverages the function approximation capability of deep neural networks with the capacity to quantify the uncertainty of statistical signal processing models. Exhaustive experiments and ablation study show that DESSERT outperforms all the baselines substantially. Further, its deployment in an advanced AI platform designed to monitor real-world problematic hateful content has improved the aggregated insights extracted for countering the spread of online harms.","publicationDate":"2021-08-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3276774.3276796","title":"research-article ","type":"Mortar: an open testbed for portable building analytics","venue":"BuildSys '18: Proceedings of the 5th Conference on Systems for Built Environments","authors":["Gabe Fierro","Marco Pritoni","Moustafa AbdelBaky","Paul Raftery","Therese Peffer","Greg Thomson","David E. Culler"],"abstract":"Access to large amounts of real-world data has long been a barrier to the development and evaluation of analytics applications for the built environment. Open data sets exist, but they are limited in their span (how much data is available) and context (what kind of data is available and how it is described). Evaluation of such analytics is also limited by how the analytics themselves are implemented, often using hard-coded names of building components, points and locations, or unique input data formats.To advance the methodology for how such analytics are implemented and evaluated, we present Mortar: an open testbed for portable building analytics, currently spanning 90 buildings and containing over 9.1 billion data points. All buildings in the testbed are described using Brick, a recently developed metadata schema, providing rich functional descriptions of building assets and subsystems. We also propose a simple architecture for writing portable analytics applications that are robust to the diversity of buildings and can configure themselves based on context. We demonstrate the utility of Mortar by implementing 11 applications from the literature.","publicationDate":"2018-11-06T23:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3486602.3486767","title":"research-article ","type":"Union and intersection contracts are hard, actually","venue":"DLS 2021: Proceedings of the 17th ACM SIGPLAN International Symposium on Dynamic Languages","authors":["Teodoro Freund","Yann Hamdaoui","Arnaud Spiwack"],"abstract":"Union and intersection types are a staple of gradually typed languages such as TypeScript. While it's long been recognized that union and intersection types are difficult to verify statically, it may appear at first that the dynamic part of gradual typing is actually pretty simple.  It turns out however, that in presence of higher-order contracts union and intersection are deceptively difficult. The literature on higher-order contracts with union and intersection, while keenly aware of the fact, doesn't really explain why. We point and illustrate the problems and trade-offs inherent to union and intersection contracts, via example and a survey of the literature.","publicationDate":"2021-10-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3275219.3275230","title":"research-article ","type":"Migrating Web Applications from Monolithic Structure to Microservices Architecture","venue":"Internetware '18: Proceedings of the Tenth Asia-Pacific Symposium on Internetware","authors":["Zhongshan Ren","Wei Wang","Guoquan Wu","Chushu Gao","Wei Chen","Jun Wei","Tao Huang"],"abstract":"In the traditional software development and deployment, the centralized monolithic is always adopted, as the modules are tightly coupled, which caused many inconvenience in software DevOps. The modules with bottlenecks in monolithic application cannot be extend separately as the application is an integral part, and different module cannot use different technology stack. To prolong the lifecycle of the monolithic applications, its need to migrated it to microservice architecture. Due to the complex logic and large number of third party framework libraries depended, get an accurate comprehensive of the application characteristics is challenging. The existing research mostly based on the static characteristics, lack of consideration of the runtime dynamic characteristics, and the completeness and accuracy of the static analysis is inadequate. To resolve above problems, we combined static and dynamic analysis to get static structure and runtime behavior characteristics of monolithic application. We employed the coupling among functions to evaluate the degree of dependence, and through function clustering to achieve the migration of legacy monolithic applications and its data to microservices architecture. Through the empirical study of migrate the typical legacy project to microservices, it is proved that we proposed method can offer precise guidance and assistance in the migration procedure. Experiments show that the method has high accuracy and low performance cost.","publicationDate":"2018-09-15T22:00:00.000Z","citationCount":17},{"url":"https://dl.acm.org/doi/10.1145/3323503.3349557","title":"research-article ","type":"Middleware architecture towards higher-level descriptions of (genuine) internet-of-things applications","venue":"WebMedia '19: Proceedings of the 25th Brazillian Symposium on Multimedia and the Web","authors":["Thomás Marques Brandão Reis","Marcelo F. Moreno"],"abstract":"The growing evolution of mobile devices and the variety of new sensors and actuactors allow applications to achieve higher potential in an Internet-of-Things environment. However, IoT application developers faces up to market fragmentation, proprietary solutions and lack of interoperability, not only in hardware, but also in development tools. With a vision that IoT resources should be seen as single machine, independently of their nature, underlying technologies and geographical distribution, in this paper we propose a distributed middleware architecture for IoT applications. Introducing concepts not yet found in similar proposals, this effort represents a step towards the conception of higher-level descriptions of (genuine) IoT applications.","publicationDate":"2019-10-28T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3469410.3469423","title":"research-article ","type":"Public Gratification Palace: A Framework for Increased Civic Engagement","venue":"MAB20: Media Architecture Biennale 20","authors":["Jennifer Jiang","Lawson Spencer","Liss C. Werner"],"abstract":"As popularly mentioned, the successful practice of urban design and planning is limited when only designers and local business or governmental institutions participate in the design and implementation of public infrastructure, placemaking and policy development. Public design cannot be a one-time event nor permanently static because community engagement ought to be a recurrent and consistent activity, in fostering the growth and sustainability of the community. Since the 1960s, there have been initiatives to democratize urban planning practices, and more recently, these initiatives have continued in this modality of citizen designer and empowerment through the implementation of media architecture, spatial blogging, and co-creation through crowdsourcing. As a conceptual framework, the Public Gratification Palace suggests a co-creative design methodology to increase civic engagement using the familiarity and intuitiveness of mobile device usage and social media platforms; thus, supporting voices of the digital literate community. Through cybernetic principles, this framework utilizes gratification methods akin to the ones used in social media to enhance user experience and continued participation. Geo-located instant gratification, as the process of attaching geographical metadata to digital media, will provide all stakeholders (e.g., local public, spatial planners and designers, and city governments) with feedback, crowd approval/disapproval and/or proposals for the design and implementation of public infrastructure as well as policies. Consequently, location-based social interactions and information exchange will increase in-situ civic engagement and community building through the networks of geo-tagging.","publicationDate":"2021-06-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3225058.3225070","title":"research-article ","type":"Learning Driven Parallelization for Large-Scale Video Workload in Hybrid CPU-GPU Cluster","venue":"ICPP 2018: Proceedings of the 47th International Conference on Parallel Processing","authors":["Haitao Zhang","Bingchang Tang","Xin Geng","Huadong Ma"],"abstract":"Hybrid CPU-GPU cluster has become a promising computing paradigm for large-scale video analytics. However, the uncertainty and variability of workloads and heterogeneous resources in the cluster can lead to the unbalanced use of the hybrid computing resources and further cause the performance degradation of the computing platform. This problem becomes more challenging with the computation complexity and dependencies of video tasks in the hybrid cluster. In this paper, we focus on the video workload parallelization problem with fine-grained task division and feature description in the hybrid CPU-GPU cluster. Firstly, for achieving high resource utilization and task throughput, we propose a two-stage video task scheduling approach based on deep reinforcement learning. In our approach, a task execution node is selected by the cluster-level scheduler for the mutually independent video tasks, and then the node-level scheduler assigns the interrelated video subtasks to the appropriate computing units. By using the deep Q-network, the two-stage scheduling model is online learned to perform the current optimal scheduling actions according to the runtime status of cluster environments, the characteristics of video tasks, and the dependencies between video tasks. Secondly, based on the transfer learning technology, a scheduling strategy generalization method is proposed to efficiently rebuild the task scheduling model referring to the existing model. Finally, we conduct the extensive experiments to analyze the impact of the model parameters on the scheduling actions, and then the experimental results also validate that our learning based task scheduling approach outperforms the other widely used methods.","publicationDate":"2018-08-12T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3205977.3205995","title":"research-article ","type":"Self-Generation of Access Control Policies","venue":"SACMAT '18: Proceedings of the 23nd ACM on Symposium on Access Control Models and Technologies","authors":["Seraphin Calo","Dinesh Verma","Supriyo Chakraborty","Elisa Bertino","Emil Lupu","Gregory Cirincione"],"abstract":"Access control for information has primarily focused on access statically granted to subjects by administrators usually in the context of a specific system. Even if mechanisms are available for access revocation, revocations must still be executed manually by an administrator. However, as physical devices become increasingly embedded and interconnected, access control needs to become an integral part of the resource being protected and be generated dynamically by resources depending on the context in which the resource is being used. In this paper, we discuss a set of scenarios for access control needed in current and future systems and use that to argue that an approach for resources to generate and manage their access control policies dynamically on their own is needed. We discuss some approaches for generating such access control policies that may address the requirements of the scenarios.","publicationDate":"2018-06-06T22:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3463274.3463334","title":"research-article ","type":"Modernizing Legacy Systems with Microservices: A Roadmap","venue":"EASE 2021: Evaluation and Assessment in Software Engineering","authors":["Daniele Wolfart","Wesley K. G. Assunção","Ivonei F. da Silva","Diogo C. P. Domingos","Ederson Schmeing","Guilherme L. Donin Villaca","Diogo do N. Paza"],"abstract":" Legacy systems are long-lived applications, with obsolete technology and degraded architecture. These systems hamper digital transformation and innovation, and require a great amount of resources for maintenance. The modernization of monolithic legacy systems is a strategy to promote better evolution and maintenance, taking advantage of new technologies such as microservices. Microservice architectural style is a paradigm to develop systems as a suite of small and autonomous services, communicating through a lightweight protocol. However, the migration of legacy systems to microservices is complex. Although we can find several studies on this topic, they usually focus on specific activities, e.g., the identification of the microservice boundaries in the legacy code. Also, existing pieces of work do not cover real-world scenarios, since they do not take into account organizational, operational, and technical aspects. To overcome this limitation, in this paper we present a roadmap for modernizing monolithic legacy systems with microservices. The roadmap is distilled from the existing body of knowledge, describing common activities and input/output information. The proposed roadmap is composed of eight activities, grouped in four phases, namely initiation, planning, execution, and monitoring. The main contributions are: (i) serve as a basis for practitioners to plan, execute, and monitor the modernization process; (ii) be a reference for researchers to design new studies; and (iii) motivate tool builders to deal with existing needs.","publicationDate":"2021-06-20T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1109/ICGSE.2017.16","title":"research-article ","type":"Emerging trends for global DevOps: a New Zealand perspective","venue":"ICGSE '17: Proceedings of the 12th International Conference on Global Software Engineering","authors":["Waqar Hussain","Tony Clear","Stephen MacDonell"],"abstract":"The DevOps phenomenon is gaining popularity through its ability to support continuous value delivery and ready accommodation of change. However, given the relative immaturity and general confusion about DevOps, a common view of expectations from a DevOps role is lacking. Through investigation of online job advertisements, combined with interviews, we identified key Knowledge Areas, Skills and Capabilities for a DevOps role and their relative importance in New Zealand's job market. Our analysis also revealed the global dimensions and the emerging nature of the DevOps role in GSE projects. This research adds a small advanced economy (New Zealand) perspective to the literature on DevOps job advertisements and should be of value to employers, job seekers, researchers as well educators and policy makers.","publicationDate":"2017-05-19T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3337821.3337851","title":"research-article ","type":"Improving Short Job Latency Performance in Hybrid Job Schedulers with Dice","venue":"ICPP 2019: Proceedings of the 48th International Conference on Parallel Processing","authors":["Wei Zhou","K. Preston White","Hongfeng Yu"],"abstract":"It is common to find a mixture of both long batch jobs and latency-sensitive short jobs in enterprise data centers. Recently hybrid job schedulers emerge as attractive alternatives of conventional centralized job schedulers.In this paper, we conduct trace-driven experiments to study the job-completion-delay performance of two representative hybrid job schedulers (Hawk and Eagle), and find that short jobs still encounter long latency issues due to fluctuating bursty nature of workloads. To this end, we propose Dice, a general performance optimization framework for hybrid job schedulers, to alleviate the high job-completion-delay problem of short jobs. Dice is composed of two simple yet effective techniques: Elastic Sizing and Opportunistic Preemption. Both Elastic Sizing and Opportunistic Preemption keep track of the task waiting times of short jobs. When the mean task waiting time of short jobs is high, Elastic Sizing dynamically and adaptively increases the short partition size to prioritize short jobs over long jobs. On the other hand, Opportunistic Preemption preempts resources from long tasks running in the general partition on demand, so as to mitigate the \"head-of-line\" blocking problem of short jobs.We enhance the two schedulers with Dice and evaluate Dice performance improvement in our prototype implementation. Experiment results show that Dice achieves 50.9%, 54.5%, and 43.5% improvement on 50th-percentile, 75th-percentile, and 90th-percentile job completion delays of short jobs in Hawk respectively, as well as 33.2%, 74.1%, and 85.3% improvement on those in Eagle respectively under the Google trace, at low performance costs to long jobs.","publicationDate":"2019-08-04T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3339186.3339213","title":"research-article ","type":"Collecting, Monitoring, and Analyzing Facility and Systems Data at the National Energy Research Scientific Computing Center","venue":"ICPP 2019: Proceedings of the 48th International Conference on Parallel Processing: Workshops","authors":["Elizabeth Bautista","Melissa Romanus","Thomas Davis","Cary Whitney","Theodore Kubaska"],"abstract":"As high-performance computing (HPC) resources continue to grow in size and complexity, so too does the volume and velocity of the operational data that is associated with them. At such scales, new mechanisms and technologies are required to continuously gather, store, and analyze this data in near-real time from heterogeneous and distributed sources without impacting the underlying data center operations or HPC resource utilization. In this paper, we describe our experiences in designing and implementing an infrastructure for extreme-scale operational data collection, known as the Operations Monitoring and Notification Infrastructure (OMNI) at the National Energy Research Scientific Computing (NERSC) center at Lawrence Berkeley National Laboratory. OMNI currently holds over 522 billion records of online operational data (totaling over 125TB) and can ingest new data points at an average rate of 25,000 data points per second. Using OMNI as a central repository, facilities and environmental data can be seamlessly integrated and correlated with machine metrics, job scheduler information, network errors, and more, providing a holistic view of data center operations. To demonstrate the value of real-time operational data collection, we present a number of real-world case studies for which having OMNI data readily available led to key operational insights at NERSC. The case results include a reduction in the downtime of an HPC system during a facility transition, as well as a $2.5 million electrical substation savings for the next-generation Perlmutter HPC system.","publicationDate":"2019-08-04T22:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3132465.3132478","title":"research-article ","type":"A knowledge and reasoning toolkit for cognitive applications","venue":"HotWeb '17: Proceedings of the fifth ACM/IEEE Workshop on Hot Topics in Web Systems and Technologies","authors":["Mustafa Canim","Cristina Cornelio","Robert Farrell","Achille Fokoue","Kyle Gao","John Gunnels","Arun Iyengar","Ryan Musa","Mariano Rodriguez-Muro","Rosario Uceda-Sosa"],"abstract":"This paper presents a knowledge and reasoning toolkit for developing cognitive applications which have significant requirements for managing structured and semi-structured data. Our system provides enhanced querying and reasoning capabilities along with natural language processing support and the ability to automatically extract data from PDF documents. We also have the capability to manage ontologies in a user-friendly way. Our system is implemented as a set of Web services, and we provide enhanced clients to allow applications to easily access our knowledge and reasoning toolkit.","publicationDate":"2017-10-13T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3357141.3357603","title":"research-article ","type":"Geological Data Access on a Polyglot Database using a Service Architecture","venue":"SBCARS '19: Proceedings of the XIII Brazilian Symposium on Software Components, Architectures, and Reuse","authors":["Leonardo Guerreiro Azevedo","Rodrigo da Silva Ferreira","Viviane Torres da Silva","Maximillien de Bayser","Elton F. de S. Soares","Raphael Melo Thiago"],"abstract":"In a microservice architecture, solutions are built through collaboration of distributed services across networks. In the Oil & Gas industry, in exploration and production phases, organization units executes different services over several diverse datasets. Geological data usually is in high volume and encompasses different kinds of data objects, with diverse structure and nature, such as seismic data, seismic horizon and well data. Querying, processing, and composing geological data presents strong demands for domain knowledge representation and reasoning, and tailored processing techniques. This work presents an application of microservices architecture and polyglot persistence technologies to handle the requirements of geological data in the Oil & Gas domain. This architecture allows parties communicate in a light way, while encapsulating processing and data access to a geological database and to a knowledge base. It also works as a common layer, composing parties' services results for data consumption by clients. We exemplify the proposal by presenting and analyzing its use in a real scenario which includes some of the implemented queries in a developed system to support geological data analysis. We present the main characteristics of the system and highlights lessons learned in its development.","publicationDate":"2019-09-22T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1109/SEAMS.2017.12","title":"research-article ","type":"Delivering elastic containerized cloud applications to enable DevOps","venue":"SEAMS '17: Proceedings of the 12th International Symposium on Software Engineering for Adaptive and Self-Managing Systems","authors":["Cornel Barna","Hamzeh Khazaei","Marios Fokaefs","Marin Litoiu"],"abstract":"Following recent technological advancements in software systems, like microservices, containers and cloud systems, DevOps has risen as a new development paradigm. Its aim is to bridge the gap between development and management of software systems and enable continuous development, deployment and integration. Towards this end, automated tools and management systems play a crucial role. In this work, we propose a method to develop an autonomic management system for multitier, multi-layer data-intensive containerized applications based on a performance model of such systems. The model is shown to be robust and accurate in estimating and predicting the system's performance for various workloads and topologies, while the AMS is capable of regulating the application's behaviour by taking independent actions on its various parts.","publicationDate":"2017-05-19T22:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3382494.3410679","title":"research-article ","type":"DevOps in an ISO 13485 Regulated Environment: A Multivocal Literature Review","venue":"ESEM '20: Proceedings of the 14th ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)","authors":["Martin Forsberg Lie","Mary Sánchez-Gordón","Ricardo Colomo-Palacios"],"abstract":"Background: Medical device development projects must follow proper directives and regulations to be able to market and sell the end-product in their respective territories. The regulations describe requirements that seem to be opposite to efficient software development and short time-to-market. As agile approaches, like DevOps, are becoming more and more popular in software industry, a discrepancy between these modern methods and traditional regulated development has been reported. Although examples of successful adoption in this context exist, the research is sparse. Aims: The objective of this study is twofold: to review the current state of DevOps adoption in regulated medical device environment; and to propose a checklist based on that review for introducing DevOps in that context. Method: A multivocal literature review is performed and evidence is synthesized from sources published between 2015 to March of 2020 to capture the opinions of experts and community in this field. Results: Our findings reveal that adoption of DevOps in a regulated medical device environment such as ISO 13485 has its challenges, but potential benefits may outweigh those in areas such as regulatory, compliance, security, organizational and technical. Conclusion: DevOps for regulated medical device environments is a highly appealing approach as compared to traditional methods and could be particularly suited for regulated medical development. However, an organization must properly anchor a transition to DevOps in top-level management and be supportive in the initial phase utilizing professional coaching and space for iterative learning; as such an initiative is a complex organizational and technical task.","publicationDate":"2020-10-04T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3342195.3387517","title":"research-article ","type":"Borg: the next generation","venue":"EuroSys '20: Proceedings of the Fifteenth European Conference on Computer Systems","authors":["Muhammad Tirmazi","Adam Barker","Nan Deng","Md E. Haque","Zhijing Gene Qin","Steven Hand","Mor Harchol-Balter","John Wilkes"],"abstract":"This paper analyzes a newly-published trace that covers 8 different Borg [35] clusters for the month of May 2019. The trace enables researchers to explore how scheduling works in large-scale production compute clusters. We highlight how Borg has evolved and perform a longitudinal comparison of the newly-published 2019 trace against the 2011 trace, which has been highly cited within the research community.Our findings show that Borg features such as alloc sets are used for resource-heavy workloads; automatic vertical scaling is effective; job-dependencies account for much of the high failure rates reported by prior studies; the workload arrival rate has increased, as has the use of resource over-commitment; the workload mix has changed, jobs have migrated from the free tier into the best-effort batch tier; the workload exhibits an extremely heavy-tailed distribution where the top 1% of jobs consume over 99% of resources; and there is a great deal of variation between different clusters.","publicationDate":"2020-04-14T22:00:00.000Z","citationCount":28},{"url":"https://dl.acm.org/doi/10.1145/3230833.3230853","title":"research-article ","type":"Cloud Architectures for Searchable Encryption","venue":"ARES 2018: Proceedings of the 13th International Conference on Availability, Reliability and Security","authors":["Johannes Blömer","Nils Löken"],"abstract":"Blömer et al. have presented a cloud architecture for enabling fine-grained cryptographic access control to data in the cloud. The architecture is intended to provide this service to large-scale orgnaizations. We revisit the cloud architecture, and enrich it with searchable encryption. In the process, we identify some shortcomings of Blömer et al.'s architecture, that prevent many cryptographic primitives from being implemented within the framework of the architecture. Subsequently, we propose fixes to these issues. As a result, we are able to propose a concrete instantiation of searchable encryption, in the form of Bost's Σoφoς scheme, in Blömer et al.'s architecture. Moreover, with our fixes, other primitives can be adapted to the architecture as well.","publicationDate":"2018-08-26T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/2993236.2993256","title":"research-article ","type":"Automatic non-functional testing of code generators families","venue":"GPCE 2016: Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences","authors":["Mohamed Boussaa","Olivier Barais","Benoit Baudry","Gerson Sunyé"],"abstract":" The intensive use of generative programming techniques provides an elegant engineering solution to deal with the heterogeneity of platforms and technological stacks. The use of domain-specific languages for example, leads to the creation of numerous code generators that automatically translate highlevel system specifications into multi-target executable code. Producing correct and efficient code generator is complex and error-prone. Although software designers provide generally high-level test suites to verify the functional outcome of generated code, it remains challenging and tedious to verify the behavior of produced code in terms of non-functional properties. This paper describes a practical approach based on a runtime monitoring infrastructure to automatically check the potential inefficient code generators. This infrastructure, based on system containers as execution platforms, allows code-generator developers to evaluate the generated code performance. We evaluate our approach by analyzing the performance of Haxe, a popular high-level programming language that involves a set of cross-platform code generators. Experimental results show that our approach is able to detect some performance inconsistencies that reveal real issues in Haxe code generators. ","publicationDate":"2016-10-19T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3460319.3464797","title":"research-article ","type":"Fixing dependency errors for Python build reproducibility","venue":"ISSTA 2021: Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis","authors":["Suchita Mukherjee","Abigail Almanza","Cindy Rubio-González"],"abstract":"Software reproducibility is important for re-usability and the cumulative progress of research. An important manifestation of unreproducible software is the changed outcome of software builds over time. While enhancing code reuse, the use of open-source dependency packages hosted on centralized repositories such as PyPI can have adverse effects on build reproducibility. Frequent updates to these packages often cause their latest versions to have breaking changes for applications using them. Large Python applications risk their historical builds becoming unreproducible due to the widespread usage of Python dependencies, and the lack of uniform practices for dependency version specification. Manually fixing dependency errors requires expensive developer time and effort, while automated approaches face challenges of parsing unstructured build logs, finding transitive dependencies, and exploring an exponential search space of dependency versions. In this paper, we investigate how open-source Python projects specify dependency versions, and how their reproducibility is impacted by dependency packages. We propose a tool PyDFix to detect and fix unreproducibility in Python builds caused by dependency errors. PyDFix is evaluated on two bug datasets BugSwarm and BugsInPy, both of which are built from real-world open-source projects. PyDFix analyzes a total of 2,702 builds, identifying 1,921 (71.1%) of them to be unreproducible due to dependency errors. From these, PyDFix provides a complete fix for 859 (44.7%) builds, and partial fixes for an additional 632 (32.9%) builds.","publicationDate":"2021-07-10T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.14778/3415478.3415568","title":"research-article ","type":"Dremel: a decade of interactive SQL analysis at web scale","venue":"Proceedings of the VLDB Endowment","authors":["Sergey Melnik","Andrey Gubarev","Jing Jing Long","Geoffrey Romer","Shiva Shivakumar","Matt Tolton","Theo Vassilakis","Hossein Ahmadi","Dan Delorey","Slava Min","Mosha Pasumansky","Jeff Shute"],"abstract":"Google's Dremel was one of the first systems that combined a set of architectural principles that have become a common practice in today's cloud-native analytics tools, including disaggregated storage and compute, in situ analysis, and columnar storage for semistructured data. In this paper, we discuss how these ideas evolved in the past decade and became the foundation for Google BigQuery.","publicationDate":"2020-07-31T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1109/ASE.2019.00048","title":"research-article ","type":"Testing regex generalizability and its implications: a large-scale many-language measurement study","venue":"ASE '19: Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering","authors":["James C. Davis","Daniel Moyer","Ayaan M. Kazerouni","Dongyoon Lee"],"abstract":"The regular expression (regex) practices of software engineers affect the maintainability, correctness, and security of their software applications. Empirical research has described characteristics like the distribution of regex feature usage, the structural complexity of regexes, and worst-case regex match behaviors. But researchers have not critically examined the methodology they follow to extract regexes, and findings to date are typically generalized from regexes written in only 1-2 programming languages. This is an incomplete foundation.Generalizing existing research depends on validating two hypotheses: (1) Various regex extraction methodologies yield similar results, and (2) Regex characteristics are similar across programming languages. To test these hypotheses, we defined eight regex metrics to capture the dimensions of regex representation, string language diversity, and worst-case match complexity. We report that the two competing regex extraction methodologies yield comparable corpuses, suggesting that simpler regex extraction techniques will still yield sound corpuses. But in comparing regexes across programming languages, we found significant differences in some characteristics by programming language. Our findings have bearing on future empirical methodology, as the programming language should be considered, and generalizability will not be assured. Our measurements on a corpus of 537,806 regexes can guide data-driven designs of a new generation of regex tools and regex engines.\"There are more things in heaven and earth, Horatio, Than are dreamt of in your philosophy.\"-Hamlet","publicationDate":"2019-11-09T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3464298.3484504","title":"research-article ","type":"Magic-Pipe: self-optimizing video analytics pipelines","venue":"Middleware '21: Proceedings of the 22nd International Middleware Conference","authors":["Giuseppe Coviello","Yi Yang","Kunal Rao","Srimat Chakradhar"],"abstract":"Microservices-based video analytics pipelines routinely use multiple deep convolutional neural networks. We observe that the best allocation of resources to deep learning engines (or microservices) in a pipeline, and the best configuration of parameters for each engine vary over time, often at a timescale of minutes or even seconds based on the dynamic content in the video. We leverage these observations to develop Magic-Pipe, a self-optimizing video analytic pipeline that leverages AI techniques to periodically self-optimize. First, we propose a new, adaptive resource allocation technique to dynamically balance the resource usage of different microservices, based on dynamic video content. Then, we propose an adaptive microservice parameter tuning technique to balance the accuracy and performance of a microservice, also based on video content. Finally, we propose two different approaches to reduce unnecessary computations due to unavoidable mismatch of independently designed, re-usable deep-learning engines: a deep learning approach to improve the feature extractor performance by filtering inputs for which no features can be extracted, and a low-overhead graph-theoretic approach to minimize redundant computations across frames. Our evaluation of Magic-Pipe shows that pipelines augmented with self-optimizing capability exhibit application response times that are an order of magnitude better than the original pipelines, while using the same hardware resources, and achieving similar high accuracy.","publicationDate":"2021-11-21T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3448891.3448938","title":"research-article ","type":"Visually-defined Real-Time Orchestration of IoT Systems","venue":"MobiQuitous '20: MobiQuitous 2020 - 17th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services","authors":["Margarida Silva","João Dias","André Restivo","Hugo Ferreira"],"abstract":" In this work, we propose a method for extending Node-RED to allow the automatic decomposition and partitioning of the system towards higher decentralization. We provide a custom firmware for constrained devices to expose their resources, as well as new nodes and modifications in the Node-RED engine that allow automatic orchestration of tasks. The firmware is responsible for low-level management of health and capabilities, as well as executing MicroPython scripts on demand. Node-RED then takes advantage of this firmware by (1) providing a device registry allowing devices to announce themselves, (2) generating MicroPython code from dynamic analysis of flow and nodes, and (3) automatically (re-)assigning nodes to devices based on pre-specified properties and priorities. A mechanism to automatically detect abnormal run-time conditions and provide dynamic self-adaptation was also explored. Our solution was tested using synthetic home automation scenarios, where several experiments were conducted with both virtual and physical devices. We then exhaustively measured each scenario to allow further understanding of our proposal and how it impacts the system’s resiliency, efficiency, and elasticity.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3412841.3442036","title":"research-article ","type":"Preventing server-side request forgery attacks","venue":"SAC '21: Proceedings of the 36th Annual ACM Symposium on Applied Computing","authors":["Bahruz Jabiyev","Omid Mirzaei","Amin Kharraz","Engin Kirda"],"abstract":"In today's web, it is not uncommon for web applications to take a complete URL as input from users. Usually, once the web application receives a URL, the server opens a connection to it. However, if the URL points to an internal service and the server still makes the connection, the server becomes vulnerable to Server-Side Request Forgery (SSRF) attacks. These attacks can be highly destructive when they exploit internal services. They are equally destructive and need much less effort to succeed if the server is hosted in a cloud environment. Therefore, with the growing use of cloud computing, the threat of SSRF attacks is becoming more serious.In this paper, we present a novel defense approach to protect internal services from SSRF attacks. Our analysis of more than 60 SSRF vulnerability reports shows that developers' awareness about this vulnerability is generally limited. Therefore, coders usually have flaws in their defenses. Even when these defenses have no flaws, they are usually still affected by important security and functionality limitations. In this work, we develop a prototype based on the proposed approach by extending the functionality of a popular reverse proxy application and deploy a set of vulnerable web applications with that prototype. We demonstrate how SSRF attacks on these applications, with almost no loss of performance, are prevented.","publicationDate":"2021-03-21T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3332165.3347944","title":"research-article ","type":"Bespoke: Interactively Synthesizing Custom GUIs from Command-Line Applications By Demonstration","venue":"UIST '19: Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology","authors":["Priyan Vaithilingam","Philip J. Guo"],"abstract":"Programmers, researchers, system administrators, and data scientists often build complex workflows based on command-line applications. To give these power users the well-known benefits of GUIs, we created Bespoke, a system that synthesizes custom GUIs by observing user demonstrations of command-line apps. Bespoke unifies the two main forms of desktop human-computer interaction (command-line and GUI) via a hybrid approach that combines the flexibility and composability of the command line with the usability and discoverability of GUIs. To assess the versatility of Bespoke, we ran an open-ended study where participants used it to create their own GUIs in domains that personally motivated them. They made a diverse set of GUIs for use cases such as cloud computing management, machine learning prototyping, lecture video transcription, integrated circuit design, remote code deployment, and gaming server management. Participants reported that the benefit of these bespoke GUIs was that they exposed only the most relevant subset of options required for their specific needs. In contrast, vendor-made GUIs usually include far more panes, menus, and settings since they must accommodate a wider range of use cases.","publicationDate":"2019-10-16T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3419249.3420180","title":"research-article ","type":"Waste Wizard: Exploring Waste Sorting using AI in Public Spaces","venue":"NordiCHI '20: Proceedings of the 11th Nordic Conference on Human-Computer Interaction: Shaping Experiences, Shaping Society","authors":["Rune Møberg Jacobsen","Patrick Skov Johansen","Lukas Bjørn Leer Bysted","Mikael B. Skov"],"abstract":"Waste sorting is getting gradually important as we produce growing amounts of waste every year. However, waste sorting has proven to be challenging due to waste complexity and lack of motivation and knowledge among citizens. In particular, waste sorting in public spaces has been found to be difficult. We present a study on waste sorting in public spaces with an automatic waste sorting bin called Waste Wizard. Waste Wizard uses machine learning to classify and sort waste. We deployed it in three public contexts: a zoo, a retail store, and a music festival. Our findings show how practices, knowledge and attitudes influence the complicated process of public waste sorting. Users also displayed playfulness in their interaction and furthermore generated ideas and wishes for public waste sorting. We discuss our findings regarding current work within sustainable HCI and implications for public waste sorting. ","publicationDate":"2020-10-24T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3448300.3467827","title":"research-article ","type":"Non-IID data re-balancing at IoT edge with peer-to-peer federated learning for anomaly detection","venue":"WiSec '21: Proceedings of the 14th ACM Conference on Security and Privacy in Wireless and Mobile Networks","authors":["Han Wang","Luis Muñoz-González","David Eklund","Shahid Raza"],"abstract":"The increase of the computational power in edge devices has enabled the penetration of distributed machine learning technologies such as federated learning, which allows to build collaborative models performing the training locally in the edge devices, improving the efficiency and the privacy for training of machine learning models, as the data remains in the edge devices. However, in some IoT networks the connectivity between devices and system components can be limited, which prevents the use of federated learning, as it requires a central node to orchestrate the training of the model. To sidestep this, peer-to-peer learning appears as a promising solution, as it does not require such an orchestrator. On the other side, the security challenges in IoT deployments have fostered the use of machine learning for attack and anomaly detection. In these problems, under supervised learning approaches, the training datasets are typically imbalanced, i.e. the number of anomalies is very small compared to the number of benign data points, which requires the use of re-balancing techniques to improve the algorithms' performance. In this paper, we propose a novel peer-to-peer algorithm,P2PK-SMOTE, to train supervised anomaly detection machine learning models in non-IID scenarios, including mechanisms to locally re-balance the training datasets via synthetic generation of data points from the minority class. To improve the performance in non-IID scenarios, we also include a mechanism for sharing a small fraction of synthetic data from the minority class across devices, aiming to reduce the risk of data de-identification. Our experimental evaluation in real datasets for IoT anomaly detection across a different set of scenarios validates the benefits of our proposed approach.","publicationDate":"2021-06-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3437378.3444367","title":"research-article ","type":"Serverless Edge Computing: Vision and Challenges","venue":"ACSW '21: 2021 Australasian Computer Science Week Multiconference","authors":["Mohammad S. Aslanpour","Adel N. Toosi","Claudio Cicconetti","Bahman Javadi","Peter Sbarski","Davide Taibi","Marcos Assuncao","Sukhpal Singh Gill","Raj Gaire","Schahram Dustdar"],"abstract":" Born from a need for a pure “pay-per-use” model and highly scalable platform, the “Serverless” paradigm emerged and has the potential to become a dominant way of building cloud applications. Although it was originally designed for cloud environments, Serverless is finding its position in the Edge Computing landscape, aiming to bring computational resources closer to the data source. That is, Serverless is crossing cloud borders to assess its merits in Edge computing, whose principal partner will be the Internet of Things (IoT) applications. This move sounds promising as Serverless brings particular benefits such as eliminating always-on services causing high electricity usage, for instance. However, the community is still hesitant to uptake Serverless Edge Computing because of the cloud-driven design of current Serverless platforms, and distinctive characteristics of edge landscape and IoT applications. In this paper, we evaluate both sides to shed light on the Serverless new territory. Our in-depth analysis promotes a broad vision for bringing Serverless to the Edge Computing. It also issues major challenges for Serverless to be met before entering Edge computing.","publicationDate":"2021-01-31T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3401025.3404097","title":"research-article ","type":"On the tracking of sensitive data and confidential executions","venue":"DEBS '20: Proceedings of the 14th ACM International Conference on Distributed and Event-based Systems","authors":["José Roberto Nascimento","José B. S. Nunes","Eduardo Lucena Falcão","Lilia Sampaio","Andrey Brito"],"abstract":"The production of large amounts of sensitive data raises growing concerns on confidentiality guarantees. Considering this, it is natural that data owners have an interest in how their data are being used. In this work, we propose Data aNd Application Tracking (DNAT), a trustworthy platform for tracking the executions of applications over sensitive data in untrusted environments. For traceability purposes, we use blockchain and smart contracts, and to guarantee execution confidentiality and, especially, enforce that operations are appropriately logged in the blockchain, we use Intel SGX. Experiments show that tracking costs on Ethereum varies from 1 to 61 cents of a US dollar, depending on the operation and urgency for consolidation. The time cost of confidential execution is associated with the SGX overhead. It increases non-linearly initially but has a linear growth rate when data and application size gets much higher than the available enclave page cache (≈ 93 MB).","publicationDate":"2020-07-12T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1109/CCGRID.2018.00046","title":"research-article ","type":"Secure and dynamic core and cache partitioning for safe and efficient server consolidation","venue":"CCGrid '18: Proceedings of the 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing","authors":["Myeonggyun Han","Seongdae Yu","Woongki Baek"],"abstract":"With server consolidation, latency-critical and batch workloads are collocated on the same physical servers. The resource manager dynamically allocates the hardware resources to the workloads to maximize the overall throughput while providing the service-level objective (SLO) guarantees for the latency-critical workloads. As the hardware resources are dynamically allocated across the workloads on the same physical server, information leakage can be established, making them vulnerable to micro-architectural side-channel attacks. Despite extensive prior works, it remains unexplored to investigate the efficient design and implementation of the dynamic resource management system that maximizes resource efficiency without compromising the SLO and security guarantees.To bridge this gap, this work proposes SDCP, secure and dynamic core and cache partitioning for safe and efficient server consolidation. In line with the state-of-the-art dynamic server consolidation techniques, SDCP dynamically allocates the hardware resources (i.e., cores and caches) to maximize the resource utilization with the SLO guarantees. In contrast to the existing techniques, however, SDCP dynamically sanitizes the hardware resources to ensure that no micro-architectural side channel is established between different security domains. Our experimental results demonstrate that SDCP provides high resource sanitization quality, incurs small performance overheads, and achieves high resource efficiency with the SLO and security guarantees.","publicationDate":"2018-04-30T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3368089.3409722","title":"research-article ","type":"Understanding the impact of GitHub suggested changes on recommendations between developers","venue":"ESEC/FSE 2020: Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","authors":["Chris Brown","Chris Parnin"],"abstract":"Recommendations between colleagues are effective for encouraging developers to adopt better practices. Research shows these peer interactions are useful for improving developer behaviors, or the adoption of activities to help software engineers complete programming tasks. However, in-person recommendations between developers in the workplace are declining. One form of online recommendations between developers are pull requests, which allow users to propose code changes and provide feedback on contributions. GitHub, a popular code hosting platform, recently introduced the suggested changes feature, which allows users to recommend improvements for pull requests. To better understand this feature and its impact on recommendations between developers, we report an empirical study of this system, measuring usage, effectiveness, and perception. Our results show that suggested changes support code review activities and significantly impact the timing and communication between developers on pull requests. This work provides insight into the suggested changes feature and implications for improving future systems for automated developer recommendations, such as providing situated, concise, and actionable feedback.","publicationDate":"2020-11-07T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3274451","title":"research-article ","type":"The Power of Bots: Characterizing and Understanding Bots in OSS Projects","venue":"Proceedings of the ACM on Human-Computer Interaction","authors":["Mairieli Wessel","Bruno Mendes de Souza","Igor Steinmacher","Igor S. Wiese","Ivanilton Polato","Ana Paula Chaves","Marco A. Gerosa"],"abstract":"Leveraging the pull request model of social coding platforms, Open Source Software (OSS) integrators review developers' contributions, checking aspects like license, code quality, and testability. Some projects use bots to automate predefined, sometimes repetitive tasks, thereby assisting integrators' and contributors' work. Our research investigates the usage and impact of such bots. We sampled 351 popular projects from GitHub and found that 93 (26%) use bots. We classified the bots, collected metrics from before and after bot adoption, and surveyed 228 developers and integrators. Our results indicate that bots perform numerous tasks. Although integrators reported that bots are useful for maintenance tasks, we did not find a consistent, statistically significant difference between before and after bot adoption across the analyzed projects in terms of number of comments, commits, changed files, and time to close pull requests. Our survey respondents deem the current bots as not smart enough and provided insights into the bots' relevance for specific tasks, challenges, and potential new features. We discuss some of the raised suggestions and challenges in light of the literature in order to help GitHub bot designers reuse and test ideas and technologies already investigated in other contexts.","publicationDate":"2018-10-31T23:00:00.000Z","citationCount":28},{"url":"https://dl.acm.org/doi/10.1145/3183428.3183438","title":"research-article ","type":"The role of foundations in open source projects","venue":"ICSE-SEIS '18: Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Society","authors":["Javier Luis Cánovas Izquierdo","Jordi Cabot"],"abstract":"In the last years, a number of Open-Source Systems (OSS) have created parallel foundations, as legal instruments to better articulate the structure, collaboration and financial model for the project. Some examples are Apache, Linux, Mozilia, Eclipse or Django foundations. Nevertheless, foundations largely differ in the kind of mission they have and the support they provide to their project/s. In this paper we study the role of foundations in open source software development. We analyze the nature of 89 software foundations and then focus on the 18 most relevant ones to study their openness and influence in the development practices taking place in the endorsed projects. Our results reveal the existence of a significant number of foundations with the sole purpose of promoting the importance of the free software movement and/or that limit them selves to core legal aspects but do not play any role in the day-to-day operations of the project (e.g., a few of them are just umbrelia organizations for a large variety of projects). Therefore, while useful, foundations do not remove the need for specific projects to develop their own governance, contribution and development policies.","publicationDate":"2018-05-26T22:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1145/3427921.3450240","title":"research-article ","type":"Context-tailored Workload Model Generation for Continuous Representative Load Testing","venue":"ICPE '21: Proceedings of the ACM/SPEC International Conference on Performance Engineering","authors":["Henning Schulz","Dušan Okanović","André van Hoorn","Petr Tůma"],"abstract":"Load tests evaluate software quality attributes, such as performance and reliability, by e.g., emulating user behavior that is representative of the production workload. Existing approaches extract workload models from recorded user requests. However, a single workload model cannot reflect the complex and evolving workload of today's applications, or take into account workload-influencing contexts, such as special offers, incidents, or weather conditions. In this paper, we propose an integrated framework for generating load tests tailored to the context of interest, which a user can describe in a language we provide. The framework applies multivariate time series forecasting for extracting a context-tailored load test from an initial workload model, which is incrementally learned by clustering user sessions recorded in production and enriched with relevant context information.We evaluated our approach with the workload of a student information system. Our results show that incrementally learned workload models can be used for generating tailored load tests. The description language is able to express the relevant contexts, which, in turn, improve the representativeness of the load tests. We have also found that the existing workload characterization concepts and forecasting tools used are limited in regard to strong workload fluctuations, which needs to be tackled in future work.","publicationDate":"2021-04-08T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3355369.3355599","title":"research-article ","type":"VisibleV8: In-browser Monitoring of JavaScript in the Wild","venue":"IMC '19: Proceedings of the Internet Measurement Conference","authors":["Jordan Jueckstock","Alexandros Kapravelos"],"abstract":"Modern web security and privacy research depends on accurate measurement of an often evasive and hostile web. No longer just a network of static, hyperlinked documents, the modern web is alive with JavaScript (JS) loaded from third parties of unknown trustworthiness. Dynamic analysis of potentially hostile JS currently presents a cruel dilemma: use heavyweight in-browser solutions that prove impossible to maintain, or use lightweight inline JS solutions that are detectable by evasive JS and which cannot match the scope of coverage provided by in-browser systems. We present VisibleV8, a dynamic analysis framework hosted inside V8, the JS engine of the Chrome browser, that logs native function or property accesses during any JS execution. At less than 600 lines (only 67 of which modify V8's existing behavior), our patches are lightweight and have been maintained from Chrome versions 63 through 72 without difficulty. VV8 consistently outperforms equivalent inline instrumentation, and it intercepts accesses impossible to instrument inline. This comprehensive coverage allows us to isolate and identify 46 JavaScript namespace artifacts used by JS code in the wild to detect automated browsing platforms and to discover that 29% of the Alexa top 50k sites load content which actively probes these artifacts.","publicationDate":"2019-10-20T22:00:00.000Z","citationCount":7},{"url":"https://dl.acm.org/doi/10.1145/3427921.3450240","title":"research-article ","type":"Context-tailored Workload Model Generation for Continuous Representative Load Testing","venue":"ICPE '21: Proceedings of the ACM/SPEC International Conference on Performance Engineering","authors":["Henning Schulz","Dušan Okanović","André van Hoorn","Petr Tůma"],"abstract":"Load tests evaluate software quality attributes, such as performance and reliability, by e.g., emulating user behavior that is representative of the production workload. Existing approaches extract workload models from recorded user requests. However, a single workload model cannot reflect the complex and evolving workload of today's applications, or take into account workload-influencing contexts, such as special offers, incidents, or weather conditions. In this paper, we propose an integrated framework for generating load tests tailored to the context of interest, which a user can describe in a language we provide. The framework applies multivariate time series forecasting for extracting a context-tailored load test from an initial workload model, which is incrementally learned by clustering user sessions recorded in production and enriched with relevant context information.We evaluated our approach with the workload of a student information system. Our results show that incrementally learned workload models can be used for generating tailored load tests. The description language is able to express the relevant contexts, which, in turn, improve the representativeness of the load tests. We have also found that the existing workload characterization concepts and forecasting tools used are limited in regard to strong workload fluctuations, which needs to be tackled in future work.","publicationDate":"2021-04-08T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3355369.3355599","title":"research-article ","type":"VisibleV8: In-browser Monitoring of JavaScript in the Wild","venue":"IMC '19: Proceedings of the Internet Measurement Conference","authors":["Jordan Jueckstock","Alexandros Kapravelos"],"abstract":"Modern web security and privacy research depends on accurate measurement of an often evasive and hostile web. No longer just a network of static, hyperlinked documents, the modern web is alive with JavaScript (JS) loaded from third parties of unknown trustworthiness. Dynamic analysis of potentially hostile JS currently presents a cruel dilemma: use heavyweight in-browser solutions that prove impossible to maintain, or use lightweight inline JS solutions that are detectable by evasive JS and which cannot match the scope of coverage provided by in-browser systems. We present VisibleV8, a dynamic analysis framework hosted inside V8, the JS engine of the Chrome browser, that logs native function or property accesses during any JS execution. At less than 600 lines (only 67 of which modify V8's existing behavior), our patches are lightweight and have been maintained from Chrome versions 63 through 72 without difficulty. VV8 consistently outperforms equivalent inline instrumentation, and it intercepts accesses impossible to instrument inline. This comprehensive coverage allows us to isolate and identify 46 JavaScript namespace artifacts used by JS code in the wild to detect automated browsing platforms and to discover that 29% of the Alexa top 50k sites load content which actively probes these artifacts.","publicationDate":"2019-10-20T22:00:00.000Z","citationCount":7},{"url":"https://dl.acm.org/doi/10.1145/3445814.3446701","title":"Article ","type":"Nightcore: efficient and scalable serverless computing for latency-sensitive, interactive microservices","venue":"ASPLOS 2021: Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems\n\t\t\t\t\n                    Nightcore: Efficient and Scalable Serverless Computing for Latency-Sensitive, Interactive Microservices (Artifacts)\n                \n            ","authors":["Zhipeng Jia","Emmett Witchel"],"abstract":"The microservice architecture is a popular software engineering approach for building flexible, large-scale online services. Serverless functions, or function as a service (FaaS), provide a simple programming model of stateless functions which are a natural substrate for implementing the stateless RPC handlers of microservices, as an alternative to containerized RPC servers. However, current serverless platforms have millisecond-scale runtime overheads, making them unable to meet the strict sub-millisecond latency targets required by existing interactive microservices. We present Nightcore, a serverless function runtime with microsecond-scale overheads that provides container-based isolation between functions. Nightcore’s design carefully considers various factors having microsecond-scale overheads, including scheduling of function requests, communication primitives, threading models for I/O, and concurrent function executions. Nightcore currently supports serverless functions written in C/C++, Go, Node.js, and Python. Our evaluation shows that when running latency-sensitive interactive microservices, Nightcore achieves 1.36×–2.93× higher throughput and up to 69% reduction in tail latency.","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3419111.3421306","title":"research-article ","type":"Sequoia: enabling quality-of-service in serverless computing","venue":"SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing","authors":["Ali Tariq","Austin Pahl","Sharat Nimmagadda","Eric Rozner","Siddharth Lanka"],"abstract":"Serverless computing is a rapidly growing paradigm that easily harnesses the power of the cloud. With serverless computing, developers simply provide an event-driven function to cloud providers, and the provider seamlessly scales function invocations to meet demands as event-triggers occur. As current and future serverless offerings support a wide variety of serverless applications, effective techniques to manage serverless workloads becomes an important issue. This work examines current management and scheduling practices in cloud providers, uncovering many issues including inflated application run times, function drops, inefficient allocations, and other undocumented and unexpected behavior. To fix these issues, a new quality-of-service function scheduling and allocation framework, called Sequoia, is designed. Sequoia allows developers or administrators to easily def ne how serverless functions and applications should be deployed, capped, prioritized, or altered based on easily configured, flexible policies. Results with controlled and realistic workloads show Sequoia seamlessly adapts to policies, eliminates mid-chain drops, reduces queuing times by up to 6.4X, enforces tight chain-level fairness, and improves run-time performance up to 25X.","publicationDate":"2020-10-11T22:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.14778/3352063.3352138","title":"research-article ","type":"Smile: a system to support machine learning on EEG data at scale","venue":"Proceedings of the VLDB Endowment","authors":["Lei Cao","Wenbo Tao","Sungtae An","Jing Jin","Yizhou Yan","Xiaoyu Liu","Wendong Ge","Adam Sah","Leilani Battle","Jimeng Sun","Remco Chang","Brandon Westover","Samuel Madden","Michael Stonebraker"],"abstract":"In order to reduce the possibility of neural injury from seizures and sidestep the need for a neurologist to spend hours on manually reviewing the EEG recording, it is critical to automatically detect and classify \"interictal-ictal continuum\" (IIC) patterns from EEG data. However, the existing IIC classification techniques are shown to be not accurate and robust enough for clinical use because of the lack of high quality labels of EEG segments as training data. Obtaining high-quality labeled data is traditionally a manual process by trained clinicians that can be tedious, time-consuming, and error-prone. In this work, we propose Smile, an industrial scale system that provides an end-to-end solution to the IIC pattern classification problem. The core components of Smile include a visualization-based time series labeling module and a deep-learning based active learning module. The labeling module enables the users to explore and label 350 million EEG segments (30TB) at interactive speed. The multiple coordinated views allow the users to examine the EEG signals from both time domain and frequency domain simultaneously. The active learning module first trains a deep neural network that automatically extracts both the local features with respect to each segment itself and the long term dynamics of the EEG signals to classify IIC patterns. Then leveraging the output of the deep learning model, the EEG segments that can best improve the model are selected and prompted to clinicians to label. This process is iterated until the clinicians and the models show high degree of agreement. Our initial experimental results show that our Smile system allows the clinicians to label the EEG segments at will with a response time below 500 ms. The accuracy of the model is progressively improved as more and more high quality labels are acquired over time.","publicationDate":"2019-07-31T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3292500.3330648","title":"research-article ","type":"Auto-Keras: An Efficient Neural Architecture Search System","venue":"KDD '19: Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","authors":["Haifeng Jin","Qingquan Song","Xia Hu"],"abstract":"Neural architecture search (NAS) has been proposed to automatically tune deep neural networks, but existing search algorithms, e.g., NASNet, PNAS, usually suffer from expensive computational cost. Network morphism, which keeps the functionality of a neural network while changing its neural architecture, could be helpful for NAS by enabling more efficient training during the search. In this paper, we propose a novel framework enabling Bayesian optimization to guide the network morphism for efficient neural architecture search. The framework develops a neural network kernel and a tree-structured acquisition function optimization algorithm to efficiently explores the search space. Extensive experiments on real-world benchmark datasets have been done to demonstrate the superior performance of the developed framework over the state-of-the-art methods. Moreover, we build an open-source AutoML system based on our method, namely Auto-Keras. The code and documentation are available at https://autokeras.com. The system runs in parallel on CPU and GPU, with an adaptive search strategy for different GPU memory limits.","publicationDate":"2019-07-24T22:00:00.000Z","citationCount":128},{"url":"https://dl.acm.org/doi/10.1145/3307681.3325400","title":"research-article ","type":"Parsl: Pervasive Parallel Programming in Python","venue":"HPDC '19: Proceedings of the 28th International Symposium on High-Performance Parallel and Distributed Computing","authors":["Yadu Babuji","Anna Woodard","Zhuozhao Li","Daniel S. Katz","Ben Clifford","Rohan Kumar","Lukasz Lacinski","Ryan Chard","Justin M. Wozniak","Ian Foster","Michael Wilde","Kyle Chard"],"abstract":"High-level programming languages such as Python are increasingly used to provide intuitive interfaces to libraries written in lower-level languages and for assembling applications from various components. This migration towards orchestration rather than implementation, coupled with the growing need for parallel computing (e.g., due to big data and the end of Moore's law), necessitates rethinking how parallelism is expressed in programs. Here, we present Parsl, a parallel scripting library that augments Python with simple, scalable, and flexible constructs for encoding parallelism. These constructs allow Parsl to construct a dynamic dependency graph of components that it can then execute efficiently on one or many processors. Parsl is designed for scalability, with an extensible set of executors tailored to different use cases, such as low-latency, high-throughput, or extreme-scale execution. We show, via experiments on the Blue Waters supercomputer, that Parsl executors can allow Python scripts to execute components with as little as 5 ms of overhead, scale to more than 250000 workers across more than 8000 nodes, and process upward of 1200 tasks per second. Other Parsl features simplify the construction and execution of composite programs by supporting elastic provisioning and scaling of infrastructure, fault-tolerant execution, and integrated wide-area data management. We show that these capabilities satisfy the needs of many-task, interactive, online, and machine learning applications in fields such as biology, cosmology, and materials science.","publicationDate":"2019-06-16T22:00:00.000Z","citationCount":42},{"url":"https://dl.acm.org/doi/10.1145/3133850.3133855","title":"research-article ","type":"The serverless trilemma: function composition for serverless computing","venue":"Onward! 2017: Proceedings of the 2017 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software","authors":["Ioana Baldini","Perry Cheng","Stephen J. Fink","Nick Mitchell","Vinod Muthusamy","Rodric Rabbah","Philippe Suter","Olivier Tardieu"],"abstract":"The field of serverless computing has recently emerged in support of highly scalable, event-driven applications. A serverless application is a set of stateless functions, along with the events that should trigger their activation. A serverless runtime allocates resources as events arrive, avoiding the need for costly pre-allocated or dedicated hardware. While an attractive economic proposition, serverless computing currently lags behind the state of the art when it comes to function composition. This paper addresses the challenge of programming a composition of functions, where the composition is itself a serverless function. We demonstrate that engineering function composition into a serverless application is possible, but requires a careful evaluation of trade-offs. To help in evaluating these trade-offs, we identify three competing constraints: functions should be considered as black boxes; function composition should obey a substitution principle with respect to synchronous invocation; and invocations should not be double-billed. Furthermore, we argue that, if the serverless runtime is limited to a reactive core, i.e. one that deals only with dispatching functions in response to events, then these constraints form the serverless trilemma. Without specific runtime support, compositions-as-functions must violate at least one of the three constraints. Finally, we demonstrate an extension to the reactive core of an open-source serverless runtime that enables the sequential composition of functions in a trilemma-satisfying way. We conjecture that this technique could be generalized to support other combinations of functions.","publicationDate":"2017-10-24T22:00:00.000Z","citationCount":36},{"url":"https://dl.acm.org/doi/10.1145/3302424.3303978","title":"research-article ","type":"Replayable Execution Optimized for Page Sharing for a Managed Runtime Environment","venue":"EuroSys '19: Proceedings of the Fourteenth EuroSys Conference 2019","authors":["Kai-Ting Amy Wang","Rayson Ho","Peng Wu"],"abstract":"We present Replayable Execution, a system for improving the efficiency of Function-as-a-Service (FaaS) frameworks. It takes advantage of standard kernel features to reduce memory usage and accelerate cold startup speed without changes to the OS kernel, language runtimes, and the surrounding FaaS deployment environment. Replayable Execution exploits the intensive-deflated execution characteristics of the majority of target applications. It uses checkpointing to save an image of an application, allowing this image to be shared across containers and resulting in speedy restoration at service startup. We apply Replayable Execution to a representative FaaS Java framework to create a ReplayableJVM execution, which together with benefits from deterministic execution of a warmed up runtime, offers 2X memory footprint reduction, and over 10X startup time improvement.","publicationDate":"2019-03-24T23:00:00.000Z","citationCount":10},{"url":"https://dl.acm.org/doi/10.5555/3291291.3291295","title":"research-article ","type":"A case study of spark resource configuration and management for image processing applications","venue":"CASCON '18: Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering","authors":["Owolabi Adekoya","Habib Sabiu","Derek Eager","Winfried Grassmann","Dwight Makaroff"],"abstract":"The world population is expected to reach an estimated 9.8 billion by 2050, necessitating substantial increases in food production. Achieving such increases will require large-scale application of computer informatics within the agricultural sector. In particular, application of informatics to crop breeding has the potential to greatly enhance our ability to develop new varieties quickly and economically. Achieving this potential, however, will require capabilities for analyzing huge volumes of data acquired from various field-deployed image acquisition technologies. Although numerous frameworks for big data processing have been developed, there are relatively few published case studies that describe user experiences with these frameworks in particular application science domains.In this paper, we describe our efforts to apply Apache Spark to three applications of initial interest within the Plant Phenotyping and Imaging Research Centre (P2IRC) at the University of Saskatchewan. We find that default Spark parameter settings do not work well for these applications. We carry out extensive performance experiments to investigate the impact of alternative Spark parameter settings, both for applications run individually and in scenarios with multiple concurrently executing applications. We find that optimizing Spark parameter settings is challenging, but can yield substantial performance improvements, particularly with concurrent applications, provided that the dataset characteristics are considered. This is a first step towards insights regarding Spark parameter tuning on these classes of applications that may be more generally applicable to broader ranges of applications.","publicationDate":"2018-10-28T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3357223.3362719","title":"research-article ","type":"HyperSched: Dynamic Resource Reallocation for Model Development on a Deadline","venue":"SoCC '19: Proceedings of the ACM Symposium on Cloud Computing","authors":["Richard Liaw","Romil Bhardwaj","Lisa Dunlap","Yitian Zou","Joseph E. Gonzalez","Ion Stoica","Alexey Tumanov"],"abstract":"Prior research in resource scheduling for machine learning training workloads has largely focused on minimizing job completion times. Commonly, these model training workloads collectively search over a large number of parameter values that control the learning process in a hyperparameter search. It is preferable to identify and maximally provision the best-performing hyperparameter configuration (trial) to achieve the highest accuracy result as soon as possible.To optimally trade-off evaluating multiple configurations and training the most promising ones by a fixed deadline, we design and build HyperSched---a dynamic application-level resource scheduler to track, identify, and preferentially allocate resources to the best performing trials to maximize accuracy by the deadline. HyperSched leverages three properties of a hyperparameter search workload overlooked in prior work -- trial disposability, progressively identifiable rankings among different configurations, and space-time constraints -- to outperform standard hyperparameter search algorithms across a variety of benchmarks.","publicationDate":"2019-11-19T23:00:00.000Z","citationCount":8},{"url":"https://dl.acm.org/doi/10.14778/3352063.3352145","title":"research-article ","type":"Integration of large-scale data processing systems and traditional parallel database technology","venue":"Proceedings of the VLDB Endowment","authors":["Azza Abouzied","Daniel J. Abadi","Kamil Bajda-Pawlikowski","Avi Silberschatz"],"abstract":"In 2009 we explored the feasibility of building a hybrid SQL data analysis system that takes the best features from two competing technologies: large-scale data processing systems (such as Google MapReduce and Apache Hadoop) and parallel database management systems (such as Greenplum and Vertica). We built a prototype, HadoopDB, and demonstrated that it can deliver the high SQL query performance and efficiency of parallel database management systems while still providing the scalability, fault tolerance, and flexibility of large-scale data processing systems. Subsequently, HadoopDB grew into a commercial product, Hadapt, whose technology was eventually acquired by Teradata. In this paper, we provide an overview of HadoopDB's original design, and its evolution during the subsequent ten years of research and development effort. We describe how the project innovated both in the research lab, and as a commercial product at Hadapt and Teradata. We then discuss the current vibrant ecosystem of software projects (most of which are open source) that continued HadoopDB's legacy of implementing a systems level integration of large-scale data processing systems and parallel database technology.","publicationDate":"2019-07-31T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3183713.3190661","title":"research-article ","type":"Pinot: Realtime OLAP for 530 Million Users","venue":"SIGMOD '18: Proceedings of the 2018 International Conference on Management of Data","authors":["Jean-François Im","Kishore Gopalakrishna","Subbu Subramaniam","Mayank Shrivastava","Adwait Tumbde","Xiaotian Jiang","Jennifer Dai","Seunghyun Lee","Neha Pawar","Jialiang Li","Ravi Aringunram"],"abstract":"Modern users demand analytical features on fresh, real time data. Offering these analytical features to hundreds of millions of users is a relevant problem encountered by many large scale web companies.Relational databases and key-value stores can be scaled to provide point lookups for a large number of users but fall apart at the combination of high ingest rates, high query rates at low latency for analytical queries. Online analytical databases typically rely on bulk data loads and are not typically built to handle nonstop operation in demanding web environments. Offline analytical systems have high throughput but do not offer low query latencies nor can scale to serving tens of thousands of queries per second.We present Pinot, a single system used in production at Linkedin that can serve tens of thousands of analytical queries per second, offers near-realtime data ingestion from streaming data sources, and handles the operational requirements of large web properties. We also provide a performance comparison with Druid, a system similar to Pinot.","publicationDate":"2018-05-26T22:00:00.000Z","citationCount":12},{"url":"https://dl.acm.org/doi/10.1145/3423211.3425690","title":"research-article ","type":"Xanadu: Mitigating cascading cold starts in serverless function chain deployments","venue":"Middleware '20: Proceedings of the 21st International Middleware Conference","authors":["Nilanjan Daw","Umesh Bellur","Purushottam Kulkarni"],"abstract":"Organization of tasks as workflows are an essential feature to expand the applicability of the serverless computing framework. Existing serverless platforms are either agnostic to function chains (workflows as a composition of functions) or rely on naive provisioning and management mechanisms of the serverless framework---an example is that they provision resources after the trigger to each function in a workflow arrives thereby forcing a setup latency for each function in the workflow. In this work, we focus on mitigating the cascading cold start problem--- the latency overheads in triggering a sequence of serverless functions according to a workflow specification. We first establish the nature and extent of the cascading effects in cold start situations across multiple commercial server platforms and cloud providers. Towards mitigating these cascading overheads, we design and develop several optimizations, that are built into our tool Xanadu. Xanadu offers multiple instantiation options based on the desired runtime isolation requirements and supports function chaining with or without explicit workflow specifications. Xanadu's optimizations to address the cascading cold start problem are built on speculative and just-in-time provisioning of resources. Our evaluation of the Xanadu system reveals almost complete elimination of cascading cold starts at minimal cost overheads, outperforming the available state of the art platforms. For even relatively short workflows, Xanadu reduces platform overheads by almost 18x compared to Knative and 10x compared to Apache Openwhisk.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3366423.3380111","title":"research-article ","type":"AutoMAP: Diagnose Your Microservice-based Web Applications Automatically","venue":"WWW '20: Proceedings of The Web Conference 2020","authors":["Meng Ma","Jingmin Xu","Yuan Wang","Pengfei Chen","Zonghua Zhang","Ping Wang"],"abstract":"The high complexity and dynamics of the microservice architecture make its application diagnosis extremely challenging. Static troubleshooting approaches may fail to obtain reliable model applies for frequently changing situations. Even if we know the calling dependency of services, we lack a more dynamic diagnosis mechanism due to the existence of indirect fault propagation. Besides, algorithm based on single metric usually fail to identify the root cause of anomaly, as single type of metric is not enough to characterize the anomalies occur in diverse services. In view of this, we design a novel tool, named AutoMAP, which enables dynamic generation of service correlations and automated diagnosis leveraging multiple types of metrics. In AutoMAP, we propose the concept of anomaly behavior graph to describe the correlations between services associated with different types of metrics. Two binary operations, as well as a similarity function on behavior graph are defined to help AutoMAP choose appropriate diagnosis metric in any particular scenario. Following the behavior graph, we design a heuristic investigation algorithm by using forward, self, and backward random walk, with an objective to identify the root cause services. To demonstrate the strengths of AutoMAP, we develop a prototype and evaluate it in both simulated environment and real-work enterprise cloud system. Experimental results clearly indicate that AutoMAP achieves over 90% precision, which significantly outperforms other selected baseline methods. AutoMAP can be quickly deployed in a variety of microservice-based systems without any system knowledge. It also supports introduction of various expert knowledge to improve accuracy.","publicationDate":"2020-04-19T22:00:00.000Z","citationCount":8},{"url":"https://dl.acm.org/doi/10.1145/3314148.3314349","title":"research-article ","type":"eZTrust: Network-Independent Zero-Trust Perimeterization for Microservices","venue":"SOSR '19: Proceedings of the 2019 ACM Symposium on SDN Research","authors":["Zirak Zaheer","Hyunseok Chang","Sarit Mukherjee","Jacobus Van der Merwe"],"abstract":"Emerging microservices-based workloads introduce new security risks in today's data centers as attacks can propagate laterally within the data center relatively easily by exploiting cross-service dependencies. As countermeasures for such attacks, traditional perimeterization approaches, such as network-endpoint-based access control, do not fare well in highly dynamic microservices environments (especially considering the management complexity, scalability and policy granularity of these earlier approaches). In this paper, we propose eZTrust, a network-independent perimeterization approach for microservices. eZTrust allows data center tenants to express access control policies based on fine-grained workload identities, and enables data center operators to enforce such policies reliably and efficiently in a purely network-independent fashion. To this end, we leverage eBPF, the extended Berkeley Packet Filter, to trace authentic workload identities and apply per-packet tagging and verification. We demonstrate the feasibility of our approach through extensive evaluation of our proof-of-concept prototype implementation. We find that, when comparable policies are enforced, eZTrust incurs 2--5 times lower packet latency and 1.5--2.5 times lower CPU overhead than traditional perimeterization schemes.","publicationDate":"2019-04-02T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.5555/3291656.3291706","title":"research-article ","type":"A reference architecture for datacenter scheduling: design, validation, and experiments","venue":"SC '18: Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis","authors":["Georgios Andreadis","Laurens Versluis","Fabian Mastenbroek","Alexandru Iosup"],"abstract":"Datacenters act as cloud-infrastructure to stakeholders across industry, government, and academia. To meet growing demand yet operate efficiently, datacenter operators employ increasingly more sophisticated scheduling systems, mechanisms, and policies. Although many scheduling techniques already exist, relatively little research has gone into the abstraction of the scheduling process itself, hampering design, tuning, and comparison of existing techniques. In this work, we propose a reference architecture for datacenter schedulers. The architecture follows five design principles: components with clearly distinct responsibilities, grouping of related components where possible, separation of mechanism from policy, scheduling as complex workflow, and hierarchical multi-scheduler structure. To demonstrate the validity of the reference architecture, we map to it state-of-the-art datacenter schedulers. We find scheduler-stages are commonly underspecified in peer-reviewed publications. Through trace-based simulation and real-world experiments, we show underspecification of scheduler-stages can lead to significant variations in performance.","publicationDate":"2018-11-10T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3267809.3267836","title":"research-article ","type":"Wharf: Sharing Docker Images in a Distributed File System","venue":"SoCC '18: Proceedings of the ACM Symposium on Cloud Computing","authors":["Chao Zheng","Lukas Rupprecht","Vasily Tarasov","Douglas Thain","Mohamed Mohamed","Dimitrios Skourtis","Amit S. Warke","Dean Hildebrand"],"abstract":"Container management frameworks, such as Docker, package diverse applications and their complex dependencies in self-contained images, which facilitates application deployment, distribution, and sharing. Currently, Docker employs a shared-nothing storage architecture, i.e. every Docker-enabled host requires its own copy of an image on local storage to create and run containers. This greatly inflates storage utilization, network load, and job completion times in the cluster. In this paper, we investigate the option of storing container images in and serving them from a distributed file system. By sharing images in a distributed storage layer, storage utilization can be reduced and redundant image retrievals from a Docker registry become unnecessary. We introduce Wharf, a middleware to transparently add distributed storage support to Docker. Wharf partitions Docker's runtime state into local and global parts and efficiently synchronizes accesses to the global state. By exploiting the layered structure of Docker images, Wharf minimizes the synchronization overhead. Our experiments show that compared to Docker on local storage, Wharf can speed up image retrievals by up to 12x, has more stable performance, and introduces only a minor overhead when accessing data on distributed storage.","publicationDate":"2018-10-10T22:00:00.000Z","citationCount":10},{"url":"https://dl.acm.org/doi/10.1145/3465480.3466920","title":"research-article ","type":"Distributed transactions on serverless stateful functions","venue":"DEBS '21: Proceedings of the 15th ACM International Conference on Distributed and Event-based Systems","authors":["Martijn de Heus","Kyriakos Psarakis","Marios Fragkoulis","Asterios Katsifodimos"],"abstract":"Serverless computing is currently the fastest-growing cloud services segment. The most prominent serverless offering is Function-as-a-Service (FaaS), where users write functions and the cloud automates deployment, maintenance, and scalability. Although FaaS is a good fit for executing stateless functions, it does not adequately support stateful constructs like microservices and scalable, low-latency cloud applications, mainly because it lacks proper state management support and the ability to perform function-to-function calls. Most importantly, executing transactions across stateful functions remains an open problem.In this paper, we introduce a programming model and implementation for transaction orchestration of stateful serverless functions. Our programming model supports serializable distributed transactions with two-phase commit, as well as relaxed transactional guarantees with Sagas. We design and implement our programming model on Apache Flink StateFun. We choose to build our solution on top of StateFun in order to leverage Flink's exactly-once processing and state management guarantees. We base our evaluation on the YCSB benchmark, which we extended with transactional operations and adapted for the SFaaS programming model. Our experiments show that our transactional orchestration adds 10% overhead to the original system and that Sagas can achieve up to 34% more transactions per second than two-phase commit transactions at a sub-200ms latency.","publicationDate":"2021-06-27T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3344341.3368803","title":"research-article ","type":"A Systematic Mapping Study on Engineering Function-as-a-Service Platforms and Tools","venue":"UCC'19: Proceedings of the 12th IEEE/ACM International Conference on Utility and Cloud Computing","authors":["Vladimir Yussupov","Uwe Breitenbücher","Frank Leymann","Michael Wurster"],"abstract":"Function-as-a-Service (FaaS) is a novel cloud service model allowing to develop fine-grained, provider-managed cloud applications. In this work, we investigate which challenges motivate researchers to introduce or enhance FaaS platforms and tools. We use a systematic mapping study method to collect and analyze the relevant scientific literature, which helps us answering the three clearly-defined research questions. We design our study using well-established guidelines and systematically apply it to 62 selected publications. The collected and synthesized data provides useful insights into the main challenges that motivate researchers to work on this topic and can be helpful in identifying research gaps for future research.","publicationDate":"2019-12-01T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3037697.3037738","title":"research-article ","type":"Breaking the Boundaries in Heterogeneous-ISA Datacenters","venue":"ASPLOS '17: Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems","authors":["Antonio Barbalace","Robert Lyerly","Christopher Jelesnianski","Anthony Carno","Ho-Ren Chuang","Vincent Legout","Binoy Ravindran"],"abstract":"Energy efficiency is one of the most important design considerations in running modern datacenters. Datacenter operating systems rely on software techniques such as execution migration to achieve energy efficiency across pools of machines. Execution migration is possible in datacenters today because they consist mainly of homogeneous-ISA machines. However, recent market trends indicate that alternate ISAs such as ARM and PowerPC are pushing into the datacenter, meaning current execution migration techniques are no longer applicable. How can execution migration be applied in future heterogeneous-ISA datacenters?In this work we present a compiler, runtime, and an operating system extension for enabling execution migration between heterogeneous-ISA servers. We present a new multi-ISA binary architecture and heterogeneous-OS containers for facilitating efficient migration of natively-compiled applications. We build and evaluate a prototype of our design and demonstrate energy savings of up to 66% for a workload running on an ARM and an x86 server interconnected by a high-speed network.","publicationDate":"2017-04-03T22:00:00.000Z","citationCount":24},{"url":"https://dl.acm.org/doi/10.1145/3448016.3457241","title":"research-article ","type":"VF2Boost: Very Fast Vertical Federated Gradient Boosting for Cross-Enterprise Learning","venue":"SIGMOD/PODS '21: Proceedings of the 2021 International Conference on Management of Data","authors":["Fangcheng Fu","Yingxia Shao","Lele Yu","Jiawei Jiang","Huanran Xue","Yangyu Tao","Bin Cui"],"abstract":"With the ever-evolving concerns on privacy protection, vertical federated learning (FL), where participants own non-overlapping features for the same set of instances, is becoming a heated topic since it enables multiple enterprises to strengthen the machine learning models collaboratively with privacy guarantees. Nevertheless, to achieve privacy preservation, vertical FL algorithms involve complicated training routines and time-consuming cryptography operations, leading to slow training speed.This paper explores the efficiency of the gradient boosting decision tree (GBDT) algorithm under the vertical FL setting. Specifically, we introduce VF^2Boost, a novel and efficient vertical federated GBDT system. Significant solutions are developed to tackle the major bottlenecks. First, to handle the deficiency caused by frequent mutual-waiting in federated training, we propose a concurrent training protocol to reduce the idle periods. Second, to speed up the cryptography operations, we analyze the characteristics of the algorithm and propose customized operations. Empirical results show that our system can be 12.8-18.9 times faster than the existing vertical federated implementations and support much larger datasets.","publicationDate":"2021-06-08T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3442381.3449966","title":"research-article ","type":"Superways: A Datacenter Topology for Incast-heavy workloads","venue":"WWW '21: Proceedings of the Web Conference 2021","authors":["Hamed Rezaei","Balajee Vamanan"],"abstract":" Several important datacenter applications cause incast congestion, which severely degrades flow completion times of short flows and throughput of long flows. Further, because most flows are short and the incast duration is shorter than typical round-trip times, reactive mechanisms that rely on congestion control are not effective. While modern datacenter topologies provide high bisection bandwidth to support all-to-all traffic, incast is fundamentally a many-to-one traffic pattern, and therefore, requires deep buffers or high bandwidth at the network edge. We propose Superways, a heterogeneous datacenter topology that provides higher bandwidth for some servers to absorb incasts, as incasts occur only at a small number of servers that aggregate responses from other senders. Our design is based on the key observation that a small subset of servers which aggregate responses are likely to be network bound, whereas most other servers that communicate only with random servers are not. Superways can be implemented over many of the existing datacenter topologies and can be expanded flexibly without incurring high cost and cabling complexity. We also provide a heuristic for scheduling jobs in our topology to fully utilize the extra capacity. Using a real CloudLab implementation and using ns-3 simulations, we show that Superways significantly improves flow completion times and throughput over existing datacenter topologies. We also analyze cost and cabling complexity, and discuss how to expand our topology. ","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3423211.3425680","title":"research-article ","type":"Sledge: a Serverless-first, Light-weight Wasm Runtime for the Edge","venue":"Middleware '20: Proceedings of the 21st International Middleware Conference","authors":["Phani Kishore Gadepalli","Sean McBride","Gregor Peach","Ludmila Cherkasova","Gabriel Parmer"],"abstract":"Emerging IoT applications with real-time latency constraints require new data processing systems operating at the Edge. Serverless computing offers a new compelling paradigm, where a user can execute a small application without handling the operational issues of server provisioning and resource management. Despite a variety of existing commercial and open source serverless platforms (utilizing VMs and containers), these solutions are too heavy-weight for a resource-constrained Edge systems (due to large memory footprint and high invocation time). Moreover, serverless workloads that focus on per-client, short-running computations are not an ideal fit for existing general purpose computing systems.In this paper, we present the design and implementation of Sledge -- a novel and efficient WebAssembly-based serverless framework for the Edge. Sledge is optimized for supporting unique properties of serverless workloads: the need for high density multi-tenancy, low startup time, bursty client request rates, and short-lived computations. Sledge is designed for these constraints by offering (i) optimized scheduling policies and efficient work-distribution for short-lived computations, and (ii) a light-weight function isolation model implemented using our own WebAssembly-based software fault isolation infrastructure. These lightweight sandboxes are designed to support high-density computation: with fast startup and teardown times to handle high client request rates. An extensive evaluation of Sledge with varying workloads and real-world serverless applications demonstrates the effectiveness of the designed serverless-first runtime for the Edge. Sledge supports up to 4 times higher throughput and 4 times lower latencies compared to Nuclio, one of the fastest open-source serverless frameworks.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3184407.3184414","title":"research-article ","type":"Virtualization Techniques Compared: Performance, Resource, and Power Usage Overheads in Clouds","venue":"ICPE '18: Proceedings of the 2018 ACM/SPEC International Conference on Performance Engineering","authors":["Selome Kostentinos Tesfatsion","Cristian Klein","Johan Tordsson"],"abstract":"Virtualization solutions based on hypervisors or containers are enabling technologies for scalable, flexible, and cost-effective resource sharing. As the fundamental limitations of each technology are yet to be understood, they need to be regularly reevaluated to better understand the trade-off provided by latest technological advances. This paper presents an in-depth quantitative analysis of virtualization overheads in these two groups of systems and their gaps relative to native environments based on a diverse set of workloads that stress CPU, memory, storage, and networking resources. KVM and XEN are used to represent hypervisor-based virtualization, and LXC and Docker for container-based platforms. The systems were evaluated with respect to several cloud resource management dimensions including performance, isolation, resource usage, energy efficiency, start-up time, and density. Our study is useful both to practitioners to understand the current state of the technology in order to make the right decision in the selection, operation and/or design of platforms and to scholars to illustrate how these technologies evolved over time.","publicationDate":"2018-03-29T22:00:00.000Z","citationCount":12},{"url":"https://dl.acm.org/doi/10.1145/3468264.3468543","title":"research-article ","type":"Identifying bad software changes via multimodal anomaly detection for online service systems","venue":"ESEC/FSE 2021: Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","authors":["Nengwen Zhao","Junjie Chen","Zhaoyang Yu","Honglin Wang","Jiesong Li","Bin Qiu","Hongyu Xu","Wenchi Zhang","Kaixin Sui","Dan Pei"],"abstract":"In large-scale online service systems, software changes are inevitable and frequent. Due to importing new code or configurations, changes are likely to incur incidents and destroy user experience. Thus it is essential for engineers to identify bad software changes, so as to reduce the influence of incidents and improve system re- liability. To better understand bad software changes, we perform the first empirical study based on large-scale real-world data from a large commercial bank. Our quantitative analyses indicate that about 50.4% of incidents are caused by bad changes, mainly be- cause of code defect, configuration error, resource contention, and software version. Besides, our qualitative analyses show that the current practice of detecting bad software changes performs not well to handle heterogeneous multi-source data involved in soft- ware changes. Based on the findings and motivation obtained from the empirical study, we propose a novel approach named SCWarn aiming to identify bad changes and produce interpretable alerts accurately and timely. The key idea of SCWarn is drawing support from multimodal learning to identify anomalies from heterogeneous multi-source data. An extensive study on two datasets with various bad software changes demonstrates our approach significantly outperforms all the compared approaches, achieving 0.95 F1-score on average and reducing MTTD (mean time to detect) by 20.4%∼60.7%. In particular, we shared some success stories and lessons learned from the practical usage.","publicationDate":"2021-08-19T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3458864.3466627","title":"research-article ","type":"SafetyNOT: on the usage of the SafetyNet attestation API in Android","venue":"MobiSys '21: Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services","authors":["Muhammad Ibrahim","Abdullah Imran","Antonio Bianchi"],"abstract":"Many apps performing security-sensitive tasks (e.g., online banking) attempt to verify the integrity of the device they are running in and the integrity of their own code. To ease this goal, Android provides an API, called the SafetyNet Attestation API, that can be used to detect if the device an app is running in is in a \"safe\" state (e.g., non-rooted) and if the app's code has not been modified (using, for instance, app repackaging). In this paper, we perform the first large-scale systematic analysis of the usage of the SafetyNet API. Our study identifies many common mistakes that app developers make when attempting to use this API. Specifically, we provide a systematic categorization of the possible misusages of this API, and we analyze how frequent each misuse is. Our results show that, for instance, more than half of the analyzed apps check SafetyNet results locally (as opposed to using a remote trusted server), rendering their checks trivially bypassable. Even more surprisingly, we found that none of the analyzed apps invoking the SafetyNet API uses it in a fully correct way.","publicationDate":"2021-06-23T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3442381.3449905","title":"research-article ","type":"MicroRank: End-to-End Latency Issue Localization with Extended Spectrum Analysis in Microservice Environments","venue":"WWW '21: Proceedings of the Web Conference 2021","authors":["Guangba Yu","Pengfei Chen","Hongyang Chen","Zijie Guan","Zicheng Huang","Linxiao Jing","Tianjun Weng","Xinmeng Sun","Xiaoyun Li"],"abstract":" With the advantages of flexible scalability and fast delivery, microservice has become a popular software architecture in the modern IT industry. However, the explosion in the number of service instances and complex dependencies make the troubleshooting extremely challenging in microservice environments. To help understand and troubleshoot a microservice system, the end-to-end tracing technology has been widely applied to capture the execution path of each request. Nevertheless, the tracing data are not fully leveraged by cloud and application providers when conducting latency issue localization in the microservice environment. This paper proposes a novel system, named MicroRank, which analyzes clues provided by normal and abnormal traces to locate root causes of latency issues. Once a latency issue is detected by the Anomaly Detector in MicroRank, the cause localization procedure is triggered. MicroRank first distinguishs which traces are abnormal. Then, MicroRank’s PageRank Scorer module uses the abnormal and normal trace information as its input and differentials the importance of different traces to extended spectrum techniques . Finally, the spectrum techniques can calculate the ranking list based on the weighted spectrum information from PageRank Scorer to locate root causes more effectively. The experimental evaluations on a widely-used open-source system and a production system show that MicroRank achieves excellent results not only in one root cause situation but also in two issues that happen at the same time. Moreover, MicroRank makes 6% to 22% improvement in recall in localizing root causes compared to current state-of-the-art methods.","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3267809.3267830","title":"research-article ","type":"The Elasticity and Plasticity in Semi-Containerized Co-locating Cloud Workload: a View from Alibaba Trace","venue":"SoCC '18: Proceedings of the ACM Symposium on Cloud Computing","authors":["Qixiao Liu","Zhibin Yu"],"abstract":"Cloud computing with large-scale datacenters provides great convenience and cost-efficiency for end users. However, the resource utilization of cloud datacenters is very low, which wastes a huge amount of infrastructure investment and energy to operate. To improve resource utilization, cloud providers usually co-locate workloads of different types on shared resources. However, resource sharing makes the quality of service (QoS) unguaranteed. In fact, improving resource utilization (IRU) and guaranteeing QoS at the same time in cloud has been a dilemma which we name an IRU-QoS curse. To tackle this issue, characterizing the workloads from real production cloud computing platforms is extremely important.In this work, we analyze a recently released 24-hour trace dataset from a production cluster in Alibaba. We reveal three key findings which are significantly different from those from the Google trace. First, each online service runs in a container while batch jobs run on physical servers. Further, they are concurrently managed by two different schedulers and co-located on same servers, which we call semi-containerized co-location. Second, batch instances largely use the spare resources that containers reserved but not used, which shows the elasticity feature of resource allocation of the Alibaba cluster. Moreover, through resource overprovisioning, overbooking, and overcommitment, the resource allocation of the Alibaba cluster achieves high elasticity. Third, as the high elasticity may hurt the performance of co-located online services, the Alibaba cluster sets bounds of resources used by batch tasks to guarantee the steady performance of both online services and batch tasks, which we call plasticity of resource allocation.","publicationDate":"2018-10-10T22:00:00.000Z","citationCount":28},{"url":"https://dl.acm.org/doi/10.14778/3282495.3282499","title":"research-article ","type":"Rafiki: machine learning as an analytics service system","venue":"Proceedings of the VLDB Endowment","authors":["Wei Wang","Jinyang Gao","Meihui Zhang","Sheng Wang","Gang Chen","Teck Khim Ng","Beng Chin Ooi","Jie Shao","Moaz Reyad"],"abstract":"Big data analytics is gaining massive momentum in the last few years. Applying machine learning models to big data has become an implicit requirement or an expectation for most analysis tasks, especially on high-stakes applications. Typical applications include sentiment analysis against reviews for analyzing on-line products, image classification in food logging applications for monitoring user's daily intake, and stock movement prediction. Extending traditional database systems to support the above analysis is intriguing but challenging. First, it is almost impossible to implement all machine learning models in the database engines. Second, expert knowledge is required to optimize the training and inference procedures in terms of efficiency and effectiveness, which imposes heavy burden on the system users. In this paper, we develop and present a system, called Rafiki, to provide the training and inference service of machine learning models. Rafiki provides distributed hyper-parameter tuning for the training service, and online ensemble modeling for the inference service which trades off between latency and accuracy. Experimental results confirm the efficiency, effectiveness, scalability and usability of Rafiki.","publicationDate":"2018-09-30T22:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3448016.3457549","title":"research-article ","type":"ExDRa: Exploratory Data Science on Federated Raw Data","venue":"SIGMOD/PODS '21: Proceedings of the 2021 International Conference on Management of Data","authors":["Sebastian Baunsgaard","Matthias Boehm","Ankit Chaudhary","Behrouz Derakhshan","Stefan Geißelsöder","Philipp M. Grulich","Michael Hildebrand","Kevin Innerebner","Volker Markl","Claus Neubauer","Sarah Osterburg","Olga Ovcharenko","Sergey Redyuk","Tobias Rieger","Alireza Rezaei Mahdiraji","Sebastian Benjamin Wrede","Steffen Zeuch"],"abstract":"Data science workflows are largely exploratory, dealing with under-specified objectives, open-ended problems, and unknown business value. Therefore, little investment is made in systematic acquisition, integration, and pre-processing of data. This lack of infrastructure results in redundant manual effort and computation. Furthermore, central data consolidation is not always technically or economically desirable or even feasible (e.g., due to privacy, and/or data ownership). The ExDRa system aims to provide system infrastructure for this exploratory data science process on federated and heterogeneous, raw data sources. Technical focus areas include (1) ad-hoc and federated data integration on raw data, (2) data organization and reuse of intermediates, and (3) optimization of the data science lifecycle, under awareness of partially accessible data. In this paper, we describe use cases, the overall system architecture, selected features of SystemDS' new federated backend (for federated linear algebra programs, federated parameter servers, and federated data preparation), as well as promising initial results. Beyond existing work on federated learning, ExDRa focuses on enterprise federated ML and related data pre-processing challenges. In this context, federated ML has the potential to create a more fine-grained spectrum of data ownership and thus, even new markets.","publicationDate":"2021-06-08T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1109/TNET.2021.3050927","title":"research-article ","type":"Elasecutor: Elastic Executor Scheduling in Data Analytics Systems","venue":"IEEE/ACM Transactions on Networking","authors":["Libin Liu","Hong Xu"],"abstract":"Modern data analytics systems use long-running executors to run an application&#x2019;s entire DAG. Executors exhibit salient time-varying resource requirements. Yet, existing schedulers simply reserve resources for executors statically, and use the peak resource demand to guide executor placement. This leads to low utilization and poor application performance. We present Elasecutor, a novel executor scheduler for data analytics systems. Elasecutor dynamically allocates and explicitly sizes resources to executors over time according to the predicted time/varying resource demands. Rather than placing executors using their peak demand, Elasecutor strategically assigns them to machines based on a concept called <italic>dominant remaining resource</italic> to minimize resource fragmentation. Elasecutor further adaptively reprovisions resources in order to tolerate inaccurate demand prediction and reschedules tasks to deal with inadequate reprovisioning resources on one machine. Testbed evaluation on a 35-node cluster with our Spark-based prototype implementation shows that Elasecutor reduces makespan by more than 36&#x0025; on average, and improves cluster utilization by up to 55&#x0025; compared to existing work.","publicationDate":"2021-03-31T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3267809.3267818","title":"research-article ","type":"Elasecutor: Elastic Executor Scheduling in Data Analytics Systems","venue":"SoCC '18: Proceedings of the ACM Symposium on Cloud Computing","authors":["Libin Liu","Hong Xu"],"abstract":"Modern data analytics systems use long-running executors to run an application's entire DAG. Executors exhibit salient time-varying resource requirements. Yet, existing schedulers simply reserve resources for executors statically, and use the peak resource demand to guide executor placement. This leads to low utilization and poor application performance.We present Elasecutor, a novel executor scheduler for data analytics systems. Elasecutor dynamically allocates and explicitly sizes resources to executors over time according to the predicted time-varying resource demands. Rather than placing executors using their peak demand, Elasecutor strategically assigns them to machines based on a concept called dominant remaining resource to minimize resource fragmentation. Elasecutor further adaptively reprovisions resources in order to tolerate inaccurate demand prediction. Testbed evaluation on a 35-node cluster with our Spark-based prototype implementation shows that Elasecutor reduces makespan by more than 42% on average, reduces median application completion time by up to 40%, and improves cluster utilization by up to 55% compared to existing work.","publicationDate":"2018-10-10T22:00:00.000Z","citationCount":11},{"url":"https://dl.acm.org/doi/10.1145/3447786.3456241","title":"research-article ","type":"Parallelizing packet processing in container overlay networks","venue":"EuroSys '21: Proceedings of the Sixteenth European Conference on Computer Systems","authors":["Jiaxin Lei","Manish Munikar","Kun Suo","Hui Lu","Jia Rao"],"abstract":"Container networking, which provides connectivity among containers on multiple hosts, is crucial to building and scaling container-based microservices. While overlay networks are widely adopted in production systems, they cause significant performance degradation in both throughput and latency compared to physical networks. This paper seeks to understand the bottlenecks of in-kernel networking when running container overlay networks. Through profiling and code analysis, we find that a prolonged data path, due to packet transformation in overlay networks, is the culprit of performance loss. Furthermore, existing scaling techniques in the Linux network stack are ineffective for parallelizing the prolonged data path of a single network flow.We propose Falcon, a fast and balanced container networking approach to scale the packet processing pipeline in overlay networks. Falcon pipelines software interrupts associated with different network devices of a single flow on multiple cores, thereby preventing execution serialization of excessive software interrupts from overloading a single core. Falcon further supports multiple network flows by effectively multiplexing and balancing software interrupts of different flows among available cores. We have developed a prototype of Falcon in Linux. Our evaluation with both micro-benchmarks and real-world applications demonstrates the effectiveness of Falcon, with significantly improved performance (by 300% for web serving) and reduced tail latency (by 53% for data caching).","publicationDate":"2021-04-20T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3425866","title":"research-article ","type":"Operating Systems for Resource-adaptive Intelligent Software: Challenges and Opportunities","venue":"ACM Transactions on Internet Technology","authors":["Xuanzhe Liu","Shangguang Wang","Yun Ma","Ying Zhang","Qiaozhu Mei","Yunxin Liu","Gang Huang"],"abstract":"The past decades witnessed the fast and wide deployment of Internet. The Internet has bred the ubiquitous computing environment that is spanning the cloud, edge, mobile devices, and IoT. Software running over such a ubiquitous computing environment environment is eating the world. A recently emerging trend of Internet-based software systems is “resource adaptive,” i.e., software systems should be robust and intelligent enough to the changes of heterogeneous resources, both physical and logical, provided by their running environment. To keep pace of such a trend, we argue that some considerations should be taken into account for the future operating system design and implementation. From the structural perspective, rather than the “monolithic OS” that manages the aggregated resources on the single machine, the OS should be dynamically composed over the distributed resources and flexibly adapt to the resource and environment changes. Meanwhile, the OS should leverage advanced machine/deep learning techniques to derive configurations and policies and automatically learn to tune itself and schedule resources. This article envisions our recent thinking of the new OS abstraction, namely, ServiceOS, for future resource-adaptive intelligent software systems. The idea of ServiceOS is inspired by the delivery model of “Software-as-a-Service” that is supported by the Service-Oriented Architecture (SOA). The key principle of ServiceOS is based on resource disaggregation, resource provisioning as a service, and learning-based resource scheduling and allocation. The major goal of this article is not providing an immediately deployable OS. Instead, we aim to summarize the challenges and potentially promising opportunities and try to provide some practical implications for researchers and practitioners.","publicationDate":"2021-03-14T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3442696","title":"research-article ","type":"Adaptive Performance Modeling of Data-intensive Workloads for Resource Provisioning in Virtualized Environment","venue":"ACM Transactions on Modeling and Performance Evaluation of Computing Systems","authors":["Hosein Mohamamdi Makrani","Hossein Sayadi","Najmeh Nazari","Sai Mnoj Pudukotai Dinakarrao","Avesta Sasan","Tinoosh Mohsenin","Setareh Rafatirad","Houman Homayoun"],"abstract":"The processing of data-intensive workloads is a challenging and time-consuming task that often requires massive infrastructure to ensure fast data analysis. The cloud platform is the most popular and powerful scale-out infrastructure to perform big data analytics and eliminate the need to maintain expensive and high-end computing resources at the user side. The performance and the cost of such infrastructure depend on the overall server configuration, such as processor, memory, network, and storage configurations. In addition to the cost of owning or maintaining the hardware, the heterogeneity in the server configuration further expands the selection space, leading to non-convergence. The challenge is further exacerbated by the dependency of the application’s performance on the underlying hardware. Despite an increasing interest in resource provisioning, few works have been done to develop accurate and practical models to proactively predict the performance of data-intensive applications corresponding to the server configuration and provision a cost-optimal configuration online.In this work, through a comprehensive real-system empirical analysis of performance, we address these challenges by introducing ProMLB: a proactive machine-learning-based methodology for resource provisioning. We first characterize diverse types of data-intensive workloads across different types of server architectures. The characterization aids in accurately capture applications’ behavior and train a model for prediction of their performance.Then, ProMLB builds a set of cross-platform performance models for each application. Based on the developed predictive model, ProMLB uses an optimization technique to distinguish close-to-optimal configuration to minimize the product of execution time and cost. Compared to the oracle scheduler, ProMLB achieves 91% accuracy in terms of application-resource matching. On average, ProMLB improves the performance and resource utilization by 42.6% and 41.1%, respectively, compared to baseline scheduler. Moreover, ProMLB improves the performance per cost by 2.5× on average.","publicationDate":"2021-03-08T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3427921.3450235","title":"research-article ","type":"A Framework for Developing DevOps Operation Automation in Clouds using Components-off-the-Shelf","venue":"ICPE '21: Proceedings of the ACM/SPEC International Conference on Performance Engineering","authors":["Yar Rouf","Joydeep Mukherjee","Marin Litoiu","Joe Wigglesworth","Radu Mateescu"],"abstract":"DevOps is an emerging paradigm that integrates the development and operations teams to enable fast and efficient continuous delivery of software. Applications and services deployed on cloud platforms can benefit from implementing the DevOps practice. This involves using different tools for enabling end-to-end automation to ensure continuous deployment and maintain good Quality-of-Service. Self-Adaptive systems can support the DevOps process by automating service deployment and maintenance without manual intervention by employing a MAPE-K (Monitoring, Analysis, Planning, Execution- Knowledge) framework. While industrial MAPE-K tools are robust and built for production environments, they lack the flexibility to adapt large applications on multi-cloud environments. Academic models are more flexible and can be used to perform sophisticated self-adaption, but can lack the robustness to be used in production environments. In this paper, we present a MAPE-K framework that is built with existing Components-off-the-Shelf (COTS) that interacts with each other to perform self-adaptive actions on multi-cloud environments. By integrating existing COTS, we are able to deploy a MAPE-K framework efficiently to support DevOps for applications running on a multi-cloud environment. We validate our framework with a prototype implementation and demonstrate its practical feasibility by a detailed case study done on a real industrial platform.","publicationDate":"2021-04-08T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3381052.3381321","title":"research-article ","type":"Edge computing: the case for heterogeneous-ISA container migration","venue":"VEE '20: Proceedings of the 16th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution Environments","authors":["Antonio Barbalace","Mohamed L. Karaoui","Wei Wang","Tong Xing","Pierre Olivier","Binoy Ravindran"],"abstract":"Edge computing is a recent computing paradigm that brings cloud services closer to the client. Among other features, edge computing offers extremely low client/server latencies. To consistently provide such low latencies, services need to run on edge nodes that are physically as close as possible to their clients. Thus, when a client changes its physical location, a service should migrate between edge nodes to maintain proximity. Differently from cloud nodes, edge nodes are built with CPUs of different Instruction Set Architectures (ISAs), hence a server program natively compiled for one ISA cannot migrate to another. This hinders migration to the closest node.We introduce H-Container, which migrates natively-compiled containerized applications across compute nodes featuring CPUs of different ISAs. H-Container advances over existing heterogeneous-ISA migration systems by being a) highly compatible - no source code nor compiler toolchain modifications are needed; b) easily deployable - fully implemented in user space, thus without any OS or hypervisor dependency, and c) largely Linux compliant - can migrate most Linux software, including server applications and dynamically linked binaries. H-Container targets Linux, adopts LLVM, extends CRIU, and integrates with Docker. Experiments demonstrate that H-Container adds no overhead on average during program execution, while between 10ms and 100ms are added during migration. Furthermore, we show the benefits of H-Container in real scenarios, proving for example up to 94% increase in Redis throughput when unlocking heterogeneity.","publicationDate":"2020-03-16T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3361525.3361540","title":"research-article ","type":"FabricCRDT: A Conflict-Free Replicated Datatypes Approach to Permissioned Blockchains","venue":"Middleware '19: Proceedings of the 20th International Middleware Conference","authors":["Pezhman Nasirifard","Ruben Mayer","Hans-Arno Jacobsen"],"abstract":"With the increased adaption of blockchain technologies, permissioned blockchains such as Hyperledger Fabric provide a robust ecosystem for developing production-grade decentralized applications. However, the additional latency between executing and committing transactions, due to Fabric's three-phase transaction lifecycle of Execute-Order-Validate (EOV), is a potential scalability bottleneck. The added latency increases the probability of concurrent updates on the same keys by different transactions, leading to transaction failures caused by Fabric's concurrency control mechanism. The transaction failures increase the application development complexity and decrease Fabric's throughput. Conflict-free Replicated Datatypes (CRDTs) provide a solution for merging and resolving conflicts in the presence of concurrent updates. In this work, we introduce FabricCRDT, an approach for integrating CRDTs to Fabric. Our evaluations show that in general, FabricCRDT offers higher throughput of successful transactions than Fabric, while successfully committing and merging all conflicting transactions without any failures.","publicationDate":"2019-12-08T23:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3236024.3236033","title":"research-article ","type":"One size does not fit all: an empirical study of containerized continuous deployment workflows","venue":"ESEC/FSE 2018: Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering","authors":["Yang Zhang","Bogdan Vasilescu","Huaimin Wang","Vladimir Filkov"],"abstract":"Continuous deployment (CD) is a software development practice aimed at automating delivery and deployment of a software product, following any changes to its code. If properly implemented, CD together with other automation in the development process can bring numerous benefits, including higher control and flexibility over release schedules, lower risks, fewer defects, and easier on-boarding of new developers. Here we focus on the (r)evolution in CD workflows caused by containerization, the virtualization technology that enables packaging an application together with all its dependencies and execution environment in a light-weight, self-contained unit, of which Docker has become the de-facto industry standard. There are many available choices for containerized CD workflows, some more appropriate than others for a given project. Owing to cross-listing of GitHub projects on Docker Hub, in this paper we report on a mixed-methods study to shed light on developers' experiences and expectations with containerized CD workflows. Starting from a survey, we explore the motivations, specific workflows, needs, and barriers with containerized CD. We find two prominent workflows, based on the automated builds feature on Docker Hub or continuous integration services, with different trade-offs. We then propose hypotheses and test them in a large-scale quantitative study.","publicationDate":"2018-10-25T22:00:00.000Z","citationCount":13},{"url":"https://dl.acm.org/doi/10.1145/3344429.3372506","title":"research-article ","type":"Toward a Cloud Computing Learning Community","venue":"ITiCSE-WGR '19: Proceedings of the Working Group Reports on Innovation and Technology in Computer Science Education","authors":["Derek Foster","Laurie White","D. Cenk Erdil","Joshua Adams","Amadeo Argüelles","Brian Hainey","Harvey Hyman","Gareth Lewis","Sajid Nazir","Van Nguyen","Majd Sakr","Lee Stott"],"abstract":"Cloud computing continues to be an important technology in higher education. This domain is a rapidly evolving space, and continues to gain momentum as a primary infrastructure topology for technological advances across emergent industries. The on-the-cloud paradigm provides numerous affordances and new methods of working in industry, and also for end users within recent fields of study, such as machine learning and artificial intelligence. As we move into the Industry 4.0 era with technology pillars such as the internet of things and cybersecurity, the importance of skillsets for cloud-based services will be an essential attribute for the majority of technology-related professions. Many higher education institutions have focused on offering training opportunities and programs for cloud computing, however, a lack of high-quality, contextualized to industry, curricula materials continues to be a challenge for educators. The purpose of this paper is to report on analyses conducted to categorize cloud computing courses currently taught in the higher education sector and to determine the possibility of moving towards the goal of a model curriculum. Additionally, the paper aims to provide guidance to educators about cloud computing skill-sets sought in the job market, and to report on a community platform designed to host cloud learning resources.","publicationDate":"2019-12-17T23:00:00.000Z","citationCount":4},{"url":"https://dl.acm.org/doi/10.1109/SC.2018.00040","title":"research-article ","type":"A reference architecture for datacenter scheduling: design, validation, and experiments","venue":"SC '18: Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis","authors":["Georgios Andreadis","Laurens Versluis","Fabian Mastenbroek","Alexandru Iosup"],"abstract":"Datacenters act as cloud-infrastructure to stakeholders across industry, government, and academia. To meet growing demand yet operate efficiently, datacenter operators employ increasingly more sophisticated scheduling systems, mechanisms, and policies. Although many scheduling techniques already exist, relatively little research has gone into the abstraction of the scheduling process itself, hampering design, tuning, and comparison of existing techniques. In this work, we propose a reference architecture for datacenter schedulers. The architecture follows five design principles: components with clearly distinct responsibilities, grouping of related components where possible, separation of mechanism from policy, scheduling as complex workflow, and hierarchical multi-scheduler structure. To demonstrate the validity of the reference architecture, we map to it state-of-the-art datacenter schedulers. We find scheduler-stages are commonly underspecified in peer-reviewed publications. Through trace-based simulation and real-world experiments, we show underspecification of scheduler-stages can lead to significant variations in performance.","publicationDate":"2018-11-10T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3180155.3180199","title":"research-article ","type":"Inferring and asserting distributed system invariants","venue":"ICSE '18: Proceedings of the 40th International Conference on Software Engineering","authors":["Stewart Grant","Hendrik Cech","Ivan Beschastnikh"],"abstract":"Distributed systems are difficult to debug and understand. A key reason for this is distributed state, which is not easily accessible and must be pieced together from the states of the individual nodes in the system.We propose Dinv, an automatic approach to help developers of distributed systems uncover the runtime distributed state properties of their systems. Dinv uses static and dynamic program analyses to infer relations between variables at different nodes. For example, in a leader election algorithm, Dinv can relate the variable leader at different nodes to derive the invariant ∀ nodes i, j, leaderi = leaderj. This can increase the developer's confidence in the correctness of their system. The developer can also use Dinv to convert an inferred invariant into a distributed runtime assertion on distributed state.We applied Dinv to several popular distributed systems, such as etcd Raft, Hashicorp Serf, and Taipei-Torrent, which have between 1.7K and 144K LOC and are widely used. Dinv derived useful invariants for these systems, including invariants that capture the correctness of distributed routing strategies, leadership, and key hash distribution. We also used Dinv to assert correctness of the inferred etcd Raft invariants at runtime, using these asserts to detect injected silent bugs.","publicationDate":"2018-05-26T22:00:00.000Z","citationCount":8},{"url":"https://dl.acm.org/doi/10.1145/3423211.3425695","title":"research-article ","type":"SplitServe: Efficiently Splitting Apache Spark Jobs Across FaaS and IaaS","venue":"Middleware '20: Proceedings of the 21st International Middleware Conference","authors":["Aman Jain","Ata F. Baarzi","George Kesidis","Bhuvan Urgaonkar","Nader Alfares","Mahmut Kandemir"],"abstract":"Due to their lower startup latencies and finer-grain pricing than virtual machines (VMs), Amazon Lambdas and other cloud functions (CFs) have been identified as ideal candidates for handling unexpected spikes in simple, stateless workloads. However, it is not immediately clear if CFs would be similarly effective in autoscaling complex workloads involving significant state transfer across distributed application components. We have found that, through careful design, currently available CFs can indeed be useful even for complex workloads. To demonstrate this, we design and implement SplitServe, an enhancement of Apache Spark. If not enough executors on existing VMs are available for a newly arriving latency-sensitive job, SplitServe is able to use CFs to quickly bridge this shortfall in VMs, so avoiding the startup latencies of newly requested VMs. If desirable in terms of performance or cost, when newly requested VMs, or executors on existing VMs, do become available, SplitServe is able to move ongoing work from CFs to them. Our experimental evaluation of SplitServe using four different workloads (either on a mixture of VM-based executors and CFs or just CFs) shows that it improves execution time by up to (a) 55% for workloads with small to modest amount of shuffling, and (b) 31% in workloads with large amounts of shuffling, when compared to only VM-based autoscaling.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3307681.3325403","title":"research-article ","type":"Adaptive Resource Views for Containers","venue":"HPDC '19: Proceedings of the 28th International Symposium on High-Performance Parallel and Distributed Computing","authors":["Hang Huang","Jia Rao","Song Wu","Hai Jin","Kun Suo","Xiaofeng Wu"],"abstract":"As OS-level virtualization advances, containers have become a viable alternative to virtual machines in deploying applications in the cloud. Unlike virtual machines, which allow guest OSes to run atop virtual hardware, containers have direct access to physical hardware and share one OS kernel. While the absence of virtual hardware abstractions eliminates most virtualization overhead, it presents unique challenges for containerized applications to efficiently utilize the underlying hardware. The lack of hardware abstraction exposes the total amount of resources that are shared among all containers to each individual container. Parallel runtimes (e.g., OpenMP) and managed programming languages (e.g., Java) that rely on OS-exported information for resource management could suffer from suboptimal performance. In this paper, we develop a per-container view of resources to export information on the actual resource allocation to containerized applications. The central design of the resource view is a per-container sys\\_namespace that calculates the effective capacity of CPU and memory in the presence of resource sharing among containers. We further create a virtual sysfs to seamlessly interface user space applications with sys\\_namespace. We use two case studies to demonstrate how to leverage the continuously updated resource view to enable elasticity in the HotSpot JVM and OpenMP. Experimental results show that an accurate view of resource allocation leads to more appropriate configurations and improved performance in a variety of containerized applications.","publicationDate":"2019-06-16T22:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3445814.3446757","title":"research-article ","type":"FaasCache: keeping serverless computing alive with greedy-dual caching","venue":"ASPLOS 2021: Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems\n\t\t\t\t\n                    Artifacts for 'FaasCache: Keeping Serverless Computing Alive with Greedy-Dual Caching'\n                \n            ","authors":["Alexander Fuerst","Prateek Sharma"],"abstract":"Functions as a Service (also called serverless computing) promises to revolutionize how applications use cloud resources. However, functions suffer from cold-start problems due to the overhead of initializing their code and data dependencies before they can start executing. Keeping functions alive and warm after they have finished execution can alleviate the cold-start overhead. Keep-alive policies must keep functions alive based on their resource and usage characteristics, which is challenging due to the diversity in FaaS workloads. Our insight is that keep-alive is analogous to caching. Our caching-inspired Greedy-Dual keep-alive policy can be effective in reducing the cold-start overhead by more than 3× compared to current approaches. Caching concepts such as reuse distances and hit-ratio curves can also be used for auto-scaled server resource provisioning, which can reduce the resource requirement of FaaS providers by 30% for real-world dynamic workloads. We implement caching-based keep-alive and resource provisioning policies in our FaasCache system, which is based on OpenWhisk. We hope that our caching analogy opens the door to more principled and optimized keep-alive and resource provisioning techniques for future FaaS workloads and platforms.","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3341301.3359658","title":"research-article ","type":"Nexus: a GPU cluster engine for accelerating DNN-based video analysis","venue":"SOSP '19: Proceedings of the 27th ACM Symposium on Operating Systems Principles","authors":["Haichen Shen","Lequn Chen","Yuchen Jin","Liangyu Zhao","Bingyu Kong","Matthai Philipose","Arvind Krishnamurthy","Ravi Sundaram"],"abstract":"We address the problem of serving Deep Neural Networks (DNNs) efficiently from a cluster of GPUs. In order to realize the promise of very low-cost processing made by accelerators such as GPUs, it is essential to run them at sustained high utilization. Doing so requires cluster-scale resource management that performs detailed scheduling of GPUs, reasoning about groups of DNN invocations that need to be co-scheduled, and moving from the conventional whole-DNN execution model to executing fragments of DNNs. Nexus is a fully implemented system that includes these innovations. In large-scale case studies on 16 GPUs, when required to stay within latency constraints at least 99% of the time, Nexus can process requests at rates 1.8-12.7X higher than state of the art systems can. A long-running multi-application deployment stays within 84% of optimal utilization and, on a 100-GPU cluster, violates latency SLOs on 0.27% of requests.","publicationDate":"2019-10-26T22:00:00.000Z","citationCount":22},{"url":"https://dl.acm.org/doi/10.1145/3144168","title":"research-article ","type":"The Hipster Approach for Improving Cloud System Efficiency","venue":"ACM Transactions on Computer Systems","authors":["Rajiv Nishtala","Paul Carpenter","Vinicius Petrucci","Xavier Martorell"],"abstract":"In 2013, U.S. data centers accounted for 2.2% of the country’s total electricity consumption, a figure that is projected to increase rapidly over the next decade. Many important data center workloads in cloud computing are interactive, and they demand strict levels of quality-of-service (QoS) to meet user expectations, making it challenging to optimize power consumption along with increasing performance demands.This article introduces Hipster, a technique that combines heuristics and reinforcement learning to improve resource efficiency in cloud systems. Hipster explores heterogeneous multi-cores and dynamic voltage and frequency scaling for reducing energy consumption while managing the QoS of the latency-critical workloads. To improve data center utilization and make best usage of the available resources, Hipster can dynamically assign remaining cores to batch workloads without violating the QoS constraints for the latency-critical workloads. We perform experiments using a 64-bit ARM big.LITTLE platform and show that, compared to prior work, Hipster improves the QoS guarantee for Web-Search from 80% to 96%, and for Memcached from 92% to 99%, while reducing the energy consumption by up to 18%. Hipster is also effective in learning and adapting automatically to specific requirements of new incoming workloads just enough to meet the QoS and optimize resource consumption.","publicationDate":"2017-12-03T23:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.5555/3433701.3433791","title":"research-article ","type":"Metis: learning to schedule long-running applications in shared container clusters at scale","venue":"SC '20: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","authors":["Luping Wang","Qizhen Weng","Wei Wang","Chen Chen","Bo Li"],"abstract":"Online cloud services are increasingly deployed as long-running applications (LRAs) in containers. Placing LRA containers is known to be difficult as they often have sophisticated resource interferences and I/O dependencies. Existing schedulers rely on operators to manually express the container scheduling requirements as placement constraints and strive to satisfy as many constraints as possible. Such schedulers, however, fall short in performance as placement constraints only provide qualitative scheduling guidelines and minimizing constraint violations does not necessarily result in the optimal performance.In this work, we present Metis, a general-purpose scheduler that learns to optimally place LRA containers using deep reinforcement learning (RL) techniques. This eliminates the complex manual specification of placement constraints and offers, for the first time, concrete quantitative scheduling criteria. As directly training an RL agent does not scale, we develop a novel hierarchical learning technique that decomposes a complex container placement problem into a hierarchy of subproblems with significantly reduced state and action space. We show that many subproblems have similar structures and can hence be solved by training a unified RL agent offline. Large-scale EC2 deployment shows that compared with the traditional constraint-based schedulers, Metis improves the throughput by up to 61%, optimizes various performance metrics, and easily scales to a large cluster where 3K containers run on over 700 machines.","publicationDate":"2020-11-08T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3419394.3423616","title":"research-article ","type":"Hiding in Plain Site: Detecting JavaScript Obfuscation through Concealed Browser API Usage","venue":"IMC '20: Proceedings of the ACM Internet Measurement Conference","authors":["Shaown Sarker","Jordan Jueckstock","Alexandros Kapravelos"],"abstract":"In this paper, we perform a large-scale measurement study of JavaScript obfuscation of browser APIs in the wild. We rely on a simple, but powerful observation: if dynamic analysis of a script's behavior (specifically, how it interacts with browser APIs) reveals browser API feature usage that cannot be reconciled with static analysis of the script's source code, then that behavior is obfuscated. To quantify and test this observation, we create a hybrid analysis platform using instrumented Chromium to log all browser API accesses by the scripts executed when a user visits a page. We filter the API access traces from our dynamic analysis through a static analysis tool that we developed in order to quantify how much and what kind of functionality is hidden on the web. When applying this methodology across the Alexa top 100k domains, we discover that 95.90% of the domains we successfully visited contain at least one script which invokes APIs that cannot be resolved from static analysis. We observe that eval is no longer the prominent obfuscation method on the web and we uncover families of novel obfuscation techniques that no longer rely on the use of eval.","publicationDate":"2020-10-26T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.5555/3291656.3291659","title":"research-article ","type":"bespoKV: application tailored scale-out key-value stores","venue":"SC '18: Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis","authors":["Ali Anwar","Yue Cheng","Hai Huang","Jingoo Han","Hyogi Sim","Dongyoon Lee","Fred Douglis","Ali R. Butt"],"abstract":"Enterprise KV stores are not well suited for HPC applications, and entail customization and cumbersome end-to-end KV design to extract the HPC application needs. To this end, in this paper we present bespoKV, an adaptive, extensible, and scale-out KV store framework. bespoKV decouples the KV store design into the control plane for distributed management and the data plane for local data store. bespoKV takes as input a single-server KV store, called a datalet, and transparently enables a scalable and fault-tolerant distributed KV store service. The resulting distributed stores are also adaptive to consistency or topology requirement changes and can be easily extended for new types of services. Experiments show that bespoKV-enabled distributed KV stores scale horizontally to a large number of nodes, and performs comparably and sometimes better than the state-of-the-art systems.","publicationDate":"2018-11-10T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.5555/3433701.3433791","title":"research-article ","type":"Metis: learning to schedule long-running applications in shared container clusters at scale","venue":"SC '20: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","authors":["Luping Wang","Qizhen Weng","Wei Wang","Chen Chen","Bo Li"],"abstract":"Online cloud services are increasingly deployed as long-running applications (LRAs) in containers. Placing LRA containers is known to be difficult as they often have sophisticated resource interferences and I/O dependencies. Existing schedulers rely on operators to manually express the container scheduling requirements as placement constraints and strive to satisfy as many constraints as possible. Such schedulers, however, fall short in performance as placement constraints only provide qualitative scheduling guidelines and minimizing constraint violations does not necessarily result in the optimal performance.In this work, we present Metis, a general-purpose scheduler that learns to optimally place LRA containers using deep reinforcement learning (RL) techniques. This eliminates the complex manual specification of placement constraints and offers, for the first time, concrete quantitative scheduling criteria. As directly training an RL agent does not scale, we develop a novel hierarchical learning technique that decomposes a complex container placement problem into a hierarchy of subproblems with significantly reduced state and action space. We show that many subproblems have similar structures and can hence be solved by training a unified RL agent offline. Large-scale EC2 deployment shows that compared with the traditional constraint-based schedulers, Metis improves the throughput by up to 61%, optimizes various performance metrics, and easily scales to a large cluster where 3K containers run on over 700 machines.","publicationDate":"2020-11-08T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3419394.3423616","title":"research-article ","type":"Hiding in Plain Site: Detecting JavaScript Obfuscation through Concealed Browser API Usage","venue":"IMC '20: Proceedings of the ACM Internet Measurement Conference","authors":["Shaown Sarker","Jordan Jueckstock","Alexandros Kapravelos"],"abstract":"In this paper, we perform a large-scale measurement study of JavaScript obfuscation of browser APIs in the wild. We rely on a simple, but powerful observation: if dynamic analysis of a script's behavior (specifically, how it interacts with browser APIs) reveals browser API feature usage that cannot be reconciled with static analysis of the script's source code, then that behavior is obfuscated. To quantify and test this observation, we create a hybrid analysis platform using instrumented Chromium to log all browser API accesses by the scripts executed when a user visits a page. We filter the API access traces from our dynamic analysis through a static analysis tool that we developed in order to quantify how much and what kind of functionality is hidden on the web. When applying this methodology across the Alexa top 100k domains, we discover that 95.90% of the domains we successfully visited contain at least one script which invokes APIs that cannot be resolved from static analysis. We observe that eval is no longer the prominent obfuscation method on the web and we uncover families of novel obfuscation techniques that no longer rely on the use of eval.","publicationDate":"2020-10-26T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3342195.3387545","title":"research-article ","type":"HovercRaft: achieving scalability and fault-tolerance for microsecond-scale datacenter services","venue":"EuroSys '20: Proceedings of the Fifteenth European Conference on Computer Systems","authors":["Marios Kogias","Edouard Bugnion"],"abstract":"Cloud platform services must simultaneously be scalable, meet low tail latency service-level objectives, and be resilient to a combination of software, hardware, and network failures. Replication plays a fundamental role in meeting both the scalability and the fault-tolerance requirement, but is subject to opposing requirements: (1) scalability is typically achieved by relaxing consistency; (2) fault-tolerance is typically achieved through the consistent replication of state machines. Adding nodes to a system can therefore either increase performance at the expense of consistency, or increase resiliency at the expense of performance.We propose HovercRaft, a new approach by which adding nodes increases both the resilience and the performance of general-purpose state-machine replication. We achieve this through an extension of the Raft protocol that carefully eliminates CPU and I/O bottlenecks and load balances requests.Our implementation uses state-of-the-art kernel-bypass techniques, datacenter transport protocols, and in-network programmability to deliver up to 1 million operations/second for clusters of up to 9 nodes, linear speedup over unreplicated configuration for selected workloads, and a 4X speedup for the YCSBE-E benchmark running on Redis over an unreplicated deployment.","publicationDate":"2020-04-14T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1109/TNET.2020.2973800","title":"research-article ","type":"Vehicular-OBUs-As-On-Demand-Fogs: Resource and Context Aware Deployment of Containerized Micro-Services","venue":"IEEE/ACM Transactions on Networking","authors":["Hani Sami","Azzam Mourad","Wassim El-Hajj"],"abstract":"Observing the headway in vehicular industry, new applications are developed demanding more resources. For instance, real-time vehicular applications require fast processing of the vast amount of generated data by vehicles in order to maintain service availability and reachability while driving. Fog devices are capable of bringing cloud intelligence near the edge, making them a suitable candidate to process vehicular requests. However, their location, processing power, and technology used to host and update services affect their availability and performance while considering the mobility patterns of vehicles. In this paper, we overcome the aforementioned limitations by taking advantage of the evolvement of On-Board Units, Kubeadm Clustering, Docker Containerization, and micro-services technologies. In this context, we propose an efficient resource and context aware approach for deploying containerized micro-services on on-demand fogs called Vehicular-OBUs-As-On-Demand-Fogs. Our proposed scheme embeds (1) a Kubeadm based approach for clustering OBUs and enabling on-demand micro-services deployment with the least costs and time using Docker containerization technology, (2) a hybrid multi-layered networking architecture to maintain reachability between the requesting user and available vehicular fog cluster, and (3) a vehicular multi-objective container placement model for producing efficient vehicles selection and services distribution. An Evolutionary Memetic Algorithm is elaborated to solve our vehicular container placement problem. Experiments and simulations demonstrate the relevance and efficiency of our approach compared to other recent techniques in the literature.","publicationDate":"2020-03-31T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3371927.3371929","title":"research-article ","type":"Securing Linux with a faster and scalable iptables","venue":"ACM SIGCOMM Computer Communication Review","authors":["Sebastiano Miano","Matteo Bertrone","Fulvio Risso","Mauricio Vásquez Bernal","Yunsong Lu","Jianwen Pi"],"abstract":"The sheer increase in network speed and the massive deployment of containerized applications in a Linux server has led to the consciousness that iptables, the current de-facto firewall in Linux, may not be able to cope with the current requirements particularly in terms of scalability in the number of rules. This paper presents an eBPF-based firewall, bpf-iptables, which emulates the iptables filtering semantic while guaranteeing higher throughput. We compare our implementation against the current version of iptables and other Linux firewalls, showing how it achieves a notable boost in terms of performance particularly when a high number of rules is involved. This result is achieved without requiring custom kernels or additional software frameworks (e.g., DPDK) that could not be allowed in some scenarios such as public data-centers.","publicationDate":"2019-11-07T23:00:00.000Z","citationCount":7},{"url":"https://dl.acm.org/doi/10.1145/3448016.3458454","title":"research-article ","type":"Asynchronous Prefix Recoverability for Fast Distributed Stores","venue":"SIGMOD/PODS '21: Proceedings of the 2021 International Conference on Management of Data","authors":["Tianyu Li","Badrish Chandramouli","Jose M. Faleiro","Samuel Madden","Donald Kossmann"],"abstract":"Accessing and updating data sharded across distributed machines safely and speedily in the face of failures remains a challenging problem. Most prominently, applications that share state across different nodes want their writes to quickly become visible to others, without giving up recoverability guarantees in case a failure occurs. Current solutions of a fast cache backed by storage cannot support this use case easily. In this work, we design a distributed protocol, called Distributed Prefix Recovery (DPR) that builds on top of a sharded cache-store architecture with single-key operations, to provide cross-shard recoverability guarantees. With DPR, many clients can read and update shared state at sub-millisecond latency, while receiving periodic prefix durability guarantees. On failure, DPR quickly restores the system to a prefix-consistent state with a novel non-blocking rollback scheme. We added DPR to a key-value store (FASTER) and cache (Redis) and show that we can get high throughput and low latency similar to in-memory systems, while lazily providing durability guarantees similar to persistent stores.","publicationDate":"2021-06-08T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3447786.3456225","title":"research-article ","type":"SmartHarvest: harvesting idle CPUs safely and efficiently in the cloud","venue":"EuroSys '21: Proceedings of the Sixteenth European Conference on Computer Systems","authors":["Yawen Wang","Kapil Arya","Marios Kogias","Manohar Vanga","Aditya Bhandari","Neeraja J. Yadwadkar","Siddhartha Sen","Sameh Elnikety","Christos Kozyrakis","Ricardo Bianchini"],"abstract":"We can increase the efficiency of public cloud datacenters by harvesting allocated but temporarily idling CPU cores from customer virtual machines (VMs) to run batch or analytics workloads. Even small efficiency gains translate into substantial savings, since provisioning and operating a datacenter costs hundreds of millions of dollars per year. The main challenge is to harvest idle cores with little or no impact on customer VMs, which could be running latency-sensitive services and are essentially black-boxes to the cloud provider.We introduce ElasticVM, a new VM type that can run batch workloads cheaply using mainly harvested cores. We also propose SmartHarvest, a system that dynamically manages the number of cores available to ElasticVMs in each fine-grained time window. SmartHarvest uses online learning to predict the core demand of primary, customer VMs and compute the number of cores that can be safely harvested. Our results show that SmartHarvest can harvest a significant amount of CPU resources without increasing the 99th-percentile tail latency of latency-critical primary workloads by more than 10%. Unlike static harvesting techniques that rely on offline profiling, SmartHarvest is robust to different primary workloads, batch workloads, and load changes. Finally, we show that the online learning in SmartHarvest is complementary to systems optimizations for VM management.","publicationDate":"2021-04-20T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3295500.3356170","title":"research-article ","type":"Slack squeeze coded computing for adaptive straggler mitigation","venue":"SC '19: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","authors":["Krishna Giri Narra","Zhifeng Lin","Mehrdad Kiamari","Salman Avestimehr","Murali Annavaram"],"abstract":"While performing distributed computations in today's cloud-based platforms, execution speed variations among compute nodes can significantly reduce the performance and create bottlenecks like stragglers. Coded computation techniques leverage coding theory to inject computational redundancy and mitigate stragglers in distributed computations. In this paper, we propose a dynamic workload distribution strategy for coded computation called Slack Squeeze Coded Computation (S2C2). S2C2 squeezes the compute slack (i.e., overhead) that is built into the coded computing frameworks by efficiently assigning work for all fast and slow nodes according to their speeds and without needing to re-distribute data. We implement an LSTM-based speed prediction algorithm to predict speeds of compute nodes. We evaluate S2C2 on linear algebraic algorithms, gradient descent, graph ranking, and graph filtering algorithms. We demonstrate 19% to 39% reduction in total computation latency using S2C2 compared to job replication and coded computation. We further show how S2C2 can be applied beyond matrix-vector multiplication.","publicationDate":"2019-11-16T23:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1109/SC.2018.00005","title":"research-article ","type":"bespoKV: application tailored scale-out key-value stores","venue":"SC '18: Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis","authors":["Ali Anwar","Yue Cheng","Hai Huang","Jingoo Han","Hyogi Sim","Dongyoon Lee","Fred Douglis","Ali R. Butt"],"abstract":"Enterprise KV stores are not well suited for HPC applications, and entail customization and cumbersome end-to-end KV design to extract the HPC application needs. To this end, in this paper we present bespoKV, an adaptive, extensible, and scale-out KV store framework. bespoKV decouples the KV store design into the control plane for distributed management and the data plane for local data store. bespoKV takes as input a single-server KV store, called a datalet, and transparently enables a scalable and fault-tolerant distributed KV store service. The resulting distributed stores are also adaptive to consistency or topology requirement changes and can be easily extended for new types of services. Experiments show that bespoKV-enabled distributed KV stores scale horizontally to a large number of nodes, and performs comparably and sometimes better than the state-of-the-art systems.","publicationDate":"2018-11-10T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.5555/3433701.3433790","title":"research-article ","type":"Waiting game: optimally provisioning fixed resources for cloud-enabled schedulers","venue":"SC '20: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","authors":["Pradeep Ambati","Noman Bashir","David Irwin","Prashant Shenoy"],"abstract":"While cloud platforms enable users to rent computing resources on demand to execute their jobs, buying fixed resources is still much cheaper than renting if their utilization is high. Thus, optimizing cloud costs requires users to determine how many fixed resources to buy versus rent based on their workload. In this paper, we introduce the concept of a waiting policy for cloud-enabled schedulers, which is the dual of a scheduling policy, and show that the optimal cost depends on it. We define multiple waiting policies and develop simple analytical models to reveal their tradeoff between fixed resource provisioning, cost, and job waiting time. We evaluate the impact of these waiting policies on a year-long production batch workload consisting of 14M jobs run on a 14.3k-core cluster, and show that a compound waiting policy decreases the cost (by 5%) and mean job waiting time (by 7×) compared to a fixed cluster of the current size.","publicationDate":"2020-11-08T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3415251","title":"research-article ","type":"Hidden Figures: Roles and Pathways of Successful OSS Contributors","venue":"Proceedings of the ACM on Human-Computer Interaction","authors":["Bianca Trinkenreich","Mariam Guizani","Igor Wiese","Anita Sarma","Igor Steinmacher"],"abstract":"Open Source Software (OSS) development is a collaborative endeavor where expert developers, distributed around the globe create software solutions. Given this characteristic, OSS communities have been studied as technical communities, where stakeholders join and evolve in their careers based on their (often voluntary) code contributions to the project. However, the OSS landscape is slowly changing with more people and companies getting involved in OSS. This means that projects now need people in non-technical roles and activities to keep the project sustainable and evolving. In this paper, we focus on understanding the roles and activities that are part of the current OSS landscape and the different career pathways in OSS. By conducting and analyzing 17 interviews with OSS contributors who are well known in the community, we provide empirical evidence of the existence and importance of community-centric roles (e.g advocate, license manager, community founder) in addition to the well-known project-centric ones (e.g maintainer, core member). However, the community-centric roles typically remain hidden, since these roles may not leave traces in software repositories typically analyzed by researchers. We found that people can build a career in OSS through different roles and activities, with different backgrounds, including those not related to writing software. Furthermore, people's career pathways are fluid, moving between project and community-centric roles. Our work highlights that communities and researchers need to take action to acknowledge the importance of these varied roles, making these roles visible and well-recognized, which can ultimately help attract and retain more people in the OSS projects.","publicationDate":"2020-10-13T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3391614.3393659","title":"research-article ","type":"DAX: Data-Driven Audience Experiences in Esports","venue":"IMX '20: ACM International Conference on Interactive Media Experiences","authors":["Athanasios Vasileios Kokkinakis","Simon Demediuk","Isabelle Nölle","Oluseyi Olarewaju","Sagarika Patra","Justus Robertson","Peter York","Alan Pedrassoli Pedrassoli Chitayat","Alistair Coates","Daniel Slawson","Peter Hughes","Nicolas Hardie","Ben Kirman","Jonathan Hook","Anders Drachen","Marian F Ursu","Florian Block"],"abstract":"Esports (competitive videogames) have grown into a global phenomenon with over 450m viewers and a 1.5bn USD market. Esports broadcasts follow a similar structure to traditional sports. However, due to their virtual nature, a large and detailed amount data is available about in-game actions not currently accessible in traditional sport. This provides an opportunity to incorporate novel insights about complex aspects of gameplay into the audience experience – enabling more in-depth coverage for experienced viewers, and increased accessibility for newcomers. Previous research has only explored a limited range of ways data could be incorporated into esports viewing (e.g. data visualizations post-match) and only a few studies have investigated how the presentation of statistics impacts spectators’ experiences and viewing behaviors. We present Weavr, a companion app that allows audiences to consume data-driven insights during and around esports broadcasts. We report on deployments at two major tournaments, that provide ecologically valid findings about how the app’s features were experienced by audiences and their impact on viewing behavior. We discuss implications for the design of second-screen apps for live esports events, and for traditional sports as similar data becomes available for them via improved tracking technologies. ","publicationDate":"2020-06-16T22:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3423211.3426400","title":"research-article ","type":"On Delivery Guarantees in Distributed Content-Based Publish/Subscribe Systems","venue":"Middleware '20: Proceedings of the 21st International Middleware Conference","authors":["Pooya Salehi","Kaiwen Zhang","Hans-Arno Jacobsen"],"abstract":"Distributed overlay-based publish/subscribe systems provide a selective and scalable communication paradigm for connecting components of a distributed application. Existing overlay-based systems only guarantee delivery of notifications to clients that are already known by all brokers in the overlay. Nonetheless, due to the propagation delay, it takes time for a client's interests to be received by all brokers comprising the overlay. The message propagation delay and unclear delivery guarantees during this time increase the complexity of developing distributed applications based on the pub/sub paradigm. In this paper, we propose a collection of message processing and delivery guarantees that allows clients to clearly define the set of publications they receive. Based on our evaluation, these delivery guarantees can reduce buffering requirements on clients by up to 10 times, prevent missing notifications due to the propagation delay, and provide clients with primitive building blocks that simplify application development. We evaluate our proposed routing algorithms and show that a pub/sub system can provide the proposed delivery guarantees without increasing its resource requirements or hindering its throughput.","publicationDate":"2020-12-06T23:00:00.000Z","citationCount":2},{"url":"https://dl.acm.org/doi/10.1145/3448016.3457550","title":"research-article ","type":"Milvus: A Purpose-Built Vector Data Management System","venue":"SIGMOD/PODS '21: Proceedings of the 2021 International Conference on Management of Data","authors":["Jianguo Wang","Xiaomeng Yi","Rentong Guo","Hai Jin","Peng Xu","Shengjun Li","Xiangyu Wang","Xiangzhou Guo","Chengming Li","Xiaohai Xu","Kun Yu","Yuxing Yuan","Yinghao Zou","Jiquan Long","Yudong Cai","Zhenxiang Li","Zhifeng Zhang","Yihua Mo","Jun Gu","Ruiyi Jiang","Yi Wei","Charles Xie"],"abstract":"Recently, there has been a pressing need to manage high-dimensional vector data in data science and AI applications. This trend is fueled by the proliferation of unstructured data and machine learning (ML), where ML models usually transform unstructured data into feature vectors for data analytics, e.g., product recommendation. Existing systems and algorithms for managing vector data have two limitations: (1) They incur serious performance issue when handling large-scale and dynamic vector data; and (2) They provide limited functionalities that cannot meet the requirements of versatile applications.This paper presents Milvus, a purpose-built data management system to efficiently manage large-scale vector data. Milvus supports easy-to-use application interfaces (including SDKs and RESTful APIs); optimizes for the heterogeneous computing platform with modern CPUs and GPUs; enables advanced query processing beyond simple vector similarity search; handles dynamic data for fast updates while ensuring efficient query processing; and distributes data across multiple nodes to achieve scalability and availability. We first describe the design and implementation of Milvus. Then we demonstrate the real-world use cases supported by Milvus. In particular, we build a series of 10 applications (e.g., image/video search, chemical structure analysis, COVID-19 dataset search, personalized recommendation, biological multi-factor authentication, intelligent question answering) on top of Milvus. Finally, we experimentally evaluate Milvus with a wide range of systems including two open source systems (Vearch and Microsoft SPTAG) and three commercial systems. Experiments show that Milvus is up to two orders of magnitude faster than the competitors while providing more functionalities. Now Milvus is deployed by hundreds of organizations worldwide and it is also recognized as an incubation-stage project of the LF AI & Data Foundation. Milvus is open-sourced at https://github.com/milvus-io/milvus.","publicationDate":"2021-06-08T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.14778/3377369.3377370","title":"research-article ","type":"A.M.B.R.O.S.I.A: providing performant virtual resiliency for distributed applications","venue":"Proceedings of the VLDB Endowment","authors":["Jonathan Goldstein","Ahmed Abdelhamid","Mike Barnett","Sebastian Burckhardt","Badrish Chandramouli","Darren Gehring","Niel Lebeck","Christopher Meiklejohn","Umar Farooq Minhas","Ryan Newton","Rahee Ghosh Peshawaria","Tal Zaccai","Irene Zhang"],"abstract":"When writing today's distributed programs, which frequently span both devices and cloud services, programmers are faced with complex decisions and coding tasks around coping with failure, especially when these distributed components are stateful. If their application can be cast as pure data processing, they benefit from the past 40--50 years of work from the database community, which has shown how declarative database systems can completely isolate the developer from the possibility of failure in a performant manner. Unfortunately, while there have been some attempts at bringing similar functionality into the more general distributed programming space, a compelling general-purpose system must handle non-determinism, be performant, support a variety of machine types with varying resiliency goals, and be language agnostic, allowing distributed components written in different languages to communicate. This paper introduces Ambrosia, the first system to satisfy all these requirements. We coin the term \"virtual resiliency\", analogous to virtual memory, for the platform feature which allows failure oblivious code to run in a failure resilient manner. We also introduce novel programming language constructs for resiliently handling non-determinism. Of further interest is the effective reapplication of much database performance optimization technology to make Ambrosia more performant than many of today's non-resilient cloud solutions.","publicationDate":"2019-12-31T23:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3377454","title":"survey ","type":"A Survey on Distributed Machine Learning","venue":"ACM Computing Surveys","authors":["Joost Verbraeken","Matthijs Wolting","Jonathan Katzy","Jeroen Kloppenburg","Tim Verbelen","Jan S. Rellermeyer"],"abstract":"The demand for artificial intelligence has grown significantly over the past decade, and this growth has been fueled by advances in machine learning techniques and the ability to leverage hardware acceleration. However, to increase the quality of predictions and render machine learning solutions feasible for more complex applications, a substantial amount of training data is required. Although small machine learning models can be trained with modest amounts of data, the input for training larger models such as neural networks grows exponentially with the number of parameters. Since the demand for processing training data has outpaced the increase in computation power of computing machinery, there is a need for distributing the machine learning workload across multiple machines, and turning the centralized into a distributed system. These distributed systems present new challenges: first and foremost, the efficient parallelization of the training process and the creation of a coherent model. This article provides an extensive overview of the current state-of-the-art in the field by outlining the challenges and opportunities of distributed machine learning over conventional (centralized) machine learning, discussing the techniques used for distributed machine learning, and providing an overview of the systems that are available.","publicationDate":"2020-03-12T23:00:00.000Z","citationCount":49},{"url":"https://dl.acm.org/doi/10.1145/3342195.3387543","title":"research-article ","type":"State-machine replication for planet-scale systems","venue":"EuroSys '20: Proceedings of the Fifteenth European Conference on Computer Systems","authors":["Vitor Enes","Carlos Baquero","Tuanir França Rezende","Alexey Gotsman","Matthieu Perrin","Pierre Sutra"],"abstract":"Online applications now routinely replicate their data at multiple sites around the world. In this paper we present Atlas, the first state-machine replication protocol tailored for such planet-scale systems. Atlas does not rely on a distinguished leader, so clients enjoy the same quality of service independently of their geographical locations. Furthermore, client-perceived latency improves as we add sites closer to clients. To achieve this, Atlas minimizes the size of its quorums using an observation that concurrent data center failures are rare. It also processes a high percentage of accesses in a single round trip, even when these conflict. We experimentally demonstrate that Atlas consistently outperforms state-of-the-art protocols in planet-scale scenarios. In particular, Atlas is up to two times faster than Flexible Paxos with identical failure assumptions, and more than doubles the performance of Egalitarian Paxos in the YCSB benchmark.","publicationDate":"2020-04-14T22:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3447993.3483273","title":"research-article ","type":"Visage: enabling timely analytics for drone imagery","venue":"MobiCom '21: Proceedings of the 27th Annual International Conference on Mobile Computing and Networking","authors":["Sagar Jha","Youjie Li","Shadi Noghabi","Vaishnavi Ranganathan","Peeyush Kumar","Andrew Nelson","Michael Toelle","Sudipta Sinha","Ranveer Chandra","Anirudh Badam"],"abstract":"Analytics with three-dimensional imagery from drones are driving the next generation of remote monitoring applications. Today, there is an unmet need in providing such analytics in an interactive manner, especially over weak Internet connections, to quickly diagnose and solve problems in the commercial industry space of monitoring assets using drones in remote parts of the world. Existing mechanisms either compromise on the quality of insights by not building 3D images and analyze individual 2D images in isolation, or spend tens of minutes building a 3D image before obtaining and uploading insights. We present Visage, a system that accelerates 3D image analytics by identifying smaller parts of the data that can actually benefit from 3D analytics and prioritizing building, and uploading the localized 3D images for those parts. To achieve this, Visage uses a graph to represent raw 2D images and their relative content overlap, and then identifies the various subgraphs using application knowledge that are good candidates for localized 3D image based insights. We evaluate Visage using data from multiple real deployments and show that it can reduce analytics-latency by up to four orders of magnitude.","publicationDate":"2021-10-24T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3387514.3405885","title":"research-article ","type":"Zero Downtime Release: Disruption-free Load Balancing of a Multi-Billion User Website","venue":"SIGCOMM '20: Proceedings of the Annual conference of the ACM Special Interest Group on Data Communication on the applications, technologies, architectures, and protocols for computer communication","authors":["Usama Naseer","Luca Niccolini","Udip Pant","Alan Frindell","Ranjeeth Dasineni","Theophilus A. Benson"],"abstract":"Modern network infrastructure has evolved into a complex organism to satisfy the performance and availability requirements for the billions of users. Frequent releases such as code upgrades, bug fixes and security updates have become a norm. Millions of globally distributed infrastructure components including servers and load-balancers are restarted frequently from multiple times per-day to per-week. However, every release brings possibilities of disruptions as it can result in reduced cluster capacity, disturb intricate interaction of the components operating at large scales and disrupt the end-users by terminating their connections. The challenge is further complicated by the scale and heterogeneity of supported services and protocols.In this paper, we leverage different components of the end-to-end networking infrastructure to prevent or mask any disruptions in face of releases. Zero Downtime Release is a collection of mechanisms used at Facebook to shield the end-users from any disruptions, preserve the cluster capacity and robustness of the infrastructure when updates are released globally. Our evaluation shows that these mechanisms prevent any significant cluster capacity degradation when a considerable number of productions servers and proxies are restarted and minimizes the disruption for different services (notably TCP, HTTP and publish/subscribe).","publicationDate":"2020-07-29T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3380955","title":"research-article ","type":"Cloud-based Enabling Mechanisms for Container Deployment and Migration at the Network Edge","venue":"ACM Transactions on Internet Technology","authors":["Zakaria Benomar","Francesco Longo","Giovanni Merlino","Antonio Puliafito"],"abstract":"In recent years, a new trend of advanced applications with huge demands in terms of Quality of Service (QoS) is gaining ground. Even though Cloud computing provides mature management facilities with ubiquitous capabilities, novel requirements and workloads, foisted by new services, start to expose its weaknesses. In this context, a new Information and Communication Technologies (ICT) trend aims at pushing computation from the Cloud to be much close as possible to data sources, raising in the evolution of new paradigms namely Fog and Mist computing. Specifically, the Fog computing paradigm exploits powerful nodes such as servers, routers, and cloudlets that are coupled with the end devices or their access networks accordingly; they are ”relatively” close by the data sources. Whereas Mist computing, which is a lightweight form of Fog computing, pushes the resources even closer. Precisely, Mist computing uses particular nodes that could reside within the same network (e.g., Local Area Network (LAN)) as the end-devices. Considering the advancement that the hardware is knowing nowadays, Fog and Mist nodes are seen suitable to provide resources such as processing, storage, and networking in the proximity of data sources; thereby, the requirements of the new services could be met. Together with the Cloud, the Fog and Mist paradigms introduce a stacked architecture for data processing where a data pre-processing could be performed at the Mist level, then offloaded vertically to the upper layers (i.e., Fog nodes or the Cloud). In these circumstances, it is fundamental to build a management system able to provision efficiently the Fog/Mist-based applications. For this purpose, the Operating System (OS)-level virtualization using containerization technologies, considering its light footprint, fits as a suitable solution to provide Fog/Mist services. The industrial-grade Cloud middlewares, such as OpenStack, which is a reference architecture for Infrastructure-as-a-Service solutions, are still far away from incorporating this new trend. This article proposes an OpenStack-based middleware platform through which containers can be deployed/managed at the Fog/Mist levels.","publicationDate":"2020-06-25T22:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3295500.3356152","title":"research-article ","type":"Spread-n-share: improving application performance and cluster throughput with resource-aware job placement","venue":"SC '19: Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","authors":["Xiongchao Tang","Haojie Wang","Xiaosong Ma","Nosayba El-Sayed","Jidong Zhai","Wenguang Chen","Ashraf Aboulnaga"],"abstract":"Traditional batch job schedulers adopt the Compact-n-Exclusive (CE) strategy, packing processes of a parallel job into as few compute nodes as possible. While CE minimizes inter-node network communication, it often brings self-contention among tasks of a resource-intensive application. Recent studies have used virtual containers to balance CPU utilization and memory capacity across physical nodes, but the imbalance in cache and memory bandwidth usage is still under-investigated.In this work, we propose Spread-n-Share (SNS): a new batch scheduling strategy that automatically scales resource-bound applications out onto more nodes to alleviate their performance bottleneck, and co-locate jobs in a resource compatible manner. We implement Uberun, a prototype scheduler to validate SNS, considering shared-cache capacity and memory bandwidth as two types of performance-critical shared resources. Experimental results using 12 diverse cluster workloads show that SNS improves the overall system throughput by 19.8% on average over CE, while achieving an average individual job speedup of 1.8%.","publicationDate":"2019-11-16T23:00:00.000Z","citationCount":3},{"url":"https://dl.acm.org/doi/10.1145/3234151","title":"survey ","type":"Brownout Approach for Adaptive Management of Resources and Applications in Cloud Computing Systems: A Taxonomy and Future Directions","venue":"ACM Computing Surveys","authors":["Minxian Xu","Rajkumar Buyya"],"abstract":"Cloud computing has been regarded as an emerging approach to provisioning resources and managing applications. It provides attractive features, such as an on-demand model, scalability enhancement, and management cost reduction. However, cloud computing systems continue to face problems such as hardware failures, overloads caused by unexpected workloads, or the waste of energy due to inefficient resource utilization, which all result in resource shortages and application issues such as delays or saturation. A paradigm, the brownout, has been applied to handle these issues by adaptively activating or deactivating optional parts of applications or services to manage resource usage in cloud computing system. Brownout has successfully shown that it can avoid overloads due to changes in workload and achieve better load balancing and energy saving effects. This article proposes a taxonomy of the brownout approach for managing resources and applications adaptively in cloud computing systems and carries out a comprehensive survey. It identifies open challenges and offers future research directions.","publicationDate":"2019-01-24T23:00:00.000Z","citationCount":19},{"url":"https://dl.acm.org/doi/10.1145/3183713.3196892","title":"research-article ","type":"DimBoost: Boosting Gradient Boosting Decision Tree to Higher Dimensions","venue":"SIGMOD '18: Proceedings of the 2018 International Conference on Management of Data","authors":["Jiawei Jiang","Bin Cui","Ce Zhang","Fangcheng Fu"],"abstract":"Gradient boosting decision tree (GBDT) is one of the most popular machine learning models widely used in both academia and industry. Although GBDT has been widely supported by existing systems such as XGBoost, LightGBM, and MLlib, one system bottleneck appears when the dimensionality of the data becomes high. As a result, when we tried to support our industrial partner on datasets of the dimension up to 330K, we observed suboptimal performance for all these aforementioned systems. In this paper, we ask \"Can we build a scalable GBDT training system whose performance scales better with respect to dimensionality of the data?\" The first contribution of this paper is a careful investigation of existing systems by developing a performance model with respect to the dimensionality of the data. We find that the collective communication operations in many existing systems only implement the algorithm designed for small messages. By just fixing this problem, we are able to speed up these systems by up to 2X. Our second contribution is a series of optimizations to further optimize the performance of collective communications. These optimizations include a task scheduler, a two-phase split finding method, and low-precision gradient histograms. Our third contribution is a sparsity-aware algorithm to build gradient histograms and a novel index structure to build histograms in parallel. We implement these optimizations in DimBoost and show that it can be 2-9X faster than existing systems.","publicationDate":"2018-05-26T22:00:00.000Z","citationCount":12},{"url":"https://dl.acm.org/doi/10.1145/3180155.3180157","title":"research-article ","type":"A static verification framework for message passing in Go using behavioural types","venue":"ICSE '18: Proceedings of the 40th International Conference on Software Engineering","authors":["Julien Lange","Nicholas Ng","Bernardo Toninho","Nobuko Yoshida"],"abstract":"The Go programming language has been heavily adopted in industry as a language that efficiently combines systems programming with concurrency. Go's concurrency primitives, inspired by process calculi such as CCS and CSP, feature channel-based communication and lightweight threads, providing a distinct means of structuring concurrent software. Despite its popularity, the Go programming ecosystem offers little to no support for guaranteeing the correctness of message-passing concurrent programs.This work proposes a practical verification framework for message passing concurrency in Go by developing a robust static analysis that infers an abstract model of a program's communication behaviour in the form of a behavioural type, a powerful process calculi typing discipline. We make use of our analysis to deploy a model and termination checking based verification of the inferred behavioural type that is suitable for a range of safety and liveness properties of Go programs, providing several improvements over existing approaches. We evaluate our framework and its implementation on publicly available real-world Go code.","publicationDate":"2018-05-26T22:00:00.000Z","citationCount":25},{"url":"https://dl.acm.org/doi/10.1145/3132037","title":"research-article ","type":"Apache REEF: Retainable Evaluator Execution Framework","venue":"ACM Transactions on Computer Systems","authors":["Byung-Gon Chun","Tyson Condie","Yingda Chen","Brian Cho","Andrew Chung","Carlo Curino","Chris Douglas","Matteo Interlandi","Beomyeol Jeon","Joo Seong Jeong","Gyewon Lee","Yunseong Lee","Tony Majestro","Dahlia Malkhi","Sergiy Matusevych","Brandon Myers","Mariia Mykhailova","Shravan Narayanamurthy","Joseph Noor","Raghu Ramakrishnan","Sriram Rao","Russell Sears","Beysim Sezgin","Taegeon Um","Julia Wang","Markus Weimer","Youngseok Yang"],"abstract":"Resource Managers like YARN and Mesos have emerged as a critical layer in the cloud computing system stack, but the developer abstractions for leasing cluster resources and instantiating application logic are very low level. This flexibility comes at a high cost in terms of developer effort, as each application must repeatedly tackle the same challenges (e.g., fault tolerance, task scheduling and coordination) and reimplement common mechanisms (e.g., caching, bulk-data transfers). This article presents REEF, a development framework that provides a control plane for scheduling and coordinating task-level (data-plane) work on cluster resources obtained from a Resource Manager. REEF provides mechanisms that facilitate resource reuse for data caching and state management abstractions that greatly ease the development of elastic data processing pipelines on cloud platforms that support a Resource Manager service. We illustrate the power of REEF by showing applications built atop: a distributed shell application, a machine-learning framework, a distributed in-memory caching system, and a port of the CORFU system. REEF is currently an Apache top-level project that has attracted contributors from several institutions and it is being used to develop several commercial offerings such as the Azure Stream Analytics service.","publicationDate":"2017-10-09T22:00:00.000Z","citationCount":5},{"url":"https://dl.acm.org/doi/10.1145/3386367.3431292","title":"research-article ","type":"Meeting SLOs in cross-platform NFV","venue":"CoNEXT '20: Proceedings of the 16th International Conference on emerging Networking EXperiments and Technologies","authors":["Jane Yen","Jianfeng Wang","Sucha Supittayapornpong","Marcos A. M. Vieira","Ramesh Govindan","Barath Raghavan"],"abstract":"Network Functions (NFs) perform on-path processing of network traffic. ISPs are deploying NF Virtualization (NFV) with software NFs run on commodity servers. ISPs aim to ensure that NF chains, directed acyclic graphs of NFs, do not violate Service Level Objectives (SLOs) promised by the ISP to its customers. To meet SLOs, NFV systems sometimes leverage on-path hardware (such as programmable switches and smart NICs) to accelerate NF execution.Lemur places and executes NF chains across heterogeneous hardware while meeting SLOs. Lemur's novel placement algorithm yields an SLO-satisfying NF placement while weighing many constraints: hardware memory and processing stages, server cores, link capacity, NF profiles, and NF chain interactions. Lemur's metacompiler automatically generates code and rules (in P4, Python, eBPF, C++, and OpenFlow) to stitch cross-platform NF chain execution while also optimizing resource usage. Our experiments show that Lemur is alone among competing strategies in meeting SLOs for canonical NF chains while maximizing marginal throughput (the traffic rate in excess of the service-level objective).","publicationDate":"2020-11-22T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3445814.3446760","title":"research-article ","type":"Switches for HIRE: resource scheduling for data center in-network computing","venue":"ASPLOS 2021: Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems\n\t\t\t\t\n                    Switches for HIRE: Resource Scheduling for Data Center In-Network Computing\n                \n            ","authors":["Marcel Blöcher","Lin Wang","Patrick Eugster","Max Schmidt"],"abstract":"The recent trend towards more programmable switching hardware in data centers opens up new possibilities for distributed applications to leverage in-network computing (INC). Literature so far has largely focused on individual application scenarios of INC, leaving aside the problem of coordinating usage of potentially scarce and heterogeneous switch resources among multiple INC scenarios, applications, and users. The traditional model of resource pools of isolated compute containers does not fit an INC-enabled data center.  This paper describes HIRE, a Holistic INC-aware Resource managEr which allows for server-local and INC resources to be coordinated in a unified manner. HIRE introduces a novel flexible resource (meta-)model to address heterogeneity, resource interchangeability, and non-linear resource requirements, and integrates dependencies between resources and locations in a unified cost model, cast as a min-cost max-flow problem. In absence of prior work, we compare HIRE against variants of state-of-the-art schedulers retrofitted to handle INC requests. Experiments with a workload trace of a 4000 machine cluster show that HIRE makes better use of INC resources by serving 8-30% more INC requests, while at the same time reducing network detours by 20%, and reducing tail placement latency by 50%.","publicationDate":"2021-04-18T22:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3190508.3190557","title":"research-article ","type":"Tableau: a high-throughput and predictable VM scheduler for high-density workloads","venue":"EuroSys '18: Proceedings of the Thirteenth EuroSys Conference","authors":["Manohar Vanga","Arpan Gujarati","Björn B. Brandenburg"],"abstract":"In the increasingly competitive public-cloud marketplace, improving the efficiency of data centers is a major concern. One way to improve efficiency is to consolidate as many VMs onto as few physical cores as possible, provided that performance expectations are not violated. However, as a prerequisite for increased VM densities, the hypervisor's VM scheduler must allocate processor time efficiently and in a timely fashion. As we show in this paper, contemporary VM schedulers leave substantial room for improvements in both regards when facing challenging high-VM-density workloads that frequently trigger the VM scheduler. As root causes, we identify (i) high runtime overheads and (ii) unpredictable scheduling heuristics. To better support high VM densities, we propose Tableau, a VM scheduler that guarantees a minimum processor share and a maximum bound on scheduling delay for every VM in the system. Tableau combines a low-overhead, core-local, table-driven dispatcher with a fast on-demand table-generation procedure (triggered on VM creation/teardown) that employs scheduling techniques typically used in hard real-time systems. In an evaluation of Tableau and three current Xen schedulers on a 16-core Intel Xeon machine, Tableau is shown to improve tail latency (e.g., a 17X reduction in maximum ping latency compared to Credit) and throughput (e.g., 1.6X peak web server throughput compared to RTDS when serving 1 KiB files with a 100 ms SLA).","publicationDate":"2018-04-22T22:00:00.000Z","citationCount":6},{"url":"https://dl.acm.org/doi/10.1145/3204947","title":"survey ","type":"Analytics for the Internet of Things: A Survey","venue":"ACM Computing Surveys","authors":["Eugene Siow","Thanassis Tiropanis","Wendy Hall"],"abstract":"The Internet of Things (IoT) envisions a world-wide, interconnected network of smart physical entities. These physical entities generate a large amount of data in operation, and as the IoT gains momentum in terms of deployment, the combined scale of those data seems destined to continue to grow. Increasingly, applications for the IoT involve analytics. Data analytics is the process of deriving knowledge from data, generating value like actionable insights from them. This article reviews work in the IoT and big data analytics from the perspective of their utility in creating efficient, effective, and innovative applications and services for a wide spectrum of domains. We review the broad vision for the IoT as it is shaped in various communities, examine the application of data analytics across IoT domains, provide a categorisation of analytic approaches, and propose a layered taxonomy from IoT data to analytics. This taxonomy provides us with insights on the appropriateness of analytical techniques, which in turn shapes a survey of enabling technology and infrastructure for IoT analytics. Finally, we look at some tradeoffs for analytics in the IoT that can shape future research.","publicationDate":"2018-07-24T22:00:00.000Z","citationCount":73},{"url":"https://dl.acm.org/doi/10.1145/2901318.2901345","title":"research-article ","type":"Picocenter: supporting long-lived, mostly-idle applications in cloud environments","venue":"EuroSys '16: Proceedings of the Eleventh European Conference on Computer Systems","authors":["Liang Zhang","James Litton","Frank Cangialosi","Theophilus Benson","Dave Levin","Alan Mislove"],"abstract":"Cloud computing has evolved to meet user demands, from arbitrary VMs offered by IaaS to the narrow application interfaces of PaaS. Unfortunately, there exists an intermediate point that is not well met by today's offerings: users who wish to run arbitrary, already available binaries (as opposed to rewriting their own application for a PaaS) yet expect their applications to be long-lived but mostly idle (as opposed to the always-on VM of IaaS). For example, end users who wish to run their own email or DNS server.In this paper, we explore an alternative approach for cloud computation based on a process-like abstraction rather than a virtual machine abstraction, thereby gaining the scalability and efficiency of PaaS along with the generality of IaaS. We present the design of Picocenter, a hosting infrastructure for such applications that enables use of legacy applications. The key technical challenge in Picocenter is enabling fast swapping of applications to and from cloud storage (since, by definition, applications are largely idle, we expect them to spend the majority of their time swapped out). We develop an ActiveSet technique that prefetches the application's predicted memory working set when reviving an application. An evaluation on EC2 demonstrates that using ActiveSet, Picocenter is able to swap in applications in under 250 ms even when they are stored in S3 while swapped out.","publicationDate":"2016-04-17T22:00:00.000Z","citationCount":19},{"url":"https://dl.acm.org/doi/10.1145/3359981","title":"survey ","type":"A Survey of DevOps Concepts and Challenges","venue":"ACM Computing Surveys","authors":["Leonardo Leite","Carla Rocha","Fabio Kon","Dejan Milojicic","Paulo Meirelles"],"abstract":"DevOpsis a collaborative and multidisciplinary organizational effort to automate continuous delivery of new software updates while guaranteeing their correctness and reliability. The present survey investigates and discusses DevOps challenges from the perspective of engineers, managers, and researchers. We review the literature and develop a DevOps conceptual map, correlating the DevOps automation tools with these concepts. We then discuss their practical implications for engineers, managers, and researchers. Finally, we critically explore some of the most relevant DevOps challenges reported by the literature.","publicationDate":"2019-11-13T23:00:00.000Z","citationCount":37},{"url":"https://dl.acm.org/doi/10.1145/3341145","title":"survey ","type":"Machine Learning Methods for Reliable Resource Provisioning in Edge-Cloud Computing: A Survey","venue":"ACM Computing Surveys","authors":["Thang Le Duc","Rafael García Leiva","Paolo Casari","Per-Olov Östberg"],"abstract":"Large-scale software systems are currently designed as distributed entities and deployed in cloud data centers. To overcome the limitations inherent to this type of deployment, applications are increasingly being supplemented with components instantiated closer to the edges of networks—a paradigm known as edge computing. The problem of how to efficiently orchestrate combined edge-cloud applications is, however, incompletely understood, and a wide range of techniques for resource and application management are currently in use.This article investigates the problem of reliable resource provisioning in joint edge-cloud environments, and surveys technologies, mechanisms, and methods that can be used to improve the reliability of distributed applications in diverse and heterogeneous network environments. Due to the complexity of the problem, special emphasis is placed on solutions to the characterization, management, and control of complex distributed applications using machine learning approaches. The survey is structured around a decomposition of the reliable resource provisioning problem into three categories of techniques: workload characterization and prediction, component placement and system consolidation, and application elasticity and remediation. Survey results are presented along with a problem-oriented discussion of the state-of-the-art. A summary of identified challenges and an outline of future research directions are presented to conclude the article.","publicationDate":"2019-09-12T22:00:00.000Z","citationCount":26},{"url":"https://dl.acm.org/doi/10.1145/3150227","title":"survey ","type":"A Systematic Review of Cloud Modeling Languages","venue":"ACM Computing Surveys","authors":["Alexander Bergmayr","Uwe Breitenbücher","Nicolas Ferry","Alessandro Rossini","Arnor Solberg","Manuel Wimmer","Gerti Kappel","Frank Leymann"],"abstract":"Modern cloud computing environments support a relatively high degree of automation in service provisioning, which allows cloud service customers (CSCs) to dynamically acquire services required for deploying cloud applications. Cloud modeling languages (CMLs) have been proposed to address the diversity of features provided by cloud computing environments and support different application scenarios, such as migrating existing applications to the cloud, developing new cloud applications, or optimizing them. There is, however, still much debate in the research community on what a CML is, and what aspects of a cloud application and its target cloud computing environment should be modeled by a CML. Furthermore, the distinction between CMLs on a fine-grain level exposing their modeling concepts is rarely made. In this article, we investigate the diverse features currently provided by existing CMLs. We classify and compare them according to a common framework with the goal to support CSCs in selecting the CML that fits the needs of their application scenario and setting. As a result, not only features of existing CMLs are pointed out for which extensive support is already provided but also in which existing CMLs are deficient, thereby suggesting a research agenda.","publicationDate":"2018-02-18T23:00:00.000Z","citationCount":52},{"url":"https://dl.acm.org/doi/10.1145/3243734.3243858","title":"research-article ","type":"MineSweeper: An In-depth Look into Drive-by Cryptocurrency Mining and Its Defense","venue":"CCS '18: Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security","authors":["Radhesh Krishnan Konoth","Emanuele Vineti","Veelasha Moonsamy","Martina Lindorfer","Christopher Kruegel","Herbert Bos","Giovanni Vigna"],"abstract":"A wave of alternative coins that can be effectively mined without specialized hardware, and a surge in cryptocurrencies' market value has led to the development of cryptocurrency mining ( cryptomining ) services, such as Coinhive, which can be easily integrated into websites to monetize the computational power of their visitors. While legitimate website operators are exploring these services as an alternative to advertisements, they have also drawn the attention of cybercriminals: drive-by mining (also known as cryptojacking ) is a new web-based attack, in which an infected website secretly executes JavaScript code and/or a WebAssembly module in the user's browser to mine cryptocurrencies without her consent. In this paper, we perform a comprehensive analysis on Alexa's Top 1 Million websites to shed light on the prevalence and profitability of this attack. We study the websites affected by drive-by mining to understand the techniques being used to evade detection, and the latest web technologies being exploited to efficiently mine cryptocurrency. As a result of our study, which covers 28 Coinhive-like services that are widely being used by drive-by mining websites, we identified 20 active cryptomining campaigns. Motivated by our findings, we investigate possible countermeasures against this type of attack. We discuss how current blacklisting approaches and heuristics based on CPU usage are insufficient, and present MineSweeper, a novel detection technique that is based on the intrinsic characteristics of cryptomining code, and, thus, is resilient to obfuscation. Our approach could be integrated into browsers to warn users about silent cryptomining when visiting websites that do not ask for their consent.","publicationDate":"2018-10-14T22:00:00.000Z","citationCount":36},{"url":"https://dl.acm.org/doi/book/10.5555/3372496","title":"","type":"","venue":"","authors":[],"abstract":"","publicationDate":null,"citationCount":null},{"url":"https://dl.acm.org/doi/10.1145/3148149","title":"survey ","type":"Auto-Scaling Web Applications in Clouds: A Taxonomy and Survey","venue":"ACM Computing Surveys","authors":["Chenhao Qu","Rodrigo N. Calheiros","Rajkumar Buyya"],"abstract":"Web application providers have been migrating their applications to cloud data centers, attracted by the emerging cloud computing paradigm. One of the appealing features of the cloud is elasticity. It allows cloud users to acquire or release computing resources on demand, which enables web application providers to automatically scale the resources provisioned to their applications without human intervention under a dynamic workload to minimize resource cost while satisfying Quality of Service (QoS) requirements. In this article, we comprehensively analyze the challenges that remain in auto-scaling web applications in clouds and review the developments in this field. We present a taxonomy of auto-scalers according to the identified challenges and key properties. We analyze the surveyed works and map them to the taxonomy to identify the weaknesses in this field. Moreover, based on the analysis, we propose new future directions that can be explored in this area.","publicationDate":"2018-07-12T22:00:00.000Z","citationCount":74},{"url":"https://dl.acm.org/doi/10.1145/3326540","title":"survey ","type":"A Survey on Mobility-Induced Service Migration in the Fog, Edge, and Related Computing Paradigms","venue":"ACM Computing Surveys","authors":["Zeineb Rejiba","Xavier Masip-Bruin","Eva Marín-Tordera"],"abstract":"With the advent of fog and edge computing paradigms, computation capabilities have been moved toward the edge of the network to support the requirements of highly demanding services. To ensure that the quality of such services is still met in the event of users’ mobility, migrating services across different computing nodes becomes essential. Several studies have emerged recently to address service migration in different edge-centric research areas, including fog computing, multi-access edge computing (MEC), cloudlets, and vehicular clouds. Since existing surveys in this area focus on either VM migration in general or migration in a single research field (e.g., MEC), the objective of this survey is to bring together studies from different, yet related, edge-centric research fields while capturing the different facets they addressed. More specifically, we examine the diversity characterizing the landscape of migration scenarios at the edge, present an objective-driven taxonomy of the literature, and highlight contributions that rather focused on architectural design and implementation. Finally, we identify a list of gaps and research opportunities based on the observation of the current state of the literature. One such opportunity lies in joining efforts from both networking and computing research communities to facilitate future research in this area.","publicationDate":"2019-09-12T22:00:00.000Z","citationCount":13},{"url":"https://dl.acm.org/doi/10.1145/3440689","title":"research-article ","type":"AI Tax: The Hidden Cost of AI Data Center Applications","venue":"ACM Transactions on Computer Systems","authors":["Daniel Richins","Dharmisha Doshi","Matthew Blackmore","Aswathy Thulaseedharan Nair","Neha Pathapati","Ankit Patel","Brainard Daguman","Daniel Dobrijalowski","Ramesh Illikkal","Kevin Long","David Zimmerman","Vijay Janapa Reddi"],"abstract":"Artificial intelligence and machine learning are experiencing widespread adoption in industry and academia. This has been driven by rapid advances in the applications and accuracy of AI through increasingly complex algorithms and models; this, in turn, has spurred research into specialized hardware AI accelerators. Given the rapid pace of advances, it is easy to forget that they are often developed and evaluated in a vacuum without considering the full application environment. This article emphasizes the need for a holistic, end-to-end analysis of artificial intelligence (AI) workloads and reveals the “AI tax.” We deploy and characterize Face Recognition in an edge data center. The application is an AI-centric edge video analytics application built using popular open source infrastructure and machine learning (ML) tools. Despite using state-of-the-art AI and ML algorithms, the application relies heavily on pre- and post-processing code. As AI-centric applications benefit from the acceleration promised by accelerators, we find they impose stresses on the hardware and software infrastructure: storage and network bandwidth become major bottlenecks with increasing AI acceleration. By specializing for AI applications, we show that a purpose-built edge data center can be designed for the stresses of accelerated AI at 15% lower TCO than one derived from homogeneous servers and infrastructure.","publicationDate":"2021-03-25T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3371038","title":"tutorial ","type":"Fast Packet Processing with eBPF and XDP: Concepts, Code, Challenges, and Applications","venue":"ACM Computing Surveys","authors":["Marcos A. M. Vieira","Matheus S. Castanho","Racyus D. G. Pacífico","Elerson R. S. Santos","Eduardo P. M. Câmara Júnior","Luiz F. M. Vieira"],"abstract":"Extended Berkeley Packet Filter (eBPF) is an instruction set and an execution environment inside the Linux kernel. It enables modification, interaction, and kernel programmability at runtime. eBPF can be used to program the eXpress Data Path (XDP), a kernel network layer that processes packets closer to the NIC for fast packet processing. Developers can write programs in C or P4 languages and then compile to eBPF instructions, which can be processed by the kernel or by programmable devices (e.g., SmartNICs). Since its introduction in 2014, eBPF has been rapidly adopted by major companies such as Facebook, Cloudflare, and Netronome. Use cases include network monitoring, network traffic manipulation, load balancing, and system profiling. This work aims to present eBPF to an inexpert audience, covering the main theoretical and fundamental aspects of eBPF and XDP, as well as introducing the reader to simple examples to give insight into the general operation and use of both technologies.","publicationDate":"2020-02-04T23:00:00.000Z","citationCount":13},{"url":"https://dl.acm.org/doi/10.1145/3478680","title":"research-article ","type":"Service Computing for Industry 4.0: State of the Art, Challenges, and Research Opportunities","venue":"ACM Computing Surveys","authors":["Frank Siqueira","Joseph G. Davis"],"abstract":"Recent advances in the large-scale adoption of information and communication technologies in manufacturing processes, known as Industry 4.0 or Smart Manufacturing, provide us a window into how the manufacturing sector will evolve in the coming decades. As a result of these initiatives, manufacturing firms have started to integrate a series of emerging technologies into their processes that will change the way products are designed, manufactured, and consumed. This article provides a comprehensive review of how service-oriented computing is being employed to develop the required software infrastructure for Industry 4.0 and identifies the major challenges and research opportunities that ensue. Particular attention is paid to the microservices architecture, which is increasingly recognized as offering a promising approach for developing innovative industrial applications. This literature review is based on the current state of the art on service computing for Industry 4.0 as described in a large corpus of recently published research papers, which helped us to identify and explore a series of challenges and opportunities for the development of this emerging technology frontier, with the goal of facilitating its widespread adoption.","publicationDate":"2021-10-06T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3186266","title":"survey ","type":"Reproducibility in Scientific Computing","venue":"ACM Computing Surveys","authors":["Peter Ivie","Douglas Thain"],"abstract":"Reproducibility is widely considered to be an essential requirement of the scientific process. However, a number of serious concerns have been raised recently, questioning whether today’s computational work is adequately reproducible. In principle, it should be possible to specify a computation to sufficient detail that anyone should be able to reproduce it exactly. But in practice, there are fundamental, technical, and social barriers to doing so. The many objectives and meanings of reproducibility are discussed within the context of scientific computing. Technical barriers to reproducibility are described, extant approaches surveyed, and open areas of research are identified.","publicationDate":"2018-07-15T22:00:00.000Z","citationCount":24},{"url":"https://dl.acm.org/doi/10.1145/3076253","title":"survey ","type":"Data Science: A Comprehensive Overview","venue":"ACM Computing Surveys","authors":["Longbing Cao"],"abstract":"The 21st century has ushered in the age of big data and data economy, in which data DNA, which carries important knowledge, insights, and potential, has become an intrinsic constituent of all data-based organisms. An appropriate understanding of data DNA and its organisms relies on the new field of data science and its keystone, analytics. Although it is widely debated whether big data is only hype and buzz, and data science is still in a very early phase, significant challenges and opportunities are emerging or have been inspired by the research, innovation, business, profession, and education of data science. This article provides a comprehensive survey and tutorial of the fundamental aspects of data science: the evolution from data analysis to data science, the data science concepts, a big picture of the era of data science, the major challenges and directions in data innovation, the nature of data analytics, new industrialization and service opportunities in the data economy, the profession and competency of data education, and the future of data science. This article is the first in the field to draw a comprehensive big picture, in addition to offering rich observations, lessons, and thinking about data science and analytics.","publicationDate":"2017-06-28T22:00:00.000Z","citationCount":115},{"url":"https://dl.acm.org/doi/10.1145/3359246","title":"research-article ","type":"How Computers See Gender: An Evaluation of Gender Classification in Commercial Facial Analysis Services","venue":"Proceedings of the ACM on Human-Computer Interaction","authors":["Morgan Klaus Scheuerman","Jacob M. Paul","Jed R. Brubaker"],"abstract":"Investigations of facial analysis (FA) technologies-such as facial detection and facial recognition-have been central to discussions about Artificial Intelligence's (AI) impact on human beings. Research on automatic gender recognition, the classification of gender by FA technologies, has raised potential concerns around issues of racial and gender bias. In this study, we augment past work with empirical data by conducting a systematic analysis of how gender classification and gender labeling in computer vision services operate when faced with gender diversity. We sought to understand how gender is concretely conceptualized and encoded into commercial facial analysis and image labeling technologies available today. We then conducted a two-phase study: (1) a system analysis of ten commercial FA and image labeling services and (2) an evaluation of five services using a custom dataset of diverse genders using self-labeled Instagram images. Our analysis highlights how gender is codified into both classifiers and data standards. We found that FA services performed consistently worse on transgender individuals and were universally unable to classify non-binary genders. In contrast, image labeling often presented multiple gendered concepts. We also found that user perceptions about gender performance and identity contradict the way gender performance is encoded into the computer vision infrastructure. We discuss our findings from three perspectives of gender identity (self-identity, gender performativity, and demographic identity) and how these perspectives interact across three layers: the classification infrastructure, the third-party applications that make use of that infrastructure, and the individuals who interact with that software. We employ Bowker and Star's concepts of \"torque\" and \"residuality\" to further discuss the social implications of gender classification. We conclude by outlining opportunities for creating more inclusive classification infrastructures and datasets, as well as with implications for policy.","publicationDate":"2019-11-06T23:00:00.000Z","citationCount":30},{"url":"https://dl.acm.org/doi/10.1145/3326066","title":"survey ","type":"Resource Management in Fog/Edge Computing: A Survey on Architectures, Infrastructure, and Algorithms","venue":"ACM Computing Surveys","authors":["Cheol-Ho Hong","Blesson Varghese"],"abstract":"Contrary to using distant and centralized cloud data center resources, employing decentralized resources at the edge of a network for processing data closer to user devices, such as smartphones and tablets, is an upcoming computing paradigm, referred to as fog/edge computing. Fog/edge resources are typically resource-constrained, heterogeneous, and dynamic compared to the cloud, thereby making resource management an important challenge that needs to be addressed. This article reviews publications as early as 1991, with 85% of the publications between 2013 and 2018, to identify and classify the architectures, infrastructure, and underlying algorithms for managing resources in fog/edge computing.","publicationDate":"2019-09-12T22:00:00.000Z","citationCount":85},{"url":"https://dl.acm.org/doi/10.1145/3368036","title":"survey ","type":"Multiple Workflows Scheduling in Multi-tenant Distributed Systems: A Taxonomy and Future Directions","venue":"ACM Computing Surveys","authors":["Muhammad H. Hilman","Maria A. Rodriguez","Rajkumar Buyya"],"abstract":"Workflows are an application model that enables the automated execution of multiple interdependent and interconnected tasks. They are widely used by the scientific community to manage the distributed execution and dataflow of complex simulations and experiments. As the popularity of scientific workflows continue to rise, and their computational requirements continue to increase, the emergence and adoption of multi-tenant computing platforms that offer the execution of these workflows as a service becomes widespread. This article discusses the scheduling and resource provisioning problems particular to this type of platform. It presents a detailed taxonomy and a comprehensive survey of the current literature and identifies future directions to foster research in the field of multiple workflow scheduling in multi-tenant distributed computing systems.","publicationDate":"2020-02-04T23:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3290342","title":"research-article ","type":"Distributed programming using role-parametric session types in go: statically-typed endpoint APIs for dynamically-instantiated communication structures","venue":"Proceedings of the ACM on Programming Languages\n\t\t\t\t\n                    Artifact for Distributed Programming using Role-Parametric Session Types in Go\n                \n            ","authors":["David Castro","Raymond Hu","Sung-Shik Jongmans","Nicholas Ng","Nobuko Yoshida"],"abstract":"This paper presents a framework for the static specification and safe programming of message passing protocols where the number and kinds of participants are dynamically instantiated.  We develop the first theory of distributed multiparty session types (MPST) to support parameterised protocols with indexed roles—our framework statically infers the different kinds of participants induced by a protocol definition as role variants, and produces decoupled endpoint projections of the protocol onto each variant. This enables safe MPST-based programming of the parameterised endpoints in distributed settings: each endpoint can be implemented separately by different programmers, using different techniques (or languages). We prove the decidability of role variant inference and well-formedness checking, and the correctness of projection.  We implement our theory as a toolchain for programming such role-parametric MPST protocols in Go. Our approach is to generate API families of lightweight, protocol- and variant-specific type wrappers for I/O. The APIs ensure a well-typed Go endpoint program (by native Go type checking) will perform only compliant I/O actions w.r.t. the source protocol. We leverage the abstractions of MPST to support the specification and implementation of Go applications involving multiple channels, possibly over mixed transports (e.g., Go channels, TCP), and channel passing via a unified programming interface. We evaluate the applicability and run-time performance of our generated APIs using microbenchmarks and real-world applications.","publicationDate":"2019-01-01T23:00:00.000Z","citationCount":22},{"url":"https://dl.acm.org/doi/10.1145/3342103","title":"survey ","type":"Cloud Pricing Models: Taxonomy, Survey, and Interdisciplinary Challenges","venue":"ACM Computing Surveys","authors":["Caesar Wu","Rajkumar Buyya","Kotagiri Ramamohanarao"],"abstract":"This article provides a systematic review of cloud pricing in an interdisciplinary approach. It examines many historical cases of pricing in practice and tracks down multiple roots of pricing in research. The aim is to help both cloud service provider (CSP) and cloud customers to capture the essence of cloud pricing when they need to make a critical decision either to achieve competitive advantages or to manage cloud resource effectively. Currently, the number of available pricing schemes in the cloud market is overwhelming. It is an intricate issue to understand these schemes and associated pricing models clearly due to involving several domains of knowledge, such as cloud technologies, microeconomics, operations research, and value theory. Some earlier studies have introduced this topic unsystematically. Their approaches inevitably lead to much confusion for many cloud decision-makers. To address their weaknesses, we present a comprehensive taxonomy of cloud pricing, which is driven by a framework of three fundamental pricing strategies that are built on nine cloud pricing categories. These categories can be further mapped onto a total of 60 pricing models. Many of the pricing models have been already adopted by CSPs. Others have been widespread across in other industries. We give descriptions of these model categories and highlight both advantages and disadvantages. Moreover, this article offers an extensive survey of many cloud pricing models that were proposed by many researchers during the past decade. Based on the survey, we identify four trends of cloud pricing and the general direction, which is moving from intrinsic value per physical box to extrinsic value per serverless sandbox. We conclude that hyper-converged cloud resources pool supported by cloud orchestration, virtual machine, Open Application Programming Interface, and serverless sandbox will drive the future of cloud pricing.","publicationDate":"2019-10-15T22:00:00.000Z","citationCount":9},{"url":"https://dl.acm.org/doi/10.1145/3398020","title":"survey ","type":"Orchestrating the Development Lifecycle of Machine Learning-based IoT Applications: A Taxonomy and Survey","venue":"ACM Computing Surveys","authors":["Bin Qian","Jie Su","Zhenyu Wen","Devki Nandan Jha","Yinhao Li","Yu Guan","Deepak Puthal","Philip James","Renyu Yang","Albert Y. Zomaya","Omer Rana","Lizhe Wang","Maciej Koutny","Rajiv Ranjan"],"abstract":"Machine Learning (ML) and Internet of Things (IoT) are complementary advances: ML techniques unlock the potential of IoT with intelligence, and IoT applications increasingly feed data collected by sensors into ML models, thereby employing results to improve their business processes and services. Hence, orchestrating ML pipelines that encompass model training and implication involved in the holistic development lifecycle of an IoT application often leads to complex system integration. This article provides a comprehensive and systematic survey of the development lifecycle of ML-based IoT applications. We outline the core roadmap and taxonomy and subsequently assess and compare existing standard techniques used at individual stages.","publicationDate":"2020-08-02T22:00:00.000Z","citationCount":10},{"url":"https://dl.acm.org/doi/10.1145/3465628","title":"research-article ","type":"Metron: High-performance NFV Service Chaining Even in the Presence of Blackboxes","venue":"ACM Transactions on Computer Systems","authors":["Georgios P. Katsikas","Tom Barbette","Dejan Kostić","JR. Gerald Q. Maguire","Rebecca Steinert"],"abstract":"Deployment of 100Gigabit Ethernet (GbE) links challenges the packet processing limits of commodity hardware used for Network Functions Virtualization (NFV). Moreover, realizing chained network functions (i.e., service chains) necessitates the use of multiple CPU cores, or even multiple servers, to process packets from such high speed links.Our system Metron jointly exploits the underlying network and commodity servers’ resources: (i) to offload part of the packet processing logic to the network, (ii)  by using smart tagging to setup and exploit the affinity of traffic classes, and (iii)  by using tag-based hardware dispatching to carry out the remaining packet processing at the speed of the servers’ cores, with zero inter-core communication. Moreover, Metron transparently integrates, manages, and load balances proprietary “blackboxes” together with Metron service chains.Metron realizes stateful network functions at the speed of 100GbE network cards on a single server, while elastically and rapidly adapting to changing workload volumes. Our experiments demonstrate that Metron service chains can coexist with heterogeneous blackboxes, while still leveraging Metron’s accurate dispatching and load balancing. In summary, Metron has (i)  2.75–8× better efficiency, up to (ii)  4.7× lower latency, and (iii)  7.8× higher throughput than OpenBox, a state-of-the-art NFV system.","publicationDate":"2021-07-07T22:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3122865.3122866","title":"prefatory ","type":"Preface","venue":"Frontiers of Multimedia Research","authors":[],"abstract":"The field of multimedia is dedicated to research and studies that leverage multiple modalities of signals and data in developing intelligent systems and technologies. Be it search engine, recommendation system, streaming service, interactive agent, or collaborative system, multimedia plays a critical role in ensuring full understanding of multimodal sensory signals, robust modeling of user-content interaction, natural and rich communication experience, and scalable system deployment. The goal is to utilize unique contributions from each modality, integrate complementary synergies, and achieve the best performance and novel functions beyond what's separately available in each individual medium. In this community, most contributors also maintain strong activities in other disciplines such as networking, computer vision, human-computer interaction, and machine learning. But the field of multimedia is unique in offering a rich and dynamic forum for researchers from \"traditional\" fields to collaborate and develop new solutions and knowledge that transcend the boundaries of individual disciplines.The field enjoys a long history of vibrant research. For example, the flagship ACM SIGMM Multimedia Conference was established in 1993, celebrating its 25th anniversary this year. The community also has several well-known conferences and journals organized by ACM, IEEE, and other groups, attracting a large number of researchers and practitioners from around the world. However, despite the prolific research activities and outcomes, there has been less effort toward developing books that serve as an introduction to the rich spectrum of topics in this broad field. Most of the few books available today either focus on specific subfields or basic background. There is a lack of tutorial-style materials covering the active topics being pursued by the leading researchers at frontiers of the field.SIGMM launched a new initiative to address this need in 2015, by selecting and inviting 12 rising-star speakers from different subfields of multimedia to deliver plenary tutorial style talks at ACM Multimedia 2015. Each speaker discussed challenges and the state of the art within their prospective research areas in a general manner to the broad community. Topics covered were comprehensive, including multimedia content understanding, multimodal human-human and human-computer interaction, multimedia social media, and multimedia system architecture and deployment. Following the very positive responses to the talks, these rising-star speakers were invited to expand the content covered in their talks to chapters that can be used as reference materials for researchers, students, and practitioners. Each resulting chapter discusses problems, technical challenges, state-of-the-art approaches and performances, open issues, and promising directions for future work. Collectively, the chapters provide an excellent sampling of major topics addressed by the community as a whole. This book, capturing outcomes of such efforts, is well positioned to fill the aforementioned needs by providing tutorial-style reference materials for frontier topics of multimedia.Section 1 of the book includes five chapters that are focused on analysis and understanding of multimedia content. Topics covered range from analysis of video content, audio content, multimodal content about interaction of freestanding conversational groups, and analysis of multimedia data in the encrypted format for preserving privacy on cloud servers, to efficient approximate similarity search techniques for searching over large-scale databases.First, Zuxuan Wu et al. review current research on understanding video content by detecting the classes of actions or events contained in a given video clip and generation of full-sentence captions describing the content in each such video. Unlike previous surveys, this review focuses on solutions based on deep learning, reflecting the recent trend of research in this area. The chapter also gives extensive reviews of the datasets used in state-of-the-art research and benchmarking efforts.Extending the modality from video to audio, in Chapter 2, Gerald Friedland et al. introduce the field of computer audition, aiming to develop the theory behind artificial systems that can extract information from sound. This chapter reviews the research datasets available, appropriate representations needed for audio, and a few challenging problems such as automatic extraction of hierarchical semantic structures from audio content and automatic discovery of high-level semantic concepts from massive audio data and associated metadata.The holy grail of research for the multimedia community is to be able to integrate and fuse information extracted from multiple modalities of data. In Chapter 3, Xavier Alameda-Pineda et al. present an excellent example and emergent research challenges in the application of detecting social interaction among freestanding conversational groups. The chapter includes overviews of research issues, approaches, evaluation of joint estimation of head and body poses using multiPreface modality data (such as wearable sensors and distributed camera networks), and results of detecting dynamic group formation of interacting people.Chapter 4 addresses a novel emerging topic prompted by the popular approach to multimedia analysis using cloud computing servers. When multimedia data is sent to the cloud for storage or processing, there is a risk of privacy breach via unauthorized access by third parties to the content in the cloud. Pradeep Atrey et al. review state-of-the-art methods and open issues for processing multimedia content in the encrypted domain without needing to convert data to the original format. This allows content to stay in its protected form while useful analysis is performed on it.In Chapter 5, Hervée Jeǵou surveys efficient techniques for finding approximate solutions for similarity search, which is of particular interest when searching massive multimedia data like images, videos, and audio recordings. Jeǵou considers various performance factors like query speed, memory requirement, and search accuracy. Multiple frameworks based on locality sensitive hashing (LSH), quantization/ compression, and hybrid combinations are also reviewed in a coherent manner.In Section 2 of the book, the emphasis shifts from content analysis to humancentered aspects of multimedia computing. This new focus goes beyond extraction of semantic information from multimedia data. Instead, the broad research scope incorporates understanding of users and user-content interaction so as to improve effectiveness of multimedia systems in many applications, such as search and recommendation.Under the human-centric theme, Chapter 6, authored by Peng Cui, discusses the evolution of multimedia computing paradigms from the data-centric, to the content-centric, and recently to the human-centric. Cui presents a new framework, called social-sensed multimedia computing, to capture many key issues involved and advances achieved, including understanding of user-content interaction behavior, understanding of user intent, multimedia representation considering user intention, and integration of heterogeneous data sensed on multimedia social networks.Chapter 7 follows the human-centric theme and further moves the focus from processing individual multimedia data streams to processing a large number of heterogeneous streams in different modalities involving a large number of people. Analysis of such massive streams offers the possibility of detecting important situations of society, such as socio-economic affairs, as well as the living environment. Vivek Singh provides an overview of the problem definition, research framework, and the EventShop toolkit he developed for application development in this emerging area.The extension to the human-centric computing paradigm also calls for formal mathematical theories and tools for explaining the phenomena observed, such as the information propagation behaviors and the occurrences of information cascades on social networks. In Chapter 8, Marian-Andrei Rizoiu et al. review stochastic processes such as the Hawkes point process for modeling discrete, interdependent events over continuous time. These are strongly related to patterns corresponding to retweet cascade events on social media. Successful models like these can help researchers understand information dissemination patterns and predict popularity on social media.Interaction between users and content reveals not only the intent of the user (covered in Chapter 6), but also attributes of the content as well as of the user him/herself. Such interaction can be manifested in multiple forms including explicit cues such as visual and verbal expressions, and implicit cues such as eye movement and physiological signals like brain activity and heart rate. Chapter 9 includes a survey by Subramanian Ramanathan et al. on how such implicit user interaction cues can be explored to improve analysis of content (scene understanding) and user (user emotion recognition).To support research and development of emerging multimedia topics discussed above, there is a critical need for new generations of communication and computing systems that take into account the unique requirements of multimedia, such as real-time, high bandwidth, distributiveness, major power consumption, and resource uncertainty. The popular cloud-based computing systems, though prevalent formanyapplications, are not suitable for large-scale multimedia applications such as cloud-based gaming service and animation rendering service.The last section of the book focuses on the systems aspect, covering distinct topics of multimedia fog computing (Chapter 10) and cloud gaming (Chapter 11). Cheng-Hsin Hsu et al. survey the emerging paradigm focused on fog computing, in which computing services are crowdsourced to the edge nodes or even to the client devices on the user end. This offers major potential benefits in terms of low latency, location awareness, scalability, and heterogeneity. However, it also poses many significant challenges in areas such as resource discovery, resource allocation and management, quality of service, and security. Discussion of these challenges, along with recent advances in this area, are presented in Chapter 10.Finally, as a concrete example of large-scale distributed multimedia computing systems, Chapter 11 (by Kuan-Ta Chen et al.) presents a comprehensive survey of cloud gaming, with emphasis on the development of platform and testbed, test scenarios, and evaluation of performance, in order to enhance optimal design of various components of the complex cloud gaming systems. In particular, the chapter overviews extensive research in areas such as open-source platforms, cloud deployment, client design, and communication between gaming servers and clients.The scope of this book is by no means exhaustive or complete. For example, it can be expanded to include other important topics such as (but not limited to) multimedia content generation, multimodal knowledge discovery and representation, multimedia immersive networked environments, and applications in areas like healthcare, learning, and infrastructure. Nonetheless, the comprehensive survey materials already covered in the book provide an excellent foundation for exploring additional topics mentioned above, and many other relevant fields.We would like to give sincere acknowledgment to Dr. Svebor Karaman, who has provided tremendous assistance in communicating with contributors and organizing the content of this book. In addition, Diane Cerra and her team at Morgan & Claypool Publishers have provided valuable guidance and editorial help","publicationDate":"2017-12-18T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3122865.3122869","title":"chapter ","type":"Multimodal analysis of free-standing conversational groups","venue":"Frontiers of Multimedia Research","authors":["Xavier Alameda-Pineda","Elisa Ricci","Nicu Sebe"],"abstract":"\"Free-standing conversational groups\" are what we call the elementary building blocks of social interactions formed in settings when people are standing and congregate in groups. The automatic detection, analysis, and tracking of such structural conversational units captured on camera poses many interesting challenges for the research community. First, although delineating these formations is strongly linked to other behavioral cues such as head and body poses, finding methods that successfully describe and exploit these links is not obvious. Second, the use of visual data is crucial, but when analyzing crowded scenes, one must account for occlusions and low-resolution images. In this regard, the use of other sensing technologies such as wearable devices can facilitate the analysis of social interactions by complementing the visual information. Yet the exploitation of multiple modalities poses other challenges in terms of data synchronization, calibration, and fusion. In this chapter, we discuss recent advances in multimodal social scene analysis, in particular for the detection of conversational groups or F-formations [Kendon 1990]. More precisely, a multimodal joint head and body pose estimator is described and compared to other recent approaches for head and body pose estimation and F-formation detection. Experimental results on the recently published SALSA dataset are reported, they evidence the long road toward a fully automated high-precision social scene analysis framework.","publicationDate":"2017-12-18T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3122865.3122868","title":"chapter ","type":"Audition for multimedia computing","venue":"Frontiers of Multimedia Research","authors":["Gerald Friedland","Paris Smaragdis","Josh McDermott","Bhiksha Raj"],"abstract":"What do the fields of robotics, human-computer interaction, AI, video retrieval, privacy, cybersecurity, Internet of Things, and big data all have in common? They all work with various sources of data: visual, textual, time stamps, links, records. But there is one source of data that has been almost completely ignored by the academic community---sound.Our comprehension of the world relies critically on audition---the ability to perceive and interpret the sounds we hear. Sound is ubiquitous, and is a unique source of information about our environment and the events occurring in it. Just by listening, we can determine whether our child's laughter originated inside or outside our house, how far away they were when they laughed, and whether the window through which the sound passed was open or shut. The ability to derive information about the world from sound is a core aspect of perceptual intelligence.Auditory inferences are often complex and sophisticated despite their routine occurrence. The number of possible inferences is typically not enumerable, and the final interpretation is not merely one of selection from a fixed set. And yet humans perform such inferences effortlessly, based only on sounds captured using two sensors, our ears.Electronic devices can also \"perceive\" sound. Every phone and tablet has at least one microphone, as do most cameras. Any device or space can be equipped with microphones at minimal expense. Indeed, machines can not only \"listen\"; they have potential advantages over humans as listening devices, in that they can communicate and coordinate their experiences in ways that biological systems simply cannot. Collections of devices that can sense sound and communicate with each other could instantiate a single electronic entity that far surpasses humans in its ability to record and process information from sound.And yet machines at present cannot truly hear. Apart from well-developed efforts to recover structure in speech and music, the state of the art in machine hearing is limited to relatively impoverished descriptions of recorded sounds: detecting occurrences of a limited pre-specified set of sound types, and their locations. Although researchers typically envision artificially intelligent agents such as robots to have human-like hearing abilities, at present the rich descriptions and inferences humans can make about sound are entirely beyond the capability of machine systems.In this chapter, we suggest establishing the field of Computer Audition to develop the theory behind artificial systems that extract information from sound. Our objective is to enable computer systems to replicate and exceed human abilities. This chapter describes the challenges of this field.","publicationDate":"2017-12-18T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3122865.3122872","title":"chapter ","type":"Social-sensed multimedia computing","venue":"Frontiers of Multimedia Research","authors":["Peng Cui"],"abstract":"","publicationDate":"2017-12-18T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3122865.3122867","title":"chapter ","type":"Deep learning for video classification and captioning","venue":"Frontiers of Multimedia Research","authors":["Zuxuan Wu","Ting Yao","Yanwei Fu","Yu-Gang Jiang"],"abstract":"","publicationDate":"2017-12-18T23:00:00.000Z","citationCount":18},{"url":"https://dl.acm.org/doi/10.1145/3122865.3122875","title":"chapter ","type":"Utilizing implicit user cues for multimedia analytics","venue":"Frontiers of Multimedia Research","authors":["Subramanian Ramanathan","Syed Omer Gilani","Nicu Sebe"],"abstract":"","publicationDate":"2017-12-18T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3122865.3122874","title":"chapter ","type":"Hawkes processes for events in social media","venue":"Frontiers of Multimedia Research","authors":["Marian-Andrei Rizoiu","Young Lee","Swapnil Mishra","Lexing Xie"],"abstract":"This chapter provides an accessible introduction for point processes, and especially Hawkes processes, for modeling discrete, inter-dependent events over continuous time. We start by reviewing the definitions and key concepts in point processes. We then introduce the Hawkes process and its event intensity function, as well as schemes for event simulation and parameter estimation. We also describe a practical example drawn from social media data---we show how to model retweet cascades using a Hawkes self-exciting process.We present a design of the memory kernel, and results on estimating parameters and predicting popularity. The code and sample event data are available in an online repository.","publicationDate":"2017-12-18T23:00:00.000Z","citationCount":11},{"url":"https://dl.acm.org/doi/10.1145/3122865.3122871","title":"chapter ","type":"Efficient similarity search","venue":"Frontiers of Multimedia Research","authors":["Hervé Jeǵou"],"abstract":"This chapter addresses one of the fundamental problems involved in multimedia systems, namely efficient similarity search for large collections of multimedia content. This problem has received a lot of attention from various research communities. In particular, it is a historical line of research in computational geometry and databases. The computer vision and multimedia communities have adopted pragmatic approaches guided by practical requirements: the large sets of features required to describe image collections make visual search a highly demanding task. As a result, early works [Flickner et al. 1995, Fagin 1998, Beis and Lowe 1997] in image indexing have foreseen the interest in approximate algorithms, especially after the dissemination of methods based on local description in the 90s, as any improvement obtained on this indexing part improves the whole visual search system.Among the existing approximate nearest neighbors (ANN) strategies, the popular framework of Locality-Sensitive Hashing (LSH) [Indyk and Motwani 1998, Gionis et al. 1999] provides theoretical guarantees on the search quality with limited assumptions on the underlying data distribution. It was first proposed [Indyk and Motwani 1998] for the Hamming and l1 spaces, and was later extended to the Euclidean/ cosine cases [Charikar 2002, Datar et al. 2004] or the earth mover's distance [Charikar 2002, Andoni and Indyk 2006]. LSH has been successfully used for local descriptors [Ke et al. 2004], 3D object indexing [Matei et al. 2006, Shakhnarovich et al. 2006], and other fields such as audio retrieval [Casey and Slaney 2007, Ryynanen and Klapuri 2008]. It has also received some attention in a context of private information retrieval [Pathak and Raj 2012, Aghasaryan et al. 2013, Furon et al. 2013].A few years ago, approaches inspired by compression and more specifically quantization-based approaches [Jǵou et al. 2011] were shown to be a viable alternative to hashing methods, and shown successful for efficiently searching in a billion-sized dataset.This chapter discusses these different trends. It is organized as follows. Section 5.1 gives some background references and concepts, including evaluation issues. Most of the methods and variants are exposed within the LSH framework. It is worth mentioning that LSH is more of a concept than a particular algorithm. The search algorithms associated with LSH follow two distinct search mechanisms, the probe-cell model and sketches, which are discussed in Sections 5.2 and 5.3, respectively. Section 5.4 describes methods inspired by compression algorithms, while Section 5.5 discusses hybrid approaches combining the non-exhaustiveness of the cell-probe model with the advantages of sketches or compression-based algorithms. Other metrics than Euclidean and cosine are briefly discussed in Section 5.6.","publicationDate":"2017-12-18T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3122865.3122870","title":"chapter ","type":"Encrypted domain multimedia content analysis","venue":"Frontiers of Multimedia Research","authors":["Pradeep K. Atrey","Ankita Lathey","Abukari M. Yakubu"],"abstract":"","publicationDate":"2017-12-18T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/10.1145/3122865.3122877","title":"chapter ","type":"Cloud gaming","venue":"Frontiers of Multimedia Research","authors":["Kuan-Ta Chen","Wei Cai","Ryan Shea","Chun-Ying Huang","Jiangchuan Liu","Victor C. M. Leung","Cheng-Hsin Hsu"],"abstract":"","publicationDate":"2017-12-18T23:00:00.000Z","citationCount":1},{"url":"https://dl.acm.org/doi/10.1145/3122865.3122873","title":"chapter ","type":"Situation recognition using multimodal data","venue":"Frontiers of Multimedia Research","authors":["Vivek Singh"],"abstract":"","publicationDate":"2017-12-18T23:00:00.000Z","citationCount":0},{"url":"https://dl.acm.org/doi/proceedings/10.1145/2950290","title":"","type":"","venue":"","authors":[],"abstract":"","publicationDate":null,"citationCount":null},{"url":"https://dl.acm.org/doi/proceedings/10.1145/2993236","title":"","type":"","venue":"","authors":[],"abstract":"","publicationDate":null,"citationCount":4.110913172906203e+25},{"url":"https://dl.acm.org/doi/proceedings/10.1145/3308560","title":"","type":"","venue":"","authors":[],"abstract":"","publicationDate":null,"citationCount":5.130000313011e+28}],"arxiv":[],"ieee":[],"scienceDirect":[],"springer":[],"wiley":[]}